2023-05-03 12:35:11,105 - mmseg - INFO - Multi-processing start method is `None`
2023-05-03 12:35:11,107 - mmseg - INFO - OpenCV num_threads is `96
2023-05-03 12:35:11,218 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+e7ed570
------------------------------------------------------------

2023-05-03 12:35:11,218 - mmseg - INFO - Distributed training: False
2023-05-03 12:35:12,190 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1035, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=19,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='CSC',
        CLASSES=('Bicyclist', 'Building', 'Car', 'Column_Pole', 'Fence',
                 'Pedestrian', 'Road', 'Sidewalk', 'SignSymbol', 'Sky',
                 'Tree')),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CamVidDataset'
data_root = 'data/CamVid/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (720, 960)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        img_scale=(960, 720),
        ratio_range=(0.5, 2.5),
        scale_step_size=0.25),
    dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(960, 720),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='train',
        ann_dir='train_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize',
                img_scale=(960, 720),
                ratio_range=(0.5, 2.5),
                scale_step_size=0.25),
            dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.1,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            {
                'backbone.backbone': dict(lr_mult=0.1),
                'backbone.text_encoder': dict(lr_mult=0.0, decay_mult=0.0),
                'backbone.contexts': dict(decay_mult=0.0),
                '.bn.': dict(decay_mult=0.0)
            })))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=200,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19'
gpu_ids = [0]
auto_resume = False

2023-05-03 12:35:12,191 - mmseg - INFO - Set random seed to 432361431, deterministic: False
2023-05-03 12:35:12,197 - mmseg - INFO - Loaded 367 images
2023-05-03 12:35:14,399 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-05-03 12:35:16,198 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.label_texts - torch.Size([11, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.contexts - torch.Size([11, 14, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.text_encoder.positional_embedding - torch.Size([19, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.text_projection - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.token_embedding.weight - torch.Size([49408, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1035, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1035, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-05-03 12:35:16,213 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1035, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1035, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-05-03 12:35:23,095 - mmseg - INFO - Loaded 101 images
2023-05-03 12:35:23,096 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19
2023-05-03 12:35:23,137 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-05-03 12:35:23,138 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-05-03 12:35:23,138 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19 by HardDiskBackend.
2023-05-03 12:36:23,070 - mmseg - INFO - Iter [50/10000]	lr: 2.439e-02, eta: 3:17:27, time: 1.191, data_time: 0.218, memory: 14792, decode.loss_ce: 1.3055, decode.acc_seg: 51.9144, aux_0.loss_ce: 1.2952, aux_0.acc_seg: 43.9531, aux_1.loss_ce: 1.3103, aux_1.acc_seg: 43.8375, aux_2.loss_ce: 0.3377, aux_2.loss_dice: 0.5000, aux_2.acc_seg: 89.0038, aux_3.loss_ce: 0.9860, aux_3.acc_seg: 61.4320, loss: 5.7348
2023-05-03 12:37:08,897 - mmseg - INFO - Iter [100/10000]	lr: 4.906e-02, eta: 2:53:50, time: 0.917, data_time: 0.199, memory: 14792, decode.loss_ce: 0.4673, decode.acc_seg: 81.2999, aux_0.loss_ce: 0.4733, aux_0.acc_seg: 81.7656, aux_1.loss_ce: 0.4999, aux_1.acc_seg: 80.7443, aux_2.loss_ce: 0.1580, aux_2.loss_dice: 0.4720, aux_2.acc_seg: 95.9515, aux_3.loss_ce: 0.4488, aux_3.acc_seg: 82.6261, loss: 2.5193
2023-05-03 12:37:54,847 - mmseg - INFO - Iter [150/10000]	lr: 7.350e-02, eta: 2:45:36, time: 0.919, data_time: 0.193, memory: 14792, decode.loss_ce: 0.3482, decode.acc_seg: 85.5048, aux_0.loss_ce: 0.3594, aux_0.acc_seg: 85.6173, aux_1.loss_ce: 0.3766, aux_1.acc_seg: 84.9640, aux_2.loss_ce: 0.1546, aux_2.loss_dice: 0.3347, aux_2.acc_seg: 95.9384, aux_3.loss_ce: 0.3565, aux_3.acc_seg: 85.6891, loss: 1.9301
2023-05-03 12:38:44,874 - mmseg - INFO - Iter [200/10000]	lr: 9.772e-02, eta: 2:44:25, time: 1.001, data_time: 0.274, memory: 14792, decode.loss_ce: 0.2877, decode.acc_seg: 88.2826, aux_0.loss_ce: 0.2977, aux_0.acc_seg: 88.1480, aux_1.loss_ce: 0.3182, aux_1.acc_seg: 87.3097, aux_2.loss_ce: 0.1415, aux_2.loss_dice: 0.3124, aux_2.acc_seg: 95.9101, aux_3.loss_ce: 0.3015, aux_3.acc_seg: 87.9914, loss: 1.6590
2023-05-03 12:39:31,019 - mmseg - INFO - Iter [250/10000]	lr: 9.776e-02, eta: 2:40:51, time: 0.923, data_time: 0.198, memory: 14792, decode.loss_ce: 0.2287, decode.acc_seg: 90.1361, aux_0.loss_ce: 0.2363, aux_0.acc_seg: 89.9642, aux_1.loss_ce: 0.2543, aux_1.acc_seg: 89.2669, aux_2.loss_ce: 0.1374, aux_2.loss_dice: 0.3003, aux_2.acc_seg: 95.9888, aux_3.loss_ce: 0.2496, aux_3.acc_seg: 89.4725, loss: 1.4066
2023-05-03 12:40:17,198 - mmseg - INFO - Iter [300/10000]	lr: 9.730e-02, eta: 2:38:15, time: 0.924, data_time: 0.199, memory: 14792, decode.loss_ce: 0.2134, decode.acc_seg: 90.7432, aux_0.loss_ce: 0.2232, aux_0.acc_seg: 90.4400, aux_1.loss_ce: 0.2418, aux_1.acc_seg: 89.7035, aux_2.loss_ce: 0.1338, aux_2.loss_dice: 0.2931, aux_2.acc_seg: 96.0733, aux_3.loss_ce: 0.2302, aux_3.acc_seg: 90.1373, loss: 1.3356
2023-05-03 12:41:03,607 - mmseg - INFO - Iter [350/10000]	lr: 9.685e-02, eta: 2:36:16, time: 0.928, data_time: 0.203, memory: 14792, decode.loss_ce: 0.1952, decode.acc_seg: 91.6889, aux_0.loss_ce: 0.2014, aux_0.acc_seg: 91.4602, aux_1.loss_ce: 0.2251, aux_1.acc_seg: 90.6368, aux_2.loss_ce: 0.1350, aux_2.loss_dice: 0.2927, aux_2.acc_seg: 95.9668, aux_3.loss_ce: 0.2171, aux_3.acc_seg: 90.9559, loss: 1.2664
2023-05-03 12:41:52,873 - mmseg - INFO - Iter [400/10000]	lr: 9.640e-02, eta: 2:35:44, time: 0.985, data_time: 0.261, memory: 14792, decode.loss_ce: 0.1839, decode.acc_seg: 91.9455, aux_0.loss_ce: 0.1877, aux_0.acc_seg: 91.7789, aux_1.loss_ce: 0.2117, aux_1.acc_seg: 90.8811, aux_2.loss_ce: 0.1342, aux_2.loss_dice: 0.2877, aux_2.acc_seg: 95.9896, aux_3.loss_ce: 0.2099, aux_3.acc_seg: 91.0717, loss: 1.2151
2023-05-03 12:42:38,557 - mmseg - INFO - Iter [450/10000]	lr: 9.595e-02, eta: 2:33:52, time: 0.914, data_time: 0.194, memory: 14792, decode.loss_ce: 0.1820, decode.acc_seg: 92.0313, aux_0.loss_ce: 0.1870, aux_0.acc_seg: 91.8106, aux_1.loss_ce: 0.2088, aux_1.acc_seg: 91.0756, aux_2.loss_ce: 0.1320, aux_2.loss_dice: 0.2866, aux_2.acc_seg: 96.0548, aux_3.loss_ce: 0.2078, aux_3.acc_seg: 91.1601, loss: 1.2042
2023-05-03 12:43:24,542 - mmseg - INFO - Iter [500/10000]	lr: 9.550e-02, eta: 2:32:19, time: 0.920, data_time: 0.195, memory: 14792, decode.loss_ce: 0.1627, decode.acc_seg: 92.6626, aux_0.loss_ce: 0.1650, aux_0.acc_seg: 92.5241, aux_1.loss_ce: 0.1878, aux_1.acc_seg: 91.6514, aux_2.loss_ce: 0.1310, aux_2.loss_dice: 0.2812, aux_2.acc_seg: 96.0605, aux_3.loss_ce: 0.1865, aux_3.acc_seg: 91.8094, loss: 1.1143
2023-05-03 12:44:10,461 - mmseg - INFO - Iter [550/10000]	lr: 9.505e-02, eta: 2:30:53, time: 0.918, data_time: 0.195, memory: 14792, decode.loss_ce: 0.1633, decode.acc_seg: 92.7161, aux_0.loss_ce: 0.1673, aux_0.acc_seg: 92.4855, aux_1.loss_ce: 0.1880, aux_1.acc_seg: 91.7192, aux_2.loss_ce: 0.1337, aux_2.loss_dice: 0.2849, aux_2.acc_seg: 95.9584, aux_3.loss_ce: 0.1918, aux_3.acc_seg: 91.6909, loss: 1.1290
2023-05-03 12:45:00,277 - mmseg - INFO - Iter [600/10000]	lr: 9.459e-02, eta: 2:30:35, time: 0.996, data_time: 0.270, memory: 14792, decode.loss_ce: 0.1558, decode.acc_seg: 92.9212, aux_0.loss_ce: 0.1577, aux_0.acc_seg: 92.8440, aux_1.loss_ce: 0.1763, aux_1.acc_seg: 92.0785, aux_2.loss_ce: 0.1309, aux_2.loss_dice: 0.2815, aux_2.acc_seg: 96.0536, aux_3.loss_ce: 0.1764, aux_3.acc_seg: 92.2904, loss: 1.0786
2023-05-03 12:45:46,402 - mmseg - INFO - Iter [650/10000]	lr: 9.414e-02, eta: 2:29:19, time: 0.922, data_time: 0.195, memory: 14792, decode.loss_ce: 0.1481, decode.acc_seg: 93.3044, aux_0.loss_ce: 0.1523, aux_0.acc_seg: 93.1177, aux_1.loss_ce: 0.1729, aux_1.acc_seg: 92.2706, aux_2.loss_ce: 0.1310, aux_2.loss_dice: 0.2800, aux_2.acc_seg: 96.0034, aux_3.loss_ce: 0.1757, aux_3.acc_seg: 92.3456, loss: 1.0600
2023-05-03 12:46:32,375 - mmseg - INFO - Iter [700/10000]	lr: 9.369e-02, eta: 2:28:05, time: 0.919, data_time: 0.196, memory: 14792, decode.loss_ce: 0.1314, decode.acc_seg: 93.8683, aux_0.loss_ce: 0.1364, aux_0.acc_seg: 93.6355, aux_1.loss_ce: 0.1547, aux_1.acc_seg: 92.8746, aux_2.loss_ce: 0.1274, aux_2.loss_dice: 0.2752, aux_2.acc_seg: 96.0846, aux_3.loss_ce: 0.1617, aux_3.acc_seg: 92.7701, loss: 0.9868
2023-05-03 12:47:22,186 - mmseg - INFO - Iter [750/10000]	lr: 9.323e-02, eta: 2:27:43, time: 0.996, data_time: 0.270, memory: 14792, decode.loss_ce: 0.1321, decode.acc_seg: 93.9427, aux_0.loss_ce: 0.1369, aux_0.acc_seg: 93.7588, aux_1.loss_ce: 0.1559, aux_1.acc_seg: 92.9155, aux_2.loss_ce: 0.1305, aux_2.loss_dice: 0.2769, aux_2.acc_seg: 95.9639, aux_3.loss_ce: 0.1607, aux_3.acc_seg: 92.9235, loss: 0.9931
2023-05-03 12:48:08,319 - mmseg - INFO - Iter [800/10000]	lr: 9.278e-02, eta: 2:26:34, time: 0.923, data_time: 0.200, memory: 14792, decode.loss_ce: 0.1192, decode.acc_seg: 94.2768, aux_0.loss_ce: 0.1246, aux_0.acc_seg: 94.0449, aux_1.loss_ce: 0.1417, aux_1.acc_seg: 93.2711, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2706, aux_2.acc_seg: 96.1226, aux_3.loss_ce: 0.1477, aux_3.acc_seg: 93.2273, loss: 0.9289
2023-05-03 12:48:53,694 - mmseg - INFO - Iter [850/10000]	lr: 9.233e-02, eta: 2:25:21, time: 0.908, data_time: 0.189, memory: 14792, decode.loss_ce: 0.1312, decode.acc_seg: 93.9484, aux_0.loss_ce: 0.1348, aux_0.acc_seg: 93.7974, aux_1.loss_ce: 0.1527, aux_1.acc_seg: 93.0143, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2748, aux_2.acc_seg: 96.0391, aux_3.loss_ce: 0.1610, aux_3.acc_seg: 92.9220, loss: 0.9825
2023-05-03 12:49:39,523 - mmseg - INFO - Iter [900/10000]	lr: 9.187e-02, eta: 2:24:14, time: 0.917, data_time: 0.195, memory: 14792, decode.loss_ce: 0.1200, decode.acc_seg: 94.3917, aux_0.loss_ce: 0.1254, aux_0.acc_seg: 94.1496, aux_1.loss_ce: 0.1434, aux_1.acc_seg: 93.3444, aux_2.loss_ce: 0.1279, aux_2.loss_dice: 0.2730, aux_2.acc_seg: 95.9938, aux_3.loss_ce: 0.1516, aux_3.acc_seg: 93.1516, loss: 0.9413
2023-05-03 12:50:29,248 - mmseg - INFO - Iter [950/10000]	lr: 9.142e-02, eta: 2:23:48, time: 0.994, data_time: 0.269, memory: 14792, decode.loss_ce: 0.1217, decode.acc_seg: 94.3850, aux_0.loss_ce: 0.1270, aux_0.acc_seg: 94.1783, aux_1.loss_ce: 0.1435, aux_1.acc_seg: 93.4303, aux_2.loss_ce: 0.1285, aux_2.loss_dice: 0.2741, aux_2.acc_seg: 96.0121, aux_3.loss_ce: 0.1518, aux_3.acc_seg: 93.3009, loss: 0.9467
2023-05-03 12:51:14,928 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-05-03 12:51:17,093 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 12:51:17,093 - mmseg - INFO - Iter [1000/10000]	lr: 9.096e-02, eta: 2:23:02, time: 0.958, data_time: 0.193, memory: 14792, decode.loss_ce: 0.1098, decode.acc_seg: 94.7313, aux_0.loss_ce: 0.1134, aux_0.acc_seg: 94.5637, aux_1.loss_ce: 0.1301, aux_1.acc_seg: 93.8036, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2700, aux_2.acc_seg: 96.0205, aux_3.loss_ce: 0.1380, aux_3.acc_seg: 93.6810, loss: 0.8881
2023-05-03 12:51:25,192 - mmseg - INFO - per class results:
2023-05-03 12:51:25,194 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 78.95 | 84.31 |
|   Building  | 93.03 |  96.3 |
|     Car     | 91.93 | 94.52 |
| Column_Pole | 16.23 | 18.47 |
|    Fence    | 78.27 | 93.09 |
|  Pedestrian | 50.07 | 66.78 |
|     Road    | 97.14 | 98.15 |
|   Sidewalk  |  90.0 |  95.8 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 94.36 | 97.43 |
|     Tree    | 93.13 | 97.41 |
+-------------+-------+-------+
2023-05-03 12:51:25,194 - mmseg - INFO - Summary:
2023-05-03 12:51:25,194 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.93 | 71.19 | 76.57 |
+-------+-------+-------+
2023-05-03 12:51:25,195 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 12:51:25,195 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9593, mIoU: 0.7119, mAcc: 0.7657, IoU.Bicyclist: 0.7895, IoU.Building: 0.9303, IoU.Car: 0.9193, IoU.Column_Pole: 0.1623, IoU.Fence: 0.7827, IoU.Pedestrian: 0.5007, IoU.Road: 0.9714, IoU.Sidewalk: 0.9000, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9436, IoU.Tree: 0.9313, Acc.Bicyclist: 0.8431, Acc.Building: 0.9630, Acc.Car: 0.9452, Acc.Column_Pole: 0.1847, Acc.Fence: 0.9309, Acc.Pedestrian: 0.6678, Acc.Road: 0.9815, Acc.Sidewalk: 0.9580, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9743, Acc.Tree: 0.9741
2023-05-03 12:52:10,963 - mmseg - INFO - Iter [1050/10000]	lr: 9.051e-02, eta: 2:23:07, time: 1.077, data_time: 0.351, memory: 14792, decode.loss_ce: 0.1117, decode.acc_seg: 94.7321, aux_0.loss_ce: 0.1156, aux_0.acc_seg: 94.5416, aux_1.loss_ce: 0.1339, aux_1.acc_seg: 93.7190, aux_2.loss_ce: 0.1278, aux_2.loss_dice: 0.2707, aux_2.acc_seg: 95.9691, aux_3.loss_ce: 0.1427, aux_3.acc_seg: 93.5647, loss: 0.9024
2023-05-03 12:52:56,667 - mmseg - INFO - Iter [1100/10000]	lr: 9.005e-02, eta: 2:22:00, time: 0.914, data_time: 0.193, memory: 14792, decode.loss_ce: 0.1150, decode.acc_seg: 94.6585, aux_0.loss_ce: 0.1197, aux_0.acc_seg: 94.4689, aux_1.loss_ce: 0.1364, aux_1.acc_seg: 93.6726, aux_2.loss_ce: 0.1271, aux_2.loss_dice: 0.2718, aux_2.acc_seg: 96.0276, aux_3.loss_ce: 0.1456, aux_3.acc_seg: 93.5606, loss: 0.9157
2023-05-03 12:53:46,444 - mmseg - INFO - Iter [1150/10000]	lr: 8.960e-02, eta: 2:21:27, time: 0.995, data_time: 0.269, memory: 14792, decode.loss_ce: 0.1095, decode.acc_seg: 94.7863, aux_0.loss_ce: 0.1140, aux_0.acc_seg: 94.5926, aux_1.loss_ce: 0.1318, aux_1.acc_seg: 93.7987, aux_2.loss_ce: 0.1266, aux_2.loss_dice: 0.2692, aux_2.acc_seg: 96.0004, aux_3.loss_ce: 0.1420, aux_3.acc_seg: 93.5620, loss: 0.8931
2023-05-03 12:54:32,276 - mmseg - INFO - Iter [1200/10000]	lr: 8.914e-02, eta: 2:20:23, time: 0.917, data_time: 0.195, memory: 14792, decode.loss_ce: 0.1099, decode.acc_seg: 94.8195, aux_0.loss_ce: 0.1144, aux_0.acc_seg: 94.6365, aux_1.loss_ce: 0.1309, aux_1.acc_seg: 93.8874, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2703, aux_2.acc_seg: 95.9465, aux_3.loss_ce: 0.1404, aux_3.acc_seg: 93.7467, loss: 0.8945
2023-05-03 12:55:17,929 - mmseg - INFO - Iter [1250/10000]	lr: 8.869e-02, eta: 2:19:20, time: 0.913, data_time: 0.195, memory: 14792, decode.loss_ce: 0.1069, decode.acc_seg: 94.8395, aux_0.loss_ce: 0.1105, aux_0.acc_seg: 94.6876, aux_1.loss_ce: 0.1285, aux_1.acc_seg: 93.8386, aux_2.loss_ce: 0.1266, aux_2.loss_dice: 0.2701, aux_2.acc_seg: 95.9909, aux_3.loss_ce: 0.1375, aux_3.acc_seg: 93.6459, loss: 0.8801
2023-05-03 12:56:07,607 - mmseg - INFO - Iter [1300/10000]	lr: 8.823e-02, eta: 2:18:45, time: 0.994, data_time: 0.270, memory: 14792, decode.loss_ce: 0.1008, decode.acc_seg: 95.2065, aux_0.loss_ce: 0.1052, aux_0.acc_seg: 95.0094, aux_1.loss_ce: 0.1223, aux_1.acc_seg: 94.2064, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2691, aux_2.acc_seg: 96.0000, aux_3.loss_ce: 0.1334, aux_3.acc_seg: 93.9745, loss: 0.8573
2023-05-03 12:56:52,951 - mmseg - INFO - Iter [1350/10000]	lr: 8.777e-02, eta: 2:17:41, time: 0.907, data_time: 0.190, memory: 14792, decode.loss_ce: 0.1009, decode.acc_seg: 95.1683, aux_0.loss_ce: 0.1053, aux_0.acc_seg: 94.9962, aux_1.loss_ce: 0.1222, aux_1.acc_seg: 94.1922, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2682, aux_2.acc_seg: 96.0102, aux_3.loss_ce: 0.1331, aux_3.acc_seg: 93.9259, loss: 0.8558
2023-05-03 12:57:38,116 - mmseg - INFO - Iter [1400/10000]	lr: 8.732e-02, eta: 2:16:38, time: 0.903, data_time: 0.189, memory: 14792, decode.loss_ce: 0.0993, decode.acc_seg: 95.2826, aux_0.loss_ce: 0.1036, aux_0.acc_seg: 95.0821, aux_1.loss_ce: 0.1206, aux_1.acc_seg: 94.2943, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2688, aux_2.acc_seg: 95.9621, aux_3.loss_ce: 0.1304, aux_3.acc_seg: 94.1053, loss: 0.8498
2023-05-03 12:58:23,340 - mmseg - INFO - Iter [1450/10000]	lr: 8.686e-02, eta: 2:15:35, time: 0.904, data_time: 0.191, memory: 14792, decode.loss_ce: 0.0997, decode.acc_seg: 95.0851, aux_0.loss_ce: 0.1041, aux_0.acc_seg: 94.9143, aux_1.loss_ce: 0.1196, aux_1.acc_seg: 94.1210, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2652, aux_2.acc_seg: 96.0056, aux_3.loss_ce: 0.1307, aux_3.acc_seg: 93.8047, loss: 0.8440
2023-05-03 12:59:12,571 - mmseg - INFO - Iter [1500/10000]	lr: 8.640e-02, eta: 2:14:57, time: 0.985, data_time: 0.265, memory: 14792, decode.loss_ce: 0.0972, decode.acc_seg: 95.3269, aux_0.loss_ce: 0.1007, aux_0.acc_seg: 95.1714, aux_1.loss_ce: 0.1169, aux_1.acc_seg: 94.3894, aux_2.loss_ce: 0.1253, aux_2.loss_dice: 0.2672, aux_2.acc_seg: 96.0155, aux_3.loss_ce: 0.1276, aux_3.acc_seg: 94.1644, loss: 0.8350
2023-05-03 12:59:58,584 - mmseg - INFO - Iter [1550/10000]	lr: 8.594e-02, eta: 2:14:01, time: 0.920, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0964, decode.acc_seg: 95.2880, aux_0.loss_ce: 0.0999, aux_0.acc_seg: 95.1574, aux_1.loss_ce: 0.1166, aux_1.acc_seg: 94.3452, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2660, aux_2.acc_seg: 96.0393, aux_3.loss_ce: 0.1265, aux_3.acc_seg: 94.1367, loss: 0.8301
2023-05-03 13:00:44,465 - mmseg - INFO - Iter [1600/10000]	lr: 8.549e-02, eta: 2:13:04, time: 0.918, data_time: 0.197, memory: 14792, decode.loss_ce: 0.0939, decode.acc_seg: 95.4136, aux_0.loss_ce: 0.0973, aux_0.acc_seg: 95.2716, aux_1.loss_ce: 0.1135, aux_1.acc_seg: 94.4720, aux_2.loss_ce: 0.1234, aux_2.loss_dice: 0.2652, aux_2.acc_seg: 96.0614, aux_3.loss_ce: 0.1234, aux_3.acc_seg: 94.2836, loss: 0.8167
2023-05-03 13:01:30,400 - mmseg - INFO - Iter [1650/10000]	lr: 8.503e-02, eta: 2:12:09, time: 0.919, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0932, decode.acc_seg: 95.4544, aux_0.loss_ce: 0.0969, aux_0.acc_seg: 95.3123, aux_1.loss_ce: 0.1131, aux_1.acc_seg: 94.5114, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2662, aux_2.acc_seg: 95.9750, aux_3.loss_ce: 0.1247, aux_3.acc_seg: 94.2435, loss: 0.8198
2023-05-03 13:02:20,064 - mmseg - INFO - Iter [1700/10000]	lr: 8.457e-02, eta: 2:11:32, time: 0.993, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0933, decode.acc_seg: 95.3355, aux_0.loss_ce: 0.0972, aux_0.acc_seg: 95.1878, aux_1.loss_ce: 0.1125, aux_1.acc_seg: 94.4321, aux_2.loss_ce: 0.1222, aux_2.loss_dice: 0.2617, aux_2.acc_seg: 96.0680, aux_3.loss_ce: 0.1228, aux_3.acc_seg: 94.1606, loss: 0.8097
2023-05-03 13:03:05,702 - mmseg - INFO - Iter [1750/10000]	lr: 8.411e-02, eta: 2:10:35, time: 0.913, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0947, decode.acc_seg: 95.2904, aux_0.loss_ce: 0.0985, aux_0.acc_seg: 95.1519, aux_1.loss_ce: 0.1144, aux_1.acc_seg: 94.3620, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2645, aux_2.acc_seg: 96.0098, aux_3.loss_ce: 0.1233, aux_3.acc_seg: 94.2011, loss: 0.8193
2023-05-03 13:03:51,955 - mmseg - INFO - Iter [1800/10000]	lr: 8.365e-02, eta: 2:09:42, time: 0.925, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0989, decode.acc_seg: 95.2241, aux_0.loss_ce: 0.1030, aux_0.acc_seg: 95.0632, aux_1.loss_ce: 0.1195, aux_1.acc_seg: 94.2808, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2646, aux_2.acc_seg: 96.0283, aux_3.loss_ce: 0.1303, aux_3.acc_seg: 94.0385, loss: 0.8407
2023-05-03 13:04:41,059 - mmseg - INFO - Iter [1850/10000]	lr: 8.319e-02, eta: 2:09:02, time: 0.982, data_time: 0.261, memory: 14792, decode.loss_ce: 0.0899, decode.acc_seg: 95.5671, aux_0.loss_ce: 0.0941, aux_0.acc_seg: 95.4037, aux_1.loss_ce: 0.1097, aux_1.acc_seg: 94.6076, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 96.0581, aux_3.loss_ce: 0.1214, aux_3.acc_seg: 94.3283, loss: 0.8023
2023-05-03 13:05:26,862 - mmseg - INFO - Iter [1900/10000]	lr: 8.273e-02, eta: 2:08:07, time: 0.916, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0906, decode.acc_seg: 95.5708, aux_0.loss_ce: 0.0947, aux_0.acc_seg: 95.4257, aux_1.loss_ce: 0.1103, aux_1.acc_seg: 94.6404, aux_2.loss_ce: 0.1227, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 96.0656, aux_3.loss_ce: 0.1216, aux_3.acc_seg: 94.3407, loss: 0.8033
2023-05-03 13:06:12,209 - mmseg - INFO - Iter [1950/10000]	lr: 8.227e-02, eta: 2:07:11, time: 0.907, data_time: 0.193, memory: 14792, decode.loss_ce: 0.0922, decode.acc_seg: 95.4426, aux_0.loss_ce: 0.0954, aux_0.acc_seg: 95.3195, aux_1.loss_ce: 0.1115, aux_1.acc_seg: 94.5092, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2643, aux_2.acc_seg: 95.9755, aux_3.loss_ce: 0.1223, aux_3.acc_seg: 94.2296, loss: 0.8107
2023-05-03 13:06:57,688 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-05-03 13:06:59,988 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:06:59,988 - mmseg - INFO - Iter [2000/10000]	lr: 8.181e-02, eta: 2:06:25, time: 0.956, data_time: 0.193, memory: 14792, decode.loss_ce: 0.0870, decode.acc_seg: 95.7941, aux_0.loss_ce: 0.0911, aux_0.acc_seg: 95.6458, aux_1.loss_ce: 0.1068, aux_1.acc_seg: 94.8777, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2641, aux_2.acc_seg: 95.9131, aux_3.loss_ce: 0.1193, aux_3.acc_seg: 94.5380, loss: 0.7938
2023-05-03 13:07:06,804 - mmseg - INFO - per class results:
2023-05-03 13:07:06,806 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.26 | 87.85 |
|   Building  | 93.42 | 96.27 |
|     Car     | 92.97 | 94.64 |
| Column_Pole | 22.02 | 25.95 |
|    Fence    | 74.77 | 81.28 |
|  Pedestrian | 55.96 |  79.3 |
|     Road    | 97.19 | 98.01 |
|   Sidewalk  | 90.44 | 96.23 |
|  SignSymbol |  0.05 |  0.05 |
|     Sky     | 94.27 | 97.16 |
|     Tree    | 91.55 |  98.4 |
+-------------+-------+-------+
2023-05-03 13:07:06,806 - mmseg - INFO - Summary:
2023-05-03 13:07:06,806 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 95.9 | 72.26 | 77.74 |
+------+-------+-------+
2023-05-03 13:07:06,806 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:07:06,806 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9590, mIoU: 0.7226, mAcc: 0.7774, IoU.Bicyclist: 0.8226, IoU.Building: 0.9342, IoU.Car: 0.9297, IoU.Column_Pole: 0.2202, IoU.Fence: 0.7477, IoU.Pedestrian: 0.5596, IoU.Road: 0.9719, IoU.Sidewalk: 0.9044, IoU.SignSymbol: 0.0005, IoU.Sky: 0.9427, IoU.Tree: 0.9155, Acc.Bicyclist: 0.8785, Acc.Building: 0.9627, Acc.Car: 0.9464, Acc.Column_Pole: 0.2595, Acc.Fence: 0.8128, Acc.Pedestrian: 0.7930, Acc.Road: 0.9801, Acc.Sidewalk: 0.9623, Acc.SignSymbol: 0.0005, Acc.Sky: 0.9716, Acc.Tree: 0.9840
2023-05-03 13:07:56,139 - mmseg - INFO - Iter [2050/10000]	lr: 8.135e-02, eta: 2:06:12, time: 1.122, data_time: 0.405, memory: 14792, decode.loss_ce: 0.0824, decode.acc_seg: 95.8677, aux_0.loss_ce: 0.0859, aux_0.acc_seg: 95.7308, aux_1.loss_ce: 0.1009, aux_1.acc_seg: 94.9554, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 96.1293, aux_3.loss_ce: 0.1141, aux_3.acc_seg: 94.5591, loss: 0.7647
2023-05-03 13:08:41,679 - mmseg - INFO - Iter [2100/10000]	lr: 8.089e-02, eta: 2:05:16, time: 0.911, data_time: 0.193, memory: 14792, decode.loss_ce: 0.0899, decode.acc_seg: 95.6129, aux_0.loss_ce: 0.0935, aux_0.acc_seg: 95.4851, aux_1.loss_ce: 0.1093, aux_1.acc_seg: 94.7061, aux_2.loss_ce: 0.1231, aux_2.loss_dice: 0.2637, aux_2.acc_seg: 96.0532, aux_3.loss_ce: 0.1204, aux_3.acc_seg: 94.4159, loss: 0.7998
2023-05-03 13:09:27,592 - mmseg - INFO - Iter [2150/10000]	lr: 8.043e-02, eta: 2:04:23, time: 0.918, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0861, decode.acc_seg: 95.7077, aux_0.loss_ce: 0.0895, aux_0.acc_seg: 95.5817, aux_1.loss_ce: 0.1039, aux_1.acc_seg: 94.8441, aux_2.loss_ce: 0.1225, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 96.0379, aux_3.loss_ce: 0.1165, aux_3.acc_seg: 94.4445, loss: 0.7798
2023-05-03 13:10:13,291 - mmseg - INFO - Iter [2200/10000]	lr: 7.997e-02, eta: 2:03:29, time: 0.914, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0915, decode.acc_seg: 95.4626, aux_0.loss_ce: 0.0942, aux_0.acc_seg: 95.3646, aux_1.loss_ce: 0.1103, aux_1.acc_seg: 94.5414, aux_2.loss_ce: 0.1231, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 96.0019, aux_3.loss_ce: 0.1200, aux_3.acc_seg: 94.3043, loss: 0.8014
2023-05-03 13:11:02,211 - mmseg - INFO - Iter [2250/10000]	lr: 7.951e-02, eta: 2:02:46, time: 0.978, data_time: 0.263, memory: 14792, decode.loss_ce: 0.1015, decode.acc_seg: 95.1043, aux_0.loss_ce: 0.1052, aux_0.acc_seg: 94.9705, aux_1.loss_ce: 0.1206, aux_1.acc_seg: 94.1673, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 96.0011, aux_3.loss_ce: 0.1283, aux_3.acc_seg: 94.0373, loss: 0.8433
2023-05-03 13:11:47,750 - mmseg - INFO - Iter [2300/10000]	lr: 7.905e-02, eta: 2:01:52, time: 0.911, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0925, decode.acc_seg: 95.4478, aux_0.loss_ce: 0.0958, aux_0.acc_seg: 95.3215, aux_1.loss_ce: 0.1113, aux_1.acc_seg: 94.5210, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.9796, aux_3.loss_ce: 0.1219, aux_3.acc_seg: 94.2802, loss: 0.8096
2023-05-03 13:12:32,783 - mmseg - INFO - Iter [2350/10000]	lr: 7.859e-02, eta: 2:00:56, time: 0.901, data_time: 0.188, memory: 14792, decode.loss_ce: 0.0867, decode.acc_seg: 95.6873, aux_0.loss_ce: 0.0895, aux_0.acc_seg: 95.5848, aux_1.loss_ce: 0.1045, aux_1.acc_seg: 94.8265, aux_2.loss_ce: 0.1236, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 96.0115, aux_3.loss_ce: 0.1169, aux_3.acc_seg: 94.4834, loss: 0.7817
2023-05-03 13:13:21,803 - mmseg - INFO - Iter [2400/10000]	lr: 7.812e-02, eta: 2:00:14, time: 0.980, data_time: 0.264, memory: 14792, decode.loss_ce: 0.0861, decode.acc_seg: 95.7714, aux_0.loss_ce: 0.0896, aux_0.acc_seg: 95.6572, aux_1.loss_ce: 0.1049, aux_1.acc_seg: 94.8743, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 95.9664, aux_3.loss_ce: 0.1171, aux_3.acc_seg: 94.5674, loss: 0.7857
2023-05-03 13:14:07,652 - mmseg - INFO - Iter [2450/10000]	lr: 7.766e-02, eta: 1:59:21, time: 0.917, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0869, decode.acc_seg: 95.7366, aux_0.loss_ce: 0.0898, aux_0.acc_seg: 95.6403, aux_1.loss_ce: 0.1041, aux_1.acc_seg: 94.8749, aux_2.loss_ce: 0.1233, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 96.0426, aux_3.loss_ce: 0.1170, aux_3.acc_seg: 94.5100, loss: 0.7833
2023-05-03 13:14:53,840 - mmseg - INFO - Iter [2500/10000]	lr: 7.720e-02, eta: 1:58:30, time: 0.924, data_time: 0.203, memory: 14792, decode.loss_ce: 0.0910, decode.acc_seg: 95.4082, aux_0.loss_ce: 0.0947, aux_0.acc_seg: 95.2799, aux_1.loss_ce: 0.1095, aux_1.acc_seg: 94.5174, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 96.0193, aux_3.loss_ce: 0.1219, aux_3.acc_seg: 94.2192, loss: 0.8020
2023-05-03 13:15:39,459 - mmseg - INFO - Iter [2550/10000]	lr: 7.674e-02, eta: 1:57:38, time: 0.912, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0891, decode.acc_seg: 95.6321, aux_0.loss_ce: 0.0922, aux_0.acc_seg: 95.5396, aux_1.loss_ce: 0.1060, aux_1.acc_seg: 94.8089, aux_2.loss_ce: 0.1213, aux_2.loss_dice: 0.2602, aux_2.acc_seg: 96.0640, aux_3.loss_ce: 0.1162, aux_3.acc_seg: 94.5326, loss: 0.7849
2023-05-03 13:16:28,773 - mmseg - INFO - Iter [2600/10000]	lr: 7.627e-02, eta: 1:56:56, time: 0.986, data_time: 0.268, memory: 14792, decode.loss_ce: 0.0855, decode.acc_seg: 95.7470, aux_0.loss_ce: 0.0884, aux_0.acc_seg: 95.6479, aux_1.loss_ce: 0.1035, aux_1.acc_seg: 94.8467, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 96.0463, aux_3.loss_ce: 0.1150, aux_3.acc_seg: 94.5338, loss: 0.7743
2023-05-03 13:17:14,776 - mmseg - INFO - Iter [2650/10000]	lr: 7.581e-02, eta: 1:56:05, time: 0.920, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0857, decode.acc_seg: 95.8426, aux_0.loss_ce: 0.0886, aux_0.acc_seg: 95.7468, aux_1.loss_ce: 0.1039, aux_1.acc_seg: 94.9815, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.9240, aux_3.loss_ce: 0.1182, aux_3.acc_seg: 94.5321, loss: 0.7861
2023-05-03 13:18:00,315 - mmseg - INFO - Iter [2700/10000]	lr: 7.534e-02, eta: 1:55:12, time: 0.911, data_time: 0.192, memory: 14792, decode.loss_ce: 0.0829, decode.acc_seg: 95.8403, aux_0.loss_ce: 0.0856, aux_0.acc_seg: 95.7570, aux_1.loss_ce: 0.0998, aux_1.acc_seg: 95.0176, aux_2.loss_ce: 0.1210, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 96.0725, aux_3.loss_ce: 0.1143, aux_3.acc_seg: 94.5744, loss: 0.7627
2023-05-03 13:18:45,881 - mmseg - INFO - Iter [2750/10000]	lr: 7.488e-02, eta: 1:54:20, time: 0.911, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0786, decode.acc_seg: 96.0110, aux_0.loss_ce: 0.0808, aux_0.acc_seg: 95.9557, aux_1.loss_ce: 0.0954, aux_1.acc_seg: 95.1929, aux_2.loss_ce: 0.1224, aux_2.loss_dice: 0.2589, aux_2.acc_seg: 96.0212, aux_3.loss_ce: 0.1100, aux_3.acc_seg: 94.7746, loss: 0.7461
2023-05-03 13:19:35,240 - mmseg - INFO - Iter [2800/10000]	lr: 7.441e-02, eta: 1:53:38, time: 0.987, data_time: 0.269, memory: 14792, decode.loss_ce: 0.0864, decode.acc_seg: 95.7523, aux_0.loss_ce: 0.0889, aux_0.acc_seg: 95.6777, aux_1.loss_ce: 0.1032, aux_1.acc_seg: 94.9403, aux_2.loss_ce: 0.1234, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 96.0211, aux_3.loss_ce: 0.1146, aux_3.acc_seg: 94.5894, loss: 0.7769
2023-05-03 13:20:21,080 - mmseg - INFO - Iter [2850/10000]	lr: 7.395e-02, eta: 1:52:47, time: 0.917, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0774, decode.acc_seg: 96.0170, aux_0.loss_ce: 0.0797, aux_0.acc_seg: 95.9472, aux_1.loss_ce: 0.0938, aux_1.acc_seg: 95.1945, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2566, aux_2.acc_seg: 96.0896, aux_3.loss_ce: 0.1056, aux_3.acc_seg: 94.8398, loss: 0.7325
2023-05-03 13:21:07,135 - mmseg - INFO - Iter [2900/10000]	lr: 7.348e-02, eta: 1:51:56, time: 0.921, data_time: 0.203, memory: 14792, decode.loss_ce: 0.0814, decode.acc_seg: 95.9140, aux_0.loss_ce: 0.0839, aux_0.acc_seg: 95.8320, aux_1.loss_ce: 0.0980, aux_1.acc_seg: 95.0757, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.9647, aux_3.loss_ce: 0.1122, aux_3.acc_seg: 94.6466, loss: 0.7596
2023-05-03 13:21:55,852 - mmseg - INFO - Iter [2950/10000]	lr: 7.302e-02, eta: 1:51:13, time: 0.974, data_time: 0.261, memory: 14792, decode.loss_ce: 0.0752, decode.acc_seg: 96.1559, aux_0.loss_ce: 0.0782, aux_0.acc_seg: 96.0485, aux_1.loss_ce: 0.0928, aux_1.acc_seg: 95.2931, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2568, aux_2.acc_seg: 96.0354, aux_3.loss_ce: 0.1074, aux_3.acc_seg: 94.8071, loss: 0.7310
2023-05-03 13:22:40,982 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-05-03 13:22:42,769 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:22:42,769 - mmseg - INFO - Iter [3000/10000]	lr: 7.255e-02, eta: 1:50:24, time: 0.939, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0764, decode.acc_seg: 96.0338, aux_0.loss_ce: 0.0788, aux_0.acc_seg: 95.9468, aux_1.loss_ce: 0.0931, aux_1.acc_seg: 95.1936, aux_2.loss_ce: 0.1211, aux_2.loss_dice: 0.2584, aux_2.acc_seg: 96.0616, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 94.7651, loss: 0.7342
2023-05-03 13:22:48,673 - mmseg - INFO - per class results:
2023-05-03 13:22:48,674 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 84.52 | 95.66 |
|   Building  | 93.37 | 95.11 |
|     Car     | 92.53 |  94.1 |
| Column_Pole | 24.16 | 28.69 |
|    Fence    | 79.06 | 88.06 |
|  Pedestrian | 67.06 | 84.03 |
|     Road    | 97.15 | 97.74 |
|   Sidewalk  | 91.06 | 97.63 |
|  SignSymbol |  0.58 |  0.58 |
|     Sky     | 93.57 | 96.01 |
|     Tree    | 91.36 | 98.69 |
+-------------+-------+-------+
2023-05-03 13:22:48,674 - mmseg - INFO - Summary:
2023-05-03 13:22:48,674 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.03 | 74.04 | 79.66 |
+-------+-------+-------+
2023-05-03 13:22:48,674 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:22:48,675 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9603, mIoU: 0.7404, mAcc: 0.7966, IoU.Bicyclist: 0.8452, IoU.Building: 0.9337, IoU.Car: 0.9253, IoU.Column_Pole: 0.2416, IoU.Fence: 0.7906, IoU.Pedestrian: 0.6706, IoU.Road: 0.9715, IoU.Sidewalk: 0.9106, IoU.SignSymbol: 0.0058, IoU.Sky: 0.9357, IoU.Tree: 0.9136, Acc.Bicyclist: 0.9566, Acc.Building: 0.9511, Acc.Car: 0.9410, Acc.Column_Pole: 0.2869, Acc.Fence: 0.8806, Acc.Pedestrian: 0.8403, Acc.Road: 0.9774, Acc.Sidewalk: 0.9763, Acc.SignSymbol: 0.0058, Acc.Sky: 0.9601, Acc.Tree: 0.9869
2023-05-03 13:23:34,378 - mmseg - INFO - Iter [3050/10000]	lr: 7.208e-02, eta: 1:49:47, time: 1.032, data_time: 0.317, memory: 14792, decode.loss_ce: 0.0738, decode.acc_seg: 96.2055, aux_0.loss_ce: 0.0762, aux_0.acc_seg: 96.1436, aux_1.loss_ce: 0.0902, aux_1.acc_seg: 95.4086, aux_2.loss_ce: 0.1206, aux_2.loss_dice: 0.2580, aux_2.acc_seg: 96.0746, aux_3.loss_ce: 0.1045, aux_3.acc_seg: 94.9454, loss: 0.7234
2023-05-03 13:24:19,250 - mmseg - INFO - Iter [3100/10000]	lr: 7.162e-02, eta: 1:48:54, time: 0.897, data_time: 0.189, memory: 14792, decode.loss_ce: 0.0757, decode.acc_seg: 96.2175, aux_0.loss_ce: 0.0785, aux_0.acc_seg: 96.1236, aux_1.loss_ce: 0.0927, aux_1.acc_seg: 95.4137, aux_2.loss_ce: 0.1221, aux_2.loss_dice: 0.2587, aux_2.acc_seg: 96.0076, aux_3.loss_ce: 0.1083, aux_3.acc_seg: 94.9033, loss: 0.7361
2023-05-03 13:25:08,502 - mmseg - INFO - Iter [3150/10000]	lr: 7.115e-02, eta: 1:48:10, time: 0.985, data_time: 0.269, memory: 14792, decode.loss_ce: 0.0748, decode.acc_seg: 96.1119, aux_0.loss_ce: 0.0774, aux_0.acc_seg: 96.0244, aux_1.loss_ce: 0.0912, aux_1.acc_seg: 95.3027, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2553, aux_2.acc_seg: 96.0168, aux_3.loss_ce: 0.1046, aux_3.acc_seg: 94.8766, loss: 0.7236
2023-05-03 13:25:53,944 - mmseg - INFO - Iter [3200/10000]	lr: 7.068e-02, eta: 1:47:19, time: 0.909, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0787, decode.acc_seg: 96.0014, aux_0.loss_ce: 0.0810, aux_0.acc_seg: 95.9341, aux_1.loss_ce: 0.0958, aux_1.acc_seg: 95.1846, aux_2.loss_ce: 0.1216, aux_2.loss_dice: 0.2581, aux_2.acc_seg: 96.0196, aux_3.loss_ce: 0.1092, aux_3.acc_seg: 94.7376, loss: 0.7445
2023-05-03 13:26:39,574 - mmseg - INFO - Iter [3250/10000]	lr: 7.022e-02, eta: 1:46:28, time: 0.913, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0760, decode.acc_seg: 96.0196, aux_0.loss_ce: 0.0788, aux_0.acc_seg: 95.9297, aux_1.loss_ce: 0.0925, aux_1.acc_seg: 95.1863, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 96.1433, aux_3.loss_ce: 0.1058, aux_3.acc_seg: 94.7651, loss: 0.7260
2023-05-03 13:27:24,992 - mmseg - INFO - Iter [3300/10000]	lr: 6.975e-02, eta: 1:45:37, time: 0.908, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0821, decode.acc_seg: 95.8946, aux_0.loss_ce: 0.0844, aux_0.acc_seg: 95.8238, aux_1.loss_ce: 0.0979, aux_1.acc_seg: 95.1194, aux_2.loss_ce: 0.1213, aux_2.loss_dice: 0.2578, aux_2.acc_seg: 96.0394, aux_3.loss_ce: 0.1110, aux_3.acc_seg: 94.6699, loss: 0.7546
2023-05-03 13:28:14,458 - mmseg - INFO - Iter [3350/10000]	lr: 6.928e-02, eta: 1:44:54, time: 0.989, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0806, decode.acc_seg: 95.9407, aux_0.loss_ce: 0.0826, aux_0.acc_seg: 95.8686, aux_1.loss_ce: 0.0961, aux_1.acc_seg: 95.1476, aux_2.loss_ce: 0.1230, aux_2.loss_dice: 0.2584, aux_2.acc_seg: 95.9579, aux_3.loss_ce: 0.1091, aux_3.acc_seg: 94.7396, loss: 0.7499
2023-05-03 13:28:59,701 - mmseg - INFO - Iter [3400/10000]	lr: 6.881e-02, eta: 1:44:03, time: 0.905, data_time: 0.192, memory: 14792, decode.loss_ce: 0.0926, decode.acc_seg: 95.4317, aux_0.loss_ce: 0.0952, aux_0.acc_seg: 95.3455, aux_1.loss_ce: 0.1091, aux_1.acc_seg: 94.6793, aux_2.loss_ce: 0.1214, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 96.1071, aux_3.loss_ce: 0.1142, aux_3.acc_seg: 94.5620, loss: 0.7929
2023-05-03 13:29:45,069 - mmseg - INFO - Iter [3450/10000]	lr: 6.834e-02, eta: 1:43:12, time: 0.907, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0904, decode.acc_seg: 95.4628, aux_0.loss_ce: 0.0931, aux_0.acc_seg: 95.3939, aux_1.loss_ce: 0.1073, aux_1.acc_seg: 94.6860, aux_2.loss_ce: 0.1197, aux_2.loss_dice: 0.2567, aux_2.acc_seg: 96.0830, aux_3.loss_ce: 0.1125, aux_3.acc_seg: 94.6080, loss: 0.7798
2023-05-03 13:30:34,039 - mmseg - INFO - Iter [3500/10000]	lr: 6.787e-02, eta: 1:42:27, time: 0.979, data_time: 0.264, memory: 14792, decode.loss_ce: 0.0845, decode.acc_seg: 95.7100, aux_0.loss_ce: 0.0868, aux_0.acc_seg: 95.6634, aux_1.loss_ce: 0.1010, aux_1.acc_seg: 94.9433, aux_2.loss_ce: 0.1216, aux_2.loss_dice: 0.2574, aux_2.acc_seg: 95.9874, aux_3.loss_ce: 0.1111, aux_3.acc_seg: 94.6803, loss: 0.7624
2023-05-03 13:31:20,196 - mmseg - INFO - Iter [3550/10000]	lr: 6.740e-02, eta: 1:41:38, time: 0.923, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0731, decode.acc_seg: 96.1919, aux_0.loss_ce: 0.0755, aux_0.acc_seg: 96.1188, aux_1.loss_ce: 0.0890, aux_1.acc_seg: 95.3940, aux_2.loss_ce: 0.1196, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 96.0901, aux_3.loss_ce: 0.1029, aux_3.acc_seg: 94.9221, loss: 0.7162
2023-05-03 13:32:06,188 - mmseg - INFO - Iter [3600/10000]	lr: 6.693e-02, eta: 1:40:49, time: 0.920, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0779, decode.acc_seg: 96.0101, aux_0.loss_ce: 0.0800, aux_0.acc_seg: 95.9505, aux_1.loss_ce: 0.0941, aux_1.acc_seg: 95.2287, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2558, aux_2.acc_seg: 96.0244, aux_3.loss_ce: 0.1065, aux_3.acc_seg: 94.8728, loss: 0.7346
2023-05-03 13:32:51,991 - mmseg - INFO - Iter [3650/10000]	lr: 6.646e-02, eta: 1:39:59, time: 0.916, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0776, decode.acc_seg: 96.0901, aux_0.loss_ce: 0.0801, aux_0.acc_seg: 96.0068, aux_1.loss_ce: 0.0932, aux_1.acc_seg: 95.3060, aux_2.loss_ce: 0.1211, aux_2.loss_dice: 0.2579, aux_2.acc_seg: 96.0236, aux_3.loss_ce: 0.1069, aux_3.acc_seg: 94.8607, loss: 0.7368
2023-05-03 13:33:41,659 - mmseg - INFO - Iter [3700/10000]	lr: 6.599e-02, eta: 1:39:16, time: 0.993, data_time: 0.273, memory: 14792, decode.loss_ce: 0.0745, decode.acc_seg: 96.2178, aux_0.loss_ce: 0.0771, aux_0.acc_seg: 96.1357, aux_1.loss_ce: 0.0912, aux_1.acc_seg: 95.3868, aux_2.loss_ce: 0.1207, aux_2.loss_dice: 0.2574, aux_2.acc_seg: 96.0419, aux_3.loss_ce: 0.1042, aux_3.acc_seg: 94.9681, loss: 0.7250
2023-05-03 13:34:27,789 - mmseg - INFO - Iter [3750/10000]	lr: 6.552e-02, eta: 1:38:26, time: 0.923, data_time: 0.205, memory: 14792, decode.loss_ce: 0.0718, decode.acc_seg: 96.2688, aux_0.loss_ce: 0.0744, aux_0.acc_seg: 96.2013, aux_1.loss_ce: 0.0880, aux_1.acc_seg: 95.4760, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2536, aux_2.acc_seg: 96.0766, aux_3.loss_ce: 0.1005, aux_3.acc_seg: 95.0333, loss: 0.7069
2023-05-03 13:35:13,602 - mmseg - INFO - Iter [3800/10000]	lr: 6.505e-02, eta: 1:37:37, time: 0.916, data_time: 0.198, memory: 14792, decode.loss_ce: 0.0716, decode.acc_seg: 96.3031, aux_0.loss_ce: 0.0740, aux_0.acc_seg: 96.2352, aux_1.loss_ce: 0.0875, aux_1.acc_seg: 95.5081, aux_2.loss_ce: 0.1189, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 96.0710, aux_3.loss_ce: 0.1015, aux_3.acc_seg: 95.0467, loss: 0.7085
2023-05-03 13:35:58,068 - mmseg - INFO - Iter [3850/10000]	lr: 6.457e-02, eta: 1:36:45, time: 0.889, data_time: 0.185, memory: 14792, decode.loss_ce: 0.0728, decode.acc_seg: 96.2570, aux_0.loss_ce: 0.0753, aux_0.acc_seg: 96.1888, aux_1.loss_ce: 0.0889, aux_1.acc_seg: 95.4607, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2562, aux_2.acc_seg: 96.0334, aux_3.loss_ce: 0.1030, aux_3.acc_seg: 94.9817, loss: 0.7167
2023-05-03 13:36:47,288 - mmseg - INFO - Iter [3900/10000]	lr: 6.410e-02, eta: 1:36:01, time: 0.984, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0715, decode.acc_seg: 96.3079, aux_0.loss_ce: 0.0735, aux_0.acc_seg: 96.2654, aux_1.loss_ce: 0.0870, aux_1.acc_seg: 95.5358, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 96.0431, aux_3.loss_ce: 0.1018, aux_3.acc_seg: 95.0329, loss: 0.7102
2023-05-03 13:37:32,855 - mmseg - INFO - Iter [3950/10000]	lr: 6.363e-02, eta: 1:35:11, time: 0.911, data_time: 0.198, memory: 14792, decode.loss_ce: 0.0704, decode.acc_seg: 96.3247, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 96.2815, aux_1.loss_ce: 0.0862, aux_1.acc_seg: 95.5439, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2533, aux_2.acc_seg: 96.0610, aux_3.loss_ce: 0.1006, aux_3.acc_seg: 95.0411, loss: 0.7012
2023-05-03 13:38:18,400 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-05-03 13:38:20,278 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:38:20,278 - mmseg - INFO - Iter [4000/10000]	lr: 6.315e-02, eta: 1:34:25, time: 0.949, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0726, decode.acc_seg: 96.3118, aux_0.loss_ce: 0.0744, aux_0.acc_seg: 96.2661, aux_1.loss_ce: 0.0877, aux_1.acc_seg: 95.5701, aux_2.loss_ce: 0.1211, aux_2.loss_dice: 0.2567, aux_2.acc_seg: 95.9961, aux_3.loss_ce: 0.1018, aux_3.acc_seg: 95.1060, loss: 0.7142
2023-05-03 13:38:25,799 - mmseg - INFO - per class results:
2023-05-03 13:38:25,800 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 85.75 | 93.27 |
|   Building  | 93.92 | 95.83 |
|     Car     | 92.89 | 94.49 |
| Column_Pole | 27.19 | 34.65 |
|    Fence    | 79.08 | 87.69 |
|  Pedestrian | 66.48 | 86.87 |
|     Road    | 97.59 | 98.64 |
|   Sidewalk  | 92.28 | 96.56 |
|  SignSymbol |  0.41 |  0.42 |
|     Sky     | 94.26 | 97.06 |
|     Tree    | 92.47 | 98.21 |
+-------------+-------+-------+
2023-05-03 13:38:25,800 - mmseg - INFO - Summary:
2023-05-03 13:38:25,801 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.39 | 74.76 | 80.34 |
+-------+-------+-------+
2023-05-03 13:38:25,801 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:38:25,801 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9639, mIoU: 0.7476, mAcc: 0.8034, IoU.Bicyclist: 0.8575, IoU.Building: 0.9392, IoU.Car: 0.9289, IoU.Column_Pole: 0.2719, IoU.Fence: 0.7908, IoU.Pedestrian: 0.6648, IoU.Road: 0.9759, IoU.Sidewalk: 0.9228, IoU.SignSymbol: 0.0041, IoU.Sky: 0.9426, IoU.Tree: 0.9247, Acc.Bicyclist: 0.9327, Acc.Building: 0.9583, Acc.Car: 0.9449, Acc.Column_Pole: 0.3465, Acc.Fence: 0.8769, Acc.Pedestrian: 0.8687, Acc.Road: 0.9864, Acc.Sidewalk: 0.9656, Acc.SignSymbol: 0.0042, Acc.Sky: 0.9706, Acc.Tree: 0.9821
2023-05-03 13:39:15,209 - mmseg - INFO - Iter [4050/10000]	lr: 6.268e-02, eta: 1:33:49, time: 1.098, data_time: 0.380, memory: 14792, decode.loss_ce: 0.0705, decode.acc_seg: 96.3838, aux_0.loss_ce: 0.0730, aux_0.acc_seg: 96.3164, aux_1.loss_ce: 0.0868, aux_1.acc_seg: 95.6010, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2557, aux_2.acc_seg: 96.0351, aux_3.loss_ce: 0.1011, aux_3.acc_seg: 95.1045, loss: 0.7074
2023-05-03 13:40:00,965 - mmseg - INFO - Iter [4100/10000]	lr: 6.221e-02, eta: 1:32:59, time: 0.915, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0719, decode.acc_seg: 96.3155, aux_0.loss_ce: 0.0739, aux_0.acc_seg: 96.2739, aux_1.loss_ce: 0.0873, aux_1.acc_seg: 95.5651, aux_2.loss_ce: 0.1194, aux_2.loss_dice: 0.2562, aux_2.acc_seg: 96.0787, aux_3.loss_ce: 0.1015, aux_3.acc_seg: 95.0916, loss: 0.7101
2023-05-03 13:40:47,532 - mmseg - INFO - Iter [4150/10000]	lr: 6.173e-02, eta: 1:32:11, time: 0.931, data_time: 0.205, memory: 14792, decode.loss_ce: 0.0719, decode.acc_seg: 96.3242, aux_0.loss_ce: 0.0737, aux_0.acc_seg: 96.2827, aux_1.loss_ce: 0.0881, aux_1.acc_seg: 95.5214, aux_2.loss_ce: 0.1230, aux_2.loss_dice: 0.2568, aux_2.acc_seg: 95.8936, aux_3.loss_ce: 0.1029, aux_3.acc_seg: 95.0074, loss: 0.7163
2023-05-03 13:41:32,853 - mmseg - INFO - Iter [4200/10000]	lr: 6.126e-02, eta: 1:31:21, time: 0.906, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0723, decode.acc_seg: 96.2999, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 96.2407, aux_1.loss_ce: 0.0875, aux_1.acc_seg: 95.5571, aux_2.loss_ce: 0.1202, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 96.0300, aux_3.loss_ce: 0.1016, aux_3.acc_seg: 95.0856, loss: 0.7113
2023-05-03 13:42:21,623 - mmseg - INFO - Iter [4250/10000]	lr: 6.078e-02, eta: 1:30:36, time: 0.975, data_time: 0.268, memory: 14792, decode.loss_ce: 0.0699, decode.acc_seg: 96.3460, aux_0.loss_ce: 0.0719, aux_0.acc_seg: 96.2776, aux_1.loss_ce: 0.0847, aux_1.acc_seg: 95.5775, aux_2.loss_ce: 0.1196, aux_2.loss_dice: 0.2542, aux_2.acc_seg: 96.0159, aux_3.loss_ce: 0.0998, aux_3.acc_seg: 95.0650, loss: 0.7000
2023-05-03 13:43:07,173 - mmseg - INFO - Iter [4300/10000]	lr: 6.031e-02, eta: 1:29:46, time: 0.911, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0699, decode.acc_seg: 96.3661, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 96.3071, aux_1.loss_ce: 0.0857, aux_1.acc_seg: 95.5775, aux_2.loss_ce: 0.1206, aux_2.loss_dice: 0.2548, aux_2.acc_seg: 95.9888, aux_3.loss_ce: 0.1004, aux_3.acc_seg: 95.0755, loss: 0.7036
2023-05-03 13:43:52,680 - mmseg - INFO - Iter [4350/10000]	lr: 5.983e-02, eta: 1:28:57, time: 0.910, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0705, decode.acc_seg: 96.3511, aux_0.loss_ce: 0.0727, aux_0.acc_seg: 96.2969, aux_1.loss_ce: 0.0867, aux_1.acc_seg: 95.5559, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2565, aux_2.acc_seg: 95.9646, aux_3.loss_ce: 0.1014, aux_3.acc_seg: 95.0456, loss: 0.7097
2023-05-03 13:44:38,050 - mmseg - INFO - Iter [4400/10000]	lr: 5.935e-02, eta: 1:28:07, time: 0.907, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0678, decode.acc_seg: 96.5171, aux_0.loss_ce: 0.0701, aux_0.acc_seg: 96.4414, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.7521, aux_2.loss_ce: 0.1201, aux_2.loss_dice: 0.2552, aux_2.acc_seg: 96.0446, aux_3.loss_ce: 0.0982, aux_3.acc_seg: 95.2531, loss: 0.6953
2023-05-03 13:45:27,120 - mmseg - INFO - Iter [4450/10000]	lr: 5.888e-02, eta: 1:27:22, time: 0.981, data_time: 0.267, memory: 14792, decode.loss_ce: 0.0689, decode.acc_seg: 96.4285, aux_0.loss_ce: 0.0709, aux_0.acc_seg: 96.3803, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.6909, aux_2.loss_ce: 0.1187, aux_2.loss_dice: 0.2545, aux_2.acc_seg: 96.0994, aux_3.loss_ce: 0.0980, aux_3.acc_seg: 95.1745, loss: 0.6948
2023-05-03 13:46:13,081 - mmseg - INFO - Iter [4500/10000]	lr: 5.840e-02, eta: 1:26:33, time: 0.919, data_time: 0.205, memory: 14792, decode.loss_ce: 0.0691, decode.acc_seg: 96.3853, aux_0.loss_ce: 0.0709, aux_0.acc_seg: 96.3447, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.6211, aux_2.loss_ce: 0.1195, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 96.0235, aux_3.loss_ce: 0.0993, aux_3.acc_seg: 95.0605, loss: 0.6974
2023-05-03 13:46:58,439 - mmseg - INFO - Iter [4550/10000]	lr: 5.792e-02, eta: 1:25:44, time: 0.907, data_time: 0.197, memory: 14792, decode.loss_ce: 0.0701, decode.acc_seg: 96.4216, aux_0.loss_ce: 0.0713, aux_0.acc_seg: 96.3912, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.7092, aux_2.loss_ce: 0.1194, aux_2.loss_dice: 0.2530, aux_2.acc_seg: 96.0273, aux_3.loss_ce: 0.0983, aux_3.acc_seg: 95.2298, loss: 0.6964
2023-05-03 13:47:47,657 - mmseg - INFO - Iter [4600/10000]	lr: 5.744e-02, eta: 1:24:59, time: 0.984, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0744, decode.acc_seg: 96.2764, aux_0.loss_ce: 0.0755, aux_0.acc_seg: 96.2346, aux_1.loss_ce: 0.0890, aux_1.acc_seg: 95.5277, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2569, aux_2.acc_seg: 95.9787, aux_3.loss_ce: 0.1022, aux_3.acc_seg: 95.0556, loss: 0.7199
2023-05-03 13:48:33,211 - mmseg - INFO - Iter [4650/10000]	lr: 5.696e-02, eta: 1:24:10, time: 0.911, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0700, decode.acc_seg: 96.3351, aux_0.loss_ce: 0.0717, aux_0.acc_seg: 96.3046, aux_1.loss_ce: 0.0852, aux_1.acc_seg: 95.5800, aux_2.loss_ce: 0.1191, aux_2.loss_dice: 0.2543, aux_2.acc_seg: 96.0564, aux_3.loss_ce: 0.0984, aux_3.acc_seg: 95.1324, loss: 0.6988
2023-05-03 13:49:18,693 - mmseg - INFO - Iter [4700/10000]	lr: 5.648e-02, eta: 1:23:21, time: 0.910, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0691, decode.acc_seg: 96.4202, aux_0.loss_ce: 0.0714, aux_0.acc_seg: 96.3637, aux_1.loss_ce: 0.0849, aux_1.acc_seg: 95.6320, aux_2.loss_ce: 0.1204, aux_2.loss_dice: 0.2546, aux_2.acc_seg: 95.9713, aux_3.loss_ce: 0.0998, aux_3.acc_seg: 95.0897, loss: 0.7003
2023-05-03 13:50:04,238 - mmseg - INFO - Iter [4750/10000]	lr: 5.600e-02, eta: 1:22:32, time: 0.911, data_time: 0.198, memory: 14792, decode.loss_ce: 0.0665, decode.acc_seg: 96.5142, aux_0.loss_ce: 0.0680, aux_0.acc_seg: 96.4878, aux_1.loss_ce: 0.0811, aux_1.acc_seg: 95.7880, aux_2.loss_ce: 0.1187, aux_2.loss_dice: 0.2529, aux_2.acc_seg: 96.0451, aux_3.loss_ce: 0.0971, aux_3.acc_seg: 95.1836, loss: 0.6842
2023-05-03 13:50:53,275 - mmseg - INFO - Iter [4800/10000]	lr: 5.552e-02, eta: 1:21:47, time: 0.981, data_time: 0.265, memory: 14792, decode.loss_ce: 0.0686, decode.acc_seg: 96.3789, aux_0.loss_ce: 0.0700, aux_0.acc_seg: 96.3587, aux_1.loss_ce: 0.0834, aux_1.acc_seg: 95.6490, aux_2.loss_ce: 0.1201, aux_2.loss_dice: 0.2535, aux_2.acc_seg: 95.9878, aux_3.loss_ce: 0.0982, aux_3.acc_seg: 95.1195, loss: 0.6938
2023-05-03 13:51:38,933 - mmseg - INFO - Iter [4850/10000]	lr: 5.504e-02, eta: 1:20:58, time: 0.913, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0662, decode.acc_seg: 96.5674, aux_0.loss_ce: 0.0679, aux_0.acc_seg: 96.5262, aux_1.loss_ce: 0.0811, aux_1.acc_seg: 95.8266, aux_2.loss_ce: 0.1197, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 96.0199, aux_3.loss_ce: 0.0967, aux_3.acc_seg: 95.2473, loss: 0.6859
2023-05-03 13:52:23,661 - mmseg - INFO - Iter [4900/10000]	lr: 5.456e-02, eta: 1:20:08, time: 0.895, data_time: 0.190, memory: 14792, decode.loss_ce: 0.0680, decode.acc_seg: 96.5105, aux_0.loss_ce: 0.0697, aux_0.acc_seg: 96.4646, aux_1.loss_ce: 0.0824, aux_1.acc_seg: 95.7712, aux_2.loss_ce: 0.1194, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 96.0416, aux_3.loss_ce: 0.0970, aux_3.acc_seg: 95.2260, loss: 0.6914
2023-05-03 13:53:09,361 - mmseg - INFO - Iter [4950/10000]	lr: 5.408e-02, eta: 1:19:19, time: 0.914, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0652, decode.acc_seg: 96.5748, aux_0.loss_ce: 0.0667, aux_0.acc_seg: 96.5353, aux_1.loss_ce: 0.0798, aux_1.acc_seg: 95.8581, aux_2.loss_ce: 0.1172, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 96.0958, aux_3.loss_ce: 0.0949, aux_3.acc_seg: 95.3106, loss: 0.6762
2023-05-03 13:53:58,926 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-05-03 13:54:01,140 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:54:01,141 - mmseg - INFO - Iter [5000/10000]	lr: 5.360e-02, eta: 1:18:37, time: 1.036, data_time: 0.274, memory: 14792, decode.loss_ce: 0.0679, decode.acc_seg: 96.4597, aux_0.loss_ce: 0.0694, aux_0.acc_seg: 96.4213, aux_1.loss_ce: 0.0829, aux_1.acc_seg: 95.7197, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2535, aux_2.acc_seg: 96.0044, aux_3.loss_ce: 0.0988, aux_3.acc_seg: 95.1246, loss: 0.6923
2023-05-03 13:54:06,773 - mmseg - INFO - per class results:
2023-05-03 13:54:06,774 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 84.57 | 91.12 |
|   Building  | 92.85 | 94.83 |
|     Car     | 93.08 | 95.72 |
| Column_Pole | 25.01 | 31.94 |
|    Fence    | 79.97 | 90.04 |
|  Pedestrian | 65.09 |  81.4 |
|     Road    | 97.61 |  98.5 |
|   Sidewalk  | 92.04 | 96.64 |
|  SignSymbol |  0.55 |  0.55 |
|     Sky     | 93.94 | 96.94 |
|     Tree    | 91.24 | 98.26 |
+-------------+-------+-------+
2023-05-03 13:54:06,774 - mmseg - INFO - Summary:
2023-05-03 13:54:06,774 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.09 | 74.18 | 79.63 |
+-------+-------+-------+
2023-05-03 13:54:06,775 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 13:54:06,775 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9609, mIoU: 0.7418, mAcc: 0.7963, IoU.Bicyclist: 0.8457, IoU.Building: 0.9285, IoU.Car: 0.9308, IoU.Column_Pole: 0.2501, IoU.Fence: 0.7997, IoU.Pedestrian: 0.6509, IoU.Road: 0.9761, IoU.Sidewalk: 0.9204, IoU.SignSymbol: 0.0055, IoU.Sky: 0.9394, IoU.Tree: 0.9124, Acc.Bicyclist: 0.9112, Acc.Building: 0.9483, Acc.Car: 0.9572, Acc.Column_Pole: 0.3194, Acc.Fence: 0.9004, Acc.Pedestrian: 0.8140, Acc.Road: 0.9850, Acc.Sidewalk: 0.9664, Acc.SignSymbol: 0.0055, Acc.Sky: 0.9694, Acc.Tree: 0.9826
2023-05-03 13:54:52,158 - mmseg - INFO - Iter [5050/10000]	lr: 5.312e-02, eta: 1:17:54, time: 1.020, data_time: 0.306, memory: 14792, decode.loss_ce: 0.0662, decode.acc_seg: 96.5391, aux_0.loss_ce: 0.0678, aux_0.acc_seg: 96.5035, aux_1.loss_ce: 0.0810, aux_1.acc_seg: 95.8024, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2518, aux_2.acc_seg: 96.0521, aux_3.loss_ce: 0.0961, aux_3.acc_seg: 95.2322, loss: 0.6811
2023-05-03 13:55:37,483 - mmseg - INFO - Iter [5100/10000]	lr: 5.263e-02, eta: 1:17:05, time: 0.906, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0651, decode.acc_seg: 96.5535, aux_0.loss_ce: 0.0667, aux_0.acc_seg: 96.5282, aux_1.loss_ce: 0.0803, aux_1.acc_seg: 95.7974, aux_2.loss_ce: 0.1181, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 96.0676, aux_3.loss_ce: 0.0946, aux_3.acc_seg: 95.2917, loss: 0.6769
2023-05-03 13:56:26,717 - mmseg - INFO - Iter [5150/10000]	lr: 5.215e-02, eta: 1:16:19, time: 0.985, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0694, decode.acc_seg: 96.3848, aux_0.loss_ce: 0.0711, aux_0.acc_seg: 96.3502, aux_1.loss_ce: 0.0843, aux_1.acc_seg: 95.6269, aux_2.loss_ce: 0.1204, aux_2.loss_dice: 0.2546, aux_2.acc_seg: 96.0116, aux_3.loss_ce: 0.0991, aux_3.acc_seg: 95.1001, loss: 0.6989
2023-05-03 13:57:12,264 - mmseg - INFO - Iter [5200/10000]	lr: 5.167e-02, eta: 1:15:31, time: 0.911, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0676, decode.acc_seg: 96.3974, aux_0.loss_ce: 0.0693, aux_0.acc_seg: 96.3521, aux_1.loss_ce: 0.0814, aux_1.acc_seg: 95.6863, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2514, aux_2.acc_seg: 96.0641, aux_3.loss_ce: 0.0965, aux_3.acc_seg: 95.1327, loss: 0.6835
2023-05-03 13:57:57,223 - mmseg - INFO - Iter [5250/10000]	lr: 5.118e-02, eta: 1:14:41, time: 0.899, data_time: 0.190, memory: 14792, decode.loss_ce: 0.0641, decode.acc_seg: 96.6526, aux_0.loss_ce: 0.0656, aux_0.acc_seg: 96.6236, aux_1.loss_ce: 0.0783, aux_1.acc_seg: 95.9296, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 96.0842, aux_3.loss_ce: 0.0930, aux_3.acc_seg: 95.4113, loss: 0.6721
2023-05-03 13:58:42,463 - mmseg - INFO - Iter [5300/10000]	lr: 5.070e-02, eta: 1:13:52, time: 0.905, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0642, decode.acc_seg: 96.6239, aux_0.loss_ce: 0.0663, aux_0.acc_seg: 96.5708, aux_1.loss_ce: 0.0785, aux_1.acc_seg: 95.9014, aux_2.loss_ce: 0.1183, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.0582, aux_3.loss_ce: 0.0942, aux_3.acc_seg: 95.3113, loss: 0.6745
2023-05-03 13:59:32,146 - mmseg - INFO - Iter [5350/10000]	lr: 5.021e-02, eta: 1:13:07, time: 0.994, data_time: 0.276, memory: 14792, decode.loss_ce: 0.0692, decode.acc_seg: 96.3750, aux_0.loss_ce: 0.0705, aux_0.acc_seg: 96.3555, aux_1.loss_ce: 0.0830, aux_1.acc_seg: 95.6757, aux_2.loss_ce: 0.1187, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 96.0398, aux_3.loss_ce: 0.0973, aux_3.acc_seg: 95.1513, loss: 0.6909
2023-05-03 14:00:18,064 - mmseg - INFO - Iter [5400/10000]	lr: 4.972e-02, eta: 1:12:19, time: 0.918, data_time: 0.203, memory: 14792, decode.loss_ce: 0.0676, decode.acc_seg: 96.4526, aux_0.loss_ce: 0.0691, aux_0.acc_seg: 96.4176, aux_1.loss_ce: 0.0825, aux_1.acc_seg: 95.7055, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2548, aux_2.acc_seg: 96.0531, aux_3.loss_ce: 0.0972, aux_3.acc_seg: 95.1774, loss: 0.6901
2023-05-03 14:01:03,795 - mmseg - INFO - Iter [5450/10000]	lr: 4.924e-02, eta: 1:11:31, time: 0.915, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0649, decode.acc_seg: 96.6250, aux_0.loss_ce: 0.0664, aux_0.acc_seg: 96.5943, aux_1.loss_ce: 0.0787, aux_1.acc_seg: 95.9322, aux_2.loss_ce: 0.1170, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.0812, aux_3.loss_ce: 0.0945, aux_3.acc_seg: 95.3395, loss: 0.6721
2023-05-03 14:01:49,708 - mmseg - INFO - Iter [5500/10000]	lr: 4.875e-02, eta: 1:10:43, time: 0.918, data_time: 0.203, memory: 14792, decode.loss_ce: 0.0659, decode.acc_seg: 96.5382, aux_0.loss_ce: 0.0674, aux_0.acc_seg: 96.5125, aux_1.loss_ce: 0.0806, aux_1.acc_seg: 95.7981, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 96.0092, aux_3.loss_ce: 0.0958, aux_3.acc_seg: 95.2529, loss: 0.6799
2023-05-03 14:02:38,939 - mmseg - INFO - Iter [5550/10000]	lr: 4.826e-02, eta: 1:09:57, time: 0.985, data_time: 0.271, memory: 14792, decode.loss_ce: 0.0635, decode.acc_seg: 96.6308, aux_0.loss_ce: 0.0652, aux_0.acc_seg: 96.5947, aux_1.loss_ce: 0.0781, aux_1.acc_seg: 95.8965, aux_2.loss_ce: 0.1197, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 95.9958, aux_3.loss_ce: 0.0943, aux_3.acc_seg: 95.2813, loss: 0.6739
2023-05-03 14:03:24,760 - mmseg - INFO - Iter [5600/10000]	lr: 4.778e-02, eta: 1:09:09, time: 0.916, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0644, decode.acc_seg: 96.6222, aux_0.loss_ce: 0.0661, aux_0.acc_seg: 96.5946, aux_1.loss_ce: 0.0792, aux_1.acc_seg: 95.9006, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2528, aux_2.acc_seg: 95.9946, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.2951, loss: 0.6771
2023-05-03 14:04:08,659 - mmseg - INFO - Iter [5650/10000]	lr: 4.729e-02, eta: 1:08:19, time: 0.878, data_time: 0.182, memory: 14792, decode.loss_ce: 0.0665, decode.acc_seg: 96.5848, aux_0.loss_ce: 0.0685, aux_0.acc_seg: 96.5386, aux_1.loss_ce: 0.0819, aux_1.acc_seg: 95.8347, aux_2.loss_ce: 0.1213, aux_2.loss_dice: 0.2562, aux_2.acc_seg: 95.9579, aux_3.loss_ce: 0.0978, aux_3.acc_seg: 95.2415, loss: 0.6922
2023-05-03 14:04:57,695 - mmseg - INFO - Iter [5700/10000]	lr: 4.680e-02, eta: 1:07:34, time: 0.981, data_time: 0.271, memory: 14792, decode.loss_ce: 0.0637, decode.acc_seg: 96.7399, aux_0.loss_ce: 0.0652, aux_0.acc_seg: 96.7021, aux_1.loss_ce: 0.0780, aux_1.acc_seg: 96.0355, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2528, aux_2.acc_seg: 96.0435, aux_3.loss_ce: 0.0944, aux_3.acc_seg: 95.4346, loss: 0.6731
2023-05-03 14:05:42,820 - mmseg - INFO - Iter [5750/10000]	lr: 4.631e-02, eta: 1:06:45, time: 0.902, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0623, decode.acc_seg: 96.6895, aux_0.loss_ce: 0.0636, aux_0.acc_seg: 96.6708, aux_1.loss_ce: 0.0766, aux_1.acc_seg: 95.9545, aux_2.loss_ce: 0.1167, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.0650, aux_3.loss_ce: 0.0925, aux_3.acc_seg: 95.3336, loss: 0.6620
2023-05-03 14:06:27,231 - mmseg - INFO - Iter [5800/10000]	lr: 4.582e-02, eta: 1:05:56, time: 0.888, data_time: 0.188, memory: 14792, decode.loss_ce: 0.0649, decode.acc_seg: 96.6183, aux_0.loss_ce: 0.0664, aux_0.acc_seg: 96.5853, aux_1.loss_ce: 0.0799, aux_1.acc_seg: 95.8738, aux_2.loss_ce: 0.1216, aux_2.loss_dice: 0.2542, aux_2.acc_seg: 95.9267, aux_3.loss_ce: 0.0960, aux_3.acc_seg: 95.2750, loss: 0.6830
2023-05-03 14:07:11,794 - mmseg - INFO - Iter [5850/10000]	lr: 4.533e-02, eta: 1:05:07, time: 0.891, data_time: 0.189, memory: 14792, decode.loss_ce: 0.0631, decode.acc_seg: 96.6864, aux_0.loss_ce: 0.0645, aux_0.acc_seg: 96.6670, aux_1.loss_ce: 0.0772, aux_1.acc_seg: 95.9860, aux_2.loss_ce: 0.1183, aux_2.loss_dice: 0.2519, aux_2.acc_seg: 96.0281, aux_3.loss_ce: 0.0943, aux_3.acc_seg: 95.3409, loss: 0.6694
2023-05-03 14:08:00,303 - mmseg - INFO - Iter [5900/10000]	lr: 4.483e-02, eta: 1:04:21, time: 0.970, data_time: 0.262, memory: 14792, decode.loss_ce: 0.0635, decode.acc_seg: 96.6138, aux_0.loss_ce: 0.0651, aux_0.acc_seg: 96.5830, aux_1.loss_ce: 0.0774, aux_1.acc_seg: 95.9150, aux_2.loss_ce: 0.1161, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.1262, aux_3.loss_ce: 0.0925, aux_3.acc_seg: 95.3342, loss: 0.6655
2023-05-03 14:08:46,045 - mmseg - INFO - Iter [5950/10000]	lr: 4.434e-02, eta: 1:03:33, time: 0.915, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0674, decode.acc_seg: 96.4469, aux_0.loss_ce: 0.0686, aux_0.acc_seg: 96.4243, aux_1.loss_ce: 0.0813, aux_1.acc_seg: 95.7304, aux_2.loss_ce: 0.1194, aux_2.loss_dice: 0.2524, aux_2.acc_seg: 95.9746, aux_3.loss_ce: 0.0966, aux_3.acc_seg: 95.1537, loss: 0.6857
2023-05-03 14:09:31,033 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-05-03 14:09:33,160 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:09:33,160 - mmseg - INFO - Iter [6000/10000]	lr: 4.385e-02, eta: 1:02:46, time: 0.943, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0650, decode.acc_seg: 96.5570, aux_0.loss_ce: 0.0668, aux_0.acc_seg: 96.5130, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 95.8330, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2521, aux_2.acc_seg: 96.0285, aux_3.loss_ce: 0.0954, aux_3.acc_seg: 95.2071, loss: 0.6772
2023-05-03 14:09:38,922 - mmseg - INFO - per class results:
2023-05-03 14:09:38,923 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 85.94 | 91.73 |
|   Building  | 93.94 | 96.73 |
|     Car     | 93.25 | 94.84 |
| Column_Pole | 23.18 | 26.28 |
|    Fence    | 80.93 | 91.89 |
|  Pedestrian | 65.79 | 76.14 |
|     Road    |  97.4 | 98.25 |
|   Sidewalk  | 91.24 | 96.34 |
|  SignSymbol |  0.28 |  0.28 |
|     Sky     | 94.41 | 96.91 |
|     Tree    | 92.94 | 98.03 |
+-------------+-------+-------+
2023-05-03 14:09:38,923 - mmseg - INFO - Summary:
2023-05-03 14:09:38,923 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.43 | 74.48 | 78.86 |
+-------+-------+-------+
2023-05-03 14:09:38,924 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:09:38,924 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9643, mIoU: 0.7448, mAcc: 0.7886, IoU.Bicyclist: 0.8594, IoU.Building: 0.9394, IoU.Car: 0.9325, IoU.Column_Pole: 0.2318, IoU.Fence: 0.8093, IoU.Pedestrian: 0.6579, IoU.Road: 0.9740, IoU.Sidewalk: 0.9124, IoU.SignSymbol: 0.0028, IoU.Sky: 0.9441, IoU.Tree: 0.9294, Acc.Bicyclist: 0.9173, Acc.Building: 0.9673, Acc.Car: 0.9484, Acc.Column_Pole: 0.2628, Acc.Fence: 0.9189, Acc.Pedestrian: 0.7614, Acc.Road: 0.9825, Acc.Sidewalk: 0.9634, Acc.SignSymbol: 0.0028, Acc.Sky: 0.9691, Acc.Tree: 0.9803
2023-05-03 14:10:24,049 - mmseg - INFO - Iter [6050/10000]	lr: 4.336e-02, eta: 1:02:01, time: 1.017, data_time: 0.311, memory: 14792, decode.loss_ce: 0.0627, decode.acc_seg: 96.7180, aux_0.loss_ce: 0.0645, aux_0.acc_seg: 96.6796, aux_1.loss_ce: 0.0765, aux_1.acc_seg: 96.0287, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2520, aux_2.acc_seg: 96.0880, aux_3.loss_ce: 0.0924, aux_3.acc_seg: 95.4223, loss: 0.6656
2023-05-03 14:11:12,562 - mmseg - INFO - Iter [6100/10000]	lr: 4.286e-02, eta: 1:01:15, time: 0.970, data_time: 0.262, memory: 14792, decode.loss_ce: 0.0632, decode.acc_seg: 96.7039, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.6661, aux_1.loss_ce: 0.0773, aux_1.acc_seg: 95.9897, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.0321, aux_3.loss_ce: 0.0934, aux_3.acc_seg: 95.3891, loss: 0.6707
2023-05-03 14:11:58,113 - mmseg - INFO - Iter [6150/10000]	lr: 4.237e-02, eta: 1:00:27, time: 0.911, data_time: 0.198, memory: 14792, decode.loss_ce: 0.0673, decode.acc_seg: 96.4286, aux_0.loss_ce: 0.0681, aux_0.acc_seg: 96.4393, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 95.8067, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 96.0785, aux_3.loss_ce: 0.0928, aux_3.acc_seg: 95.2902, loss: 0.6775
2023-05-03 14:12:44,237 - mmseg - INFO - Iter [6200/10000]	lr: 4.187e-02, eta: 0:59:39, time: 0.922, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0734, decode.acc_seg: 96.2238, aux_0.loss_ce: 0.0741, aux_0.acc_seg: 96.2598, aux_1.loss_ce: 0.0851, aux_1.acc_seg: 95.6201, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2533, aux_2.acc_seg: 96.0604, aux_3.loss_ce: 0.0966, aux_3.acc_seg: 95.1553, loss: 0.7009
2023-05-03 14:13:33,960 - mmseg - INFO - Iter [6250/10000]	lr: 4.138e-02, eta: 0:58:54, time: 0.994, data_time: 0.271, memory: 14792, decode.loss_ce: 0.0665, decode.acc_seg: 96.5141, aux_0.loss_ce: 0.0681, aux_0.acc_seg: 96.4832, aux_1.loss_ce: 0.0803, aux_1.acc_seg: 95.8196, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2514, aux_2.acc_seg: 96.0202, aux_3.loss_ce: 0.0945, aux_3.acc_seg: 95.2810, loss: 0.6793
2023-05-03 14:14:19,782 - mmseg - INFO - Iter [6300/10000]	lr: 4.088e-02, eta: 0:58:06, time: 0.916, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0644, decode.acc_seg: 96.6185, aux_0.loss_ce: 0.0660, aux_0.acc_seg: 96.5926, aux_1.loss_ce: 0.0783, aux_1.acc_seg: 95.9208, aux_2.loss_ce: 0.1195, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 95.9574, aux_3.loss_ce: 0.0938, aux_3.acc_seg: 95.3591, loss: 0.6743
2023-05-03 14:15:05,609 - mmseg - INFO - Iter [6350/10000]	lr: 4.038e-02, eta: 0:57:18, time: 0.917, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0634, decode.acc_seg: 96.6994, aux_0.loss_ce: 0.0652, aux_0.acc_seg: 96.6597, aux_1.loss_ce: 0.0773, aux_1.acc_seg: 96.0029, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 96.0894, aux_3.loss_ce: 0.0935, aux_3.acc_seg: 95.3801, loss: 0.6711
2023-05-03 14:15:50,921 - mmseg - INFO - Iter [6400/10000]	lr: 3.988e-02, eta: 0:56:30, time: 0.906, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0630, decode.acc_seg: 96.6772, aux_0.loss_ce: 0.0646, aux_0.acc_seg: 96.6571, aux_1.loss_ce: 0.0768, aux_1.acc_seg: 95.9917, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2519, aux_2.acc_seg: 96.0196, aux_3.loss_ce: 0.0933, aux_3.acc_seg: 95.3571, loss: 0.6682
2023-05-03 14:16:39,783 - mmseg - INFO - Iter [6450/10000]	lr: 3.938e-02, eta: 0:55:44, time: 0.977, data_time: 0.263, memory: 14792, decode.loss_ce: 0.0649, decode.acc_seg: 96.5743, aux_0.loss_ce: 0.0664, aux_0.acc_seg: 96.5579, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 95.8511, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 96.0351, aux_3.loss_ce: 0.0949, aux_3.acc_seg: 95.2792, loss: 0.6764
2023-05-03 14:17:25,748 - mmseg - INFO - Iter [6500/10000]	lr: 3.888e-02, eta: 0:54:56, time: 0.919, data_time: 0.205, memory: 14792, decode.loss_ce: 0.0634, decode.acc_seg: 96.6756, aux_0.loss_ce: 0.0649, aux_0.acc_seg: 96.6566, aux_1.loss_ce: 0.0767, aux_1.acc_seg: 96.0091, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 96.1179, aux_3.loss_ce: 0.0928, aux_3.acc_seg: 95.3878, loss: 0.6661
2023-05-03 14:18:11,300 - mmseg - INFO - Iter [6550/10000]	lr: 3.838e-02, eta: 0:54:08, time: 0.911, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0609, decode.acc_seg: 96.7536, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.7304, aux_1.loss_ce: 0.0745, aux_1.acc_seg: 96.0666, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.0499, aux_3.loss_ce: 0.0900, aux_3.acc_seg: 95.4775, loss: 0.6555
2023-05-03 14:18:56,775 - mmseg - INFO - Iter [6600/10000]	lr: 3.788e-02, eta: 0:53:20, time: 0.909, data_time: 0.198, memory: 14792, decode.loss_ce: 0.0616, decode.acc_seg: 96.7376, aux_0.loss_ce: 0.0629, aux_0.acc_seg: 96.7107, aux_1.loss_ce: 0.0755, aux_1.acc_seg: 96.0326, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 96.0370, aux_3.loss_ce: 0.0917, aux_3.acc_seg: 95.4300, loss: 0.6601
2023-05-03 14:19:45,832 - mmseg - INFO - Iter [6650/10000]	lr: 3.738e-02, eta: 0:52:34, time: 0.981, data_time: 0.268, memory: 14792, decode.loss_ce: 0.0599, decode.acc_seg: 96.8245, aux_0.loss_ce: 0.0613, aux_0.acc_seg: 96.7963, aux_1.loss_ce: 0.0737, aux_1.acc_seg: 96.1243, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2507, aux_2.acc_seg: 96.0554, aux_3.loss_ce: 0.0904, aux_3.acc_seg: 95.4922, loss: 0.6533
2023-05-03 14:20:31,730 - mmseg - INFO - Iter [6700/10000]	lr: 3.688e-02, eta: 0:51:46, time: 0.918, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0621, decode.acc_seg: 96.7107, aux_0.loss_ce: 0.0634, aux_0.acc_seg: 96.6929, aux_1.loss_ce: 0.0760, aux_1.acc_seg: 96.0098, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 96.0073, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.3566, loss: 0.6659
2023-05-03 14:21:17,507 - mmseg - INFO - Iter [6750/10000]	lr: 3.638e-02, eta: 0:50:59, time: 0.916, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0596, decode.acc_seg: 96.8215, aux_0.loss_ce: 0.0611, aux_0.acc_seg: 96.7961, aux_1.loss_ce: 0.0737, aux_1.acc_seg: 96.1046, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.0189, aux_3.loss_ce: 0.0906, aux_3.acc_seg: 95.4583, loss: 0.6531
2023-05-03 14:22:05,893 - mmseg - INFO - Iter [6800/10000]	lr: 3.587e-02, eta: 0:50:12, time: 0.968, data_time: 0.261, memory: 14792, decode.loss_ce: 0.0608, decode.acc_seg: 96.7490, aux_0.loss_ce: 0.0624, aux_0.acc_seg: 96.7272, aux_1.loss_ce: 0.0746, aux_1.acc_seg: 96.0561, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 96.0398, aux_3.loss_ce: 0.0904, aux_3.acc_seg: 95.4520, loss: 0.6558
2023-05-03 14:22:51,591 - mmseg - INFO - Iter [6850/10000]	lr: 3.537e-02, eta: 0:49:25, time: 0.914, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0639, decode.acc_seg: 96.7046, aux_0.loss_ce: 0.0654, aux_0.acc_seg: 96.6812, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 95.9885, aux_2.loss_ce: 0.1211, aux_2.loss_dice: 0.2536, aux_2.acc_seg: 95.9102, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.3408, loss: 0.6777
2023-05-03 14:23:37,453 - mmseg - INFO - Iter [6900/10000]	lr: 3.486e-02, eta: 0:48:37, time: 0.917, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0600, decode.acc_seg: 96.8103, aux_0.loss_ce: 0.0616, aux_0.acc_seg: 96.7772, aux_1.loss_ce: 0.0738, aux_1.acc_seg: 96.1064, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.0235, aux_3.loss_ce: 0.0900, aux_3.acc_seg: 95.4859, loss: 0.6528
2023-05-03 14:24:23,056 - mmseg - INFO - Iter [6950/10000]	lr: 3.436e-02, eta: 0:47:49, time: 0.912, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0601, decode.acc_seg: 96.7810, aux_0.loss_ce: 0.0617, aux_0.acc_seg: 96.7410, aux_1.loss_ce: 0.0742, aux_1.acc_seg: 96.0531, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2507, aux_2.acc_seg: 96.0143, aux_3.loss_ce: 0.0909, aux_3.acc_seg: 95.3979, loss: 0.6552
2023-05-03 14:25:12,695 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-05-03 14:25:14,571 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:25:14,571 - mmseg - INFO - Iter [7000/10000]	lr: 3.385e-02, eta: 0:47:04, time: 1.031, data_time: 0.280, memory: 14792, decode.loss_ce: 0.0590, decode.acc_seg: 96.8489, aux_0.loss_ce: 0.0606, aux_0.acc_seg: 96.8201, aux_1.loss_ce: 0.0731, aux_1.acc_seg: 96.1506, aux_2.loss_ce: 0.1179, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 96.0392, aux_3.loss_ce: 0.0901, aux_3.acc_seg: 95.4798, loss: 0.6524
2023-05-03 14:25:20,035 - mmseg - INFO - per class results:
2023-05-03 14:25:20,037 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.38 | 93.71 |
|   Building  | 93.89 | 95.94 |
|     Car     | 93.89 | 95.69 |
| Column_Pole | 30.07 | 36.11 |
|    Fence    | 81.71 | 90.63 |
|  Pedestrian | 68.64 | 82.32 |
|     Road    | 97.84 | 98.68 |
|   Sidewalk  | 92.77 | 97.14 |
|  SignSymbol |  0.65 |  0.66 |
|     Sky     | 94.38 | 97.06 |
|     Tree    | 92.39 | 98.03 |
+-------------+-------+-------+
2023-05-03 14:25:20,037 - mmseg - INFO - Summary:
2023-05-03 14:25:20,037 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.56 | 75.69 | 80.54 |
+-------+-------+-------+
2023-05-03 14:25:20,037 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:25:20,037 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9656, mIoU: 0.7569, mAcc: 0.8054, IoU.Bicyclist: 0.8638, IoU.Building: 0.9389, IoU.Car: 0.9389, IoU.Column_Pole: 0.3007, IoU.Fence: 0.8171, IoU.Pedestrian: 0.6864, IoU.Road: 0.9784, IoU.Sidewalk: 0.9277, IoU.SignSymbol: 0.0065, IoU.Sky: 0.9438, IoU.Tree: 0.9239, Acc.Bicyclist: 0.9371, Acc.Building: 0.9594, Acc.Car: 0.9569, Acc.Column_Pole: 0.3611, Acc.Fence: 0.9063, Acc.Pedestrian: 0.8232, Acc.Road: 0.9868, Acc.Sidewalk: 0.9714, Acc.SignSymbol: 0.0066, Acc.Sky: 0.9706, Acc.Tree: 0.9803
2023-05-03 14:26:05,788 - mmseg - INFO - Iter [7050/10000]	lr: 3.334e-02, eta: 0:46:19, time: 1.024, data_time: 0.310, memory: 14792, decode.loss_ce: 0.0591, decode.acc_seg: 96.8558, aux_0.loss_ce: 0.0604, aux_0.acc_seg: 96.8398, aux_1.loss_ce: 0.0727, aux_1.acc_seg: 96.1740, aux_2.loss_ce: 0.1165, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0865, aux_3.loss_ce: 0.0897, aux_3.acc_seg: 95.5102, loss: 0.6493
2023-05-03 14:26:51,489 - mmseg - INFO - Iter [7100/10000]	lr: 3.283e-02, eta: 0:45:31, time: 0.914, data_time: 0.199, memory: 14792, decode.loss_ce: 0.0616, decode.acc_seg: 96.7828, aux_0.loss_ce: 0.0628, aux_0.acc_seg: 96.7777, aux_1.loss_ce: 0.0752, aux_1.acc_seg: 96.1234, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.0597, aux_3.loss_ce: 0.0915, aux_3.acc_seg: 95.5187, loss: 0.6596
2023-05-03 14:27:37,086 - mmseg - INFO - Iter [7150/10000]	lr: 3.232e-02, eta: 0:44:43, time: 0.912, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0593, decode.acc_seg: 96.7831, aux_0.loss_ce: 0.0605, aux_0.acc_seg: 96.7826, aux_1.loss_ce: 0.0726, aux_1.acc_seg: 96.1182, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.0542, aux_3.loss_ce: 0.0892, aux_3.acc_seg: 95.4637, loss: 0.6472
2023-05-03 14:28:26,223 - mmseg - INFO - Iter [7200/10000]	lr: 3.181e-02, eta: 0:43:57, time: 0.983, data_time: 0.272, memory: 14792, decode.loss_ce: 0.0598, decode.acc_seg: 96.8877, aux_0.loss_ce: 0.0611, aux_0.acc_seg: 96.8620, aux_1.loss_ce: 0.0734, aux_1.acc_seg: 96.2168, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 96.0134, aux_3.loss_ce: 0.0904, aux_3.acc_seg: 95.5588, loss: 0.6564
2023-05-03 14:29:11,926 - mmseg - INFO - Iter [7250/10000]	lr: 3.130e-02, eta: 0:43:10, time: 0.914, data_time: 0.203, memory: 14792, decode.loss_ce: 0.0577, decode.acc_seg: 96.8756, aux_0.loss_ce: 0.0590, aux_0.acc_seg: 96.8578, aux_1.loss_ce: 0.0714, aux_1.acc_seg: 96.1792, aux_2.loss_ce: 0.1154, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.1182, aux_3.loss_ce: 0.0880, aux_3.acc_seg: 95.5295, loss: 0.6406
2023-05-03 14:29:57,484 - mmseg - INFO - Iter [7300/10000]	lr: 3.079e-02, eta: 0:42:22, time: 0.911, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0604, decode.acc_seg: 96.7628, aux_0.loss_ce: 0.0621, aux_0.acc_seg: 96.7344, aux_1.loss_ce: 0.0741, aux_1.acc_seg: 96.0596, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 96.0050, aux_3.loss_ce: 0.0914, aux_3.acc_seg: 95.3933, loss: 0.6572
2023-05-03 14:30:46,647 - mmseg - INFO - Iter [7350/10000]	lr: 3.027e-02, eta: 0:41:36, time: 0.983, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0584, decode.acc_seg: 96.8636, aux_0.loss_ce: 0.0597, aux_0.acc_seg: 96.8416, aux_1.loss_ce: 0.0725, aux_1.acc_seg: 96.1447, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 96.0055, aux_3.loss_ce: 0.0900, aux_3.acc_seg: 95.4410, loss: 0.6483
2023-05-03 14:31:32,777 - mmseg - INFO - Iter [7400/10000]	lr: 2.976e-02, eta: 0:40:48, time: 0.923, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0579, decode.acc_seg: 96.9086, aux_0.loss_ce: 0.0591, aux_0.acc_seg: 96.8950, aux_1.loss_ce: 0.0714, aux_1.acc_seg: 96.2305, aux_2.loss_ce: 0.1180, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 96.0324, aux_3.loss_ce: 0.0886, aux_3.acc_seg: 95.5443, loss: 0.6462
2023-05-03 14:32:18,639 - mmseg - INFO - Iter [7450/10000]	lr: 2.924e-02, eta: 0:40:01, time: 0.917, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0573, decode.acc_seg: 96.9478, aux_0.loss_ce: 0.0586, aux_0.acc_seg: 96.9412, aux_1.loss_ce: 0.0710, aux_1.acc_seg: 96.2719, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.0713, aux_3.loss_ce: 0.0880, aux_3.acc_seg: 95.6024, loss: 0.6414
2023-05-03 14:33:04,241 - mmseg - INFO - Iter [7500/10000]	lr: 2.873e-02, eta: 0:39:13, time: 0.912, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0595, decode.acc_seg: 96.8586, aux_0.loss_ce: 0.0608, aux_0.acc_seg: 96.8504, aux_1.loss_ce: 0.0733, aux_1.acc_seg: 96.1744, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2516, aux_2.acc_seg: 96.0073, aux_3.loss_ce: 0.0912, aux_3.acc_seg: 95.4913, loss: 0.6549
2023-05-03 14:33:51,881 - mmseg - INFO - Iter [7550/10000]	lr: 2.821e-02, eta: 0:38:26, time: 0.953, data_time: 0.254, memory: 14792, decode.loss_ce: 0.0579, decode.acc_seg: 96.8964, aux_0.loss_ce: 0.0595, aux_0.acc_seg: 96.8713, aux_1.loss_ce: 0.0715, aux_1.acc_seg: 96.2180, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.0120, aux_3.loss_ce: 0.0891, aux_3.acc_seg: 95.5140, loss: 0.6452
2023-05-03 14:34:37,853 - mmseg - INFO - Iter [7600/10000]	lr: 2.769e-02, eta: 0:37:39, time: 0.919, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0594, decode.acc_seg: 96.8437, aux_0.loss_ce: 0.0607, aux_0.acc_seg: 96.8366, aux_1.loss_ce: 0.0728, aux_1.acc_seg: 96.1751, aux_2.loss_ce: 0.1197, aux_2.loss_dice: 0.2521, aux_2.acc_seg: 95.9596, aux_3.loss_ce: 0.0911, aux_3.acc_seg: 95.4712, loss: 0.6558
2023-05-03 14:35:23,147 - mmseg - INFO - Iter [7650/10000]	lr: 2.717e-02, eta: 0:36:51, time: 0.906, data_time: 0.195, memory: 14792, decode.loss_ce: 0.0572, decode.acc_seg: 96.9064, aux_0.loss_ce: 0.0589, aux_0.acc_seg: 96.8795, aux_1.loss_ce: 0.0712, aux_1.acc_seg: 96.1863, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.0962, aux_3.loss_ce: 0.0890, aux_3.acc_seg: 95.4653, loss: 0.6410
2023-05-03 14:36:08,984 - mmseg - INFO - Iter [7700/10000]	lr: 2.665e-02, eta: 0:36:04, time: 0.917, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0569, decode.acc_seg: 96.9382, aux_0.loss_ce: 0.0584, aux_0.acc_seg: 96.9203, aux_1.loss_ce: 0.0711, aux_1.acc_seg: 96.2290, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 95.9818, aux_3.loss_ce: 0.0888, aux_3.acc_seg: 95.5445, loss: 0.6426
2023-05-03 14:36:58,572 - mmseg - INFO - Iter [7750/10000]	lr: 2.613e-02, eta: 0:35:17, time: 0.992, data_time: 0.276, memory: 14792, decode.loss_ce: 0.0567, decode.acc_seg: 96.9154, aux_0.loss_ce: 0.0583, aux_0.acc_seg: 96.8830, aux_1.loss_ce: 0.0701, aux_1.acc_seg: 96.2268, aux_2.loss_ce: 0.1153, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 96.0723, aux_3.loss_ce: 0.0868, aux_3.acc_seg: 95.5543, loss: 0.6345
2023-05-03 14:37:44,911 - mmseg - INFO - Iter [7800/10000]	lr: 2.561e-02, eta: 0:34:30, time: 0.927, data_time: 0.210, memory: 14792, decode.loss_ce: 0.0578, decode.acc_seg: 96.9284, aux_0.loss_ce: 0.0589, aux_0.acc_seg: 96.9165, aux_1.loss_ce: 0.0713, aux_1.acc_seg: 96.2514, aux_2.loss_ce: 0.1179, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.0190, aux_3.loss_ce: 0.0901, aux_3.acc_seg: 95.5150, loss: 0.6470
2023-05-03 14:38:30,767 - mmseg - INFO - Iter [7850/10000]	lr: 2.508e-02, eta: 0:33:43, time: 0.917, data_time: 0.203, memory: 14792, decode.loss_ce: 0.0582, decode.acc_seg: 96.8706, aux_0.loss_ce: 0.0596, aux_0.acc_seg: 96.8544, aux_1.loss_ce: 0.0721, aux_1.acc_seg: 96.1800, aux_2.loss_ce: 0.1192, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 95.9475, aux_3.loss_ce: 0.0899, aux_3.acc_seg: 95.4753, loss: 0.6490
2023-05-03 14:39:19,982 - mmseg - INFO - Iter [7900/10000]	lr: 2.456e-02, eta: 0:32:56, time: 0.984, data_time: 0.271, memory: 14792, decode.loss_ce: 0.0600, decode.acc_seg: 96.8143, aux_0.loss_ce: 0.0616, aux_0.acc_seg: 96.7898, aux_1.loss_ce: 0.0734, aux_1.acc_seg: 96.1449, aux_2.loss_ce: 0.1161, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.0774, aux_3.loss_ce: 0.0904, aux_3.acc_seg: 95.4810, loss: 0.6506
2023-05-03 14:40:05,180 - mmseg - INFO - Iter [7950/10000]	lr: 2.403e-02, eta: 0:32:09, time: 0.904, data_time: 0.191, memory: 14792, decode.loss_ce: 0.0590, decode.acc_seg: 96.8074, aux_0.loss_ce: 0.0605, aux_0.acc_seg: 96.7738, aux_1.loss_ce: 0.0728, aux_1.acc_seg: 96.0908, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2481, aux_2.acc_seg: 96.0759, aux_3.loss_ce: 0.0887, aux_3.acc_seg: 95.4649, loss: 0.6446
2023-05-03 14:40:51,039 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-05-03 14:40:53,383 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:40:53,383 - mmseg - INFO - Iter [8000/10000]	lr: 2.350e-02, eta: 0:31:22, time: 0.965, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0572, decode.acc_seg: 96.9699, aux_0.loss_ce: 0.0584, aux_0.acc_seg: 96.9613, aux_1.loss_ce: 0.0710, aux_1.acc_seg: 96.2789, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.0170, aux_3.loss_ce: 0.0892, aux_3.acc_seg: 95.5663, loss: 0.6431
2023-05-03 14:40:58,708 - mmseg - INFO - per class results:
2023-05-03 14:40:58,709 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 84.74 | 88.68 |
|   Building  | 93.44 | 95.69 |
|     Car     |  93.3 | 94.55 |
| Column_Pole | 26.04 | 30.65 |
|    Fence    | 81.28 |  94.3 |
|  Pedestrian | 67.95 | 78.36 |
|     Road    |  97.7 | 98.81 |
|   Sidewalk  | 92.47 | 96.49 |
|  SignSymbol |  0.49 |  0.49 |
|     Sky     | 94.24 | 97.47 |
|     Tree    | 92.33 | 97.86 |
+-------------+-------+-------+
2023-05-03 14:40:58,709 - mmseg - INFO - Summary:
2023-05-03 14:40:58,709 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 96.4 | 74.91 | 79.39 |
+------+-------+-------+
2023-05-03 14:40:58,709 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:40:58,710 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9640, mIoU: 0.7491, mAcc: 0.7939, IoU.Bicyclist: 0.8474, IoU.Building: 0.9344, IoU.Car: 0.9330, IoU.Column_Pole: 0.2604, IoU.Fence: 0.8128, IoU.Pedestrian: 0.6795, IoU.Road: 0.9770, IoU.Sidewalk: 0.9247, IoU.SignSymbol: 0.0049, IoU.Sky: 0.9424, IoU.Tree: 0.9233, Acc.Bicyclist: 0.8868, Acc.Building: 0.9569, Acc.Car: 0.9455, Acc.Column_Pole: 0.3065, Acc.Fence: 0.9430, Acc.Pedestrian: 0.7836, Acc.Road: 0.9881, Acc.Sidewalk: 0.9649, Acc.SignSymbol: 0.0049, Acc.Sky: 0.9747, Acc.Tree: 0.9786
2023-05-03 14:41:44,304 - mmseg - INFO - Iter [8050/10000]	lr: 2.297e-02, eta: 0:30:36, time: 1.018, data_time: 0.303, memory: 14792, decode.loss_ce: 0.0595, decode.acc_seg: 96.8881, aux_0.loss_ce: 0.0607, aux_0.acc_seg: 96.8816, aux_1.loss_ce: 0.0733, aux_1.acc_seg: 96.2050, aux_2.loss_ce: 0.1188, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 95.9949, aux_3.loss_ce: 0.0918, aux_3.acc_seg: 95.4788, loss: 0.6558
2023-05-03 14:42:33,595 - mmseg - INFO - Iter [8100/10000]	lr: 2.244e-02, eta: 0:29:49, time: 0.986, data_time: 0.272, memory: 14792, decode.loss_ce: 0.0569, decode.acc_seg: 96.9177, aux_0.loss_ce: 0.0581, aux_0.acc_seg: 96.9126, aux_1.loss_ce: 0.0711, aux_1.acc_seg: 96.1950, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 95.9386, aux_3.loss_ce: 0.0894, aux_3.acc_seg: 95.4884, loss: 0.6451
2023-05-03 14:43:19,633 - mmseg - INFO - Iter [8150/10000]	lr: 2.191e-02, eta: 0:29:02, time: 0.921, data_time: 0.207, memory: 14792, decode.loss_ce: 0.0542, decode.acc_seg: 97.0496, aux_0.loss_ce: 0.0556, aux_0.acc_seg: 97.0198, aux_1.loss_ce: 0.0676, aux_1.acc_seg: 96.3658, aux_2.loss_ce: 0.1154, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.1038, aux_3.loss_ce: 0.0851, aux_3.acc_seg: 95.6635, loss: 0.6265
2023-05-03 14:44:05,129 - mmseg - INFO - Iter [8200/10000]	lr: 2.138e-02, eta: 0:28:14, time: 0.910, data_time: 0.197, memory: 14792, decode.loss_ce: 0.0567, decode.acc_seg: 97.0065, aux_0.loss_ce: 0.0584, aux_0.acc_seg: 96.9706, aux_1.loss_ce: 0.0704, aux_1.acc_seg: 96.3057, aux_2.loss_ce: 0.1159, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.1168, aux_3.loss_ce: 0.0882, aux_3.acc_seg: 95.6091, loss: 0.6391
2023-05-03 14:44:50,833 - mmseg - INFO - Iter [8250/10000]	lr: 2.084e-02, eta: 0:27:27, time: 0.914, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0582, decode.acc_seg: 96.9260, aux_0.loss_ce: 0.0593, aux_0.acc_seg: 96.9132, aux_1.loss_ce: 0.0720, aux_1.acc_seg: 96.2241, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2541, aux_2.acc_seg: 95.9543, aux_3.loss_ce: 0.0906, aux_3.acc_seg: 95.4956, loss: 0.6547
2023-05-03 14:45:39,849 - mmseg - INFO - Iter [8300/10000]	lr: 2.031e-02, eta: 0:26:40, time: 0.980, data_time: 0.272, memory: 14792, decode.loss_ce: 0.0577, decode.acc_seg: 96.9158, aux_0.loss_ce: 0.0593, aux_0.acc_seg: 96.8898, aux_1.loss_ce: 0.0712, aux_1.acc_seg: 96.2394, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 95.9986, aux_3.loss_ce: 0.0891, aux_3.acc_seg: 95.5238, loss: 0.6448
2023-05-03 14:46:25,367 - mmseg - INFO - Iter [8350/10000]	lr: 1.977e-02, eta: 0:25:53, time: 0.910, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0561, decode.acc_seg: 96.9904, aux_0.loss_ce: 0.0575, aux_0.acc_seg: 96.9615, aux_1.loss_ce: 0.0700, aux_1.acc_seg: 96.2619, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.0030, aux_3.loss_ce: 0.0883, aux_3.acc_seg: 95.5361, loss: 0.6402
2023-05-03 14:47:10,797 - mmseg - INFO - Iter [8400/10000]	lr: 1.923e-02, eta: 0:25:06, time: 0.909, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0563, decode.acc_seg: 96.9815, aux_0.loss_ce: 0.0577, aux_0.acc_seg: 96.9615, aux_1.loss_ce: 0.0698, aux_1.acc_seg: 96.3101, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 96.0937, aux_3.loss_ce: 0.0883, aux_3.acc_seg: 95.5633, loss: 0.6377
2023-05-03 14:48:00,167 - mmseg - INFO - Iter [8450/10000]	lr: 1.869e-02, eta: 0:24:19, time: 0.987, data_time: 0.273, memory: 14792, decode.loss_ce: 0.0562, decode.acc_seg: 96.9285, aux_0.loss_ce: 0.0576, aux_0.acc_seg: 96.9029, aux_1.loss_ce: 0.0697, aux_1.acc_seg: 96.2327, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.0473, aux_3.loss_ce: 0.0883, aux_3.acc_seg: 95.4717, loss: 0.6386
2023-05-03 14:48:45,655 - mmseg - INFO - Iter [8500/10000]	lr: 1.815e-02, eta: 0:23:32, time: 0.910, data_time: 0.200, memory: 14792, decode.loss_ce: 0.0563, decode.acc_seg: 96.9892, aux_0.loss_ce: 0.0578, aux_0.acc_seg: 96.9554, aux_1.loss_ce: 0.0702, aux_1.acc_seg: 96.2855, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 95.9946, aux_3.loss_ce: 0.0889, aux_3.acc_seg: 95.5400, loss: 0.6424
2023-05-03 14:49:31,325 - mmseg - INFO - Iter [8550/10000]	lr: 1.760e-02, eta: 0:22:44, time: 0.913, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0564, decode.acc_seg: 96.9343, aux_0.loss_ce: 0.0577, aux_0.acc_seg: 96.9198, aux_1.loss_ce: 0.0704, aux_1.acc_seg: 96.2146, aux_2.loss_ce: 0.1179, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 95.9922, aux_3.loss_ce: 0.0890, aux_3.acc_seg: 95.4637, loss: 0.6410
2023-05-03 14:50:16,577 - mmseg - INFO - Iter [8600/10000]	lr: 1.705e-02, eta: 0:21:57, time: 0.905, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0550, decode.acc_seg: 97.0354, aux_0.loss_ce: 0.0565, aux_0.acc_seg: 97.0112, aux_1.loss_ce: 0.0687, aux_1.acc_seg: 96.3395, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.0467, aux_3.loss_ce: 0.0865, aux_3.acc_seg: 95.6289, loss: 0.6320
2023-05-03 14:51:05,532 - mmseg - INFO - Iter [8650/10000]	lr: 1.650e-02, eta: 0:21:10, time: 0.979, data_time: 0.269, memory: 14792, decode.loss_ce: 0.0562, decode.acc_seg: 96.9538, aux_0.loss_ce: 0.0575, aux_0.acc_seg: 96.9321, aux_1.loss_ce: 0.0703, aux_1.acc_seg: 96.2368, aux_2.loss_ce: 0.1172, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 95.9948, aux_3.loss_ce: 0.0892, aux_3.acc_seg: 95.4742, loss: 0.6386
2023-05-03 14:51:50,121 - mmseg - INFO - Iter [8700/10000]	lr: 1.595e-02, eta: 0:20:23, time: 0.892, data_time: 0.191, memory: 14792, decode.loss_ce: 0.0555, decode.acc_seg: 97.0381, aux_0.loss_ce: 0.0571, aux_0.acc_seg: 97.0045, aux_1.loss_ce: 0.0696, aux_1.acc_seg: 96.3360, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 96.0163, aux_3.loss_ce: 0.0880, aux_3.acc_seg: 95.6120, loss: 0.6382
2023-05-03 14:52:35,745 - mmseg - INFO - Iter [8750/10000]	lr: 1.540e-02, eta: 0:19:36, time: 0.912, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0551, decode.acc_seg: 96.9849, aux_0.loss_ce: 0.0562, aux_0.acc_seg: 96.9824, aux_1.loss_ce: 0.0685, aux_1.acc_seg: 96.2991, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2483, aux_2.acc_seg: 96.0756, aux_3.loss_ce: 0.0868, aux_3.acc_seg: 95.5583, loss: 0.6305
2023-05-03 14:53:21,296 - mmseg - INFO - Iter [8800/10000]	lr: 1.485e-02, eta: 0:18:48, time: 0.911, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0536, decode.acc_seg: 97.1130, aux_0.loss_ce: 0.0549, aux_0.acc_seg: 97.0858, aux_1.loss_ce: 0.0671, aux_1.acc_seg: 96.4285, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.0472, aux_3.loss_ce: 0.0854, aux_3.acc_seg: 95.6932, loss: 0.6266
2023-05-03 14:54:10,445 - mmseg - INFO - Iter [8850/10000]	lr: 1.429e-02, eta: 0:18:02, time: 0.983, data_time: 0.272, memory: 14792, decode.loss_ce: 0.0561, decode.acc_seg: 97.0316, aux_0.loss_ce: 0.0573, aux_0.acc_seg: 97.0088, aux_1.loss_ce: 0.0700, aux_1.acc_seg: 96.3367, aux_2.loss_ce: 0.1189, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 95.9700, aux_3.loss_ce: 0.0890, aux_3.acc_seg: 95.5700, loss: 0.6421
2023-05-03 14:54:56,095 - mmseg - INFO - Iter [8900/10000]	lr: 1.373e-02, eta: 0:17:14, time: 0.913, data_time: 0.202, memory: 14792, decode.loss_ce: 0.0555, decode.acc_seg: 96.9485, aux_0.loss_ce: 0.0570, aux_0.acc_seg: 96.9163, aux_1.loss_ce: 0.0694, aux_1.acc_seg: 96.2295, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 95.9932, aux_3.loss_ce: 0.0880, aux_3.acc_seg: 95.4708, loss: 0.6360
2023-05-03 14:55:41,995 - mmseg - INFO - Iter [8950/10000]	lr: 1.317e-02, eta: 0:16:27, time: 0.918, data_time: 0.205, memory: 14792, decode.loss_ce: 0.0537, decode.acc_seg: 97.1182, aux_0.loss_ce: 0.0548, aux_0.acc_seg: 97.1042, aux_1.loss_ce: 0.0672, aux_1.acc_seg: 96.4353, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.0503, aux_3.loss_ce: 0.0866, aux_3.acc_seg: 95.6509, loss: 0.6285
2023-05-03 14:56:31,182 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-05-03 14:56:33,077 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:56:33,077 - mmseg - INFO - Iter [9000/10000]	lr: 1.260e-02, eta: 0:15:41, time: 1.022, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0531, decode.acc_seg: 97.1358, aux_0.loss_ce: 0.0545, aux_0.acc_seg: 97.1078, aux_1.loss_ce: 0.0668, aux_1.acc_seg: 96.4420, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.0888, aux_3.loss_ce: 0.0854, aux_3.acc_seg: 95.6810, loss: 0.6253
2023-05-03 14:56:39,202 - mmseg - INFO - per class results:
2023-05-03 14:56:39,204 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.39 | 92.85 |
|   Building  | 93.83 | 95.75 |
|     Car     | 93.18 | 95.51 |
| Column_Pole | 23.63 | 26.29 |
|    Fence    | 83.04 | 94.14 |
|  Pedestrian |  69.2 | 82.98 |
|     Road    | 97.79 | 98.65 |
|   Sidewalk  | 92.71 | 97.04 |
|  SignSymbol |  0.73 |  0.73 |
|     Sky     | 93.98 | 96.97 |
|     Tree    | 92.64 | 98.25 |
+-------------+-------+-------+
2023-05-03 14:56:39,204 - mmseg - INFO - Summary:
2023-05-03 14:56:39,204 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.56 | 75.19 | 79.92 |
+-------+-------+-------+
2023-05-03 14:56:39,205 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 14:56:39,205 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9656, mIoU: 0.7519, mAcc: 0.7992, IoU.Bicyclist: 0.8639, IoU.Building: 0.9383, IoU.Car: 0.9318, IoU.Column_Pole: 0.2363, IoU.Fence: 0.8304, IoU.Pedestrian: 0.6920, IoU.Road: 0.9779, IoU.Sidewalk: 0.9271, IoU.SignSymbol: 0.0073, IoU.Sky: 0.9398, IoU.Tree: 0.9264, Acc.Bicyclist: 0.9285, Acc.Building: 0.9575, Acc.Car: 0.9551, Acc.Column_Pole: 0.2629, Acc.Fence: 0.9414, Acc.Pedestrian: 0.8298, Acc.Road: 0.9865, Acc.Sidewalk: 0.9704, Acc.SignSymbol: 0.0073, Acc.Sky: 0.9697, Acc.Tree: 0.9825
2023-05-03 14:57:24,589 - mmseg - INFO - Iter [9050/10000]	lr: 1.203e-02, eta: 0:14:54, time: 1.030, data_time: 0.322, memory: 14792, decode.loss_ce: 0.0521, decode.acc_seg: 97.1522, aux_0.loss_ce: 0.0535, aux_0.acc_seg: 97.1282, aux_1.loss_ce: 0.0659, aux_1.acc_seg: 96.4355, aux_2.loss_ce: 0.1143, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.1105, aux_3.loss_ce: 0.0838, aux_3.acc_seg: 95.7075, loss: 0.6166
2023-05-03 14:58:09,758 - mmseg - INFO - Iter [9100/10000]	lr: 1.146e-02, eta: 0:14:07, time: 0.903, data_time: 0.198, memory: 14792, decode.loss_ce: 0.0553, decode.acc_seg: 97.0199, aux_0.loss_ce: 0.0567, aux_0.acc_seg: 96.9924, aux_1.loss_ce: 0.0695, aux_1.acc_seg: 96.2880, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 95.9426, aux_3.loss_ce: 0.0890, aux_3.acc_seg: 95.5271, loss: 0.6377
2023-05-03 14:58:55,256 - mmseg - INFO - Iter [9150/10000]	lr: 1.089e-02, eta: 0:13:19, time: 0.910, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0549, decode.acc_seg: 97.0747, aux_0.loss_ce: 0.0563, aux_0.acc_seg: 97.0464, aux_1.loss_ce: 0.0690, aux_1.acc_seg: 96.3693, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 95.9878, aux_3.loss_ce: 0.0881, aux_3.acc_seg: 95.6023, loss: 0.6374
2023-05-03 14:59:44,375 - mmseg - INFO - Iter [9200/10000]	lr: 1.031e-02, eta: 0:12:33, time: 0.982, data_time: 0.275, memory: 14792, decode.loss_ce: 0.0551, decode.acc_seg: 97.0771, aux_0.loss_ce: 0.0562, aux_0.acc_seg: 97.0703, aux_1.loss_ce: 0.0686, aux_1.acc_seg: 96.4111, aux_2.loss_ce: 0.1179, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 96.0053, aux_3.loss_ce: 0.0882, aux_3.acc_seg: 95.6299, loss: 0.6362
2023-05-03 15:00:29,850 - mmseg - INFO - Iter [9250/10000]	lr: 9.730e-03, eta: 0:11:45, time: 0.909, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0548, decode.acc_seg: 97.0291, aux_0.loss_ce: 0.0561, aux_0.acc_seg: 97.0117, aux_1.loss_ce: 0.0689, aux_1.acc_seg: 96.3060, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 96.0038, aux_3.loss_ce: 0.0878, aux_3.acc_seg: 95.5401, loss: 0.6349
2023-05-03 15:01:15,892 - mmseg - INFO - Iter [9300/10000]	lr: 9.145e-03, eta: 0:10:58, time: 0.921, data_time: 0.205, memory: 14792, decode.loss_ce: 0.0554, decode.acc_seg: 97.0170, aux_0.loss_ce: 0.0567, aux_0.acc_seg: 96.9915, aux_1.loss_ce: 0.0693, aux_1.acc_seg: 96.3031, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.0117, aux_3.loss_ce: 0.0888, aux_3.acc_seg: 95.5015, loss: 0.6369
2023-05-03 15:02:01,778 - mmseg - INFO - Iter [9350/10000]	lr: 8.556e-03, eta: 0:10:11, time: 0.918, data_time: 0.204, memory: 14792, decode.loss_ce: 0.0543, decode.acc_seg: 97.0678, aux_0.loss_ce: 0.0560, aux_0.acc_seg: 97.0321, aux_1.loss_ce: 0.0682, aux_1.acc_seg: 96.3527, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2483, aux_2.acc_seg: 96.0201, aux_3.loss_ce: 0.0876, aux_3.acc_seg: 95.5427, loss: 0.6312
2023-05-03 15:02:51,071 - mmseg - INFO - Iter [9400/10000]	lr: 7.962e-03, eta: 0:09:24, time: 0.986, data_time: 0.274, memory: 14792, decode.loss_ce: 0.0536, decode.acc_seg: 97.1086, aux_0.loss_ce: 0.0551, aux_0.acc_seg: 97.0828, aux_1.loss_ce: 0.0675, aux_1.acc_seg: 96.4121, aux_2.loss_ce: 0.1157, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 96.0341, aux_3.loss_ce: 0.0862, aux_3.acc_seg: 95.6570, loss: 0.6255
2023-05-03 15:03:36,021 - mmseg - INFO - Iter [9450/10000]	lr: 7.364e-03, eta: 0:08:37, time: 0.899, data_time: 0.197, memory: 14792, decode.loss_ce: 0.0531, decode.acc_seg: 97.1022, aux_0.loss_ce: 0.0545, aux_0.acc_seg: 97.0752, aux_1.loss_ce: 0.0670, aux_1.acc_seg: 96.3877, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2476, aux_2.acc_seg: 96.0422, aux_3.loss_ce: 0.0863, aux_3.acc_seg: 95.5953, loss: 0.6245
2023-05-03 15:04:21,458 - mmseg - INFO - Iter [9500/10000]	lr: 6.759e-03, eta: 0:07:50, time: 0.909, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0525, decode.acc_seg: 97.1252, aux_0.loss_ce: 0.0540, aux_0.acc_seg: 97.0893, aux_1.loss_ce: 0.0667, aux_1.acc_seg: 96.3883, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 96.0499, aux_3.loss_ce: 0.0857, aux_3.acc_seg: 95.6147, loss: 0.6216
2023-05-03 15:05:10,151 - mmseg - INFO - Iter [9550/10000]	lr: 6.149e-03, eta: 0:07:03, time: 0.974, data_time: 0.266, memory: 14792, decode.loss_ce: 0.0537, decode.acc_seg: 97.0992, aux_0.loss_ce: 0.0552, aux_0.acc_seg: 97.0676, aux_1.loss_ce: 0.0677, aux_1.acc_seg: 96.3762, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.0683, aux_3.loss_ce: 0.0877, aux_3.acc_seg: 95.5891, loss: 0.6291
2023-05-03 15:05:55,523 - mmseg - INFO - Iter [9600/10000]	lr: 5.532e-03, eta: 0:06:16, time: 0.907, data_time: 0.201, memory: 14792, decode.loss_ce: 0.0542, decode.acc_seg: 97.0765, aux_0.loss_ce: 0.0556, aux_0.acc_seg: 97.0445, aux_1.loss_ce: 0.0680, aux_1.acc_seg: 96.3708, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 96.0437, aux_3.loss_ce: 0.0878, aux_3.acc_seg: 95.5640, loss: 0.6316
2023-05-03 15:06:40,514 - mmseg - INFO - Iter [9650/10000]	lr: 4.908e-03, eta: 0:05:29, time: 0.900, data_time: 0.197, memory: 14792, decode.loss_ce: 0.0531, decode.acc_seg: 97.1356, aux_0.loss_ce: 0.0545, aux_0.acc_seg: 97.1078, aux_1.loss_ce: 0.0668, aux_1.acc_seg: 96.4358, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.0621, aux_3.loss_ce: 0.0865, aux_3.acc_seg: 95.6468, loss: 0.6271
2023-05-03 15:07:25,614 - mmseg - INFO - Iter [9700/10000]	lr: 4.274e-03, eta: 0:04:42, time: 0.902, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0525, decode.acc_seg: 97.0989, aux_0.loss_ce: 0.0541, aux_0.acc_seg: 97.0689, aux_1.loss_ce: 0.0665, aux_1.acc_seg: 96.3789, aux_2.loss_ce: 0.1152, aux_2.loss_dice: 0.2466, aux_2.acc_seg: 96.0687, aux_3.loss_ce: 0.0860, aux_3.acc_seg: 95.5602, loss: 0.6209
2023-05-03 15:08:14,549 - mmseg - INFO - Iter [9750/10000]	lr: 3.629e-03, eta: 0:03:55, time: 0.979, data_time: 0.268, memory: 14792, decode.loss_ce: 0.0522, decode.acc_seg: 97.1577, aux_0.loss_ce: 0.0535, aux_0.acc_seg: 97.1333, aux_1.loss_ce: 0.0659, aux_1.acc_seg: 96.4631, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 96.0888, aux_3.loss_ce: 0.0847, aux_3.acc_seg: 95.6785, loss: 0.6177
2023-05-03 15:08:59,867 - mmseg - INFO - Iter [9800/10000]	lr: 2.972e-03, eta: 0:03:08, time: 0.906, data_time: 0.197, memory: 14792, decode.loss_ce: 0.0514, decode.acc_seg: 97.2095, aux_0.loss_ce: 0.0529, aux_0.acc_seg: 97.1788, aux_1.loss_ce: 0.0652, aux_1.acc_seg: 96.5048, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 96.0325, aux_3.loss_ce: 0.0848, aux_3.acc_seg: 95.7173, loss: 0.6183
2023-05-03 15:09:44,785 - mmseg - INFO - Iter [9850/10000]	lr: 2.298e-03, eta: 0:02:21, time: 0.898, data_time: 0.194, memory: 14792, decode.loss_ce: 0.0535, decode.acc_seg: 97.1082, aux_0.loss_ce: 0.0551, aux_0.acc_seg: 97.0660, aux_1.loss_ce: 0.0675, aux_1.acc_seg: 96.3964, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 96.0176, aux_3.loss_ce: 0.0872, aux_3.acc_seg: 95.5909, loss: 0.6307
2023-05-03 15:10:30,285 - mmseg - INFO - Iter [9900/10000]	lr: 1.600e-03, eta: 0:01:34, time: 0.910, data_time: 0.198, memory: 14792, decode.loss_ce: 0.0532, decode.acc_seg: 97.1297, aux_0.loss_ce: 0.0547, aux_0.acc_seg: 97.1035, aux_1.loss_ce: 0.0674, aux_1.acc_seg: 96.4106, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.0189, aux_3.loss_ce: 0.0871, aux_3.acc_seg: 95.6040, loss: 0.6294
2023-05-03 15:11:19,277 - mmseg - INFO - Iter [9950/10000]	lr: 8.656e-04, eta: 0:00:47, time: 0.980, data_time: 0.270, memory: 14792, decode.loss_ce: 0.0529, decode.acc_seg: 97.1225, aux_0.loss_ce: 0.0543, aux_0.acc_seg: 97.0871, aux_1.loss_ce: 0.0670, aux_1.acc_seg: 96.4002, aux_2.loss_ce: 0.1156, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 96.0455, aux_3.loss_ce: 0.0864, aux_3.acc_seg: 95.6156, loss: 0.6230
2023-05-03 15:12:04,474 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-05-03 15:12:06,830 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 15:12:06,830 - mmseg - INFO - Iter [10000/10000]	lr: 2.612e-05, eta: 0:00:00, time: 0.952, data_time: 0.196, memory: 14792, decode.loss_ce: 0.0538, decode.acc_seg: 97.0862, aux_0.loss_ce: 0.0555, aux_0.acc_seg: 97.0592, aux_1.loss_ce: 0.0679, aux_1.acc_seg: 96.3768, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.0005, aux_3.loss_ce: 0.0882, aux_3.acc_seg: 95.5415, loss: 0.6332
2023-05-03 15:12:12,327 - mmseg - INFO - per class results:
2023-05-03 15:12:12,328 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.36 | 93.99 |
|   Building  | 93.62 | 95.42 |
|     Car     | 93.67 | 95.69 |
| Column_Pole | 25.01 | 28.18 |
|    Fence    | 82.96 | 93.95 |
|  Pedestrian | 69.25 |  83.8 |
|     Road    | 97.85 | 98.68 |
|   Sidewalk  |  92.8 | 97.22 |
|  SignSymbol |  0.71 |  0.71 |
|     Sky     |  93.8 | 97.05 |
|     Tree    | 92.58 | 98.17 |
+-------------+-------+-------+
2023-05-03 15:12:12,328 - mmseg - INFO - Summary:
2023-05-03 15:12:12,328 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.53 | 75.33 | 80.26 |
+-------+-------+-------+
2023-05-03 15:12:12,329 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength19.py
2023-05-03 15:12:12,329 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9653, mIoU: 0.7533, mAcc: 0.8026, IoU.Bicyclist: 0.8636, IoU.Building: 0.9362, IoU.Car: 0.9367, IoU.Column_Pole: 0.2501, IoU.Fence: 0.8296, IoU.Pedestrian: 0.6925, IoU.Road: 0.9785, IoU.Sidewalk: 0.9280, IoU.SignSymbol: 0.0071, IoU.Sky: 0.9380, IoU.Tree: 0.9258, Acc.Bicyclist: 0.9399, Acc.Building: 0.9542, Acc.Car: 0.9569, Acc.Column_Pole: 0.2818, Acc.Fence: 0.9395, Acc.Pedestrian: 0.8380, Acc.Road: 0.9868, Acc.Sidewalk: 0.9722, Acc.SignSymbol: 0.0071, Acc.Sky: 0.9705, Acc.Tree: 0.9817
