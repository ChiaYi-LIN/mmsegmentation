2023-03-28 20:32:13,968 - mmseg - INFO - Multi-processing start method is `None`
2023-03-28 20:32:14,006 - mmseg - INFO - OpenCV num_threads is `96
2023-03-28 20:32:14,007 - mmseg - INFO - OMP num threads is 1
2023-03-28 20:32:14,128 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+792c24a
------------------------------------------------------------

2023-03-28 20:32:14,129 - mmseg - INFO - Distributed training: True
2023-03-28 20:32:15,005 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1035, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=13,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='UC',
        CLASSES=None),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CamVidDataset'
data_root = 'data/CamVid/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (720, 960)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 720), ratio_range=(0.5, 2.5)),
    dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 720),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=12,
    workers_per_gpu=4,
    train=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='train',
        ann_dir='train_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(2048, 720), ratio_range=(0.5, 2.5)),
            dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.01,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            text_encoder=dict(lr_mult=0.0, decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=200,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/stdc1-uctext_2x12_720x960_10k_camvid'
gpu_ids = range(0, 2)
auto_resume = False

2023-03-28 20:32:17,185 - mmseg - INFO - Set random seed to 1769576419, deterministic: False
2023-03-28 20:32:17,192 - mmseg - INFO - Loaded 367 images
2023-03-28 20:32:18,705 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-03-28 20:32:20,133 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.contexts - torch.Size([8, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.text_encoder.positional_embedding - torch.Size([13, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.text_projection - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.token_embedding.weight - torch.Size([49408, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1035, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1035, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-03-28 20:32:20,139 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1035, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1035, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-03-28 20:32:20,918 - mmseg - INFO - Loaded 101 images
2023-03-28 20:32:20,931 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1-uctext_2x12_720x960_10k_camvid
2023-03-28 20:32:20,931 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-03-28 20:32:20,932 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-03-28 20:32:20,932 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1-uctext_2x12_720x960_10k_camvid by HardDiskBackend.
2023-03-28 20:34:03,124 - mmseg - INFO - Iter [50/10000]	lr: 2.439e-03, eta: 5:37:30, time: 2.035, data_time: 0.840, memory: 9072, decode.loss_ce: 1.9095, decode.acc_seg: 35.6906, aux_0.loss_ce: 1.8023, aux_0.acc_seg: 21.1598, aux_1.loss_ce: 1.7855, aux_1.acc_seg: 22.2625, aux_2.loss_ce: 0.5424, aux_2.loss_dice: 0.4735, aux_2.acc_seg: 83.0439, aux_3.loss_ce: 1.8860, aux_3.acc_seg: 10.7115, loss: 8.3993
2023-03-28 20:35:05,560 - mmseg - INFO - Iter [100/10000]	lr: 4.906e-03, eta: 4:30:54, time: 1.248, data_time: 0.223, memory: 9072, decode.loss_ce: 0.9805, decode.acc_seg: 63.9805, aux_0.loss_ce: 0.9579, aux_0.acc_seg: 65.6953, aux_1.loss_ce: 0.9997, aux_1.acc_seg: 63.8472, aux_2.loss_ce: 0.2583, aux_2.loss_dice: 0.4465, aux_2.acc_seg: 95.7998, aux_3.loss_ce: 1.8376, aux_3.acc_seg: 19.3524, loss: 5.4805
2023-03-28 20:36:12,301 - mmseg - INFO - Iter [150/10000]	lr: 7.350e-03, eta: 4:12:45, time: 1.335, data_time: 0.241, memory: 9072, decode.loss_ce: 0.6067, decode.acc_seg: 77.3027, aux_0.loss_ce: 0.5450, aux_0.acc_seg: 80.2494, aux_1.loss_ce: 0.5671, aux_1.acc_seg: 79.4008, aux_2.loss_ce: 0.2171, aux_2.loss_dice: 0.3869, aux_2.acc_seg: 95.8436, aux_3.loss_ce: 1.8442, aux_3.acc_seg: 45.5293, loss: 4.1671
2023-03-28 20:37:17,358 - mmseg - INFO - Iter [200/10000]	lr: 9.772e-03, eta: 4:01:43, time: 1.301, data_time: 0.286, memory: 9072, decode.loss_ce: 0.3952, decode.acc_seg: 84.7634, aux_0.loss_ce: 0.3813, aux_0.acc_seg: 85.4835, aux_1.loss_ce: 0.3985, aux_1.acc_seg: 85.1829, aux_2.loss_ce: 0.1792, aux_2.loss_dice: 0.3405, aux_2.acc_seg: 95.8528, aux_3.loss_ce: 1.7825, aux_3.acc_seg: 67.5060, loss: 3.4772
2023-03-28 20:38:20,098 - mmseg - INFO - Iter [250/10000]	lr: 9.776e-03, eta: 3:53:10, time: 1.255, data_time: 0.225, memory: 9072, decode.loss_ce: 0.3208, decode.acc_seg: 87.0647, aux_0.loss_ce: 0.3278, aux_0.acc_seg: 87.3327, aux_1.loss_ce: 0.3408, aux_1.acc_seg: 86.9272, aux_2.loss_ce: 0.1577, aux_2.loss_dice: 0.3229, aux_2.acc_seg: 95.7647, aux_3.loss_ce: 1.6810, aux_3.acc_seg: 74.9012, loss: 3.1511
2023-03-28 20:39:27,103 - mmseg - INFO - Iter [300/10000]	lr: 9.731e-03, eta: 3:49:25, time: 1.340, data_time: 0.236, memory: 9072, decode.loss_ce: 0.2739, decode.acc_seg: 88.4231, aux_0.loss_ce: 0.2816, aux_0.acc_seg: 88.5516, aux_1.loss_ce: 0.2997, aux_1.acc_seg: 87.9272, aux_2.loss_ce: 0.1488, aux_2.loss_dice: 0.3132, aux_2.acc_seg: 95.7244, aux_3.loss_ce: 1.4261, aux_3.acc_seg: 80.1548, loss: 2.7433
2023-03-28 20:40:31,774 - mmseg - INFO - Iter [350/10000]	lr: 9.685e-03, eta: 3:45:21, time: 1.293, data_time: 0.283, memory: 9072, decode.loss_ce: 0.2387, decode.acc_seg: 89.5891, aux_0.loss_ce: 0.2469, aux_0.acc_seg: 89.7690, aux_1.loss_ce: 0.2708, aux_1.acc_seg: 88.8582, aux_2.loss_ce: 0.1449, aux_2.loss_dice: 0.3076, aux_2.acc_seg: 95.6895, aux_3.loss_ce: 1.0537, aux_3.acc_seg: 83.9856, loss: 2.2625
2023-03-28 20:41:31,270 - mmseg - INFO - Iter [400/10000]	lr: 9.640e-03, eta: 3:39:57, time: 1.190, data_time: 0.221, memory: 9072, decode.loss_ce: 0.2351, decode.acc_seg: 89.7447, aux_0.loss_ce: 0.2420, aux_0.acc_seg: 89.8031, aux_1.loss_ce: 0.2640, aux_1.acc_seg: 89.1818, aux_2.loss_ce: 0.1423, aux_2.loss_dice: 0.3049, aux_2.acc_seg: 95.7068, aux_3.loss_ce: 0.7431, aux_3.acc_seg: 85.7620, loss: 1.9314
2023-03-28 20:42:38,245 - mmseg - INFO - Iter [450/10000]	lr: 9.595e-03, eta: 3:38:11, time: 1.340, data_time: 0.228, memory: 9072, decode.loss_ce: 0.2219, decode.acc_seg: 90.1809, aux_0.loss_ce: 0.2284, aux_0.acc_seg: 90.1065, aux_1.loss_ce: 0.2484, aux_1.acc_seg: 89.5112, aux_2.loss_ce: 0.1411, aux_2.loss_dice: 0.3024, aux_2.acc_seg: 95.7126, aux_3.loss_ce: 0.5907, aux_3.acc_seg: 86.9546, loss: 1.7328
2023-03-28 20:43:44,897 - mmseg - INFO - Iter [500/10000]	lr: 9.550e-03, eta: 3:36:26, time: 1.333, data_time: 0.309, memory: 9072, decode.loss_ce: 0.1969, decode.acc_seg: 91.0805, aux_0.loss_ce: 0.2049, aux_0.acc_seg: 90.8311, aux_1.loss_ce: 0.2251, aux_1.acc_seg: 90.2075, aux_2.loss_ce: 0.1399, aux_2.loss_dice: 0.3002, aux_2.acc_seg: 95.7667, aux_3.loss_ce: 0.4928, aux_3.acc_seg: 88.6885, loss: 1.5599
2023-03-28 20:44:43,988 - mmseg - INFO - Iter [550/10000]	lr: 9.505e-03, eta: 3:32:39, time: 1.182, data_time: 0.224, memory: 9072, decode.loss_ce: 0.1900, decode.acc_seg: 91.4074, aux_0.loss_ce: 0.2020, aux_0.acc_seg: 91.1088, aux_1.loss_ce: 0.2201, aux_1.acc_seg: 90.4503, aux_2.loss_ce: 0.1394, aux_2.loss_dice: 0.2976, aux_2.acc_seg: 95.6665, aux_3.loss_ce: 0.4097, aux_3.acc_seg: 89.6307, loss: 1.4588
2023-03-28 20:45:47,847 - mmseg - INFO - Iter [600/10000]	lr: 9.459e-03, eta: 3:30:34, time: 1.277, data_time: 0.226, memory: 9072, decode.loss_ce: 0.1780, decode.acc_seg: 91.8248, aux_0.loss_ce: 0.1875, aux_0.acc_seg: 91.6107, aux_1.loss_ce: 0.2047, aux_1.acc_seg: 91.0011, aux_2.loss_ce: 0.1365, aux_2.loss_dice: 0.2961, aux_2.acc_seg: 95.7933, aux_3.loss_ce: 0.3313, aux_3.acc_seg: 90.3606, loss: 1.3339
2023-03-28 20:46:52,513 - mmseg - INFO - Iter [650/10000]	lr: 9.414e-03, eta: 3:28:51, time: 1.293, data_time: 0.296, memory: 9072, decode.loss_ce: 0.1681, decode.acc_seg: 92.2860, aux_0.loss_ce: 0.1798, aux_0.acc_seg: 91.9349, aux_1.loss_ce: 0.1981, aux_1.acc_seg: 91.4044, aux_2.loss_ce: 0.1381, aux_2.loss_dice: 0.2948, aux_2.acc_seg: 95.6850, aux_3.loss_ce: 0.3023, aux_3.acc_seg: 90.8494, loss: 1.2813
2023-03-28 20:47:42,526 - mmseg - INFO - Iter [700/10000]	lr: 9.369e-03, eta: 3:23:58, time: 1.000, data_time: 0.222, memory: 9072, decode.loss_ce: 0.1613, decode.acc_seg: 92.4433, aux_0.loss_ce: 0.1729, aux_0.acc_seg: 92.0770, aux_1.loss_ce: 0.1903, aux_1.acc_seg: 91.5373, aux_2.loss_ce: 0.1370, aux_2.loss_dice: 0.2928, aux_2.acc_seg: 95.7519, aux_3.loss_ce: 0.2715, aux_3.acc_seg: 91.1962, loss: 1.2258
2023-03-28 20:48:48,022 - mmseg - INFO - Iter [750/10000]	lr: 9.323e-03, eta: 3:22:48, time: 1.310, data_time: 0.221, memory: 9072, decode.loss_ce: 0.1569, decode.acc_seg: 92.5836, aux_0.loss_ce: 0.1681, aux_0.acc_seg: 92.2297, aux_1.loss_ce: 0.1858, aux_1.acc_seg: 91.6728, aux_2.loss_ce: 0.1370, aux_2.loss_dice: 0.2922, aux_2.acc_seg: 95.6946, aux_3.loss_ce: 0.2573, aux_3.acc_seg: 91.3520, loss: 1.1973
2023-03-28 20:49:57,345 - mmseg - INFO - Iter [800/10000]	lr: 9.278e-03, eta: 3:22:23, time: 1.386, data_time: 0.298, memory: 9072, decode.loss_ce: 0.1424, decode.acc_seg: 93.0793, aux_0.loss_ce: 0.1538, aux_0.acc_seg: 92.7585, aux_1.loss_ce: 0.1688, aux_1.acc_seg: 92.1694, aux_2.loss_ce: 0.1344, aux_2.loss_dice: 0.2877, aux_2.acc_seg: 95.7779, aux_3.loss_ce: 0.2284, aux_3.acc_seg: 91.8828, loss: 1.1155
2023-03-28 20:50:57,537 - mmseg - INFO - Iter [850/10000]	lr: 9.233e-03, eta: 3:20:15, time: 1.204, data_time: 0.234, memory: 9072, decode.loss_ce: 0.1380, decode.acc_seg: 93.2533, aux_0.loss_ce: 0.1492, aux_0.acc_seg: 92.9194, aux_1.loss_ce: 0.1648, aux_1.acc_seg: 92.3567, aux_2.loss_ce: 0.1343, aux_2.loss_dice: 0.2872, aux_2.acc_seg: 95.7769, aux_3.loss_ce: 0.2155, aux_3.acc_seg: 92.1106, loss: 1.0890
2023-03-28 20:52:01,278 - mmseg - INFO - Iter [900/10000]	lr: 9.187e-03, eta: 3:18:50, time: 1.275, data_time: 0.224, memory: 9072, decode.loss_ce: 0.1347, decode.acc_seg: 93.4004, aux_0.loss_ce: 0.1463, aux_0.acc_seg: 93.0339, aux_1.loss_ce: 0.1619, aux_1.acc_seg: 92.4341, aux_2.loss_ce: 0.1345, aux_2.loss_dice: 0.2856, aux_2.acc_seg: 95.7682, aux_3.loss_ce: 0.2104, aux_3.acc_seg: 92.1994, loss: 1.0735
2023-03-28 20:53:11,884 - mmseg - INFO - Iter [950/10000]	lr: 9.142e-03, eta: 3:18:32, time: 1.412, data_time: 0.309, memory: 9072, decode.loss_ce: 0.1322, decode.acc_seg: 93.6291, aux_0.loss_ce: 0.1426, aux_0.acc_seg: 93.3185, aux_1.loss_ce: 0.1582, aux_1.acc_seg: 92.7243, aux_2.loss_ce: 0.1347, aux_2.loss_dice: 0.2855, aux_2.acc_seg: 95.7398, aux_3.loss_ce: 0.2024, aux_3.acc_seg: 92.4352, loss: 1.0555
2023-03-28 20:54:11,860 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-03-28 20:54:13,408 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 20:54:13,409 - mmseg - INFO - Iter [1000/10000]	lr: 9.096e-03, eta: 3:16:48, time: 1.231, data_time: 0.229, memory: 9072, decode.loss_ce: 0.1308, decode.acc_seg: 93.6588, aux_0.loss_ce: 0.1411, aux_0.acc_seg: 93.3413, aux_1.loss_ce: 0.1582, aux_1.acc_seg: 92.7015, aux_2.loss_ce: 0.1325, aux_2.loss_dice: 0.2837, aux_2.acc_seg: 95.8357, aux_3.loss_ce: 0.2027, aux_3.acc_seg: 92.4490, loss: 1.0490
2023-03-28 20:54:49,069 - mmseg - INFO - per class results:
2023-03-28 20:54:49,070 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 61.71 |  65.1 |
|   Building  | 90.29 | 92.12 |
|     Car     | 87.65 |  91.8 |
| Column_Pole |  3.18 |  3.59 |
|    Fence    | 68.27 |  98.5 |
|  Pedestrian | 32.09 | 75.96 |
|     Road    | 96.31 | 97.59 |
|   Sidewalk  |  88.1 | 97.37 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     |  93.2 | 95.32 |
|     Tree    |  90.6 | 96.41 |
+-------------+-------+-------+
2023-03-28 20:54:49,070 - mmseg - INFO - Summary:
2023-03-28 20:54:49,071 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 94.1 | 64.67 | 73.98 |
+------+-------+-------+
2023-03-28 20:54:49,071 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 20:54:49,071 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9410, mIoU: 0.6467, mAcc: 0.7398, IoU.Bicyclist: 0.6171, IoU.Building: 0.9029, IoU.Car: 0.8765, IoU.Column_Pole: 0.0318, IoU.Fence: 0.6827, IoU.Pedestrian: 0.3209, IoU.Road: 0.9631, IoU.Sidewalk: 0.8810, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9320, IoU.Tree: 0.9060, Acc.Bicyclist: 0.6510, Acc.Building: 0.9212, Acc.Car: 0.9180, Acc.Column_Pole: 0.0359, Acc.Fence: 0.9850, Acc.Pedestrian: 0.7596, Acc.Road: 0.9759, Acc.Sidewalk: 0.9737, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9532, Acc.Tree: 0.9641
2023-03-28 20:55:52,649 - mmseg - INFO - Iter [1050/10000]	lr: 9.051e-03, eta: 3:20:29, time: 1.985, data_time: 0.945, memory: 9072, decode.loss_ce: 0.1375, decode.acc_seg: 93.3222, aux_0.loss_ce: 0.1476, aux_0.acc_seg: 92.9975, aux_1.loss_ce: 0.1619, aux_1.acc_seg: 92.4157, aux_2.loss_ce: 0.1344, aux_2.loss_dice: 0.2852, aux_2.acc_seg: 95.7707, aux_3.loss_ce: 0.2040, aux_3.acc_seg: 92.2165, loss: 1.0705
2023-03-28 20:57:03,830 - mmseg - INFO - Iter [1100/10000]	lr: 9.005e-03, eta: 3:19:54, time: 1.424, data_time: 0.307, memory: 9072, decode.loss_ce: 0.1384, decode.acc_seg: 93.2989, aux_0.loss_ce: 0.1464, aux_0.acc_seg: 92.9832, aux_1.loss_ce: 0.1628, aux_1.acc_seg: 92.3662, aux_2.loss_ce: 0.1333, aux_2.loss_dice: 0.2838, aux_2.acc_seg: 95.8153, aux_3.loss_ce: 0.2050, aux_3.acc_seg: 92.2239, loss: 1.0696
2023-03-28 20:58:03,887 - mmseg - INFO - Iter [1150/10000]	lr: 8.960e-03, eta: 3:17:50, time: 1.201, data_time: 0.235, memory: 9072, decode.loss_ce: 0.1374, decode.acc_seg: 93.2982, aux_0.loss_ce: 0.1447, aux_0.acc_seg: 93.0984, aux_1.loss_ce: 0.1626, aux_1.acc_seg: 92.4435, aux_2.loss_ce: 0.1344, aux_2.loss_dice: 0.2857, aux_2.acc_seg: 95.7647, aux_3.loss_ce: 0.2030, aux_3.acc_seg: 92.1841, loss: 1.0677
2023-03-28 20:59:07,768 - mmseg - INFO - Iter [1200/10000]	lr: 8.914e-03, eta: 3:16:20, time: 1.277, data_time: 0.227, memory: 9072, decode.loss_ce: 0.1247, decode.acc_seg: 93.6773, aux_0.loss_ce: 0.1330, aux_0.acc_seg: 93.3893, aux_1.loss_ce: 0.1490, aux_1.acc_seg: 92.7390, aux_2.loss_ce: 0.1337, aux_2.loss_dice: 0.2815, aux_2.acc_seg: 95.7537, aux_3.loss_ce: 0.1865, aux_3.acc_seg: 92.4592, loss: 1.0085
2023-03-28 21:00:19,271 - mmseg - INFO - Iter [1250/10000]	lr: 8.869e-03, eta: 3:15:45, time: 1.430, data_time: 0.307, memory: 9072, decode.loss_ce: 0.1231, decode.acc_seg: 93.9889, aux_0.loss_ce: 0.1309, aux_0.acc_seg: 93.7316, aux_1.loss_ce: 0.1461, aux_1.acc_seg: 93.1487, aux_2.loss_ce: 0.1337, aux_2.loss_dice: 0.2831, aux_2.acc_seg: 95.7705, aux_3.loss_ce: 0.1823, aux_3.acc_seg: 92.8766, loss: 0.9993
2023-03-28 21:01:19,429 - mmseg - INFO - Iter [1300/10000]	lr: 8.823e-03, eta: 3:13:51, time: 1.203, data_time: 0.223, memory: 9072, decode.loss_ce: 0.1219, decode.acc_seg: 93.9307, aux_0.loss_ce: 0.1290, aux_0.acc_seg: 93.6976, aux_1.loss_ce: 0.1431, aux_1.acc_seg: 93.1474, aux_2.loss_ce: 0.1332, aux_2.loss_dice: 0.2813, aux_2.acc_seg: 95.7718, aux_3.loss_ce: 0.1788, aux_3.acc_seg: 92.7752, loss: 0.9873
2023-03-28 21:02:22,852 - mmseg - INFO - Iter [1350/10000]	lr: 8.777e-03, eta: 3:12:22, time: 1.269, data_time: 0.222, memory: 9072, decode.loss_ce: 0.1199, decode.acc_seg: 93.9859, aux_0.loss_ce: 0.1275, aux_0.acc_seg: 93.7272, aux_1.loss_ce: 0.1420, aux_1.acc_seg: 93.1318, aux_2.loss_ce: 0.1321, aux_2.loss_dice: 0.2804, aux_2.acc_seg: 95.8236, aux_3.loss_ce: 0.1766, aux_3.acc_seg: 92.8430, loss: 0.9786
2023-03-28 21:03:33,916 - mmseg - INFO - Iter [1400/10000]	lr: 8.732e-03, eta: 3:11:42, time: 1.421, data_time: 0.300, memory: 9072, decode.loss_ce: 0.1180, decode.acc_seg: 94.0099, aux_0.loss_ce: 0.1257, aux_0.acc_seg: 93.7366, aux_1.loss_ce: 0.1392, aux_1.acc_seg: 93.1588, aux_2.loss_ce: 0.1331, aux_2.loss_dice: 0.2814, aux_2.acc_seg: 95.7496, aux_3.loss_ce: 0.1738, aux_3.acc_seg: 92.9325, loss: 0.9712
2023-03-28 21:04:34,185 - mmseg - INFO - Iter [1450/10000]	lr: 8.686e-03, eta: 3:09:56, time: 1.205, data_time: 0.236, memory: 9072, decode.loss_ce: 0.1199, decode.acc_seg: 94.0687, aux_0.loss_ce: 0.1264, aux_0.acc_seg: 93.8167, aux_1.loss_ce: 0.1401, aux_1.acc_seg: 93.2385, aux_2.loss_ce: 0.1343, aux_2.loss_dice: 0.2809, aux_2.acc_seg: 95.7508, aux_3.loss_ce: 0.1732, aux_3.acc_seg: 93.0285, loss: 0.9746
2023-03-28 21:05:37,687 - mmseg - INFO - Iter [1500/10000]	lr: 8.640e-03, eta: 3:08:32, time: 1.270, data_time: 0.224, memory: 9072, decode.loss_ce: 0.1204, decode.acc_seg: 94.0320, aux_0.loss_ce: 0.1267, aux_0.acc_seg: 93.8290, aux_1.loss_ce: 0.1415, aux_1.acc_seg: 93.2345, aux_2.loss_ce: 0.1338, aux_2.loss_dice: 0.2809, aux_2.acc_seg: 95.7641, aux_3.loss_ce: 0.1718, aux_3.acc_seg: 93.0020, loss: 0.9751
2023-03-28 21:06:46,858 - mmseg - INFO - Iter [1550/10000]	lr: 8.595e-03, eta: 3:07:40, time: 1.383, data_time: 0.297, memory: 9072, decode.loss_ce: 0.1130, decode.acc_seg: 94.3078, aux_0.loss_ce: 0.1208, aux_0.acc_seg: 94.0482, aux_1.loss_ce: 0.1340, aux_1.acc_seg: 93.4695, aux_2.loss_ce: 0.1328, aux_2.loss_dice: 0.2787, aux_2.acc_seg: 95.7649, aux_3.loss_ce: 0.1654, aux_3.acc_seg: 93.2618, loss: 0.9447
2023-03-28 21:07:53,253 - mmseg - INFO - Iter [1600/10000]	lr: 8.549e-03, eta: 3:06:32, time: 1.328, data_time: 0.239, memory: 9072, decode.loss_ce: 0.1156, decode.acc_seg: 94.2073, aux_0.loss_ce: 0.1215, aux_0.acc_seg: 93.9810, aux_1.loss_ce: 0.1356, aux_1.acc_seg: 93.3651, aux_2.loss_ce: 0.1319, aux_2.loss_dice: 0.2789, aux_2.acc_seg: 95.8160, aux_3.loss_ce: 0.1659, aux_3.acc_seg: 93.2094, loss: 0.9494
2023-03-28 21:08:54,510 - mmseg - INFO - Iter [1650/10000]	lr: 8.503e-03, eta: 3:04:58, time: 1.225, data_time: 0.235, memory: 9072, decode.loss_ce: 0.1100, decode.acc_seg: 94.4324, aux_0.loss_ce: 0.1168, aux_0.acc_seg: 94.1788, aux_1.loss_ce: 0.1302, aux_1.acc_seg: 93.6034, aux_2.loss_ce: 0.1324, aux_2.loss_dice: 0.2777, aux_2.acc_seg: 95.7498, aux_3.loss_ce: 0.1579, aux_3.acc_seg: 93.3914, loss: 0.9249
2023-03-28 21:10:01,876 - mmseg - INFO - Iter [1700/10000]	lr: 8.457e-03, eta: 3:03:56, time: 1.347, data_time: 0.301, memory: 9072, decode.loss_ce: 0.1066, decode.acc_seg: 94.5240, aux_0.loss_ce: 0.1127, aux_0.acc_seg: 94.3185, aux_1.loss_ce: 0.1265, aux_1.acc_seg: 93.7173, aux_2.loss_ce: 0.1321, aux_2.loss_dice: 0.2779, aux_2.acc_seg: 95.7777, aux_3.loss_ce: 0.1552, aux_3.acc_seg: 93.5457, loss: 0.9110
2023-03-28 21:11:12,059 - mmseg - INFO - Iter [1750/10000]	lr: 8.411e-03, eta: 3:03:07, time: 1.404, data_time: 0.265, memory: 9072, decode.loss_ce: 0.1053, decode.acc_seg: 94.5765, aux_0.loss_ce: 0.1118, aux_0.acc_seg: 94.3531, aux_1.loss_ce: 0.1238, aux_1.acc_seg: 93.7801, aux_2.loss_ce: 0.1315, aux_2.loss_dice: 0.2751, aux_2.acc_seg: 95.8001, aux_3.loss_ce: 0.1518, aux_3.acc_seg: 93.5767, loss: 0.8991
2023-03-28 21:12:13,067 - mmseg - INFO - Iter [1800/10000]	lr: 8.365e-03, eta: 3:01:35, time: 1.220, data_time: 0.248, memory: 9072, decode.loss_ce: 0.1035, decode.acc_seg: 94.7521, aux_0.loss_ce: 0.1098, aux_0.acc_seg: 94.5420, aux_1.loss_ce: 0.1231, aux_1.acc_seg: 93.9553, aux_2.loss_ce: 0.1321, aux_2.loss_dice: 0.2759, aux_2.acc_seg: 95.7999, aux_3.loss_ce: 0.1500, aux_3.acc_seg: 93.8168, loss: 0.8944
2023-03-28 21:13:18,200 - mmseg - INFO - Iter [1850/10000]	lr: 8.320e-03, eta: 3:00:23, time: 1.303, data_time: 0.294, memory: 9072, decode.loss_ce: 0.1045, decode.acc_seg: 94.6761, aux_0.loss_ce: 0.1105, aux_0.acc_seg: 94.4548, aux_1.loss_ce: 0.1238, aux_1.acc_seg: 93.8720, aux_2.loss_ce: 0.1307, aux_2.loss_dice: 0.2758, aux_2.acc_seg: 95.8490, aux_3.loss_ce: 0.1506, aux_3.acc_seg: 93.7221, loss: 0.8959
2023-03-28 21:14:29,633 - mmseg - INFO - Iter [1900/10000]	lr: 8.274e-03, eta: 2:59:38, time: 1.429, data_time: 0.258, memory: 9072, decode.loss_ce: 0.1028, decode.acc_seg: 94.6253, aux_0.loss_ce: 0.1091, aux_0.acc_seg: 94.4008, aux_1.loss_ce: 0.1216, aux_1.acc_seg: 93.8361, aux_2.loss_ce: 0.1309, aux_2.loss_dice: 0.2750, aux_2.acc_seg: 95.8271, aux_3.loss_ce: 0.1473, aux_3.acc_seg: 93.6911, loss: 0.8866
2023-03-28 21:15:31,480 - mmseg - INFO - Iter [1950/10000]	lr: 8.228e-03, eta: 2:58:12, time: 1.237, data_time: 0.255, memory: 9072, decode.loss_ce: 0.1040, decode.acc_seg: 94.7101, aux_0.loss_ce: 0.1105, aux_0.acc_seg: 94.5002, aux_1.loss_ce: 0.1229, aux_1.acc_seg: 93.9489, aux_2.loss_ce: 0.1312, aux_2.loss_dice: 0.2758, aux_2.acc_seg: 95.8181, aux_3.loss_ce: 0.1503, aux_3.acc_seg: 93.7645, loss: 0.8948
2023-03-28 21:16:36,480 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-03-28 21:16:38,047 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 21:16:38,047 - mmseg - INFO - Iter [2000/10000]	lr: 8.182e-03, eta: 2:57:06, time: 1.332, data_time: 0.299, memory: 9072, decode.loss_ce: 0.0993, decode.acc_seg: 94.7840, aux_0.loss_ce: 0.1043, aux_0.acc_seg: 94.6005, aux_1.loss_ce: 0.1173, aux_1.acc_seg: 93.9734, aux_2.loss_ce: 0.1306, aux_2.loss_dice: 0.2738, aux_2.acc_seg: 95.8096, aux_3.loss_ce: 0.1416, aux_3.acc_seg: 93.8596, loss: 0.8669
2023-03-28 21:16:41,426 - mmseg - INFO - per class results:
2023-03-28 21:16:41,427 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 76.15 | 83.36 |
|   Building  | 90.44 | 92.15 |
|     Car     | 89.05 | 91.85 |
| Column_Pole |  7.18 |  8.62 |
|    Fence    | 72.69 | 97.43 |
|  Pedestrian | 46.35 | 80.71 |
|     Road    | 96.93 | 98.23 |
|   Sidewalk  | 90.01 |  96.5 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.45 | 96.17 |
|     Tree    | 90.63 |  97.2 |
+-------------+-------+-------+
2023-03-28 21:16:41,427 - mmseg - INFO - Summary:
2023-03-28 21:16:41,427 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.89 | 68.44 | 76.56 |
+-------+-------+-------+
2023-03-28 21:16:41,427 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 21:16:41,427 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9489, mIoU: 0.6844, mAcc: 0.7656, IoU.Bicyclist: 0.7615, IoU.Building: 0.9044, IoU.Car: 0.8905, IoU.Column_Pole: 0.0718, IoU.Fence: 0.7269, IoU.Pedestrian: 0.4635, IoU.Road: 0.9693, IoU.Sidewalk: 0.9001, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9345, IoU.Tree: 0.9063, Acc.Bicyclist: 0.8336, Acc.Building: 0.9215, Acc.Car: 0.9185, Acc.Column_Pole: 0.0862, Acc.Fence: 0.9743, Acc.Pedestrian: 0.8071, Acc.Road: 0.9823, Acc.Sidewalk: 0.9650, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9617, Acc.Tree: 0.9720
2023-03-28 21:17:42,575 - mmseg - INFO - Iter [2050/10000]	lr: 8.136e-03, eta: 2:55:52, time: 1.291, data_time: 0.306, memory: 9072, decode.loss_ce: 0.0975, decode.acc_seg: 94.9240, aux_0.loss_ce: 0.1040, aux_0.acc_seg: 94.6982, aux_1.loss_ce: 0.1151, aux_1.acc_seg: 94.1373, aux_2.loss_ce: 0.1293, aux_2.loss_dice: 0.2734, aux_2.acc_seg: 95.8715, aux_3.loss_ce: 0.1408, aux_3.acc_seg: 93.9780, loss: 0.8601
2023-03-28 21:18:45,998 - mmseg - INFO - Iter [2100/10000]	lr: 8.090e-03, eta: 2:54:35, time: 1.268, data_time: 0.240, memory: 9072, decode.loss_ce: 0.0980, decode.acc_seg: 94.8793, aux_0.loss_ce: 0.1047, aux_0.acc_seg: 94.6757, aux_1.loss_ce: 0.1172, aux_1.acc_seg: 94.0473, aux_2.loss_ce: 0.1313, aux_2.loss_dice: 0.2747, aux_2.acc_seg: 95.8003, aux_3.loss_ce: 0.1405, aux_3.acc_seg: 93.9412, loss: 0.8665
2023-03-28 21:19:58,442 - mmseg - INFO - Iter [2150/10000]	lr: 8.043e-03, eta: 2:53:51, time: 1.449, data_time: 0.320, memory: 9072, decode.loss_ce: 0.0972, decode.acc_seg: 94.9465, aux_0.loss_ce: 0.1031, aux_0.acc_seg: 94.7417, aux_1.loss_ce: 0.1144, aux_1.acc_seg: 94.1604, aux_2.loss_ce: 0.1302, aux_2.loss_dice: 0.2730, aux_2.acc_seg: 95.8190, aux_3.loss_ce: 0.1376, aux_3.acc_seg: 94.0419, loss: 0.8555
2023-03-28 21:21:00,657 - mmseg - INFO - Iter [2200/10000]	lr: 7.997e-03, eta: 2:52:30, time: 1.244, data_time: 0.249, memory: 9072, decode.loss_ce: 0.0967, decode.acc_seg: 94.9020, aux_0.loss_ce: 0.1017, aux_0.acc_seg: 94.6964, aux_1.loss_ce: 0.1146, aux_1.acc_seg: 94.1198, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2718, aux_2.acc_seg: 95.8799, aux_3.loss_ce: 0.1367, aux_3.acc_seg: 93.9850, loss: 0.8504
2023-03-28 21:22:04,318 - mmseg - INFO - Iter [2250/10000]	lr: 7.951e-03, eta: 2:51:14, time: 1.273, data_time: 0.244, memory: 9072, decode.loss_ce: 0.0983, decode.acc_seg: 94.8055, aux_0.loss_ce: 0.1044, aux_0.acc_seg: 94.5901, aux_1.loss_ce: 0.1160, aux_1.acc_seg: 94.0020, aux_2.loss_ce: 0.1301, aux_2.loss_dice: 0.2725, aux_2.acc_seg: 95.8187, aux_3.loss_ce: 0.1390, aux_3.acc_seg: 93.8885, loss: 0.8602
2023-03-28 21:23:17,001 - mmseg - INFO - Iter [2300/10000]	lr: 7.905e-03, eta: 2:50:29, time: 1.454, data_time: 0.323, memory: 9072, decode.loss_ce: 0.0981, decode.acc_seg: 94.9008, aux_0.loss_ce: 0.1042, aux_0.acc_seg: 94.7057, aux_1.loss_ce: 0.1166, aux_1.acc_seg: 94.1218, aux_2.loss_ce: 0.1311, aux_2.loss_dice: 0.2740, aux_2.acc_seg: 95.7775, aux_3.loss_ce: 0.1394, aux_3.acc_seg: 93.9882, loss: 0.8635
2023-03-28 21:24:23,812 - mmseg - INFO - Iter [2350/10000]	lr: 7.859e-03, eta: 2:49:24, time: 1.336, data_time: 0.274, memory: 9072, decode.loss_ce: 0.0958, decode.acc_seg: 94.9400, aux_0.loss_ce: 0.1012, aux_0.acc_seg: 94.7201, aux_1.loss_ce: 0.1137, aux_1.acc_seg: 94.1300, aux_2.loss_ce: 0.1295, aux_2.loss_dice: 0.2723, aux_2.acc_seg: 95.8055, aux_3.loss_ce: 0.1360, aux_3.acc_seg: 94.0023, loss: 0.8485
2023-03-28 21:25:25,564 - mmseg - INFO - Iter [2400/10000]	lr: 7.813e-03, eta: 2:48:03, time: 1.235, data_time: 0.236, memory: 9072, decode.loss_ce: 0.0967, decode.acc_seg: 94.9163, aux_0.loss_ce: 0.1022, aux_0.acc_seg: 94.7439, aux_1.loss_ce: 0.1138, aux_1.acc_seg: 94.1244, aux_2.loss_ce: 0.1290, aux_2.loss_dice: 0.2719, aux_2.acc_seg: 95.8414, aux_3.loss_ce: 0.1368, aux_3.acc_seg: 93.9763, loss: 0.8504
2023-03-28 21:26:31,221 - mmseg - INFO - Iter [2450/10000]	lr: 7.766e-03, eta: 2:46:54, time: 1.313, data_time: 0.304, memory: 9072, decode.loss_ce: 0.0985, decode.acc_seg: 94.9224, aux_0.loss_ce: 0.1029, aux_0.acc_seg: 94.7286, aux_1.loss_ce: 0.1160, aux_1.acc_seg: 94.1486, aux_2.loss_ce: 0.1306, aux_2.loss_dice: 0.2733, aux_2.acc_seg: 95.8105, aux_3.loss_ce: 0.1384, aux_3.acc_seg: 93.9841, loss: 0.8597
2023-03-28 21:27:33,957 - mmseg - INFO - Iter [2500/10000]	lr: 7.720e-03, eta: 2:45:37, time: 1.255, data_time: 0.239, memory: 9072, decode.loss_ce: 0.0957, decode.acc_seg: 94.9456, aux_0.loss_ce: 0.1009, aux_0.acc_seg: 94.7670, aux_1.loss_ce: 0.1132, aux_1.acc_seg: 94.1636, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2715, aux_2.acc_seg: 95.8999, aux_3.loss_ce: 0.1346, aux_3.acc_seg: 94.0649, loss: 0.8444
2023-03-28 21:28:43,467 - mmseg - INFO - Iter [2550/10000]	lr: 7.674e-03, eta: 2:44:40, time: 1.390, data_time: 0.255, memory: 9072, decode.loss_ce: 0.0943, decode.acc_seg: 95.0249, aux_0.loss_ce: 0.0997, aux_0.acc_seg: 94.8143, aux_1.loss_ce: 0.1120, aux_1.acc_seg: 94.2076, aux_2.loss_ce: 0.1280, aux_2.loss_dice: 0.2706, aux_2.acc_seg: 95.8812, aux_3.loss_ce: 0.1320, aux_3.acc_seg: 94.1359, loss: 0.8365
2023-03-28 21:29:50,602 - mmseg - INFO - Iter [2600/10000]	lr: 7.627e-03, eta: 2:43:36, time: 1.343, data_time: 0.319, memory: 9072, decode.loss_ce: 0.0922, decode.acc_seg: 95.1104, aux_0.loss_ce: 0.0989, aux_0.acc_seg: 94.8831, aux_1.loss_ce: 0.1097, aux_1.acc_seg: 94.3145, aux_2.loss_ce: 0.1297, aux_2.loss_dice: 0.2708, aux_2.acc_seg: 95.7964, aux_3.loss_ce: 0.1309, aux_3.acc_seg: 94.1869, loss: 0.8322
2023-03-28 21:30:51,932 - mmseg - INFO - Iter [2650/10000]	lr: 7.581e-03, eta: 2:42:16, time: 1.226, data_time: 0.230, memory: 9072, decode.loss_ce: 0.0946, decode.acc_seg: 95.0439, aux_0.loss_ce: 0.0999, aux_0.acc_seg: 94.8284, aux_1.loss_ce: 0.1119, aux_1.acc_seg: 94.2600, aux_2.loss_ce: 0.1304, aux_2.loss_dice: 0.2724, aux_2.acc_seg: 95.7978, aux_3.loss_ce: 0.1321, aux_3.acc_seg: 94.1635, loss: 0.8414
2023-03-28 21:32:01,094 - mmseg - INFO - Iter [2700/10000]	lr: 7.535e-03, eta: 2:41:18, time: 1.383, data_time: 0.243, memory: 9072, decode.loss_ce: 0.0912, decode.acc_seg: 95.1354, aux_0.loss_ce: 0.0969, aux_0.acc_seg: 94.9522, aux_1.loss_ce: 0.1085, aux_1.acc_seg: 94.3541, aux_2.loss_ce: 0.1288, aux_2.loss_dice: 0.2700, aux_2.acc_seg: 95.8282, aux_3.loss_ce: 0.1294, aux_3.acc_seg: 94.2312, loss: 0.8248
2023-03-28 21:33:08,581 - mmseg - INFO - Iter [2750/10000]	lr: 7.488e-03, eta: 2:40:15, time: 1.349, data_time: 0.319, memory: 9072, decode.loss_ce: 0.0937, decode.acc_seg: 95.0377, aux_0.loss_ce: 0.0993, aux_0.acc_seg: 94.8565, aux_1.loss_ce: 0.1111, aux_1.acc_seg: 94.2600, aux_2.loss_ce: 0.1302, aux_2.loss_dice: 0.2726, aux_2.acc_seg: 95.8288, aux_3.loss_ce: 0.1314, aux_3.acc_seg: 94.1109, loss: 0.8384
2023-03-28 21:34:08,160 - mmseg - INFO - Iter [2800/10000]	lr: 7.442e-03, eta: 2:38:51, time: 1.192, data_time: 0.225, memory: 9072, decode.loss_ce: 0.0918, decode.acc_seg: 95.1079, aux_0.loss_ce: 0.0967, aux_0.acc_seg: 94.9112, aux_1.loss_ce: 0.1084, aux_1.acc_seg: 94.3093, aux_2.loss_ce: 0.1295, aux_2.loss_dice: 0.2708, aux_2.acc_seg: 95.8052, aux_3.loss_ce: 0.1297, aux_3.acc_seg: 94.1675, loss: 0.8268
2023-03-28 21:35:16,513 - mmseg - INFO - Iter [2850/10000]	lr: 7.395e-03, eta: 2:37:50, time: 1.367, data_time: 0.250, memory: 9072, decode.loss_ce: 0.0915, decode.acc_seg: 95.1858, aux_0.loss_ce: 0.0960, aux_0.acc_seg: 95.0251, aux_1.loss_ce: 0.1086, aux_1.acc_seg: 94.4188, aux_2.loss_ce: 0.1291, aux_2.loss_dice: 0.2699, aux_2.acc_seg: 95.8341, aux_3.loss_ce: 0.1276, aux_3.acc_seg: 94.3004, loss: 0.8225
2023-03-28 21:36:28,043 - mmseg - INFO - Iter [2900/10000]	lr: 7.349e-03, eta: 2:36:57, time: 1.431, data_time: 0.380, memory: 9072, decode.loss_ce: 0.0890, decode.acc_seg: 95.2336, aux_0.loss_ce: 0.0940, aux_0.acc_seg: 95.0492, aux_1.loss_ce: 0.1048, aux_1.acc_seg: 94.4694, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2694, aux_2.acc_seg: 95.8216, aux_3.loss_ce: 0.1242, aux_3.acc_seg: 94.3583, loss: 0.8103
2023-03-28 21:37:29,032 - mmseg - INFO - Iter [2950/10000]	lr: 7.302e-03, eta: 2:35:38, time: 1.220, data_time: 0.243, memory: 9072, decode.loss_ce: 0.0893, decode.acc_seg: 95.2521, aux_0.loss_ce: 0.0940, aux_0.acc_seg: 95.0745, aux_1.loss_ce: 0.1064, aux_1.acc_seg: 94.5066, aux_2.loss_ce: 0.1277, aux_2.loss_dice: 0.2687, aux_2.acc_seg: 95.8856, aux_3.loss_ce: 0.1259, aux_3.acc_seg: 94.3852, loss: 0.8120
2023-03-28 21:38:39,546 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-03-28 21:38:41,459 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 21:38:41,459 - mmseg - INFO - Iter [3000/10000]	lr: 7.255e-03, eta: 2:34:46, time: 1.449, data_time: 0.273, memory: 9072, decode.loss_ce: 0.0932, decode.acc_seg: 95.1132, aux_0.loss_ce: 0.0983, aux_0.acc_seg: 94.9323, aux_1.loss_ce: 0.1100, aux_1.acc_seg: 94.3405, aux_2.loss_ce: 0.1292, aux_2.loss_dice: 0.2715, aux_2.acc_seg: 95.8489, aux_3.loss_ce: 0.1285, aux_3.acc_seg: 94.2164, loss: 0.8307
2023-03-28 21:38:45,459 - mmseg - INFO - per class results:
2023-03-28 21:38:45,460 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 78.72 | 83.91 |
|   Building  | 91.13 | 92.99 |
|     Car     | 90.43 | 93.28 |
| Column_Pole | 11.08 | 13.36 |
|    Fence    | 77.46 | 90.47 |
|  Pedestrian | 51.75 | 80.18 |
|     Road    | 97.02 | 98.64 |
|   Sidewalk  | 90.34 | 95.52 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.55 | 96.07 |
|     Tree    | 89.57 | 98.54 |
+-------------+-------+-------+
2023-03-28 21:38:45,460 - mmseg - INFO - Summary:
2023-03-28 21:38:45,460 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 95.19 | 70.1 | 76.63 |
+-------+------+-------+
2023-03-28 21:38:45,461 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 21:38:45,461 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9519, mIoU: 0.7010, mAcc: 0.7663, IoU.Bicyclist: 0.7872, IoU.Building: 0.9113, IoU.Car: 0.9043, IoU.Column_Pole: 0.1108, IoU.Fence: 0.7746, IoU.Pedestrian: 0.5175, IoU.Road: 0.9702, IoU.Sidewalk: 0.9034, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9355, IoU.Tree: 0.8957, Acc.Bicyclist: 0.8391, Acc.Building: 0.9299, Acc.Car: 0.9328, Acc.Column_Pole: 0.1336, Acc.Fence: 0.9047, Acc.Pedestrian: 0.8018, Acc.Road: 0.9864, Acc.Sidewalk: 0.9552, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9607, Acc.Tree: 0.9854
2023-03-28 21:39:49,876 - mmseg - INFO - Iter [3050/10000]	lr: 7.209e-03, eta: 2:33:45, time: 1.368, data_time: 0.400, memory: 9072, decode.loss_ce: 0.0897, decode.acc_seg: 95.2314, aux_0.loss_ce: 0.0946, aux_0.acc_seg: 95.0601, aux_1.loss_ce: 0.1059, aux_1.acc_seg: 94.4950, aux_2.loss_ce: 0.1290, aux_2.loss_dice: 0.2681, aux_2.acc_seg: 95.7852, aux_3.loss_ce: 0.1243, aux_3.acc_seg: 94.3849, loss: 0.8115
2023-03-28 21:40:56,814 - mmseg - INFO - Iter [3100/10000]	lr: 7.162e-03, eta: 2:32:40, time: 1.339, data_time: 0.253, memory: 9072, decode.loss_ce: 0.0887, decode.acc_seg: 95.2730, aux_0.loss_ce: 0.0930, aux_0.acc_seg: 95.0990, aux_1.loss_ce: 0.1059, aux_1.acc_seg: 94.4786, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2694, aux_2.acc_seg: 95.8003, aux_3.loss_ce: 0.1238, aux_3.acc_seg: 94.3896, loss: 0.8096
2023-03-28 21:42:06,556 - mmseg - INFO - Iter [3150/10000]	lr: 7.115e-03, eta: 2:31:41, time: 1.395, data_time: 0.307, memory: 9072, decode.loss_ce: 0.0891, decode.acc_seg: 95.2872, aux_0.loss_ce: 0.0937, aux_0.acc_seg: 95.1405, aux_1.loss_ce: 0.1051, aux_1.acc_seg: 94.5555, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2697, aux_2.acc_seg: 95.9023, aux_3.loss_ce: 0.1232, aux_3.acc_seg: 94.4320, loss: 0.8089
2023-03-28 21:43:12,298 - mmseg - INFO - Iter [3200/10000]	lr: 7.069e-03, eta: 2:30:33, time: 1.315, data_time: 0.322, memory: 9072, decode.loss_ce: 0.0877, decode.acc_seg: 95.2783, aux_0.loss_ce: 0.0934, aux_0.acc_seg: 95.0857, aux_1.loss_ce: 0.1036, aux_1.acc_seg: 94.5118, aux_2.loss_ce: 0.1279, aux_2.loss_dice: 0.2678, aux_2.acc_seg: 95.8818, aux_3.loss_ce: 0.1220, aux_3.acc_seg: 94.3816, loss: 0.8024
2023-03-28 21:44:17,135 - mmseg - INFO - Iter [3250/10000]	lr: 7.022e-03, eta: 2:29:23, time: 1.297, data_time: 0.256, memory: 9072, decode.loss_ce: 0.0876, decode.acc_seg: 95.3259, aux_0.loss_ce: 0.0929, aux_0.acc_seg: 95.1444, aux_1.loss_ce: 0.1039, aux_1.acc_seg: 94.5551, aux_2.loss_ce: 0.1294, aux_2.loss_dice: 0.2693, aux_2.acc_seg: 95.7949, aux_3.loss_ce: 0.1221, aux_3.acc_seg: 94.4236, loss: 0.8053
2023-03-28 21:45:27,960 - mmseg - INFO - Iter [3300/10000]	lr: 6.975e-03, eta: 2:28:26, time: 1.417, data_time: 0.272, memory: 9072, decode.loss_ce: 0.0849, decode.acc_seg: 95.4046, aux_0.loss_ce: 0.0893, aux_0.acc_seg: 95.2330, aux_1.loss_ce: 0.1012, aux_1.acc_seg: 94.6476, aux_2.loss_ce: 0.1280, aux_2.loss_dice: 0.2680, aux_2.acc_seg: 95.8295, aux_3.loss_ce: 0.1180, aux_3.acc_seg: 94.5519, loss: 0.7893
2023-03-28 21:46:35,982 - mmseg - INFO - Iter [3350/10000]	lr: 6.928e-03, eta: 2:27:22, time: 1.360, data_time: 0.341, memory: 9072, decode.loss_ce: 0.0861, decode.acc_seg: 95.3655, aux_0.loss_ce: 0.0908, aux_0.acc_seg: 95.1801, aux_1.loss_ce: 0.1019, aux_1.acc_seg: 94.6142, aux_2.loss_ce: 0.1284, aux_2.loss_dice: 0.2685, aux_2.acc_seg: 95.8421, aux_3.loss_ce: 0.1200, aux_3.acc_seg: 94.5081, loss: 0.7957
2023-03-28 21:47:36,768 - mmseg - INFO - Iter [3400/10000]	lr: 6.881e-03, eta: 2:26:05, time: 1.216, data_time: 0.241, memory: 9072, decode.loss_ce: 0.0864, decode.acc_seg: 95.3926, aux_0.loss_ce: 0.0912, aux_0.acc_seg: 95.2119, aux_1.loss_ce: 0.1031, aux_1.acc_seg: 94.6198, aux_2.loss_ce: 0.1280, aux_2.loss_dice: 0.2694, aux_2.acc_seg: 95.8738, aux_3.loss_ce: 0.1195, aux_3.acc_seg: 94.5045, loss: 0.7977
2023-03-28 21:48:41,653 - mmseg - INFO - Iter [3450/10000]	lr: 6.834e-03, eta: 2:24:55, time: 1.298, data_time: 0.248, memory: 9072, decode.loss_ce: 0.0861, decode.acc_seg: 95.4229, aux_0.loss_ce: 0.0908, aux_0.acc_seg: 95.2624, aux_1.loss_ce: 0.1030, aux_1.acc_seg: 94.6750, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2686, aux_2.acc_seg: 95.8616, aux_3.loss_ce: 0.1204, aux_3.acc_seg: 94.5852, loss: 0.7964
2023-03-28 21:49:57,117 - mmseg - INFO - Iter [3500/10000]	lr: 6.787e-03, eta: 2:24:06, time: 1.509, data_time: 0.371, memory: 9072, decode.loss_ce: 0.0857, decode.acc_seg: 95.3694, aux_0.loss_ce: 0.0896, aux_0.acc_seg: 95.2029, aux_1.loss_ce: 0.1026, aux_1.acc_seg: 94.5826, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2675, aux_2.acc_seg: 95.7973, aux_3.loss_ce: 0.1186, aux_3.acc_seg: 94.4764, loss: 0.7926
2023-03-28 21:50:57,847 - mmseg - INFO - Iter [3550/10000]	lr: 6.740e-03, eta: 2:22:49, time: 1.215, data_time: 0.262, memory: 9072, decode.loss_ce: 0.0844, decode.acc_seg: 95.4095, aux_0.loss_ce: 0.0889, aux_0.acc_seg: 95.2245, aux_1.loss_ce: 0.1009, aux_1.acc_seg: 94.6482, aux_2.loss_ce: 0.1274, aux_2.loss_dice: 0.2674, aux_2.acc_seg: 95.8492, aux_3.loss_ce: 0.1179, aux_3.acc_seg: 94.5231, loss: 0.7871
2023-03-28 21:52:01,523 - mmseg - INFO - Iter [3600/10000]	lr: 6.693e-03, eta: 2:21:37, time: 1.274, data_time: 0.249, memory: 9072, decode.loss_ce: 0.0830, decode.acc_seg: 95.4160, aux_0.loss_ce: 0.0885, aux_0.acc_seg: 95.2106, aux_1.loss_ce: 0.0988, aux_1.acc_seg: 94.6363, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2668, aux_2.acc_seg: 95.8597, aux_3.loss_ce: 0.1155, aux_3.acc_seg: 94.5202, loss: 0.7801
2023-03-28 21:53:15,268 - mmseg - INFO - Iter [3650/10000]	lr: 6.646e-03, eta: 2:20:44, time: 1.475, data_time: 0.335, memory: 9072, decode.loss_ce: 0.0855, decode.acc_seg: 95.4325, aux_0.loss_ce: 0.0898, aux_0.acc_seg: 95.2681, aux_1.loss_ce: 0.1016, aux_1.acc_seg: 94.6812, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2666, aux_2.acc_seg: 95.8450, aux_3.loss_ce: 0.1177, aux_3.acc_seg: 94.5604, loss: 0.7887
2023-03-28 21:54:20,744 - mmseg - INFO - Iter [3700/10000]	lr: 6.599e-03, eta: 2:19:36, time: 1.310, data_time: 0.287, memory: 9072, decode.loss_ce: 0.0837, decode.acc_seg: 95.4498, aux_0.loss_ce: 0.0877, aux_0.acc_seg: 95.2866, aux_1.loss_ce: 0.0998, aux_1.acc_seg: 94.6886, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2683, aux_2.acc_seg: 95.7782, aux_3.loss_ce: 0.1160, aux_3.acc_seg: 94.5739, loss: 0.7843
2023-03-28 21:55:23,743 - mmseg - INFO - Iter [3750/10000]	lr: 6.552e-03, eta: 2:18:23, time: 1.260, data_time: 0.254, memory: 9072, decode.loss_ce: 0.0840, decode.acc_seg: 95.4447, aux_0.loss_ce: 0.0889, aux_0.acc_seg: 95.2550, aux_1.loss_ce: 0.1004, aux_1.acc_seg: 94.6544, aux_2.loss_ce: 0.1280, aux_2.loss_dice: 0.2666, aux_2.acc_seg: 95.8298, aux_3.loss_ce: 0.1163, aux_3.acc_seg: 94.5626, loss: 0.7842
2023-03-28 21:56:35,555 - mmseg - INFO - Iter [3800/10000]	lr: 6.505e-03, eta: 2:17:26, time: 1.436, data_time: 0.331, memory: 9072, decode.loss_ce: 0.0853, decode.acc_seg: 95.4747, aux_0.loss_ce: 0.0895, aux_0.acc_seg: 95.3181, aux_1.loss_ce: 0.1018, aux_1.acc_seg: 94.6891, aux_2.loss_ce: 0.1279, aux_2.loss_dice: 0.2679, aux_2.acc_seg: 95.8452, aux_3.loss_ce: 0.1175, aux_3.acc_seg: 94.6131, loss: 0.7899
2023-03-28 21:57:41,196 - mmseg - INFO - Iter [3850/10000]	lr: 6.458e-03, eta: 2:16:18, time: 1.313, data_time: 0.291, memory: 9072, decode.loss_ce: 0.0838, decode.acc_seg: 95.5063, aux_0.loss_ce: 0.0885, aux_0.acc_seg: 95.3314, aux_1.loss_ce: 0.0994, aux_1.acc_seg: 94.7567, aux_2.loss_ce: 0.1273, aux_2.loss_dice: 0.2679, aux_2.acc_seg: 95.8865, aux_3.loss_ce: 0.1155, aux_3.acc_seg: 94.6326, loss: 0.7824
2023-03-28 21:58:44,435 - mmseg - INFO - Iter [3900/10000]	lr: 6.410e-03, eta: 2:15:06, time: 1.265, data_time: 0.260, memory: 9072, decode.loss_ce: 0.0827, decode.acc_seg: 95.5331, aux_0.loss_ce: 0.0880, aux_0.acc_seg: 95.3623, aux_1.loss_ce: 0.0988, aux_1.acc_seg: 94.7822, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2670, aux_2.acc_seg: 95.8440, aux_3.loss_ce: 0.1147, aux_3.acc_seg: 94.6607, loss: 0.7788
2023-03-28 21:59:57,993 - mmseg - INFO - Iter [3950/10000]	lr: 6.363e-03, eta: 2:14:11, time: 1.471, data_time: 0.346, memory: 9072, decode.loss_ce: 0.0813, decode.acc_seg: 95.5472, aux_0.loss_ce: 0.0855, aux_0.acc_seg: 95.3784, aux_1.loss_ce: 0.0964, aux_1.acc_seg: 94.8094, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2663, aux_2.acc_seg: 95.8377, aux_3.loss_ce: 0.1122, aux_3.acc_seg: 94.6891, loss: 0.7689
2023-03-28 22:01:02,251 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-03-28 22:01:04,057 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 22:01:04,057 - mmseg - INFO - Iter [4000/10000]	lr: 6.316e-03, eta: 2:13:03, time: 1.321, data_time: 0.292, memory: 9072, decode.loss_ce: 0.0823, decode.acc_seg: 95.5378, aux_0.loss_ce: 0.0864, aux_0.acc_seg: 95.3719, aux_1.loss_ce: 0.0976, aux_1.acc_seg: 94.7761, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2658, aux_2.acc_seg: 95.8642, aux_3.loss_ce: 0.1138, aux_3.acc_seg: 94.6716, loss: 0.7727
2023-03-28 22:01:07,854 - mmseg - INFO - per class results:
2023-03-28 22:01:07,855 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.09 | 89.85 |
|   Building  | 91.93 | 93.72 |
|     Car     | 90.79 | 93.57 |
| Column_Pole |  8.25 |  9.14 |
|    Fence    | 80.12 | 92.35 |
|  Pedestrian | 55.39 | 83.05 |
|     Road    |  97.3 | 98.33 |
|   Sidewalk  | 91.23 | 96.74 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.47 | 95.87 |
|     Tree    | 90.17 | 98.53 |
+-------------+-------+-------+
2023-03-28 22:01:07,856 - mmseg - INFO - Summary:
2023-03-28 22:01:07,856 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.59 | 70.98 | 77.38 |
+-------+-------+-------+
2023-03-28 22:01:07,856 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 22:01:07,856 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9559, mIoU: 0.7098, mAcc: 0.7738, IoU.Bicyclist: 0.8209, IoU.Building: 0.9193, IoU.Car: 0.9079, IoU.Column_Pole: 0.0825, IoU.Fence: 0.8012, IoU.Pedestrian: 0.5539, IoU.Road: 0.9730, IoU.Sidewalk: 0.9123, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9347, IoU.Tree: 0.9017, Acc.Bicyclist: 0.8985, Acc.Building: 0.9372, Acc.Car: 0.9357, Acc.Column_Pole: 0.0914, Acc.Fence: 0.9235, Acc.Pedestrian: 0.8305, Acc.Road: 0.9833, Acc.Sidewalk: 0.9674, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9587, Acc.Tree: 0.9853
2023-03-28 22:02:18,561 - mmseg - INFO - Iter [4050/10000]	lr: 6.268e-03, eta: 2:12:09, time: 1.490, data_time: 0.364, memory: 9072, decode.loss_ce: 0.0812, decode.acc_seg: 95.4817, aux_0.loss_ce: 0.0853, aux_0.acc_seg: 95.3293, aux_1.loss_ce: 0.0976, aux_1.acc_seg: 94.7268, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2645, aux_2.acc_seg: 95.8888, aux_3.loss_ce: 0.1127, aux_3.acc_seg: 94.6115, loss: 0.7672
2023-03-28 22:03:24,801 - mmseg - INFO - Iter [4100/10000]	lr: 6.221e-03, eta: 2:11:01, time: 1.325, data_time: 0.330, memory: 9072, decode.loss_ce: 0.0814, decode.acc_seg: 95.5775, aux_0.loss_ce: 0.0854, aux_0.acc_seg: 95.4221, aux_1.loss_ce: 0.0971, aux_1.acc_seg: 94.8270, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2660, aux_2.acc_seg: 95.8954, aux_3.loss_ce: 0.1128, aux_3.acc_seg: 94.6992, loss: 0.7690
2023-03-28 22:04:25,647 - mmseg - INFO - Iter [4150/10000]	lr: 6.174e-03, eta: 2:09:47, time: 1.217, data_time: 0.237, memory: 9072, decode.loss_ce: 0.0813, decode.acc_seg: 95.5227, aux_0.loss_ce: 0.0858, aux_0.acc_seg: 95.3293, aux_1.loss_ce: 0.0980, aux_1.acc_seg: 94.7198, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8423, aux_3.loss_ce: 0.1126, aux_3.acc_seg: 94.6142, loss: 0.7718
2023-03-28 22:05:35,014 - mmseg - INFO - Iter [4200/10000]	lr: 6.126e-03, eta: 2:08:44, time: 1.387, data_time: 0.254, memory: 9072, decode.loss_ce: 0.0801, decode.acc_seg: 95.5791, aux_0.loss_ce: 0.0846, aux_0.acc_seg: 95.3989, aux_1.loss_ce: 0.0958, aux_1.acc_seg: 94.8104, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 95.8472, aux_3.loss_ce: 0.1107, aux_3.acc_seg: 94.6868, loss: 0.7626
2023-03-28 22:06:45,620 - mmseg - INFO - Iter [4250/10000]	lr: 6.079e-03, eta: 2:07:43, time: 1.412, data_time: 0.361, memory: 9072, decode.loss_ce: 0.0823, decode.acc_seg: 95.5521, aux_0.loss_ce: 0.0868, aux_0.acc_seg: 95.3915, aux_1.loss_ce: 0.0980, aux_1.acc_seg: 94.8049, aux_2.loss_ce: 0.1288, aux_2.loss_dice: 0.2683, aux_2.acc_seg: 95.8254, aux_3.loss_ce: 0.1122, aux_3.acc_seg: 94.7362, loss: 0.7765
2023-03-28 22:07:45,558 - mmseg - INFO - Iter [4300/10000]	lr: 6.031e-03, eta: 2:06:27, time: 1.199, data_time: 0.265, memory: 9072, decode.loss_ce: 0.0836, decode.acc_seg: 95.5102, aux_0.loss_ce: 0.0879, aux_0.acc_seg: 95.3362, aux_1.loss_ce: 0.0995, aux_1.acc_seg: 94.7313, aux_2.loss_ce: 0.1295, aux_2.loss_dice: 0.2675, aux_2.acc_seg: 95.7728, aux_3.loss_ce: 0.1151, aux_3.acc_seg: 94.6205, loss: 0.7831
2023-03-28 22:08:49,083 - mmseg - INFO - Iter [4350/10000]	lr: 5.983e-03, eta: 2:05:17, time: 1.270, data_time: 0.254, memory: 9072, decode.loss_ce: 0.0802, decode.acc_seg: 95.6129, aux_0.loss_ce: 0.0845, aux_0.acc_seg: 95.4629, aux_1.loss_ce: 0.0963, aux_1.acc_seg: 94.8472, aux_2.loss_ce: 0.1277, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8456, aux_3.loss_ce: 0.1111, aux_3.acc_seg: 94.7588, loss: 0.7663
2023-03-28 22:10:03,468 - mmseg - INFO - Iter [4400/10000]	lr: 5.936e-03, eta: 2:04:20, time: 1.488, data_time: 0.349, memory: 9072, decode.loss_ce: 0.0807, decode.acc_seg: 95.5792, aux_0.loss_ce: 0.0852, aux_0.acc_seg: 95.4149, aux_1.loss_ce: 0.0965, aux_1.acc_seg: 94.8281, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2658, aux_2.acc_seg: 95.8541, aux_3.loss_ce: 0.1108, aux_3.acc_seg: 94.7174, loss: 0.7663
2023-03-28 22:11:06,507 - mmseg - INFO - Iter [4450/10000]	lr: 5.888e-03, eta: 2:03:09, time: 1.261, data_time: 0.279, memory: 9072, decode.loss_ce: 0.0799, decode.acc_seg: 95.6589, aux_0.loss_ce: 0.0843, aux_0.acc_seg: 95.5014, aux_1.loss_ce: 0.0960, aux_1.acc_seg: 94.8837, aux_2.loss_ce: 0.1271, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8522, aux_3.loss_ce: 0.1110, aux_3.acc_seg: 94.7636, loss: 0.7647
2023-03-28 22:12:09,437 - mmseg - INFO - Iter [4500/10000]	lr: 5.840e-03, eta: 2:01:58, time: 1.258, data_time: 0.248, memory: 9072, decode.loss_ce: 0.0799, decode.acc_seg: 95.5690, aux_0.loss_ce: 0.0842, aux_0.acc_seg: 95.4111, aux_1.loss_ce: 0.0958, aux_1.acc_seg: 94.8046, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2653, aux_2.acc_seg: 95.8606, aux_3.loss_ce: 0.1100, aux_3.acc_seg: 94.6978, loss: 0.7620
2023-03-28 22:13:22,782 - mmseg - INFO - Iter [4550/10000]	lr: 5.792e-03, eta: 2:01:00, time: 1.467, data_time: 0.325, memory: 9072, decode.loss_ce: 0.0776, decode.acc_seg: 95.7373, aux_0.loss_ce: 0.0822, aux_0.acc_seg: 95.5763, aux_1.loss_ce: 0.0927, aux_1.acc_seg: 94.9989, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2645, aux_2.acc_seg: 95.8943, aux_3.loss_ce: 0.1075, aux_3.acc_seg: 94.8748, loss: 0.7504
2023-03-28 22:14:27,103 - mmseg - INFO - Iter [4600/10000]	lr: 5.745e-03, eta: 1:59:51, time: 1.287, data_time: 0.282, memory: 9072, decode.loss_ce: 0.0791, decode.acc_seg: 95.6716, aux_0.loss_ce: 0.0833, aux_0.acc_seg: 95.5001, aux_1.loss_ce: 0.0957, aux_1.acc_seg: 94.8759, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2645, aux_2.acc_seg: 95.8506, aux_3.loss_ce: 0.1098, aux_3.acc_seg: 94.7839, loss: 0.7589
2023-03-28 22:15:29,921 - mmseg - INFO - Iter [4650/10000]	lr: 5.697e-03, eta: 1:58:40, time: 1.256, data_time: 0.247, memory: 9072, decode.loss_ce: 0.0797, decode.acc_seg: 95.5890, aux_0.loss_ce: 0.0835, aux_0.acc_seg: 95.4350, aux_1.loss_ce: 0.0950, aux_1.acc_seg: 94.8444, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2639, aux_2.acc_seg: 95.8444, aux_3.loss_ce: 0.1094, aux_3.acc_seg: 94.7312, loss: 0.7580
2023-03-28 22:16:42,087 - mmseg - INFO - Iter [4700/10000]	lr: 5.649e-03, eta: 1:57:39, time: 1.443, data_time: 0.353, memory: 9072, decode.loss_ce: 0.0798, decode.acc_seg: 95.6225, aux_0.loss_ce: 0.0834, aux_0.acc_seg: 95.4706, aux_1.loss_ce: 0.0958, aux_1.acc_seg: 94.8486, aux_2.loss_ce: 0.1273, aux_2.loss_dice: 0.2658, aux_2.acc_seg: 95.8382, aux_3.loss_ce: 0.1089, aux_3.acc_seg: 94.7793, loss: 0.7611
2023-03-28 22:17:48,224 - mmseg - INFO - Iter [4750/10000]	lr: 5.601e-03, eta: 1:56:32, time: 1.323, data_time: 0.295, memory: 9072, decode.loss_ce: 0.0795, decode.acc_seg: 95.6156, aux_0.loss_ce: 0.0832, aux_0.acc_seg: 95.4852, aux_1.loss_ce: 0.0951, aux_1.acc_seg: 94.8458, aux_2.loss_ce: 0.1274, aux_2.loss_dice: 0.2656, aux_2.acc_seg: 95.8378, aux_3.loss_ce: 0.1088, aux_3.acc_seg: 94.7440, loss: 0.7596
2023-03-28 22:18:50,838 - mmseg - INFO - Iter [4800/10000]	lr: 5.553e-03, eta: 1:55:21, time: 1.252, data_time: 0.247, memory: 9072, decode.loss_ce: 0.0781, decode.acc_seg: 95.6901, aux_0.loss_ce: 0.0815, aux_0.acc_seg: 95.5751, aux_1.loss_ce: 0.0930, aux_1.acc_seg: 94.9666, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2646, aux_2.acc_seg: 95.8807, aux_3.loss_ce: 0.1069, aux_3.acc_seg: 94.8442, loss: 0.7502
2023-03-28 22:20:02,694 - mmseg - INFO - Iter [4850/10000]	lr: 5.505e-03, eta: 1:54:20, time: 1.437, data_time: 0.338, memory: 9072, decode.loss_ce: 0.0801, decode.acc_seg: 95.6562, aux_0.loss_ce: 0.0849, aux_0.acc_seg: 95.5352, aux_1.loss_ce: 0.0956, aux_1.acc_seg: 94.9272, aux_2.loss_ce: 0.1282, aux_2.loss_dice: 0.2661, aux_2.acc_seg: 95.8073, aux_3.loss_ce: 0.1099, aux_3.acc_seg: 94.7826, loss: 0.7648
2023-03-28 22:21:09,675 - mmseg - INFO - Iter [4900/10000]	lr: 5.457e-03, eta: 1:53:14, time: 1.340, data_time: 0.283, memory: 9072, decode.loss_ce: 0.0762, decode.acc_seg: 95.7267, aux_0.loss_ce: 0.0803, aux_0.acc_seg: 95.5644, aux_1.loss_ce: 0.0919, aux_1.acc_seg: 94.9613, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8586, aux_3.loss_ce: 0.1054, aux_3.acc_seg: 94.8703, loss: 0.7438
2023-03-28 22:22:11,854 - mmseg - INFO - Iter [4950/10000]	lr: 5.408e-03, eta: 1:52:03, time: 1.243, data_time: 0.257, memory: 9072, decode.loss_ce: 0.0794, decode.acc_seg: 95.6028, aux_0.loss_ce: 0.0837, aux_0.acc_seg: 95.4464, aux_1.loss_ce: 0.0945, aux_1.acc_seg: 94.8424, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2651, aux_2.acc_seg: 95.9041, aux_3.loss_ce: 0.1090, aux_3.acc_seg: 94.7332, loss: 0.7576
2023-03-28 22:23:17,342 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-03-28 22:23:19,107 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 22:23:19,108 - mmseg - INFO - Iter [5000/10000]	lr: 5.360e-03, eta: 1:50:57, time: 1.345, data_time: 0.328, memory: 9072, decode.loss_ce: 0.0766, decode.acc_seg: 95.7730, aux_0.loss_ce: 0.0809, aux_0.acc_seg: 95.6203, aux_1.loss_ce: 0.0918, aux_1.acc_seg: 95.0100, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 95.8340, aux_3.loss_ce: 0.1043, aux_3.acc_seg: 94.9393, loss: 0.7429
2023-03-28 22:23:22,827 - mmseg - INFO - per class results:
2023-03-28 22:23:22,828 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.24 | 91.93 |
|   Building  | 91.67 | 93.48 |
|     Car     | 91.64 |  94.0 |
| Column_Pole |  9.25 | 10.42 |
|    Fence    | 78.53 | 92.15 |
|  Pedestrian | 60.03 | 82.71 |
|     Road    | 97.44 | 98.54 |
|   Sidewalk  | 91.71 | 96.45 |
|  SignSymbol |  0.01 |  0.01 |
|     Sky     | 93.61 | 96.35 |
|     Tree    | 90.25 | 98.39 |
+-------------+-------+-------+
2023-03-28 22:23:22,829 - mmseg - INFO - Summary:
2023-03-28 22:23:22,829 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.63 | 71.58 | 77.68 |
+-------+-------+-------+
2023-03-28 22:23:22,829 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 22:23:22,829 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9563, mIoU: 0.7158, mAcc: 0.7768, IoU.Bicyclist: 0.8324, IoU.Building: 0.9167, IoU.Car: 0.9164, IoU.Column_Pole: 0.0925, IoU.Fence: 0.7853, IoU.Pedestrian: 0.6003, IoU.Road: 0.9744, IoU.Sidewalk: 0.9171, IoU.SignSymbol: 0.0001, IoU.Sky: 0.9361, IoU.Tree: 0.9025, Acc.Bicyclist: 0.9193, Acc.Building: 0.9348, Acc.Car: 0.9400, Acc.Column_Pole: 0.1042, Acc.Fence: 0.9215, Acc.Pedestrian: 0.8271, Acc.Road: 0.9854, Acc.Sidewalk: 0.9645, Acc.SignSymbol: 0.0001, Acc.Sky: 0.9635, Acc.Tree: 0.9839
2023-03-28 22:24:25,897 - mmseg - INFO - Iter [5050/10000]	lr: 5.312e-03, eta: 1:49:51, time: 1.336, data_time: 0.360, memory: 9072, decode.loss_ce: 0.0756, decode.acc_seg: 95.8253, aux_0.loss_ce: 0.0793, aux_0.acc_seg: 95.6858, aux_1.loss_ce: 0.0914, aux_1.acc_seg: 95.0645, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2641, aux_2.acc_seg: 95.8670, aux_3.loss_ce: 0.1038, aux_3.acc_seg: 94.9872, loss: 0.7403
2023-03-28 22:25:30,390 - mmseg - INFO - Iter [5100/10000]	lr: 5.264e-03, eta: 1:48:42, time: 1.290, data_time: 0.265, memory: 9072, decode.loss_ce: 0.0769, decode.acc_seg: 95.6771, aux_0.loss_ce: 0.0815, aux_0.acc_seg: 95.5206, aux_1.loss_ce: 0.0928, aux_1.acc_seg: 94.9001, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2644, aux_2.acc_seg: 95.8353, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 94.7948, loss: 0.7487
2023-03-28 22:26:44,809 - mmseg - INFO - Iter [5150/10000]	lr: 5.215e-03, eta: 1:47:43, time: 1.489, data_time: 0.352, memory: 9072, decode.loss_ce: 0.0774, decode.acc_seg: 95.7461, aux_0.loss_ce: 0.0814, aux_0.acc_seg: 95.6121, aux_1.loss_ce: 0.0931, aux_1.acc_seg: 95.0010, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2644, aux_2.acc_seg: 95.8620, aux_3.loss_ce: 0.1050, aux_3.acc_seg: 94.9213, loss: 0.7478
2023-03-28 22:27:52,295 - mmseg - INFO - Iter [5200/10000]	lr: 5.167e-03, eta: 1:46:37, time: 1.350, data_time: 0.304, memory: 9072, decode.loss_ce: 0.0760, decode.acc_seg: 95.7446, aux_0.loss_ce: 0.0800, aux_0.acc_seg: 95.6058, aux_1.loss_ce: 0.0915, aux_1.acc_seg: 94.9951, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8478, aux_3.loss_ce: 0.1040, aux_3.acc_seg: 94.8816, loss: 0.7418
2023-03-28 22:28:55,010 - mmseg - INFO - Iter [5250/10000]	lr: 5.119e-03, eta: 1:45:27, time: 1.254, data_time: 0.292, memory: 9072, decode.loss_ce: 0.0746, decode.acc_seg: 95.8781, aux_0.loss_ce: 0.0785, aux_0.acc_seg: 95.7422, aux_1.loss_ce: 0.0899, aux_1.acc_seg: 95.1273, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2637, aux_2.acc_seg: 95.8667, aux_3.loss_ce: 0.1029, aux_3.acc_seg: 95.0213, loss: 0.7356
2023-03-28 22:30:00,039 - mmseg - INFO - Iter [5300/10000]	lr: 5.070e-03, eta: 1:44:19, time: 1.300, data_time: 0.326, memory: 9072, decode.loss_ce: 0.0750, decode.acc_seg: 95.8308, aux_0.loss_ce: 0.0794, aux_0.acc_seg: 95.6990, aux_1.loss_ce: 0.0903, aux_1.acc_seg: 95.1083, aux_2.loss_ce: 0.1243, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 95.9593, aux_3.loss_ce: 0.1029, aux_3.acc_seg: 95.0020, loss: 0.7355
2023-03-28 22:31:13,146 - mmseg - INFO - Iter [5350/10000]	lr: 5.022e-03, eta: 1:43:18, time: 1.462, data_time: 0.288, memory: 9072, decode.loss_ce: 0.0775, decode.acc_seg: 95.7038, aux_0.loss_ce: 0.0810, aux_0.acc_seg: 95.5599, aux_1.loss_ce: 0.0933, aux_1.acc_seg: 94.9516, aux_2.loss_ce: 0.1280, aux_2.loss_dice: 0.2662, aux_2.acc_seg: 95.8241, aux_3.loss_ce: 0.1057, aux_3.acc_seg: 94.8356, loss: 0.7517
2023-03-28 22:32:15,071 - mmseg - INFO - Iter [5400/10000]	lr: 4.973e-03, eta: 1:42:07, time: 1.238, data_time: 0.249, memory: 9072, decode.loss_ce: 0.0756, decode.acc_seg: 95.8547, aux_0.loss_ce: 0.0805, aux_0.acc_seg: 95.7074, aux_1.loss_ce: 0.0912, aux_1.acc_seg: 95.1001, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2644, aux_2.acc_seg: 95.7913, aux_3.loss_ce: 0.1038, aux_3.acc_seg: 94.9966, loss: 0.7431
2023-03-28 22:33:25,166 - mmseg - INFO - Iter [5450/10000]	lr: 4.924e-03, eta: 1:41:04, time: 1.402, data_time: 0.316, memory: 9072, decode.loss_ce: 0.0739, decode.acc_seg: 95.8360, aux_0.loss_ce: 0.0781, aux_0.acc_seg: 95.6921, aux_1.loss_ce: 0.0881, aux_1.acc_seg: 95.1006, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2624, aux_2.acc_seg: 95.8382, aux_3.loss_ce: 0.1016, aux_3.acc_seg: 94.9968, loss: 0.7299
2023-03-28 22:34:29,803 - mmseg - INFO - Iter [5500/10000]	lr: 4.876e-03, eta: 1:39:55, time: 1.293, data_time: 0.245, memory: 9072, decode.loss_ce: 0.0755, decode.acc_seg: 95.7848, aux_0.loss_ce: 0.0784, aux_0.acc_seg: 95.6881, aux_1.loss_ce: 0.0901, aux_1.acc_seg: 95.0759, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 95.8383, aux_3.loss_ce: 0.1031, aux_3.acc_seg: 94.9550, loss: 0.7370
2023-03-28 22:35:30,874 - mmseg - INFO - Iter [5550/10000]	lr: 4.827e-03, eta: 1:38:44, time: 1.221, data_time: 0.240, memory: 9072, decode.loss_ce: 0.0773, decode.acc_seg: 95.8133, aux_0.loss_ce: 0.0805, aux_0.acc_seg: 95.6891, aux_1.loss_ce: 0.0925, aux_1.acc_seg: 95.0752, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2647, aux_2.acc_seg: 95.8146, aux_3.loss_ce: 0.1052, aux_3.acc_seg: 94.9686, loss: 0.7475
2023-03-28 22:36:37,653 - mmseg - INFO - Iter [5600/10000]	lr: 4.778e-03, eta: 1:37:38, time: 1.336, data_time: 0.297, memory: 9072, decode.loss_ce: 0.0755, decode.acc_seg: 95.8268, aux_0.loss_ce: 0.0797, aux_0.acc_seg: 95.6942, aux_1.loss_ce: 0.0905, aux_1.acc_seg: 95.0795, aux_2.loss_ce: 0.1269, aux_2.loss_dice: 0.2639, aux_2.acc_seg: 95.8297, aux_3.loss_ce: 0.1033, aux_3.acc_seg: 94.9908, loss: 0.7399
2023-03-28 22:37:47,950 - mmseg - INFO - Iter [5650/10000]	lr: 4.729e-03, eta: 1:36:34, time: 1.406, data_time: 0.283, memory: 9072, decode.loss_ce: 0.0751, decode.acc_seg: 95.7725, aux_0.loss_ce: 0.0790, aux_0.acc_seg: 95.6242, aux_1.loss_ce: 0.0906, aux_1.acc_seg: 95.0157, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 95.8452, aux_3.loss_ce: 0.1030, aux_3.acc_seg: 94.9189, loss: 0.7372
2023-03-28 22:38:49,152 - mmseg - INFO - Iter [5700/10000]	lr: 4.680e-03, eta: 1:35:24, time: 1.224, data_time: 0.233, memory: 9072, decode.loss_ce: 0.0744, decode.acc_seg: 95.8154, aux_0.loss_ce: 0.0788, aux_0.acc_seg: 95.6812, aux_1.loss_ce: 0.0895, aux_1.acc_seg: 95.0760, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 95.8982, aux_3.loss_ce: 0.1017, aux_3.acc_seg: 94.9654, loss: 0.7323
2023-03-28 22:39:55,842 - mmseg - INFO - Iter [5750/10000]	lr: 4.631e-03, eta: 1:34:17, time: 1.334, data_time: 0.304, memory: 9072, decode.loss_ce: 0.0749, decode.acc_seg: 95.8249, aux_0.loss_ce: 0.0778, aux_0.acc_seg: 95.6958, aux_1.loss_ce: 0.0901, aux_1.acc_seg: 95.0639, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2631, aux_2.acc_seg: 95.8452, aux_3.loss_ce: 0.1026, aux_3.acc_seg: 94.9662, loss: 0.7347
2023-03-28 22:41:05,329 - mmseg - INFO - Iter [5800/10000]	lr: 4.582e-03, eta: 1:33:13, time: 1.390, data_time: 0.293, memory: 9072, decode.loss_ce: 0.0763, decode.acc_seg: 95.8383, aux_0.loss_ce: 0.0804, aux_0.acc_seg: 95.6854, aux_1.loss_ce: 0.0918, aux_1.acc_seg: 95.0627, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2628, aux_2.acc_seg: 95.8251, aux_3.loss_ce: 0.1051, aux_3.acc_seg: 94.9505, loss: 0.7424
2023-03-28 22:42:08,192 - mmseg - INFO - Iter [5850/10000]	lr: 4.533e-03, eta: 1:32:03, time: 1.257, data_time: 0.254, memory: 9072, decode.loss_ce: 0.0746, decode.acc_seg: 95.8432, aux_0.loss_ce: 0.0782, aux_0.acc_seg: 95.7119, aux_1.loss_ce: 0.0892, aux_1.acc_seg: 95.1205, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.8003, aux_3.loss_ce: 0.1015, aux_3.acc_seg: 95.0124, loss: 0.7337
2023-03-28 22:43:21,015 - mmseg - INFO - Iter [5900/10000]	lr: 4.484e-03, eta: 1:31:01, time: 1.456, data_time: 0.344, memory: 9072, decode.loss_ce: 0.0761, decode.acc_seg: 95.7897, aux_0.loss_ce: 0.0803, aux_0.acc_seg: 95.6618, aux_1.loss_ce: 0.0913, aux_1.acc_seg: 95.0626, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2642, aux_2.acc_seg: 95.8578, aux_3.loss_ce: 0.1042, aux_3.acc_seg: 94.9231, loss: 0.7422
2023-03-28 22:44:23,501 - mmseg - INFO - Iter [5950/10000]	lr: 4.435e-03, eta: 1:29:52, time: 1.250, data_time: 0.244, memory: 9072, decode.loss_ce: 0.0736, decode.acc_seg: 95.9331, aux_0.loss_ce: 0.0778, aux_0.acc_seg: 95.7855, aux_1.loss_ce: 0.0892, aux_1.acc_seg: 95.1833, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8623, aux_3.loss_ce: 0.1005, aux_3.acc_seg: 95.0818, loss: 0.7310
2023-03-28 22:45:26,577 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-03-28 22:45:28,323 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 22:45:28,323 - mmseg - INFO - Iter [6000/10000]	lr: 4.385e-03, eta: 1:28:44, time: 1.296, data_time: 0.241, memory: 9072, decode.loss_ce: 0.0738, decode.acc_seg: 95.8764, aux_0.loss_ce: 0.0787, aux_0.acc_seg: 95.7074, aux_1.loss_ce: 0.0885, aux_1.acc_seg: 95.1085, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8195, aux_3.loss_ce: 0.1010, aux_3.acc_seg: 94.9986, loss: 0.7300
2023-03-28 22:45:31,594 - mmseg - INFO - per class results:
2023-03-28 22:45:31,596 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.78 | 88.91 |
|   Building  | 92.78 | 94.78 |
|     Car     | 91.78 | 94.15 |
| Column_Pole | 12.96 | 14.66 |
|    Fence    | 79.75 | 92.81 |
|  Pedestrian | 58.13 |  81.9 |
|     Road    | 97.45 | 98.62 |
|   Sidewalk  | 91.71 | 96.59 |
|  SignSymbol |  0.35 |  0.35 |
|     Sky     |  93.7 | 96.19 |
|     Tree    | 91.58 |  98.3 |
+-------------+-------+-------+
2023-03-28 22:45:31,596 - mmseg - INFO - Summary:
2023-03-28 22:45:31,596 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.95 | 72.09 | 77.93 |
+-------+-------+-------+
2023-03-28 22:45:31,596 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 22:45:31,596 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9595, mIoU: 0.7209, mAcc: 0.7793, IoU.Bicyclist: 0.8278, IoU.Building: 0.9278, IoU.Car: 0.9178, IoU.Column_Pole: 0.1296, IoU.Fence: 0.7975, IoU.Pedestrian: 0.5813, IoU.Road: 0.9745, IoU.Sidewalk: 0.9171, IoU.SignSymbol: 0.0035, IoU.Sky: 0.9370, IoU.Tree: 0.9158, Acc.Bicyclist: 0.8891, Acc.Building: 0.9478, Acc.Car: 0.9415, Acc.Column_Pole: 0.1466, Acc.Fence: 0.9281, Acc.Pedestrian: 0.8190, Acc.Road: 0.9862, Acc.Sidewalk: 0.9659, Acc.SignSymbol: 0.0035, Acc.Sky: 0.9619, Acc.Tree: 0.9830
2023-03-28 22:46:40,107 - mmseg - INFO - Iter [6050/10000]	lr: 4.336e-03, eta: 1:27:41, time: 1.436, data_time: 0.409, memory: 9072, decode.loss_ce: 0.0756, decode.acc_seg: 95.8259, aux_0.loss_ce: 0.0796, aux_0.acc_seg: 95.6899, aux_1.loss_ce: 0.0908, aux_1.acc_seg: 95.0775, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2645, aux_2.acc_seg: 95.8378, aux_3.loss_ce: 0.1036, aux_3.acc_seg: 94.9421, loss: 0.7410
2023-03-28 22:47:41,150 - mmseg - INFO - Iter [6100/10000]	lr: 4.287e-03, eta: 1:26:31, time: 1.221, data_time: 0.235, memory: 9072, decode.loss_ce: 0.0736, decode.acc_seg: 95.8624, aux_0.loss_ce: 0.0773, aux_0.acc_seg: 95.7372, aux_1.loss_ce: 0.0888, aux_1.acc_seg: 95.1178, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2631, aux_2.acc_seg: 95.8590, aux_3.loss_ce: 0.1006, aux_3.acc_seg: 95.0068, loss: 0.7295
2023-03-28 22:48:45,163 - mmseg - INFO - Iter [6150/10000]	lr: 4.237e-03, eta: 1:25:23, time: 1.280, data_time: 0.261, memory: 9072, decode.loss_ce: 0.0713, decode.acc_seg: 95.9744, aux_0.loss_ce: 0.0751, aux_0.acc_seg: 95.8365, aux_1.loss_ce: 0.0861, aux_1.acc_seg: 95.2376, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.9070, aux_3.loss_ce: 0.0982, aux_3.acc_seg: 95.1277, loss: 0.7150
2023-03-28 22:49:58,867 - mmseg - INFO - Iter [6200/10000]	lr: 4.188e-03, eta: 1:24:21, time: 1.474, data_time: 0.343, memory: 9072, decode.loss_ce: 0.0730, decode.acc_seg: 95.9549, aux_0.loss_ce: 0.0763, aux_0.acc_seg: 95.8295, aux_1.loss_ce: 0.0879, aux_1.acc_seg: 95.2343, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 95.8760, aux_3.loss_ce: 0.1002, aux_3.acc_seg: 95.0863, loss: 0.7261
2023-03-28 22:50:59,341 - mmseg - INFO - Iter [6250/10000]	lr: 4.138e-03, eta: 1:23:10, time: 1.210, data_time: 0.233, memory: 9072, decode.loss_ce: 0.0751, decode.acc_seg: 95.8832, aux_0.loss_ce: 0.0785, aux_0.acc_seg: 95.7464, aux_1.loss_ce: 0.0899, aux_1.acc_seg: 95.1676, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2647, aux_2.acc_seg: 95.8636, aux_3.loss_ce: 0.1019, aux_3.acc_seg: 95.0376, loss: 0.7365
2023-03-28 22:52:02,728 - mmseg - INFO - Iter [6300/10000]	lr: 4.088e-03, eta: 1:22:02, time: 1.268, data_time: 0.229, memory: 9072, decode.loss_ce: 0.0741, decode.acc_seg: 95.8842, aux_0.loss_ce: 0.0786, aux_0.acc_seg: 95.7429, aux_1.loss_ce: 0.0890, aux_1.acc_seg: 95.1393, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8591, aux_3.loss_ce: 0.1017, aux_3.acc_seg: 95.0205, loss: 0.7317
2023-03-28 22:53:17,961 - mmseg - INFO - Iter [6350/10000]	lr: 4.039e-03, eta: 1:21:00, time: 1.505, data_time: 0.354, memory: 9072, decode.loss_ce: 0.0734, decode.acc_seg: 95.9429, aux_0.loss_ce: 0.0776, aux_0.acc_seg: 95.7980, aux_1.loss_ce: 0.0886, aux_1.acc_seg: 95.2135, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2631, aux_2.acc_seg: 95.8277, aux_3.loss_ce: 0.0999, aux_3.acc_seg: 95.1078, loss: 0.7292
2023-03-28 22:54:21,323 - mmseg - INFO - Iter [6400/10000]	lr: 3.989e-03, eta: 1:19:52, time: 1.267, data_time: 0.273, memory: 9072, decode.loss_ce: 0.0719, decode.acc_seg: 95.9565, aux_0.loss_ce: 0.0755, aux_0.acc_seg: 95.8353, aux_1.loss_ce: 0.0865, aux_1.acc_seg: 95.2271, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2619, aux_2.acc_seg: 95.8760, aux_3.loss_ce: 0.0987, aux_3.acc_seg: 95.0970, loss: 0.7195
2023-03-28 22:55:26,388 - mmseg - INFO - Iter [6450/10000]	lr: 3.939e-03, eta: 1:18:45, time: 1.301, data_time: 0.235, memory: 9072, decode.loss_ce: 0.0719, decode.acc_seg: 95.9475, aux_0.loss_ce: 0.0758, aux_0.acc_seg: 95.8220, aux_1.loss_ce: 0.0875, aux_1.acc_seg: 95.2042, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8311, aux_3.loss_ce: 0.0979, aux_3.acc_seg: 95.1028, loss: 0.7218
2023-03-28 22:56:37,497 - mmseg - INFO - Iter [6500/10000]	lr: 3.889e-03, eta: 1:17:40, time: 1.422, data_time: 0.332, memory: 9072, decode.loss_ce: 0.0746, decode.acc_seg: 95.8756, aux_0.loss_ce: 0.0786, aux_0.acc_seg: 95.7326, aux_1.loss_ce: 0.0895, aux_1.acc_seg: 95.1133, aux_2.loss_ce: 0.1269, aux_2.loss_dice: 0.2639, aux_2.acc_seg: 95.8024, aux_3.loss_ce: 0.1015, aux_3.acc_seg: 94.9897, loss: 0.7351
2023-03-28 22:57:37,428 - mmseg - INFO - Iter [6550/10000]	lr: 3.839e-03, eta: 1:16:30, time: 1.199, data_time: 0.236, memory: 9072, decode.loss_ce: 0.0717, decode.acc_seg: 95.9965, aux_0.loss_ce: 0.0756, aux_0.acc_seg: 95.8502, aux_1.loss_ce: 0.0868, aux_1.acc_seg: 95.2514, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8837, aux_3.loss_ce: 0.0980, aux_3.acc_seg: 95.1205, loss: 0.7174
2023-03-28 22:58:47,394 - mmseg - INFO - Iter [6600/10000]	lr: 3.789e-03, eta: 1:15:26, time: 1.399, data_time: 0.272, memory: 9072, decode.loss_ce: 0.0727, decode.acc_seg: 95.8981, aux_0.loss_ce: 0.0770, aux_0.acc_seg: 95.7619, aux_1.loss_ce: 0.0882, aux_1.acc_seg: 95.1454, aux_2.loss_ce: 0.1270, aux_2.loss_dice: 0.2642, aux_2.acc_seg: 95.8095, aux_3.loss_ce: 0.1005, aux_3.acc_seg: 95.0057, loss: 0.7296
2023-03-28 22:59:56,331 - mmseg - INFO - Iter [6650/10000]	lr: 3.739e-03, eta: 1:14:20, time: 1.379, data_time: 0.335, memory: 9072, decode.loss_ce: 0.0719, decode.acc_seg: 95.9676, aux_0.loss_ce: 0.0761, aux_0.acc_seg: 95.8269, aux_1.loss_ce: 0.0869, aux_1.acc_seg: 95.2276, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 95.8335, aux_3.loss_ce: 0.0983, aux_3.acc_seg: 95.1162, loss: 0.7225
2023-03-28 23:00:57,032 - mmseg - INFO - Iter [6700/10000]	lr: 3.689e-03, eta: 1:13:11, time: 1.214, data_time: 0.247, memory: 9072, decode.loss_ce: 0.0727, decode.acc_seg: 95.9314, aux_0.loss_ce: 0.0768, aux_0.acc_seg: 95.7786, aux_1.loss_ce: 0.0872, aux_1.acc_seg: 95.1821, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.8524, aux_3.loss_ce: 0.0991, aux_3.acc_seg: 95.0608, loss: 0.7228
2023-03-28 23:02:04,972 - mmseg - INFO - Iter [6750/10000]	lr: 3.638e-03, eta: 1:12:05, time: 1.359, data_time: 0.234, memory: 9072, decode.loss_ce: 0.0712, decode.acc_seg: 95.9979, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 95.8627, aux_1.loss_ce: 0.0854, aux_1.acc_seg: 95.2495, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.8708, aux_3.loss_ce: 0.0972, aux_3.acc_seg: 95.1449, loss: 0.7145
2023-03-28 23:03:15,662 - mmseg - INFO - Iter [6800/10000]	lr: 3.588e-03, eta: 1:11:00, time: 1.414, data_time: 0.353, memory: 9072, decode.loss_ce: 0.0709, decode.acc_seg: 96.0595, aux_0.loss_ce: 0.0749, aux_0.acc_seg: 95.9123, aux_1.loss_ce: 0.0866, aux_1.acc_seg: 95.2865, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 95.8222, aux_3.loss_ce: 0.0975, aux_3.acc_seg: 95.1731, loss: 0.7189
2023-03-28 23:04:16,750 - mmseg - INFO - Iter [6850/10000]	lr: 3.537e-03, eta: 1:09:51, time: 1.222, data_time: 0.238, memory: 9072, decode.loss_ce: 0.0710, decode.acc_seg: 96.0175, aux_0.loss_ce: 0.0744, aux_0.acc_seg: 95.8806, aux_1.loss_ce: 0.0852, aux_1.acc_seg: 95.2999, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8544, aux_3.loss_ce: 0.0969, aux_3.acc_seg: 95.1671, loss: 0.7137
2023-03-28 23:05:24,253 - mmseg - INFO - Iter [6900/10000]	lr: 3.487e-03, eta: 1:08:45, time: 1.350, data_time: 0.233, memory: 9072, decode.loss_ce: 0.0723, decode.acc_seg: 95.9575, aux_0.loss_ce: 0.0766, aux_0.acc_seg: 95.8128, aux_1.loss_ce: 0.0878, aux_1.acc_seg: 95.1889, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8638, aux_3.loss_ce: 0.0988, aux_3.acc_seg: 95.0716, loss: 0.7231
2023-03-28 23:06:33,640 - mmseg - INFO - Iter [6950/10000]	lr: 3.436e-03, eta: 1:07:40, time: 1.388, data_time: 0.334, memory: 9072, decode.loss_ce: 0.0717, decode.acc_seg: 95.9945, aux_0.loss_ce: 0.0752, aux_0.acc_seg: 95.8415, aux_1.loss_ce: 0.0866, aux_1.acc_seg: 95.2355, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2624, aux_2.acc_seg: 95.8749, aux_3.loss_ce: 0.0975, aux_3.acc_seg: 95.1117, loss: 0.7184
2023-03-28 23:07:34,065 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-03-28 23:07:35,843 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 23:07:35,844 - mmseg - INFO - Iter [7000/10000]	lr: 3.386e-03, eta: 1:06:31, time: 1.244, data_time: 0.236, memory: 9072, decode.loss_ce: 0.0723, decode.acc_seg: 95.9586, aux_0.loss_ce: 0.0755, aux_0.acc_seg: 95.8251, aux_1.loss_ce: 0.0865, aux_1.acc_seg: 95.2364, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2624, aux_2.acc_seg: 95.8735, aux_3.loss_ce: 0.0984, aux_3.acc_seg: 95.0767, loss: 0.7204
2023-03-28 23:07:39,304 - mmseg - INFO - per class results:
2023-03-28 23:07:39,304 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.28 | 89.85 |
|   Building  | 93.23 | 95.14 |
|     Car     | 91.92 | 94.18 |
| Column_Pole | 11.05 | 12.01 |
|    Fence    | 80.98 |  93.1 |
|  Pedestrian | 60.47 | 82.14 |
|     Road    | 97.48 | 98.62 |
|   Sidewalk  | 91.79 | 96.71 |
|  SignSymbol |  0.28 |  0.28 |
|     Sky     | 93.53 | 95.92 |
|     Tree    | 91.55 | 98.41 |
+-------------+-------+-------+
2023-03-28 23:07:39,305 - mmseg - INFO - Summary:
2023-03-28 23:07:39,305 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.07 | 72.32 | 77.85 |
+-------+-------+-------+
2023-03-28 23:07:39,305 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 23:07:39,305 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9607, mIoU: 0.7232, mAcc: 0.7785, IoU.Bicyclist: 0.8328, IoU.Building: 0.9323, IoU.Car: 0.9192, IoU.Column_Pole: 0.1105, IoU.Fence: 0.8098, IoU.Pedestrian: 0.6047, IoU.Road: 0.9748, IoU.Sidewalk: 0.9179, IoU.SignSymbol: 0.0028, IoU.Sky: 0.9353, IoU.Tree: 0.9155, Acc.Bicyclist: 0.8985, Acc.Building: 0.9514, Acc.Car: 0.9418, Acc.Column_Pole: 0.1201, Acc.Fence: 0.9310, Acc.Pedestrian: 0.8214, Acc.Road: 0.9862, Acc.Sidewalk: 0.9671, Acc.SignSymbol: 0.0028, Acc.Sky: 0.9592, Acc.Tree: 0.9841
2023-03-28 23:08:46,529 - mmseg - INFO - Iter [7050/10000]	lr: 3.335e-03, eta: 1:05:27, time: 1.414, data_time: 0.345, memory: 9072, decode.loss_ce: 0.0712, decode.acc_seg: 95.9766, aux_0.loss_ce: 0.0742, aux_0.acc_seg: 95.8526, aux_1.loss_ce: 0.0863, aux_1.acc_seg: 95.2455, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8915, aux_3.loss_ce: 0.0972, aux_3.acc_seg: 95.1223, loss: 0.7149
2023-03-28 23:09:52,947 - mmseg - INFO - Iter [7100/10000]	lr: 3.284e-03, eta: 1:04:20, time: 1.328, data_time: 0.332, memory: 9072, decode.loss_ce: 0.0717, decode.acc_seg: 95.9531, aux_0.loss_ce: 0.0759, aux_0.acc_seg: 95.7899, aux_1.loss_ce: 0.0862, aux_1.acc_seg: 95.2136, aux_2.loss_ce: 0.1253, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.8486, aux_3.loss_ce: 0.0975, aux_3.acc_seg: 95.0605, loss: 0.7181
2023-03-28 23:11:00,821 - mmseg - INFO - Iter [7150/10000]	lr: 3.233e-03, eta: 1:03:14, time: 1.357, data_time: 0.259, memory: 9072, decode.loss_ce: 0.0714, decode.acc_seg: 96.0359, aux_0.loss_ce: 0.0753, aux_0.acc_seg: 95.8933, aux_1.loss_ce: 0.0877, aux_1.acc_seg: 95.2950, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2622, aux_2.acc_seg: 95.8026, aux_3.loss_ce: 0.0974, aux_3.acc_seg: 95.1895, loss: 0.7199
2023-03-28 23:12:08,333 - mmseg - INFO - Iter [7200/10000]	lr: 3.182e-03, eta: 1:02:08, time: 1.350, data_time: 0.292, memory: 9072, decode.loss_ce: 0.0700, decode.acc_seg: 96.0646, aux_0.loss_ce: 0.0738, aux_0.acc_seg: 95.9110, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.3204, aux_2.loss_ce: 0.1253, aux_2.loss_dice: 0.2617, aux_2.acc_seg: 95.8440, aux_3.loss_ce: 0.0963, aux_3.acc_seg: 95.1949, loss: 0.7116
2023-03-28 23:13:13,070 - mmseg - INFO - Iter [7250/10000]	lr: 3.131e-03, eta: 1:01:00, time: 1.295, data_time: 0.307, memory: 9072, decode.loss_ce: 0.0706, decode.acc_seg: 96.0423, aux_0.loss_ce: 0.0748, aux_0.acc_seg: 95.9038, aux_1.loss_ce: 0.0844, aux_1.acc_seg: 95.3243, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.8556, aux_3.loss_ce: 0.0963, aux_3.acc_seg: 95.1859, loss: 0.7129
2023-03-28 23:14:19,449 - mmseg - INFO - Iter [7300/10000]	lr: 3.079e-03, eta: 0:59:54, time: 1.327, data_time: 0.254, memory: 9072, decode.loss_ce: 0.0703, decode.acc_seg: 96.0418, aux_0.loss_ce: 0.0748, aux_0.acc_seg: 95.8894, aux_1.loss_ce: 0.0860, aux_1.acc_seg: 95.2519, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2617, aux_2.acc_seg: 95.8422, aux_3.loss_ce: 0.0971, aux_3.acc_seg: 95.1461, loss: 0.7154
2023-03-28 23:15:28,235 - mmseg - INFO - Iter [7350/10000]	lr: 3.028e-03, eta: 0:58:48, time: 1.376, data_time: 0.302, memory: 9072, decode.loss_ce: 0.0713, decode.acc_seg: 96.0246, aux_0.loss_ce: 0.0759, aux_0.acc_seg: 95.8590, aux_1.loss_ce: 0.0865, aux_1.acc_seg: 95.2839, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2622, aux_2.acc_seg: 95.8325, aux_3.loss_ce: 0.0971, aux_3.acc_seg: 95.1642, loss: 0.7186
2023-03-28 23:16:33,105 - mmseg - INFO - Iter [7400/10000]	lr: 2.977e-03, eta: 0:57:41, time: 1.297, data_time: 0.314, memory: 9072, decode.loss_ce: 0.0733, decode.acc_seg: 95.9190, aux_0.loss_ce: 0.0766, aux_0.acc_seg: 95.7831, aux_1.loss_ce: 0.0876, aux_1.acc_seg: 95.1741, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8665, aux_3.loss_ce: 0.0989, aux_3.acc_seg: 95.0437, loss: 0.7227
2023-03-28 23:17:39,122 - mmseg - INFO - Iter [7450/10000]	lr: 2.925e-03, eta: 0:56:34, time: 1.320, data_time: 0.253, memory: 9072, decode.loss_ce: 0.0707, decode.acc_seg: 95.9857, aux_0.loss_ce: 0.0748, aux_0.acc_seg: 95.8463, aux_1.loss_ce: 0.0857, aux_1.acc_seg: 95.2489, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8265, aux_3.loss_ce: 0.0969, aux_3.acc_seg: 95.1079, loss: 0.7139
2023-03-28 23:18:46,994 - mmseg - INFO - Iter [7500/10000]	lr: 2.873e-03, eta: 0:55:28, time: 1.357, data_time: 0.275, memory: 9072, decode.loss_ce: 0.0677, decode.acc_seg: 96.1345, aux_0.loss_ce: 0.0712, aux_0.acc_seg: 95.9843, aux_1.loss_ce: 0.0817, aux_1.acc_seg: 95.4076, aux_2.loss_ce: 0.1229, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 95.9380, aux_3.loss_ce: 0.0930, aux_3.acc_seg: 95.2788, loss: 0.6970
2023-03-28 23:19:52,890 - mmseg - INFO - Iter [7550/10000]	lr: 2.822e-03, eta: 0:54:21, time: 1.318, data_time: 0.344, memory: 9072, decode.loss_ce: 0.0707, decode.acc_seg: 96.0337, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 95.9016, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.3151, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2622, aux_2.acc_seg: 95.8289, aux_3.loss_ce: 0.0957, aux_3.acc_seg: 95.1907, loss: 0.7135
2023-03-28 23:21:02,982 - mmseg - INFO - Iter [7600/10000]	lr: 2.770e-03, eta: 0:53:16, time: 1.402, data_time: 0.260, memory: 9072, decode.loss_ce: 0.0699, decode.acc_seg: 96.0916, aux_0.loss_ce: 0.0737, aux_0.acc_seg: 95.9538, aux_1.loss_ce: 0.0844, aux_1.acc_seg: 95.3499, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8843, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.2110, loss: 0.7089
2023-03-28 23:22:08,130 - mmseg - INFO - Iter [7650/10000]	lr: 2.718e-03, eta: 0:52:09, time: 1.303, data_time: 0.278, memory: 9072, decode.loss_ce: 0.0722, decode.acc_seg: 95.9923, aux_0.loss_ce: 0.0765, aux_0.acc_seg: 95.8526, aux_1.loss_ce: 0.0865, aux_1.acc_seg: 95.2786, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2629, aux_2.acc_seg: 95.8477, aux_3.loss_ce: 0.0979, aux_3.acc_seg: 95.1237, loss: 0.7218
2023-03-28 23:23:14,379 - mmseg - INFO - Iter [7700/10000]	lr: 2.666e-03, eta: 0:51:02, time: 1.325, data_time: 0.323, memory: 9072, decode.loss_ce: 0.0694, decode.acc_seg: 95.9939, aux_0.loss_ce: 0.0735, aux_0.acc_seg: 95.8608, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.2650, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8494, aux_3.loss_ce: 0.0951, aux_3.acc_seg: 95.1300, loss: 0.7079
2023-03-28 23:24:27,176 - mmseg - INFO - Iter [7750/10000]	lr: 2.614e-03, eta: 0:49:57, time: 1.456, data_time: 0.287, memory: 9072, decode.loss_ce: 0.0707, decode.acc_seg: 96.0513, aux_0.loss_ce: 0.0752, aux_0.acc_seg: 95.8918, aux_1.loss_ce: 0.0863, aux_1.acc_seg: 95.3078, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 95.7849, aux_3.loss_ce: 0.0964, aux_3.acc_seg: 95.2020, loss: 0.7169
2023-03-28 23:25:30,359 - mmseg - INFO - Iter [7800/10000]	lr: 2.561e-03, eta: 0:48:50, time: 1.264, data_time: 0.290, memory: 9072, decode.loss_ce: 0.0707, decode.acc_seg: 96.0114, aux_0.loss_ce: 0.0751, aux_0.acc_seg: 95.8740, aux_1.loss_ce: 0.0850, aux_1.acc_seg: 95.2910, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2618, aux_2.acc_seg: 95.8547, aux_3.loss_ce: 0.0959, aux_3.acc_seg: 95.1454, loss: 0.7134
2023-03-28 23:26:35,620 - mmseg - INFO - Iter [7850/10000]	lr: 2.509e-03, eta: 0:47:43, time: 1.305, data_time: 0.307, memory: 9072, decode.loss_ce: 0.0713, decode.acc_seg: 96.0222, aux_0.loss_ce: 0.0749, aux_0.acc_seg: 95.8824, aux_1.loss_ce: 0.0859, aux_1.acc_seg: 95.2768, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8838, aux_3.loss_ce: 0.0967, aux_3.acc_seg: 95.1396, loss: 0.7152
2023-03-28 23:27:47,411 - mmseg - INFO - Iter [7900/10000]	lr: 2.457e-03, eta: 0:46:38, time: 1.436, data_time: 0.281, memory: 9072, decode.loss_ce: 0.0707, decode.acc_seg: 96.0623, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 95.9265, aux_1.loss_ce: 0.0858, aux_1.acc_seg: 95.3536, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2628, aux_2.acc_seg: 95.8214, aux_3.loss_ce: 0.0961, aux_3.acc_seg: 95.2241, loss: 0.7159
2023-03-28 23:28:54,395 - mmseg - INFO - Iter [7950/10000]	lr: 2.404e-03, eta: 0:45:31, time: 1.340, data_time: 0.307, memory: 9072, decode.loss_ce: 0.0714, decode.acc_seg: 95.9574, aux_0.loss_ce: 0.0745, aux_0.acc_seg: 95.8253, aux_1.loss_ce: 0.0853, aux_1.acc_seg: 95.2287, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 95.7969, aux_3.loss_ce: 0.0965, aux_3.acc_seg: 95.0921, loss: 0.7147
2023-03-28 23:30:02,228 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-03-28 23:30:03,758 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 23:30:03,759 - mmseg - INFO - Iter [8000/10000]	lr: 2.351e-03, eta: 0:44:25, time: 1.387, data_time: 0.345, memory: 9072, decode.loss_ce: 0.0706, decode.acc_seg: 96.0325, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.9046, aux_1.loss_ce: 0.0855, aux_1.acc_seg: 95.2959, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8748, aux_3.loss_ce: 0.0954, aux_3.acc_seg: 95.1691, loss: 0.7104
2023-03-28 23:30:07,663 - mmseg - INFO - per class results:
2023-03-28 23:30:07,664 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 84.36 | 91.81 |
|   Building  | 92.75 | 94.61 |
|     Car     | 91.94 | 94.72 |
| Column_Pole |  8.37 |  8.95 |
|    Fence    | 80.49 | 95.17 |
|  Pedestrian | 60.38 | 80.83 |
|     Road    | 97.52 | 98.62 |
|   Sidewalk  | 91.79 |  96.6 |
|  SignSymbol |  0.29 |  0.29 |
|     Sky     |  93.8 | 96.53 |
|     Tree    | 91.69 | 98.16 |
+-------------+-------+-------+
2023-03-28 23:30:07,664 - mmseg - INFO - Summary:
2023-03-28 23:30:07,665 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.03 | 72.13 | 77.84 |
+-------+-------+-------+
2023-03-28 23:30:07,665 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 23:30:07,665 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9603, mIoU: 0.7213, mAcc: 0.7784, IoU.Bicyclist: 0.8436, IoU.Building: 0.9275, IoU.Car: 0.9194, IoU.Column_Pole: 0.0837, IoU.Fence: 0.8049, IoU.Pedestrian: 0.6038, IoU.Road: 0.9752, IoU.Sidewalk: 0.9179, IoU.SignSymbol: 0.0029, IoU.Sky: 0.9380, IoU.Tree: 0.9169, Acc.Bicyclist: 0.9181, Acc.Building: 0.9461, Acc.Car: 0.9472, Acc.Column_Pole: 0.0895, Acc.Fence: 0.9517, Acc.Pedestrian: 0.8083, Acc.Road: 0.9862, Acc.Sidewalk: 0.9660, Acc.SignSymbol: 0.0029, Acc.Sky: 0.9653, Acc.Tree: 0.9816
2023-03-28 23:31:17,562 - mmseg - INFO - Iter [8050/10000]	lr: 2.298e-03, eta: 0:43:20, time: 1.476, data_time: 0.356, memory: 9072, decode.loss_ce: 0.0709, decode.acc_seg: 96.0647, aux_0.loss_ce: 0.0737, aux_0.acc_seg: 95.9323, aux_1.loss_ce: 0.0855, aux_1.acc_seg: 95.3706, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8454, aux_3.loss_ce: 0.0960, aux_3.acc_seg: 95.2084, loss: 0.7138
2023-03-28 23:32:19,282 - mmseg - INFO - Iter [8100/10000]	lr: 2.245e-03, eta: 0:42:12, time: 1.234, data_time: 0.243, memory: 9072, decode.loss_ce: 0.0690, decode.acc_seg: 96.0990, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 95.9374, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.3389, aux_2.loss_ce: 0.1242, aux_2.loss_dice: 0.2600, aux_2.acc_seg: 95.8920, aux_3.loss_ce: 0.0945, aux_3.acc_seg: 95.2266, loss: 0.7053
2023-03-28 23:33:28,488 - mmseg - INFO - Iter [8150/10000]	lr: 2.192e-03, eta: 0:41:06, time: 1.384, data_time: 0.309, memory: 9072, decode.loss_ce: 0.0697, decode.acc_seg: 96.0302, aux_0.loss_ce: 0.0735, aux_0.acc_seg: 95.8867, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.2782, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2606, aux_2.acc_seg: 95.8603, aux_3.loss_ce: 0.0952, aux_3.acc_seg: 95.1441, loss: 0.7081
2023-03-28 23:34:36,799 - mmseg - INFO - Iter [8200/10000]	lr: 2.139e-03, eta: 0:40:00, time: 1.366, data_time: 0.292, memory: 9072, decode.loss_ce: 0.0709, decode.acc_seg: 96.0656, aux_0.loss_ce: 0.0749, aux_0.acc_seg: 95.9319, aux_1.loss_ce: 0.0858, aux_1.acc_seg: 95.3291, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 95.8181, aux_3.loss_ce: 0.0958, aux_3.acc_seg: 95.2053, loss: 0.7156
2023-03-28 23:35:39,282 - mmseg - INFO - Iter [8250/10000]	lr: 2.085e-03, eta: 0:38:52, time: 1.249, data_time: 0.255, memory: 9072, decode.loss_ce: 0.0696, decode.acc_seg: 96.0320, aux_0.loss_ce: 0.0741, aux_0.acc_seg: 95.8850, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.2687, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.9083, aux_3.loss_ce: 0.0947, aux_3.acc_seg: 95.1324, loss: 0.7072
2023-03-28 23:36:48,154 - mmseg - INFO - Iter [8300/10000]	lr: 2.031e-03, eta: 0:37:46, time: 1.377, data_time: 0.302, memory: 9072, decode.loss_ce: 0.0685, decode.acc_seg: 96.0910, aux_0.loss_ce: 0.0725, aux_0.acc_seg: 95.9510, aux_1.loss_ce: 0.0827, aux_1.acc_seg: 95.3803, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 95.8632, aux_3.loss_ce: 0.0930, aux_3.acc_seg: 95.2425, loss: 0.7018
2023-03-28 23:37:54,836 - mmseg - INFO - Iter [8350/10000]	lr: 1.978e-03, eta: 0:36:40, time: 1.334, data_time: 0.261, memory: 9072, decode.loss_ce: 0.0692, decode.acc_seg: 96.0845, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 95.9345, aux_1.loss_ce: 0.0839, aux_1.acc_seg: 95.3604, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.8668, aux_3.loss_ce: 0.0936, aux_3.acc_seg: 95.2211, loss: 0.7056
2023-03-28 23:38:57,380 - mmseg - INFO - Iter [8400/10000]	lr: 1.924e-03, eta: 0:35:32, time: 1.251, data_time: 0.246, memory: 9072, decode.loss_ce: 0.0682, decode.acc_seg: 96.1470, aux_0.loss_ce: 0.0720, aux_0.acc_seg: 96.0125, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.4057, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8213, aux_3.loss_ce: 0.0933, aux_3.acc_seg: 95.2678, loss: 0.7038
2023-03-28 23:40:09,764 - mmseg - INFO - Iter [8450/10000]	lr: 1.870e-03, eta: 0:34:26, time: 1.448, data_time: 0.344, memory: 9072, decode.loss_ce: 0.0685, decode.acc_seg: 96.0864, aux_0.loss_ce: 0.0716, aux_0.acc_seg: 95.9537, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.3609, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 95.8918, aux_3.loss_ce: 0.0934, aux_3.acc_seg: 95.2190, loss: 0.7015
2023-03-28 23:41:16,537 - mmseg - INFO - Iter [8500/10000]	lr: 1.815e-03, eta: 0:33:20, time: 1.336, data_time: 0.277, memory: 9072, decode.loss_ce: 0.0689, decode.acc_seg: 96.1080, aux_0.loss_ce: 0.0725, aux_0.acc_seg: 95.9675, aux_1.loss_ce: 0.0829, aux_1.acc_seg: 95.3947, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8791, aux_3.loss_ce: 0.0933, aux_3.acc_seg: 95.2419, loss: 0.7032
2023-03-28 23:42:21,988 - mmseg - INFO - Iter [8550/10000]	lr: 1.761e-03, eta: 0:32:13, time: 1.309, data_time: 0.262, memory: 9072, decode.loss_ce: 0.0686, decode.acc_seg: 96.1171, aux_0.loss_ce: 0.0725, aux_0.acc_seg: 95.9721, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.3868, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 95.8645, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.2586, loss: 0.7022
2023-03-28 23:43:36,058 - mmseg - INFO - Iter [8600/10000]	lr: 1.706e-03, eta: 0:31:07, time: 1.481, data_time: 0.353, memory: 9072, decode.loss_ce: 0.0711, decode.acc_seg: 96.0220, aux_0.loss_ce: 0.0745, aux_0.acc_seg: 95.8959, aux_1.loss_ce: 0.0857, aux_1.acc_seg: 95.2944, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 95.8704, aux_3.loss_ce: 0.0960, aux_3.acc_seg: 95.1538, loss: 0.7152
2023-03-28 23:44:36,658 - mmseg - INFO - Iter [8650/10000]	lr: 1.651e-03, eta: 0:30:00, time: 1.212, data_time: 0.243, memory: 9072, decode.loss_ce: 0.0688, decode.acc_seg: 96.1248, aux_0.loss_ce: 0.0726, aux_0.acc_seg: 95.9890, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.4006, aux_2.loss_ce: 0.1242, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.8697, aux_3.loss_ce: 0.0936, aux_3.acc_seg: 95.2651, loss: 0.7025
2023-03-28 23:45:40,491 - mmseg - INFO - Iter [8700/10000]	lr: 1.596e-03, eta: 0:28:53, time: 1.277, data_time: 0.237, memory: 9072, decode.loss_ce: 0.0679, decode.acc_seg: 96.1529, aux_0.loss_ce: 0.0721, aux_0.acc_seg: 95.9918, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.4114, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 95.8333, aux_3.loss_ce: 0.0925, aux_3.acc_seg: 95.2685, loss: 0.7013
2023-03-28 23:46:54,203 - mmseg - INFO - Iter [8750/10000]	lr: 1.541e-03, eta: 0:27:47, time: 1.474, data_time: 0.331, memory: 9072, decode.loss_ce: 0.0690, decode.acc_seg: 96.0857, aux_0.loss_ce: 0.0726, aux_0.acc_seg: 95.9476, aux_1.loss_ce: 0.0833, aux_1.acc_seg: 95.3441, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 95.8622, aux_3.loss_ce: 0.0933, aux_3.acc_seg: 95.2139, loss: 0.7045
2023-03-28 23:47:56,714 - mmseg - INFO - Iter [8800/10000]	lr: 1.485e-03, eta: 0:26:40, time: 1.250, data_time: 0.265, memory: 9072, decode.loss_ce: 0.0698, decode.acc_seg: 96.0680, aux_0.loss_ce: 0.0732, aux_0.acc_seg: 95.9356, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.3284, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 95.8060, aux_3.loss_ce: 0.0945, aux_3.acc_seg: 95.1993, loss: 0.7110
2023-03-28 23:48:47,868 - mmseg - INFO - Iter [8850/10000]	lr: 1.430e-03, eta: 0:25:31, time: 1.023, data_time: 0.240, memory: 9072, decode.loss_ce: 0.0694, decode.acc_seg: 96.0271, aux_0.loss_ce: 0.0728, aux_0.acc_seg: 95.8967, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.2750, aux_2.loss_ce: 0.1233, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 95.9158, aux_3.loss_ce: 0.0941, aux_3.acc_seg: 95.1781, loss: 0.7033
2023-03-28 23:49:35,706 - mmseg - INFO - Iter [8900/10000]	lr: 1.374e-03, eta: 0:24:22, time: 0.957, data_time: 0.342, memory: 9072, decode.loss_ce: 0.0685, decode.acc_seg: 96.1321, aux_0.loss_ce: 0.0717, aux_0.acc_seg: 96.0039, aux_1.loss_ce: 0.0826, aux_1.acc_seg: 95.4183, aux_2.loss_ce: 0.1242, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.9114, aux_3.loss_ce: 0.0930, aux_3.acc_seg: 95.2567, loss: 0.7009
2023-03-28 23:50:18,607 - mmseg - INFO - Iter [8950/10000]	lr: 1.317e-03, eta: 0:23:13, time: 0.858, data_time: 0.247, memory: 9072, decode.loss_ce: 0.0690, decode.acc_seg: 96.1305, aux_0.loss_ce: 0.0730, aux_0.acc_seg: 95.9877, aux_1.loss_ce: 0.0829, aux_1.acc_seg: 95.4033, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8321, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.2585, loss: 0.7054
2023-03-28 23:51:00,756 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-03-28 23:51:02,731 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 23:51:02,731 - mmseg - INFO - Iter [9000/10000]	lr: 1.261e-03, eta: 0:22:04, time: 0.883, data_time: 0.238, memory: 9072, decode.loss_ce: 0.0705, decode.acc_seg: 96.0532, aux_0.loss_ce: 0.0746, aux_0.acc_seg: 95.9055, aux_1.loss_ce: 0.0859, aux_1.acc_seg: 95.3027, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 95.8392, aux_3.loss_ce: 0.0952, aux_3.acc_seg: 95.1892, loss: 0.7143
2023-03-28 23:51:05,940 - mmseg - INFO - per class results:
2023-03-28 23:51:05,941 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.17 | 89.52 |
|   Building  | 92.48 | 94.37 |
|     Car     | 91.92 | 94.19 |
| Column_Pole | 10.38 | 11.41 |
|    Fence    | 79.96 | 93.66 |
|  Pedestrian | 58.74 | 82.88 |
|     Road    | 97.48 | 98.57 |
|   Sidewalk  | 91.65 | 96.76 |
|  SignSymbol |  0.15 |  0.15 |
|     Sky     | 93.71 | 96.25 |
|     Tree    | 91.27 | 98.36 |
+-------------+-------+-------+
2023-03-28 23:51:05,941 - mmseg - INFO - Summary:
2023-03-28 23:51:05,941 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 95.89 | 71.9 | 77.83 |
+-------+------+-------+
2023-03-28 23:51:05,941 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-28 23:51:05,941 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9589, mIoU: 0.7190, mAcc: 0.7783, IoU.Bicyclist: 0.8317, IoU.Building: 0.9248, IoU.Car: 0.9192, IoU.Column_Pole: 0.1038, IoU.Fence: 0.7996, IoU.Pedestrian: 0.5874, IoU.Road: 0.9748, IoU.Sidewalk: 0.9165, IoU.SignSymbol: 0.0015, IoU.Sky: 0.9371, IoU.Tree: 0.9127, Acc.Bicyclist: 0.8952, Acc.Building: 0.9437, Acc.Car: 0.9419, Acc.Column_Pole: 0.1141, Acc.Fence: 0.9366, Acc.Pedestrian: 0.8288, Acc.Road: 0.9857, Acc.Sidewalk: 0.9676, Acc.SignSymbol: 0.0015, Acc.Sky: 0.9625, Acc.Tree: 0.9836
2023-03-28 23:51:51,319 - mmseg - INFO - Iter [9050/10000]	lr: 1.204e-03, eta: 0:20:56, time: 0.972, data_time: 0.360, memory: 9072, decode.loss_ce: 0.0682, decode.acc_seg: 96.1319, aux_0.loss_ce: 0.0717, aux_0.acc_seg: 96.0076, aux_1.loss_ce: 0.0823, aux_1.acc_seg: 95.4193, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2606, aux_2.acc_seg: 95.9080, aux_3.loss_ce: 0.0926, aux_3.acc_seg: 95.2662, loss: 0.6992
2023-03-28 23:52:33,279 - mmseg - INFO - Iter [9100/10000]	lr: 1.147e-03, eta: 0:19:47, time: 0.839, data_time: 0.233, memory: 9072, decode.loss_ce: 0.0672, decode.acc_seg: 96.1738, aux_0.loss_ce: 0.0713, aux_0.acc_seg: 96.0457, aux_1.loss_ce: 0.0819, aux_1.acc_seg: 95.4534, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2606, aux_2.acc_seg: 95.8561, aux_3.loss_ce: 0.0914, aux_3.acc_seg: 95.3077, loss: 0.6969
2023-03-28 23:53:14,988 - mmseg - INFO - Iter [9150/10000]	lr: 1.090e-03, eta: 0:18:39, time: 0.834, data_time: 0.231, memory: 9072, decode.loss_ce: 0.0687, decode.acc_seg: 96.1173, aux_0.loss_ce: 0.0731, aux_0.acc_seg: 95.9797, aux_1.loss_ce: 0.0844, aux_1.acc_seg: 95.3768, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8637, aux_3.loss_ce: 0.0930, aux_3.acc_seg: 95.2504, loss: 0.7053
2023-03-28 23:54:00,344 - mmseg - INFO - Iter [9200/10000]	lr: 1.032e-03, eta: 0:17:32, time: 0.907, data_time: 0.299, memory: 9072, decode.loss_ce: 0.0682, decode.acc_seg: 96.1516, aux_0.loss_ce: 0.0718, aux_0.acc_seg: 96.0130, aux_1.loss_ce: 0.0828, aux_1.acc_seg: 95.4048, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8358, aux_3.loss_ce: 0.0930, aux_3.acc_seg: 95.2570, loss: 0.7019
2023-03-28 23:54:42,335 - mmseg - INFO - Iter [9250/10000]	lr: 9.738e-04, eta: 0:16:24, time: 0.840, data_time: 0.235, memory: 9072, decode.loss_ce: 0.0690, decode.acc_seg: 96.0790, aux_0.loss_ce: 0.0730, aux_0.acc_seg: 95.9334, aux_1.loss_ce: 0.0833, aux_1.acc_seg: 95.3355, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8878, aux_3.loss_ce: 0.0933, aux_3.acc_seg: 95.2017, loss: 0.7042
2023-03-28 23:55:24,118 - mmseg - INFO - Iter [9300/10000]	lr: 9.153e-04, eta: 0:15:16, time: 0.836, data_time: 0.233, memory: 9072, decode.loss_ce: 0.0686, decode.acc_seg: 96.1450, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 95.9976, aux_1.loss_ce: 0.0824, aux_1.acc_seg: 95.4045, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2598, aux_2.acc_seg: 95.9038, aux_3.loss_ce: 0.0923, aux_3.acc_seg: 95.2633, loss: 0.6988
2023-03-28 23:56:10,967 - mmseg - INFO - Iter [9350/10000]	lr: 8.564e-04, eta: 0:14:10, time: 0.937, data_time: 0.319, memory: 9072, decode.loss_ce: 0.0692, decode.acc_seg: 96.1025, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 95.9731, aux_1.loss_ce: 0.0839, aux_1.acc_seg: 95.3689, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.8634, aux_3.loss_ce: 0.0932, aux_3.acc_seg: 95.2398, loss: 0.7040
2023-03-28 23:56:53,290 - mmseg - INFO - Iter [9400/10000]	lr: 7.971e-04, eta: 0:13:03, time: 0.846, data_time: 0.234, memory: 9072, decode.loss_ce: 0.0683, decode.acc_seg: 96.1212, aux_0.loss_ce: 0.0725, aux_0.acc_seg: 95.9819, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.3943, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2602, aux_2.acc_seg: 95.8431, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.2564, loss: 0.7019
2023-03-28 23:57:36,474 - mmseg - INFO - Iter [9450/10000]	lr: 7.372e-04, eta: 0:11:56, time: 0.864, data_time: 0.252, memory: 9072, decode.loss_ce: 0.0694, decode.acc_seg: 96.0932, aux_0.loss_ce: 0.0731, aux_0.acc_seg: 95.9690, aux_1.loss_ce: 0.0836, aux_1.acc_seg: 95.3769, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2617, aux_2.acc_seg: 95.7999, aux_3.loss_ce: 0.0940, aux_3.acc_seg: 95.2208, loss: 0.7081
2023-03-28 23:58:22,871 - mmseg - INFO - Iter [9500/10000]	lr: 6.768e-04, eta: 0:10:50, time: 0.928, data_time: 0.312, memory: 9072, decode.loss_ce: 0.0681, decode.acc_seg: 96.1232, aux_0.loss_ce: 0.0711, aux_0.acc_seg: 95.9958, aux_1.loss_ce: 0.0822, aux_1.acc_seg: 95.3920, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8926, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.2543, loss: 0.6989
2023-03-28 23:59:04,239 - mmseg - INFO - Iter [9550/10000]	lr: 6.158e-04, eta: 0:09:44, time: 0.827, data_time: 0.229, memory: 9072, decode.loss_ce: 0.0684, decode.acc_seg: 96.1817, aux_0.loss_ce: 0.0721, aux_0.acc_seg: 96.0496, aux_1.loss_ce: 0.0829, aux_1.acc_seg: 95.4805, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8778, aux_3.loss_ce: 0.0925, aux_3.acc_seg: 95.3218, loss: 0.7012
2023-03-28 23:59:46,957 - mmseg - INFO - Iter [9600/10000]	lr: 5.541e-04, eta: 0:08:38, time: 0.854, data_time: 0.244, memory: 9072, decode.loss_ce: 0.0683, decode.acc_seg: 96.1291, aux_0.loss_ce: 0.0726, aux_0.acc_seg: 96.0021, aux_1.loss_ce: 0.0827, aux_1.acc_seg: 95.4152, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 95.8100, aux_3.loss_ce: 0.0923, aux_3.acc_seg: 95.2757, loss: 0.7025
2023-03-29 00:00:32,347 - mmseg - INFO - Iter [9650/10000]	lr: 4.916e-04, eta: 0:07:33, time: 0.908, data_time: 0.296, memory: 9072, decode.loss_ce: 0.0683, decode.acc_seg: 96.1435, aux_0.loss_ce: 0.0730, aux_0.acc_seg: 95.9927, aux_1.loss_ce: 0.0824, aux_1.acc_seg: 95.4126, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2606, aux_2.acc_seg: 95.8206, aux_3.loss_ce: 0.0925, aux_3.acc_seg: 95.2587, loss: 0.7021
2023-03-29 00:01:13,862 - mmseg - INFO - Iter [9700/10000]	lr: 4.282e-04, eta: 0:06:27, time: 0.830, data_time: 0.228, memory: 9072, decode.loss_ce: 0.0682, decode.acc_seg: 96.1633, aux_0.loss_ce: 0.0716, aux_0.acc_seg: 96.0415, aux_1.loss_ce: 0.0825, aux_1.acc_seg: 95.4696, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.8740, aux_3.loss_ce: 0.0918, aux_3.acc_seg: 95.3324, loss: 0.6986
2023-03-29 00:01:55,702 - mmseg - INFO - Iter [9750/10000]	lr: 3.638e-04, eta: 0:05:22, time: 0.837, data_time: 0.231, memory: 9072, decode.loss_ce: 0.0672, decode.acc_seg: 96.1921, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 96.0324, aux_1.loss_ce: 0.0821, aux_1.acc_seg: 95.4482, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 95.8433, aux_3.loss_ce: 0.0914, aux_3.acc_seg: 95.3262, loss: 0.6975
2023-03-29 00:02:57,118 - mmseg - INFO - Iter [9800/10000]	lr: 2.981e-04, eta: 0:04:17, time: 1.228, data_time: 0.297, memory: 9072, decode.loss_ce: 0.0674, decode.acc_seg: 96.1747, aux_0.loss_ce: 0.0710, aux_0.acc_seg: 96.0548, aux_1.loss_ce: 0.0817, aux_1.acc_seg: 95.4736, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2600, aux_2.acc_seg: 95.8771, aux_3.loss_ce: 0.0912, aux_3.acc_seg: 95.3201, loss: 0.6952
2023-03-29 00:04:11,833 - mmseg - INFO - Iter [9850/10000]	lr: 2.306e-04, eta: 0:03:13, time: 1.494, data_time: 0.221, memory: 9072, decode.loss_ce: 0.0687, decode.acc_seg: 96.1276, aux_0.loss_ce: 0.0725, aux_0.acc_seg: 95.9814, aux_1.loss_ce: 0.0821, aux_1.acc_seg: 95.3964, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2602, aux_2.acc_seg: 95.8783, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.2573, loss: 0.6995
2023-03-29 00:05:27,908 - mmseg - INFO - Iter [9900/10000]	lr: 1.609e-04, eta: 0:02:09, time: 1.521, data_time: 0.231, memory: 9072, decode.loss_ce: 0.0679, decode.acc_seg: 96.1300, aux_0.loss_ce: 0.0718, aux_0.acc_seg: 95.9880, aux_1.loss_ce: 0.0822, aux_1.acc_seg: 95.4082, aux_2.loss_ce: 0.1231, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 95.8924, aux_3.loss_ce: 0.0914, aux_3.acc_seg: 95.2806, loss: 0.6959
2023-03-29 00:06:46,192 - mmseg - INFO - Iter [9950/10000]	lr: 8.745e-05, eta: 0:01:04, time: 1.566, data_time: 0.288, memory: 9072, decode.loss_ce: 0.0678, decode.acc_seg: 96.1624, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 96.0128, aux_1.loss_ce: 0.0823, aux_1.acc_seg: 95.4267, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 95.8604, aux_3.loss_ce: 0.0915, aux_3.acc_seg: 95.2852, loss: 0.6978
2023-03-29 00:08:01,559 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-03-29 00:08:02,855 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-29 00:08:02,855 - mmseg - INFO - Iter [10000/10000]	lr: 3.512e-06, eta: 0:00:00, time: 1.533, data_time: 0.228, memory: 9072, decode.loss_ce: 0.0670, decode.acc_seg: 96.1887, aux_0.loss_ce: 0.0710, aux_0.acc_seg: 96.0458, aux_1.loss_ce: 0.0809, aux_1.acc_seg: 95.4702, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2593, aux_2.acc_seg: 95.8244, aux_3.loss_ce: 0.0911, aux_3.acc_seg: 95.3026, loss: 0.6942
2023-03-29 00:08:05,976 - mmseg - INFO - per class results:
2023-03-29 00:08:05,977 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.21 | 89.54 |
|   Building  | 92.21 | 94.04 |
|     Car     |  91.9 | 94.38 |
| Column_Pole | 11.77 | 13.15 |
|    Fence    | 80.38 | 92.95 |
|  Pedestrian | 58.76 | 82.15 |
|     Road    | 97.47 |  98.6 |
|   Sidewalk  | 91.49 | 96.89 |
|  SignSymbol |  0.04 |  0.04 |
|     Sky     | 93.72 | 96.29 |
|     Tree    | 90.93 | 98.41 |
+-------------+-------+-------+
2023-03-29 00:08:05,977 - mmseg - INFO - Summary:
2023-03-29 00:08:05,977 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.82 | 71.99 | 77.86 |
+-------+-------+-------+
2023-03-29 00:08:05,977 - mmseg - INFO - Exp name: stdc1-uctext_2x12_720x960_10k_camvid.py
2023-03-29 00:08:05,977 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9582, mIoU: 0.7199, mAcc: 0.7786, IoU.Bicyclist: 0.8321, IoU.Building: 0.9221, IoU.Car: 0.9190, IoU.Column_Pole: 0.1177, IoU.Fence: 0.8038, IoU.Pedestrian: 0.5876, IoU.Road: 0.9747, IoU.Sidewalk: 0.9149, IoU.SignSymbol: 0.0004, IoU.Sky: 0.9372, IoU.Tree: 0.9093, Acc.Bicyclist: 0.8954, Acc.Building: 0.9404, Acc.Car: 0.9438, Acc.Column_Pole: 0.1315, Acc.Fence: 0.9295, Acc.Pedestrian: 0.8215, Acc.Road: 0.9860, Acc.Sidewalk: 0.9689, Acc.SignSymbol: 0.0004, Acc.Sky: 0.9629, Acc.Tree: 0.9841
