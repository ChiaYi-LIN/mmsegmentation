2023-03-29 19:27:21,164 - mmseg - INFO - Multi-processing start method is `None`
2023-03-29 19:27:21,199 - mmseg - INFO - OpenCV num_threads is `96
2023-03-29 19:27:21,199 - mmseg - INFO - OMP num threads is 1
2023-03-29 19:27:21,336 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+792c24a
------------------------------------------------------------

2023-03-29 19:27:21,337 - mmseg - INFO - Distributed training: True
2023-03-29 19:27:22,365 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1035, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=13,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='CSC',
        CLASSES=None),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CamVidDataset'
data_root = 'data/CamVid/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (720, 960)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(960, 720), ratio_range=(0.5, 2.5)),
    dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 720),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=12,
    workers_per_gpu=4,
    train=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='train',
        ann_dir='train_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(960, 720), ratio_range=(0.5, 2.5)),
            dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.01,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            text_encoder=dict(lr_mult=0.0, decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=200,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/stdc1-csctext_2x12_720x960_10k_camvid'
gpu_ids = range(0, 2)
auto_resume = False

2023-03-29 19:27:26,269 - mmseg - INFO - Set random seed to 1741966601, deterministic: False
2023-03-29 19:27:26,277 - mmseg - INFO - Loaded 367 images
2023-03-29 19:27:28,105 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-03-29 19:27:29,492 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.contexts - torch.Size([11, 8, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.text_encoder.positional_embedding - torch.Size([13, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.text_projection - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.token_embedding.weight - torch.Size([49408, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1035, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1035, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-03-29 19:27:29,497 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1035, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1035, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-03-29 19:27:29,600 - mmseg - INFO - Loaded 101 images
2023-03-29 19:27:29,600 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1-csctext_2x12_720x960_10k_camvid
2023-03-29 19:27:29,601 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-03-29 19:27:29,601 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-03-29 19:27:29,601 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1-csctext_2x12_720x960_10k_camvid by HardDiskBackend.
2023-03-29 19:29:17,275 - mmseg - INFO - Iter [50/10000]	lr: 2.439e-03, eta: 5:55:50, time: 2.146, data_time: 0.927, memory: 9073, decode.loss_ce: 1.9212, decode.acc_seg: 37.9437, aux_0.loss_ce: 1.7190, aux_0.acc_seg: 26.6126, aux_1.loss_ce: 1.7126, aux_1.acc_seg: 26.4175, aux_2.loss_ce: 0.5807, aux_2.loss_dice: 0.4971, aux_2.acc_seg: 70.5319, aux_3.loss_ce: 1.9632, aux_3.acc_seg: 7.2404, loss: 8.3938
2023-03-29 19:30:25,234 - mmseg - INFO - Iter [100/10000]	lr: 4.906e-03, eta: 4:49:10, time: 1.359, data_time: 0.278, memory: 9073, decode.loss_ce: 0.9855, decode.acc_seg: 62.8585, aux_0.loss_ce: 0.9406, aux_0.acc_seg: 67.4103, aux_1.loss_ce: 1.0525, aux_1.acc_seg: 60.8897, aux_2.loss_ce: 0.2528, aux_2.loss_dice: 0.4499, aux_2.acc_seg: 95.7620, aux_3.loss_ce: 1.4705, aux_3.acc_seg: 61.0996, loss: 5.1516
2023-03-29 19:31:28,524 - mmseg - INFO - Iter [150/10000]	lr: 7.350e-03, eta: 4:21:04, time: 1.266, data_time: 0.292, memory: 9073, decode.loss_ce: 0.6198, decode.acc_seg: 76.7435, aux_0.loss_ce: 0.5363, aux_0.acc_seg: 80.1233, aux_1.loss_ce: 0.5744, aux_1.acc_seg: 78.7888, aux_2.loss_ce: 0.2153, aux_2.loss_dice: 0.3968, aux_2.acc_seg: 95.8504, aux_3.loss_ce: 0.9307, aux_3.acc_seg: 82.1669, loss: 3.2733
2023-03-29 19:32:33,899 - mmseg - INFO - Iter [200/10000]	lr: 9.772e-03, eta: 4:08:11, time: 1.307, data_time: 0.317, memory: 9073, decode.loss_ce: 0.3951, decode.acc_seg: 84.6486, aux_0.loss_ce: 0.3807, aux_0.acc_seg: 85.3360, aux_1.loss_ce: 0.4024, aux_1.acc_seg: 84.5189, aux_2.loss_ce: 0.1825, aux_2.loss_dice: 0.3457, aux_2.acc_seg: 95.8515, aux_3.loss_ce: 0.6246, aux_3.acc_seg: 85.1258, loss: 2.3310
2023-03-29 19:33:39,337 - mmseg - INFO - Iter [250/10000]	lr: 9.776e-03, eta: 4:00:04, time: 1.309, data_time: 0.273, memory: 9073, decode.loss_ce: 0.3261, decode.acc_seg: 86.7021, aux_0.loss_ce: 0.3252, aux_0.acc_seg: 86.9936, aux_1.loss_ce: 0.3395, aux_1.acc_seg: 86.4918, aux_2.loss_ce: 0.1591, aux_2.loss_dice: 0.3240, aux_2.acc_seg: 95.8132, aux_3.loss_ce: 0.4958, aux_3.acc_seg: 86.3079, loss: 1.9696
2023-03-29 19:34:41,126 - mmseg - INFO - Iter [300/10000]	lr: 9.731e-03, eta: 3:52:20, time: 1.236, data_time: 0.249, memory: 9073, decode.loss_ce: 0.2810, decode.acc_seg: 88.1748, aux_0.loss_ce: 0.2865, aux_0.acc_seg: 88.1734, aux_1.loss_ce: 0.3020, aux_1.acc_seg: 87.6389, aux_2.loss_ce: 0.1513, aux_2.loss_dice: 0.3145, aux_2.acc_seg: 95.7245, aux_3.loss_ce: 0.4246, aux_3.acc_seg: 87.6377, loss: 1.7598
2023-03-29 19:35:48,319 - mmseg - INFO - Iter [350/10000]	lr: 9.685e-03, eta: 3:48:59, time: 1.344, data_time: 0.324, memory: 9073, decode.loss_ce: 0.2444, decode.acc_seg: 89.4498, aux_0.loss_ce: 0.2525, aux_0.acc_seg: 89.4069, aux_1.loss_ce: 0.2671, aux_1.acc_seg: 88.8559, aux_2.loss_ce: 0.1445, aux_2.loss_dice: 0.3090, aux_2.acc_seg: 95.7721, aux_3.loss_ce: 0.3600, aux_3.acc_seg: 88.9736, loss: 1.5774
2023-03-29 19:36:48,371 - mmseg - INFO - Iter [400/10000]	lr: 9.640e-03, eta: 3:43:21, time: 1.201, data_time: 0.242, memory: 9073, decode.loss_ce: 0.2245, decode.acc_seg: 89.8691, aux_0.loss_ce: 0.2327, aux_0.acc_seg: 90.0112, aux_1.loss_ce: 0.2479, aux_1.acc_seg: 89.4810, aux_2.loss_ce: 0.1430, aux_2.loss_dice: 0.3047, aux_2.acc_seg: 95.6969, aux_3.loss_ce: 0.3292, aux_3.acc_seg: 89.5335, loss: 1.4821
2023-03-29 19:37:50,682 - mmseg - INFO - Iter [450/10000]	lr: 9.595e-03, eta: 3:39:32, time: 1.246, data_time: 0.237, memory: 9073, decode.loss_ce: 0.2121, decode.acc_seg: 90.4988, aux_0.loss_ce: 0.2188, aux_0.acc_seg: 90.5357, aux_1.loss_ce: 0.2326, aux_1.acc_seg: 89.9363, aux_2.loss_ce: 0.1413, aux_2.loss_dice: 0.3022, aux_2.acc_seg: 95.6745, aux_3.loss_ce: 0.3083, aux_3.acc_seg: 90.0056, loss: 1.4153
2023-03-29 19:38:59,918 - mmseg - INFO - Iter [500/10000]	lr: 9.550e-03, eta: 3:38:28, time: 1.385, data_time: 0.340, memory: 9073, decode.loss_ce: 0.1964, decode.acc_seg: 91.1063, aux_0.loss_ce: 0.2035, aux_0.acc_seg: 90.8713, aux_1.loss_ce: 0.2189, aux_1.acc_seg: 90.3489, aux_2.loss_ce: 0.1393, aux_2.loss_dice: 0.2999, aux_2.acc_seg: 95.7505, aux_3.loss_ce: 0.2947, aux_3.acc_seg: 90.3361, loss: 1.3526
2023-03-29 19:40:00,808 - mmseg - INFO - Iter [550/10000]	lr: 9.505e-03, eta: 3:35:00, time: 1.218, data_time: 0.249, memory: 9073, decode.loss_ce: 0.1851, decode.acc_seg: 91.5782, aux_0.loss_ce: 0.1959, aux_0.acc_seg: 91.2057, aux_1.loss_ce: 0.2104, aux_1.acc_seg: 90.6964, aux_2.loss_ce: 0.1385, aux_2.loss_dice: 0.2974, aux_2.acc_seg: 95.7563, aux_3.loss_ce: 0.2791, aux_3.acc_seg: 90.7669, loss: 1.3065
2023-03-29 19:41:05,255 - mmseg - INFO - Iter [600/10000]	lr: 9.459e-03, eta: 3:32:52, time: 1.289, data_time: 0.271, memory: 9073, decode.loss_ce: 0.1712, decode.acc_seg: 92.1013, aux_0.loss_ce: 0.1811, aux_0.acc_seg: 91.8177, aux_1.loss_ce: 0.1965, aux_1.acc_seg: 91.2547, aux_2.loss_ce: 0.1378, aux_2.loss_dice: 0.2961, aux_2.acc_seg: 95.7450, aux_3.loss_ce: 0.2622, aux_3.acc_seg: 91.2570, loss: 1.2448
2023-03-29 19:42:13,547 - mmseg - INFO - Iter [650/10000]	lr: 9.414e-03, eta: 3:31:49, time: 1.366, data_time: 0.342, memory: 9073, decode.loss_ce: 0.1676, decode.acc_seg: 92.0540, aux_0.loss_ce: 0.1790, aux_0.acc_seg: 91.7568, aux_1.loss_ce: 0.1937, aux_1.acc_seg: 91.2168, aux_2.loss_ce: 0.1370, aux_2.loss_dice: 0.2931, aux_2.acc_seg: 95.7489, aux_3.loss_ce: 0.2533, aux_3.acc_seg: 91.1580, loss: 1.2237
2023-03-29 19:43:13,735 - mmseg - INFO - Iter [700/10000]	lr: 9.369e-03, eta: 3:28:58, time: 1.204, data_time: 0.241, memory: 9073, decode.loss_ce: 0.1557, decode.acc_seg: 92.5571, aux_0.loss_ce: 0.1661, aux_0.acc_seg: 92.2878, aux_1.loss_ce: 0.1793, aux_1.acc_seg: 91.7450, aux_2.loss_ce: 0.1347, aux_2.loss_dice: 0.2918, aux_2.acc_seg: 95.8188, aux_3.loss_ce: 0.2377, aux_3.acc_seg: 91.6891, loss: 1.1653
2023-03-29 19:44:05,920 - mmseg - INFO - Iter [750/10000]	lr: 9.323e-03, eta: 3:24:43, time: 1.044, data_time: 0.228, memory: 9073, decode.loss_ce: 0.1535, decode.acc_seg: 92.7885, aux_0.loss_ce: 0.1634, aux_0.acc_seg: 92.5044, aux_1.loss_ce: 0.1797, aux_1.acc_seg: 91.9524, aux_2.loss_ce: 0.1362, aux_2.loss_dice: 0.2906, aux_2.acc_seg: 95.7535, aux_3.loss_ce: 0.2346, aux_3.acc_seg: 91.8661, loss: 1.1580
2023-03-29 19:45:13,020 - mmseg - INFO - Iter [800/10000]	lr: 9.278e-03, eta: 3:23:44, time: 1.342, data_time: 0.335, memory: 9073, decode.loss_ce: 0.1544, decode.acc_seg: 92.6499, aux_0.loss_ce: 0.1635, aux_0.acc_seg: 92.4264, aux_1.loss_ce: 0.1787, aux_1.acc_seg: 91.8311, aux_2.loss_ce: 0.1355, aux_2.loss_dice: 0.2890, aux_2.acc_seg: 95.7887, aux_3.loss_ce: 0.2333, aux_3.acc_seg: 91.7259, loss: 1.1545
2023-03-29 19:46:14,162 - mmseg - INFO - Iter [850/10000]	lr: 9.233e-03, eta: 3:21:41, time: 1.223, data_time: 0.250, memory: 9073, decode.loss_ce: 0.1497, decode.acc_seg: 92.8189, aux_0.loss_ce: 0.1592, aux_0.acc_seg: 92.5293, aux_1.loss_ce: 0.1764, aux_1.acc_seg: 91.9014, aux_2.loss_ce: 0.1347, aux_2.loss_dice: 0.2879, aux_2.acc_seg: 95.8001, aux_3.loss_ce: 0.2311, aux_3.acc_seg: 91.8611, loss: 1.1391
2023-03-29 19:47:17,494 - mmseg - INFO - Iter [900/10000]	lr: 9.187e-03, eta: 3:20:07, time: 1.267, data_time: 0.261, memory: 9073, decode.loss_ce: 0.1397, decode.acc_seg: 93.2475, aux_0.loss_ce: 0.1501, aux_0.acc_seg: 93.0409, aux_1.loss_ce: 0.1660, aux_1.acc_seg: 92.3697, aux_2.loss_ce: 0.1346, aux_2.loss_dice: 0.2863, aux_2.acc_seg: 95.7924, aux_3.loss_ce: 0.2227, aux_3.acc_seg: 92.2505, loss: 1.0996
2023-03-29 19:48:24,454 - mmseg - INFO - Iter [950/10000]	lr: 9.142e-03, eta: 3:19:10, time: 1.339, data_time: 0.320, memory: 9073, decode.loss_ce: 0.1433, decode.acc_seg: 93.1751, aux_0.loss_ce: 0.1522, aux_0.acc_seg: 92.9506, aux_1.loss_ce: 0.1700, aux_1.acc_seg: 92.2942, aux_2.loss_ce: 0.1366, aux_2.loss_dice: 0.2878, aux_2.acc_seg: 95.7146, aux_3.loss_ce: 0.2214, aux_3.acc_seg: 92.2509, loss: 1.1113
2023-03-29 19:49:25,516 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-03-29 19:49:30,068 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 19:49:30,068 - mmseg - INFO - Iter [1000/10000]	lr: 9.096e-03, eta: 3:18:00, time: 1.312, data_time: 0.247, memory: 9073, decode.loss_ce: 0.1324, decode.acc_seg: 93.4952, aux_0.loss_ce: 0.1429, aux_0.acc_seg: 93.2265, aux_1.loss_ce: 0.1581, aux_1.acc_seg: 92.5901, aux_2.loss_ce: 0.1350, aux_2.loss_dice: 0.2847, aux_2.acc_seg: 95.7312, aux_3.loss_ce: 0.2071, aux_3.acc_seg: 92.5148, loss: 1.0602
2023-03-29 19:49:58,511 - mmseg - INFO - per class results:
2023-03-29 19:49:58,512 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 37.21 | 38.04 |
|   Building  | 90.72 | 92.78 |
|     Car     | 83.19 | 93.68 |
| Column_Pole |  10.0 | 13.32 |
|    Fence    | 73.95 | 94.19 |
|  Pedestrian | 25.95 | 71.54 |
|     Road    | 96.54 |  98.2 |
|   Sidewalk  | 88.51 | 96.73 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.67 | 95.87 |
|     Tree    | 91.08 | 97.85 |
+-------------+-------+-------+
2023-03-29 19:49:58,512 - mmseg - INFO - Summary:
2023-03-29 19:49:58,512 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 93.97 | 62.8 | 72.02 |
+-------+------+-------+
2023-03-29 19:49:58,513 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 19:49:58,513 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9397, mIoU: 0.6280, mAcc: 0.7202, IoU.Bicyclist: 0.3721, IoU.Building: 0.9072, IoU.Car: 0.8319, IoU.Column_Pole: 0.1000, IoU.Fence: 0.7395, IoU.Pedestrian: 0.2595, IoU.Road: 0.9654, IoU.Sidewalk: 0.8851, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9367, IoU.Tree: 0.9108, Acc.Bicyclist: 0.3804, Acc.Building: 0.9278, Acc.Car: 0.9368, Acc.Column_Pole: 0.1332, Acc.Fence: 0.9419, Acc.Pedestrian: 0.7154, Acc.Road: 0.9820, Acc.Sidewalk: 0.9673, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9587, Acc.Tree: 0.9785
2023-03-29 19:51:02,594 - mmseg - INFO - Iter [1050/10000]	lr: 9.051e-03, eta: 3:20:40, time: 1.851, data_time: 0.833, memory: 9073, decode.loss_ce: 0.1311, decode.acc_seg: 93.5569, aux_0.loss_ce: 0.1387, aux_0.acc_seg: 93.3631, aux_1.loss_ce: 0.1551, aux_1.acc_seg: 92.6884, aux_2.loss_ce: 0.1342, aux_2.loss_dice: 0.2838, aux_2.acc_seg: 95.7739, aux_3.loss_ce: 0.2035, aux_3.acc_seg: 92.5824, loss: 1.0463
2023-03-29 19:52:10,159 - mmseg - INFO - Iter [1100/10000]	lr: 9.005e-03, eta: 3:19:35, time: 1.351, data_time: 0.335, memory: 9073, decode.loss_ce: 0.1248, decode.acc_seg: 93.8369, aux_0.loss_ce: 0.1324, aux_0.acc_seg: 93.5866, aux_1.loss_ce: 0.1481, aux_1.acc_seg: 92.9538, aux_2.loss_ce: 0.1337, aux_2.loss_dice: 0.2822, aux_2.acc_seg: 95.8042, aux_3.loss_ce: 0.1968, aux_3.acc_seg: 92.8013, loss: 1.0179
2023-03-29 19:53:10,958 - mmseg - INFO - Iter [1150/10000]	lr: 8.960e-03, eta: 3:17:38, time: 1.216, data_time: 0.258, memory: 9073, decode.loss_ce: 0.1283, decode.acc_seg: 93.6921, aux_0.loss_ce: 0.1351, aux_0.acc_seg: 93.4650, aux_1.loss_ce: 0.1518, aux_1.acc_seg: 92.8339, aux_2.loss_ce: 0.1330, aux_2.loss_dice: 0.2815, aux_2.acc_seg: 95.8329, aux_3.loss_ce: 0.2004, aux_3.acc_seg: 92.7105, loss: 1.0300
2023-03-29 19:54:15,364 - mmseg - INFO - Iter [1200/10000]	lr: 8.914e-03, eta: 3:16:12, time: 1.288, data_time: 0.278, memory: 9073, decode.loss_ce: 0.1266, decode.acc_seg: 93.7916, aux_0.loss_ce: 0.1345, aux_0.acc_seg: 93.5282, aux_1.loss_ce: 0.1504, aux_1.acc_seg: 92.9158, aux_2.loss_ce: 0.1352, aux_2.loss_dice: 0.2836, aux_2.acc_seg: 95.7284, aux_3.loss_ce: 0.1958, aux_3.acc_seg: 92.8355, loss: 1.0262
2023-03-29 19:55:24,176 - mmseg - INFO - Iter [1250/10000]	lr: 8.869e-03, eta: 3:15:19, time: 1.376, data_time: 0.343, memory: 9073, decode.loss_ce: 0.1211, decode.acc_seg: 93.9423, aux_0.loss_ce: 0.1276, aux_0.acc_seg: 93.7036, aux_1.loss_ce: 0.1429, aux_1.acc_seg: 93.0961, aux_2.loss_ce: 0.1349, aux_2.loss_dice: 0.2816, aux_2.acc_seg: 95.7126, aux_3.loss_ce: 0.1883, aux_3.acc_seg: 93.0107, loss: 0.9964
2023-03-29 19:56:26,655 - mmseg - INFO - Iter [1300/10000]	lr: 8.823e-03, eta: 3:13:42, time: 1.250, data_time: 0.264, memory: 9073, decode.loss_ce: 0.1193, decode.acc_seg: 94.0405, aux_0.loss_ce: 0.1258, aux_0.acc_seg: 93.8075, aux_1.loss_ce: 0.1414, aux_1.acc_seg: 93.2137, aux_2.loss_ce: 0.1325, aux_2.loss_dice: 0.2791, aux_2.acc_seg: 95.8309, aux_3.loss_ce: 0.1862, aux_3.acc_seg: 93.0760, loss: 0.9844
2023-03-29 19:57:29,296 - mmseg - INFO - Iter [1350/10000]	lr: 8.777e-03, eta: 3:12:08, time: 1.253, data_time: 0.264, memory: 9073, decode.loss_ce: 0.1169, decode.acc_seg: 94.1394, aux_0.loss_ce: 0.1226, aux_0.acc_seg: 93.9220, aux_1.loss_ce: 0.1391, aux_1.acc_seg: 93.2974, aux_2.loss_ce: 0.1330, aux_2.loss_dice: 0.2797, aux_2.acc_seg: 95.7852, aux_3.loss_ce: 0.1800, aux_3.acc_seg: 93.1613, loss: 0.9713
2023-03-29 19:58:34,170 - mmseg - INFO - Iter [1400/10000]	lr: 8.732e-03, eta: 3:10:51, time: 1.298, data_time: 0.340, memory: 9073, decode.loss_ce: 0.1181, decode.acc_seg: 94.1372, aux_0.loss_ce: 0.1245, aux_0.acc_seg: 93.9027, aux_1.loss_ce: 0.1394, aux_1.acc_seg: 93.2862, aux_2.loss_ce: 0.1340, aux_2.loss_dice: 0.2796, aux_2.acc_seg: 95.7956, aux_3.loss_ce: 0.1839, aux_3.acc_seg: 93.1894, loss: 0.9794
2023-03-29 19:59:36,962 - mmseg - INFO - Iter [1450/10000]	lr: 8.686e-03, eta: 3:09:22, time: 1.256, data_time: 0.269, memory: 9073, decode.loss_ce: 0.1130, decode.acc_seg: 94.2624, aux_0.loss_ce: 0.1202, aux_0.acc_seg: 93.9914, aux_1.loss_ce: 0.1360, aux_1.acc_seg: 93.3927, aux_2.loss_ce: 0.1332, aux_2.loss_dice: 0.2778, aux_2.acc_seg: 95.7729, aux_3.loss_ce: 0.1757, aux_3.acc_seg: 93.2728, loss: 0.9559
2023-03-29 20:00:41,437 - mmseg - INFO - Iter [1500/10000]	lr: 8.640e-03, eta: 3:08:04, time: 1.289, data_time: 0.261, memory: 9073, decode.loss_ce: 0.1104, decode.acc_seg: 94.3536, aux_0.loss_ce: 0.1171, aux_0.acc_seg: 94.1307, aux_1.loss_ce: 0.1313, aux_1.acc_seg: 93.5731, aux_2.loss_ce: 0.1322, aux_2.loss_dice: 0.2778, aux_2.acc_seg: 95.8289, aux_3.loss_ce: 0.1709, aux_3.acc_seg: 93.4347, loss: 0.9398
2023-03-29 20:01:50,323 - mmseg - INFO - Iter [1550/10000]	lr: 8.595e-03, eta: 3:07:12, time: 1.378, data_time: 0.353, memory: 9073, decode.loss_ce: 0.1107, decode.acc_seg: 94.3256, aux_0.loss_ce: 0.1158, aux_0.acc_seg: 94.1238, aux_1.loss_ce: 0.1302, aux_1.acc_seg: 93.5290, aux_2.loss_ce: 0.1312, aux_2.loss_dice: 0.2765, aux_2.acc_seg: 95.8516, aux_3.loss_ce: 0.1696, aux_3.acc_seg: 93.4095, loss: 0.9339
2023-03-29 20:02:51,013 - mmseg - INFO - Iter [1600/10000]	lr: 8.549e-03, eta: 3:05:35, time: 1.214, data_time: 0.261, memory: 9073, decode.loss_ce: 0.1117, decode.acc_seg: 94.3050, aux_0.loss_ce: 0.1174, aux_0.acc_seg: 94.1008, aux_1.loss_ce: 0.1329, aux_1.acc_seg: 93.4705, aux_2.loss_ce: 0.1321, aux_2.loss_dice: 0.2769, aux_2.acc_seg: 95.8082, aux_3.loss_ce: 0.1736, aux_3.acc_seg: 93.3279, loss: 0.9446
2023-03-29 20:03:55,565 - mmseg - INFO - Iter [1650/10000]	lr: 8.503e-03, eta: 3:04:20, time: 1.291, data_time: 0.268, memory: 9073, decode.loss_ce: 0.1062, decode.acc_seg: 94.5244, aux_0.loss_ce: 0.1119, aux_0.acc_seg: 94.2714, aux_1.loss_ce: 0.1270, aux_1.acc_seg: 93.6935, aux_2.loss_ce: 0.1313, aux_2.loss_dice: 0.2758, aux_2.acc_seg: 95.8376, aux_3.loss_ce: 0.1640, aux_3.acc_seg: 93.5711, loss: 0.9162
2023-03-29 20:05:04,580 - mmseg - INFO - Iter [1700/10000]	lr: 8.457e-03, eta: 3:03:27, time: 1.380, data_time: 0.357, memory: 9073, decode.loss_ce: 0.1069, decode.acc_seg: 94.5167, aux_0.loss_ce: 0.1127, aux_0.acc_seg: 94.2769, aux_1.loss_ce: 0.1264, aux_1.acc_seg: 93.6999, aux_2.loss_ce: 0.1313, aux_2.loss_dice: 0.2750, aux_2.acc_seg: 95.8055, aux_3.loss_ce: 0.1636, aux_3.acc_seg: 93.5416, loss: 0.9158
2023-03-29 20:06:06,289 - mmseg - INFO - Iter [1750/10000]	lr: 8.411e-03, eta: 3:01:59, time: 1.234, data_time: 0.281, memory: 9073, decode.loss_ce: 0.1062, decode.acc_seg: 94.6456, aux_0.loss_ce: 0.1121, aux_0.acc_seg: 94.4234, aux_1.loss_ce: 0.1257, aux_1.acc_seg: 93.8522, aux_2.loss_ce: 0.1324, aux_2.loss_dice: 0.2765, aux_2.acc_seg: 95.7729, aux_3.loss_ce: 0.1639, aux_3.acc_seg: 93.7019, loss: 0.9167
2023-03-29 20:07:10,242 - mmseg - INFO - Iter [1800/10000]	lr: 8.365e-03, eta: 3:00:43, time: 1.279, data_time: 0.261, memory: 9073, decode.loss_ce: 0.1046, decode.acc_seg: 94.6001, aux_0.loss_ce: 0.1100, aux_0.acc_seg: 94.3951, aux_1.loss_ce: 0.1242, aux_1.acc_seg: 93.7842, aux_2.loss_ce: 0.1301, aux_2.loss_dice: 0.2745, aux_2.acc_seg: 95.8566, aux_3.loss_ce: 0.1613, aux_3.acc_seg: 93.6703, loss: 0.9048
2023-03-29 20:08:18,656 - mmseg - INFO - Iter [1850/10000]	lr: 8.320e-03, eta: 2:59:47, time: 1.368, data_time: 0.336, memory: 9073, decode.loss_ce: 0.1041, decode.acc_seg: 94.6741, aux_0.loss_ce: 0.1099, aux_0.acc_seg: 94.4525, aux_1.loss_ce: 0.1238, aux_1.acc_seg: 93.8471, aux_2.loss_ce: 0.1296, aux_2.loss_dice: 0.2738, aux_2.acc_seg: 95.8878, aux_3.loss_ce: 0.1592, aux_3.acc_seg: 93.7830, loss: 0.9004
2023-03-29 20:09:20,215 - mmseg - INFO - Iter [1900/10000]	lr: 8.274e-03, eta: 2:58:21, time: 1.231, data_time: 0.273, memory: 9073, decode.loss_ce: 0.1032, decode.acc_seg: 94.6393, aux_0.loss_ce: 0.1093, aux_0.acc_seg: 94.4061, aux_1.loss_ce: 0.1221, aux_1.acc_seg: 93.8261, aux_2.loss_ce: 0.1305, aux_2.loss_dice: 0.2740, aux_2.acc_seg: 95.8389, aux_3.loss_ce: 0.1566, aux_3.acc_seg: 93.7104, loss: 0.8957
2023-03-29 20:10:23,580 - mmseg - INFO - Iter [1950/10000]	lr: 8.228e-03, eta: 2:57:04, time: 1.267, data_time: 0.258, memory: 9073, decode.loss_ce: 0.1022, decode.acc_seg: 94.6471, aux_0.loss_ce: 0.1084, aux_0.acc_seg: 94.4272, aux_1.loss_ce: 0.1218, aux_1.acc_seg: 93.8315, aux_2.loss_ce: 0.1298, aux_2.loss_dice: 0.2732, aux_2.acc_seg: 95.8419, aux_3.loss_ce: 0.1566, aux_3.acc_seg: 93.6894, loss: 0.8922
2023-03-29 20:11:31,811 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-03-29 20:11:35,239 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 20:11:35,239 - mmseg - INFO - Iter [2000/10000]	lr: 8.182e-03, eta: 2:56:20, time: 1.433, data_time: 0.338, memory: 9073, decode.loss_ce: 0.1004, decode.acc_seg: 94.8837, aux_0.loss_ce: 0.1067, aux_0.acc_seg: 94.6344, aux_1.loss_ce: 0.1193, aux_1.acc_seg: 94.0720, aux_2.loss_ce: 0.1300, aux_2.loss_dice: 0.2736, aux_2.acc_seg: 95.8452, aux_3.loss_ce: 0.1513, aux_3.acc_seg: 93.9468, loss: 0.8811
2023-03-29 20:11:38,351 - mmseg - INFO - per class results:
2023-03-29 20:11:38,352 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 76.93 | 84.22 |
|   Building  | 92.39 |  94.4 |
|     Car     | 90.63 | 94.45 |
| Column_Pole | 18.07 | 21.98 |
|    Fence    | 77.48 | 90.21 |
|  Pedestrian |  46.1 | 76.18 |
|     Road    | 96.91 | 97.85 |
|   Sidewalk  | 89.53 | 97.24 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.99 | 97.06 |
|     Tree    | 91.67 | 97.72 |
+-------------+-------+-------+
2023-03-29 20:11:38,353 - mmseg - INFO - Summary:
2023-03-29 20:11:38,353 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.48 | 70.34 | 77.39 |
+-------+-------+-------+
2023-03-29 20:11:38,353 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 20:11:38,353 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9548, mIoU: 0.7034, mAcc: 0.7739, IoU.Bicyclist: 0.7693, IoU.Building: 0.9239, IoU.Car: 0.9063, IoU.Column_Pole: 0.1807, IoU.Fence: 0.7748, IoU.Pedestrian: 0.4610, IoU.Road: 0.9691, IoU.Sidewalk: 0.8953, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9399, IoU.Tree: 0.9167, Acc.Bicyclist: 0.8422, Acc.Building: 0.9440, Acc.Car: 0.9445, Acc.Column_Pole: 0.2198, Acc.Fence: 0.9021, Acc.Pedestrian: 0.7618, Acc.Road: 0.9785, Acc.Sidewalk: 0.9724, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9706, Acc.Tree: 0.9772
2023-03-29 20:12:42,588 - mmseg - INFO - Iter [2050/10000]	lr: 8.136e-03, eta: 2:55:19, time: 1.347, data_time: 0.347, memory: 9073, decode.loss_ce: 0.1016, decode.acc_seg: 94.6603, aux_0.loss_ce: 0.1068, aux_0.acc_seg: 94.4732, aux_1.loss_ce: 0.1188, aux_1.acc_seg: 93.9208, aux_2.loss_ce: 0.1303, aux_2.loss_dice: 0.2728, aux_2.acc_seg: 95.8491, aux_3.loss_ce: 0.1528, aux_3.acc_seg: 93.7336, loss: 0.8831
2023-03-29 20:13:46,746 - mmseg - INFO - Iter [2100/10000]	lr: 8.090e-03, eta: 2:54:05, time: 1.283, data_time: 0.267, memory: 9073, decode.loss_ce: 0.1057, decode.acc_seg: 94.5744, aux_0.loss_ce: 0.1107, aux_0.acc_seg: 94.4034, aux_1.loss_ce: 0.1241, aux_1.acc_seg: 93.8338, aux_2.loss_ce: 0.1297, aux_2.loss_dice: 0.2745, aux_2.acc_seg: 95.9152, aux_3.loss_ce: 0.1585, aux_3.acc_seg: 93.6835, loss: 0.9032
2023-03-29 20:14:55,795 - mmseg - INFO - Iter [2150/10000]	lr: 8.043e-03, eta: 2:53:10, time: 1.381, data_time: 0.350, memory: 9073, decode.loss_ce: 0.0999, decode.acc_seg: 94.7554, aux_0.loss_ce: 0.1061, aux_0.acc_seg: 94.5651, aux_1.loss_ce: 0.1195, aux_1.acc_seg: 93.9617, aux_2.loss_ce: 0.1301, aux_2.loss_dice: 0.2724, aux_2.acc_seg: 95.8487, aux_3.loss_ce: 0.1518, aux_3.acc_seg: 93.8167, loss: 0.8798
2023-03-29 20:15:57,913 - mmseg - INFO - Iter [2200/10000]	lr: 7.997e-03, eta: 2:51:49, time: 1.242, data_time: 0.260, memory: 9073, decode.loss_ce: 0.0990, decode.acc_seg: 94.8685, aux_0.loss_ce: 0.1045, aux_0.acc_seg: 94.6591, aux_1.loss_ce: 0.1181, aux_1.acc_seg: 94.0640, aux_2.loss_ce: 0.1303, aux_2.loss_dice: 0.2724, aux_2.acc_seg: 95.8296, aux_3.loss_ce: 0.1510, aux_3.acc_seg: 93.9185, loss: 0.8752
2023-03-29 20:17:00,357 - mmseg - INFO - Iter [2250/10000]	lr: 7.951e-03, eta: 2:50:31, time: 1.249, data_time: 0.259, memory: 9073, decode.loss_ce: 0.0970, decode.acc_seg: 94.9590, aux_0.loss_ce: 0.1020, aux_0.acc_seg: 94.7724, aux_1.loss_ce: 0.1157, aux_1.acc_seg: 94.1539, aux_2.loss_ce: 0.1296, aux_2.loss_dice: 0.2719, aux_2.acc_seg: 95.8441, aux_3.loss_ce: 0.1479, aux_3.acc_seg: 94.0195, loss: 0.8641
2023-03-29 20:18:06,093 - mmseg - INFO - Iter [2300/10000]	lr: 7.905e-03, eta: 2:49:24, time: 1.315, data_time: 0.336, memory: 9073, decode.loss_ce: 0.0974, decode.acc_seg: 94.9366, aux_0.loss_ce: 0.1026, aux_0.acc_seg: 94.7461, aux_1.loss_ce: 0.1163, aux_1.acc_seg: 94.1376, aux_2.loss_ce: 0.1300, aux_2.loss_dice: 0.2718, aux_2.acc_seg: 95.8204, aux_3.loss_ce: 0.1487, aux_3.acc_seg: 93.9806, loss: 0.8668
2023-03-29 20:19:13,022 - mmseg - INFO - Iter [2350/10000]	lr: 7.859e-03, eta: 2:48:21, time: 1.339, data_time: 0.279, memory: 9073, decode.loss_ce: 0.0947, decode.acc_seg: 95.0343, aux_0.loss_ce: 0.0995, aux_0.acc_seg: 94.8535, aux_1.loss_ce: 0.1127, aux_1.acc_seg: 94.2751, aux_2.loss_ce: 0.1304, aux_2.loss_dice: 0.2717, aux_2.acc_seg: 95.8084, aux_3.loss_ce: 0.1425, aux_3.acc_seg: 94.1293, loss: 0.8515
2023-03-29 20:20:15,146 - mmseg - INFO - Iter [2400/10000]	lr: 7.813e-03, eta: 2:47:02, time: 1.242, data_time: 0.271, memory: 9073, decode.loss_ce: 0.0938, decode.acc_seg: 95.0609, aux_0.loss_ce: 0.1003, aux_0.acc_seg: 94.8820, aux_1.loss_ce: 0.1120, aux_1.acc_seg: 94.2912, aux_2.loss_ce: 0.1299, aux_2.loss_dice: 0.2716, aux_2.acc_seg: 95.8168, aux_3.loss_ce: 0.1415, aux_3.acc_seg: 94.1832, loss: 0.8491
2023-03-29 20:21:21,960 - mmseg - INFO - Iter [2450/10000]	lr: 7.766e-03, eta: 2:45:59, time: 1.336, data_time: 0.365, memory: 9073, decode.loss_ce: 0.0962, decode.acc_seg: 95.0133, aux_0.loss_ce: 0.1012, aux_0.acc_seg: 94.8006, aux_1.loss_ce: 0.1138, aux_1.acc_seg: 94.2109, aux_2.loss_ce: 0.1295, aux_2.loss_dice: 0.2716, aux_2.acc_seg: 95.8297, aux_3.loss_ce: 0.1437, aux_3.acc_seg: 94.1146, loss: 0.8559
2023-03-29 20:22:29,015 - mmseg - INFO - Iter [2500/10000]	lr: 7.720e-03, eta: 2:44:56, time: 1.341, data_time: 0.292, memory: 9073, decode.loss_ce: 0.0971, decode.acc_seg: 94.8904, aux_0.loss_ce: 0.1014, aux_0.acc_seg: 94.7071, aux_1.loss_ce: 0.1136, aux_1.acc_seg: 94.1355, aux_2.loss_ce: 0.1290, aux_2.loss_dice: 0.2709, aux_2.acc_seg: 95.8863, aux_3.loss_ce: 0.1432, aux_3.acc_seg: 94.0124, loss: 0.8552
2023-03-29 20:23:33,206 - mmseg - INFO - Iter [2550/10000]	lr: 7.674e-03, eta: 2:43:45, time: 1.284, data_time: 0.305, memory: 9073, decode.loss_ce: 0.0960, decode.acc_seg: 95.0124, aux_0.loss_ce: 0.1010, aux_0.acc_seg: 94.8459, aux_1.loss_ce: 0.1127, aux_1.acc_seg: 94.2446, aux_2.loss_ce: 0.1309, aux_2.loss_dice: 0.2723, aux_2.acc_seg: 95.7861, aux_3.loss_ce: 0.1428, aux_3.acc_seg: 94.1051, loss: 0.8557
2023-03-29 20:24:42,208 - mmseg - INFO - Iter [2600/10000]	lr: 7.627e-03, eta: 2:42:48, time: 1.380, data_time: 0.389, memory: 9073, decode.loss_ce: 0.0922, decode.acc_seg: 95.1132, aux_0.loss_ce: 0.0976, aux_0.acc_seg: 94.9260, aux_1.loss_ce: 0.1103, aux_1.acc_seg: 94.3141, aux_2.loss_ce: 0.1287, aux_2.loss_dice: 0.2697, aux_2.acc_seg: 95.8503, aux_3.loss_ce: 0.1388, aux_3.acc_seg: 94.1848, loss: 0.8372
2023-03-29 20:25:45,922 - mmseg - INFO - Iter [2650/10000]	lr: 7.581e-03, eta: 2:41:36, time: 1.274, data_time: 0.292, memory: 9073, decode.loss_ce: 0.0898, decode.acc_seg: 95.1504, aux_0.loss_ce: 0.0942, aux_0.acc_seg: 94.9662, aux_1.loss_ce: 0.1070, aux_1.acc_seg: 94.3884, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2693, aux_2.acc_seg: 95.8628, aux_3.loss_ce: 0.1342, aux_3.acc_seg: 94.2478, loss: 0.8226
2023-03-29 20:26:51,851 - mmseg - INFO - Iter [2700/10000]	lr: 7.535e-03, eta: 2:40:30, time: 1.319, data_time: 0.291, memory: 9073, decode.loss_ce: 0.0896, decode.acc_seg: 95.2425, aux_0.loss_ce: 0.0946, aux_0.acc_seg: 95.0616, aux_1.loss_ce: 0.1070, aux_1.acc_seg: 94.4723, aux_2.loss_ce: 0.1283, aux_2.loss_dice: 0.2691, aux_2.acc_seg: 95.8710, aux_3.loss_ce: 0.1342, aux_3.acc_seg: 94.3279, loss: 0.8229
2023-03-29 20:28:03,201 - mmseg - INFO - Iter [2750/10000]	lr: 7.488e-03, eta: 2:39:38, time: 1.427, data_time: 0.387, memory: 9073, decode.loss_ce: 0.0908, decode.acc_seg: 95.1290, aux_0.loss_ce: 0.0962, aux_0.acc_seg: 94.9515, aux_1.loss_ce: 0.1087, aux_1.acc_seg: 94.3530, aux_2.loss_ce: 0.1285, aux_2.loss_dice: 0.2702, aux_2.acc_seg: 95.8721, aux_3.loss_ce: 0.1349, aux_3.acc_seg: 94.2114, loss: 0.8293
2023-03-29 20:29:05,393 - mmseg - INFO - Iter [2800/10000]	lr: 7.442e-03, eta: 2:38:22, time: 1.244, data_time: 0.288, memory: 9073, decode.loss_ce: 0.0903, decode.acc_seg: 95.1574, aux_0.loss_ce: 0.0953, aux_0.acc_seg: 94.9719, aux_1.loss_ce: 0.1075, aux_1.acc_seg: 94.3791, aux_2.loss_ce: 0.1283, aux_2.loss_dice: 0.2689, aux_2.acc_seg: 95.8638, aux_3.loss_ce: 0.1339, aux_3.acc_seg: 94.2238, loss: 0.8242
2023-03-29 20:30:10,954 - mmseg - INFO - Iter [2850/10000]	lr: 7.395e-03, eta: 2:37:15, time: 1.311, data_time: 0.279, memory: 9073, decode.loss_ce: 0.0951, decode.acc_seg: 95.0290, aux_0.loss_ce: 0.0989, aux_0.acc_seg: 94.8576, aux_1.loss_ce: 0.1109, aux_1.acc_seg: 94.2800, aux_2.loss_ce: 0.1305, aux_2.loss_dice: 0.2706, aux_2.acc_seg: 95.7926, aux_3.loss_ce: 0.1383, aux_3.acc_seg: 94.1250, loss: 0.8442
2023-03-29 20:31:15,866 - mmseg - INFO - Iter [2900/10000]	lr: 7.349e-03, eta: 2:36:06, time: 1.298, data_time: 0.341, memory: 9073, decode.loss_ce: 0.0920, decode.acc_seg: 95.1538, aux_0.loss_ce: 0.0973, aux_0.acc_seg: 94.9689, aux_1.loss_ce: 0.1097, aux_1.acc_seg: 94.3568, aux_2.loss_ce: 0.1296, aux_2.loss_dice: 0.2702, aux_2.acc_seg: 95.8128, aux_3.loss_ce: 0.1372, aux_3.acc_seg: 94.2178, loss: 0.8360
2023-03-29 20:32:20,701 - mmseg - INFO - Iter [2950/10000]	lr: 7.302e-03, eta: 2:34:58, time: 1.297, data_time: 0.264, memory: 9073, decode.loss_ce: 0.0897, decode.acc_seg: 95.1944, aux_0.loss_ce: 0.0943, aux_0.acc_seg: 95.0121, aux_1.loss_ce: 0.1067, aux_1.acc_seg: 94.3979, aux_2.loss_ce: 0.1284, aux_2.loss_dice: 0.2691, aux_2.acc_seg: 95.8497, aux_3.loss_ce: 0.1315, aux_3.acc_seg: 94.2993, loss: 0.8197
2023-03-29 20:33:25,155 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-03-29 20:33:28,633 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 20:33:28,633 - mmseg - INFO - Iter [3000/10000]	lr: 7.255e-03, eta: 2:33:56, time: 1.359, data_time: 0.297, memory: 9073, decode.loss_ce: 0.0892, decode.acc_seg: 95.2048, aux_0.loss_ce: 0.0942, aux_0.acc_seg: 95.0247, aux_1.loss_ce: 0.1065, aux_1.acc_seg: 94.4119, aux_2.loss_ce: 0.1277, aux_2.loss_dice: 0.2689, aux_2.acc_seg: 95.9118, aux_3.loss_ce: 0.1332, aux_3.acc_seg: 94.2464, loss: 0.8196
2023-03-29 20:33:32,138 - mmseg - INFO - per class results:
2023-03-29 20:33:32,139 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 80.64 | 86.84 |
|   Building  | 91.35 |  93.5 |
|     Car     | 91.51 | 95.27 |
| Column_Pole | 15.51 | 18.33 |
|    Fence    | 77.55 | 87.16 |
|  Pedestrian |  53.0 | 80.18 |
|     Road    | 97.15 | 98.32 |
|   Sidewalk  | 90.41 | 96.12 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.94 |  96.9 |
|     Tree    | 89.44 | 98.18 |
+-------------+-------+-------+
2023-03-29 20:33:32,139 - mmseg - INFO - Summary:
2023-03-29 20:33:32,140 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.33 | 70.95 | 77.35 |
+-------+-------+-------+
2023-03-29 20:33:32,140 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 20:33:32,140 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9533, mIoU: 0.7095, mAcc: 0.7735, IoU.Bicyclist: 0.8064, IoU.Building: 0.9135, IoU.Car: 0.9151, IoU.Column_Pole: 0.1551, IoU.Fence: 0.7755, IoU.Pedestrian: 0.5300, IoU.Road: 0.9715, IoU.Sidewalk: 0.9041, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9394, IoU.Tree: 0.8944, Acc.Bicyclist: 0.8684, Acc.Building: 0.9350, Acc.Car: 0.9527, Acc.Column_Pole: 0.1833, Acc.Fence: 0.8716, Acc.Pedestrian: 0.8018, Acc.Road: 0.9832, Acc.Sidewalk: 0.9612, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9690, Acc.Tree: 0.9818
2023-03-29 20:34:40,707 - mmseg - INFO - Iter [3050/10000]	lr: 7.209e-03, eta: 2:33:04, time: 1.441, data_time: 0.414, memory: 9073, decode.loss_ce: 0.0881, decode.acc_seg: 95.2599, aux_0.loss_ce: 0.0927, aux_0.acc_seg: 95.0861, aux_1.loss_ce: 0.1054, aux_1.acc_seg: 94.4745, aux_2.loss_ce: 0.1288, aux_2.loss_dice: 0.2684, aux_2.acc_seg: 95.8164, aux_3.loss_ce: 0.1296, aux_3.acc_seg: 94.3480, loss: 0.8130
2023-03-29 20:35:43,013 - mmseg - INFO - Iter [3100/10000]	lr: 7.162e-03, eta: 2:31:50, time: 1.246, data_time: 0.278, memory: 9073, decode.loss_ce: 0.0867, decode.acc_seg: 95.3370, aux_0.loss_ce: 0.0913, aux_0.acc_seg: 95.1419, aux_1.loss_ce: 0.1034, aux_1.acc_seg: 94.5307, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2679, aux_2.acc_seg: 95.8175, aux_3.loss_ce: 0.1280, aux_3.acc_seg: 94.3930, loss: 0.8059
2023-03-29 20:36:47,288 - mmseg - INFO - Iter [3150/10000]	lr: 7.115e-03, eta: 2:30:40, time: 1.286, data_time: 0.259, memory: 9073, decode.loss_ce: 0.0878, decode.acc_seg: 95.2939, aux_0.loss_ce: 0.0923, aux_0.acc_seg: 95.1349, aux_1.loss_ce: 0.1047, aux_1.acc_seg: 94.5547, aux_2.loss_ce: 0.1287, aux_2.loss_dice: 0.2682, aux_2.acc_seg: 95.8442, aux_3.loss_ce: 0.1292, aux_3.acc_seg: 94.4047, loss: 0.8109
2023-03-29 20:37:56,313 - mmseg - INFO - Iter [3200/10000]	lr: 7.069e-03, eta: 2:29:40, time: 1.380, data_time: 0.357, memory: 9073, decode.loss_ce: 0.0890, decode.acc_seg: 95.2398, aux_0.loss_ce: 0.0938, aux_0.acc_seg: 95.0546, aux_1.loss_ce: 0.1060, aux_1.acc_seg: 94.4643, aux_2.loss_ce: 0.1298, aux_2.loss_dice: 0.2690, aux_2.acc_seg: 95.7764, aux_3.loss_ce: 0.1300, aux_3.acc_seg: 94.3105, loss: 0.8176
2023-03-29 20:38:57,042 - mmseg - INFO - Iter [3250/10000]	lr: 7.022e-03, eta: 2:28:23, time: 1.215, data_time: 0.264, memory: 9073, decode.loss_ce: 0.0897, decode.acc_seg: 95.2440, aux_0.loss_ce: 0.0942, aux_0.acc_seg: 95.0711, aux_1.loss_ce: 0.1078, aux_1.acc_seg: 94.4576, aux_2.loss_ce: 0.1288, aux_2.loss_dice: 0.2684, aux_2.acc_seg: 95.8228, aux_3.loss_ce: 0.1319, aux_3.acc_seg: 94.3129, loss: 0.8209
2023-03-29 20:40:01,812 - mmseg - INFO - Iter [3300/10000]	lr: 6.975e-03, eta: 2:27:15, time: 1.295, data_time: 0.267, memory: 9073, decode.loss_ce: 0.0877, decode.acc_seg: 95.3373, aux_0.loss_ce: 0.0924, aux_0.acc_seg: 95.1712, aux_1.loss_ce: 0.1040, aux_1.acc_seg: 94.5660, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2684, aux_2.acc_seg: 95.8160, aux_3.loss_ce: 0.1279, aux_3.acc_seg: 94.3983, loss: 0.8094
2023-03-29 20:41:10,779 - mmseg - INFO - Iter [3350/10000]	lr: 6.928e-03, eta: 2:26:15, time: 1.379, data_time: 0.351, memory: 9073, decode.loss_ce: 0.0860, decode.acc_seg: 95.3746, aux_0.loss_ce: 0.0908, aux_0.acc_seg: 95.2034, aux_1.loss_ce: 0.1022, aux_1.acc_seg: 94.6223, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2681, aux_2.acc_seg: 95.8595, aux_3.loss_ce: 0.1256, aux_3.acc_seg: 94.4747, loss: 0.8008
2023-03-29 20:42:11,808 - mmseg - INFO - Iter [3400/10000]	lr: 6.881e-03, eta: 2:24:59, time: 1.221, data_time: 0.263, memory: 9073, decode.loss_ce: 0.0877, decode.acc_seg: 95.3421, aux_0.loss_ce: 0.0923, aux_0.acc_seg: 95.1818, aux_1.loss_ce: 0.1042, aux_1.acc_seg: 94.5961, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2692, aux_2.acc_seg: 95.8169, aux_3.loss_ce: 0.1275, aux_3.acc_seg: 94.4393, loss: 0.8098
2023-03-29 20:43:16,600 - mmseg - INFO - Iter [3450/10000]	lr: 6.834e-03, eta: 2:23:51, time: 1.296, data_time: 0.279, memory: 9073, decode.loss_ce: 0.0882, decode.acc_seg: 95.3031, aux_0.loss_ce: 0.0918, aux_0.acc_seg: 95.1607, aux_1.loss_ce: 0.1033, aux_1.acc_seg: 94.5890, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2679, aux_2.acc_seg: 95.8335, aux_3.loss_ce: 0.1275, aux_3.acc_seg: 94.4272, loss: 0.8073
2023-03-29 20:44:25,478 - mmseg - INFO - Iter [3500/10000]	lr: 6.787e-03, eta: 2:22:51, time: 1.378, data_time: 0.339, memory: 9073, decode.loss_ce: 0.0847, decode.acc_seg: 95.3602, aux_0.loss_ce: 0.0893, aux_0.acc_seg: 95.1868, aux_1.loss_ce: 0.1016, aux_1.acc_seg: 94.5770, aux_2.loss_ce: 0.1284, aux_2.loss_dice: 0.2674, aux_2.acc_seg: 95.8261, aux_3.loss_ce: 0.1233, aux_3.acc_seg: 94.4674, loss: 0.7946
2023-03-29 20:45:27,864 - mmseg - INFO - Iter [3550/10000]	lr: 6.740e-03, eta: 2:21:39, time: 1.248, data_time: 0.284, memory: 9073, decode.loss_ce: 0.0854, decode.acc_seg: 95.3974, aux_0.loss_ce: 0.0898, aux_0.acc_seg: 95.2267, aux_1.loss_ce: 0.1024, aux_1.acc_seg: 94.6504, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2681, aux_2.acc_seg: 95.8818, aux_3.loss_ce: 0.1235, aux_3.acc_seg: 94.5150, loss: 0.7970
2023-03-29 20:46:31,023 - mmseg - INFO - Iter [3600/10000]	lr: 6.693e-03, eta: 2:20:28, time: 1.263, data_time: 0.257, memory: 9073, decode.loss_ce: 0.0852, decode.acc_seg: 95.3616, aux_0.loss_ce: 0.0897, aux_0.acc_seg: 95.2149, aux_1.loss_ce: 0.1012, aux_1.acc_seg: 94.6204, aux_2.loss_ce: 0.1282, aux_2.loss_dice: 0.2669, aux_2.acc_seg: 95.8239, aux_3.loss_ce: 0.1240, aux_3.acc_seg: 94.4839, loss: 0.7952
2023-03-29 20:47:37,073 - mmseg - INFO - Iter [3650/10000]	lr: 6.646e-03, eta: 2:19:22, time: 1.321, data_time: 0.340, memory: 9073, decode.loss_ce: 0.0843, decode.acc_seg: 95.4961, aux_0.loss_ce: 0.0882, aux_0.acc_seg: 95.3288, aux_1.loss_ce: 0.0999, aux_1.acc_seg: 94.7444, aux_2.loss_ce: 0.1279, aux_2.loss_dice: 0.2680, aux_2.acc_seg: 95.8524, aux_3.loss_ce: 0.1222, aux_3.acc_seg: 94.5863, loss: 0.7905
2023-03-29 20:48:40,217 - mmseg - INFO - Iter [3700/10000]	lr: 6.599e-03, eta: 2:18:12, time: 1.263, data_time: 0.256, memory: 9073, decode.loss_ce: 0.0830, decode.acc_seg: 95.4701, aux_0.loss_ce: 0.0884, aux_0.acc_seg: 95.3072, aux_1.loss_ce: 0.0995, aux_1.acc_seg: 94.6934, aux_2.loss_ce: 0.1270, aux_2.loss_dice: 0.2661, aux_2.acc_seg: 95.8984, aux_3.loss_ce: 0.1208, aux_3.acc_seg: 94.5504, loss: 0.7848
2023-03-29 20:49:43,933 - mmseg - INFO - Iter [3750/10000]	lr: 6.552e-03, eta: 2:17:03, time: 1.274, data_time: 0.253, memory: 9073, decode.loss_ce: 0.0844, decode.acc_seg: 95.4257, aux_0.loss_ce: 0.0880, aux_0.acc_seg: 95.2852, aux_1.loss_ce: 0.1003, aux_1.acc_seg: 94.6940, aux_2.loss_ce: 0.1280, aux_2.loss_dice: 0.2681, aux_2.acc_seg: 95.8553, aux_3.loss_ce: 0.1209, aux_3.acc_seg: 94.5504, loss: 0.7897
2023-03-29 20:50:51,868 - mmseg - INFO - Iter [3800/10000]	lr: 6.505e-03, eta: 2:16:00, time: 1.359, data_time: 0.345, memory: 9073, decode.loss_ce: 0.0822, decode.acc_seg: 95.5520, aux_0.loss_ce: 0.0863, aux_0.acc_seg: 95.4023, aux_1.loss_ce: 0.0986, aux_1.acc_seg: 94.8138, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2651, aux_2.acc_seg: 95.9352, aux_3.loss_ce: 0.1202, aux_3.acc_seg: 94.6775, loss: 0.7783
2023-03-29 20:51:53,241 - mmseg - INFO - Iter [3850/10000]	lr: 6.458e-03, eta: 2:14:47, time: 1.228, data_time: 0.267, memory: 9073, decode.loss_ce: 0.0828, decode.acc_seg: 95.5006, aux_0.loss_ce: 0.0872, aux_0.acc_seg: 95.3425, aux_1.loss_ce: 0.0992, aux_1.acc_seg: 94.7229, aux_2.loss_ce: 0.1273, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8541, aux_3.loss_ce: 0.1189, aux_3.acc_seg: 94.6060, loss: 0.7819
2023-03-29 20:52:57,167 - mmseg - INFO - Iter [3900/10000]	lr: 6.410e-03, eta: 2:13:39, time: 1.278, data_time: 0.270, memory: 9073, decode.loss_ce: 0.0835, decode.acc_seg: 95.4929, aux_0.loss_ce: 0.0872, aux_0.acc_seg: 95.3351, aux_1.loss_ce: 0.0990, aux_1.acc_seg: 94.7538, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2656, aux_2.acc_seg: 95.8251, aux_3.loss_ce: 0.1198, aux_3.acc_seg: 94.6031, loss: 0.7826
2023-03-29 20:54:05,804 - mmseg - INFO - Iter [3950/10000]	lr: 6.363e-03, eta: 2:12:38, time: 1.373, data_time: 0.340, memory: 9073, decode.loss_ce: 0.0838, decode.acc_seg: 95.4252, aux_0.loss_ce: 0.0879, aux_0.acc_seg: 95.2888, aux_1.loss_ce: 0.1003, aux_1.acc_seg: 94.6545, aux_2.loss_ce: 0.1274, aux_2.loss_dice: 0.2660, aux_2.acc_seg: 95.8528, aux_3.loss_ce: 0.1198, aux_3.acc_seg: 94.5478, loss: 0.7851
2023-03-29 20:55:08,415 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-03-29 20:55:12,249 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 20:55:12,250 - mmseg - INFO - Iter [4000/10000]	lr: 6.316e-03, eta: 2:11:33, time: 1.329, data_time: 0.269, memory: 9073, decode.loss_ce: 0.0828, decode.acc_seg: 95.4897, aux_0.loss_ce: 0.0864, aux_0.acc_seg: 95.3497, aux_1.loss_ce: 0.0990, aux_1.acc_seg: 94.7415, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2660, aux_2.acc_seg: 95.8405, aux_3.loss_ce: 0.1193, aux_3.acc_seg: 94.6137, loss: 0.7810
2023-03-29 20:55:16,819 - mmseg - INFO - per class results:
2023-03-29 20:55:16,820 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.56 | 90.27 |
|   Building  | 91.72 | 93.84 |
|     Car     | 92.32 | 95.81 |
| Column_Pole | 16.21 | 18.66 |
|    Fence    | 77.83 |  90.5 |
|  Pedestrian | 57.98 | 80.21 |
|     Road    | 97.22 | 98.04 |
|   Sidewalk  | 90.75 | 96.61 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.76 |  96.6 |
|     Tree    | 90.11 | 98.14 |
+-------------+-------+-------+
2023-03-29 20:55:16,820 - mmseg - INFO - Summary:
2023-03-29 20:55:16,820 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.55 | 71.86 | 78.06 |
+-------+-------+-------+
2023-03-29 20:55:16,820 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 20:55:16,820 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9555, mIoU: 0.7186, mAcc: 0.7806, IoU.Bicyclist: 0.8256, IoU.Building: 0.9172, IoU.Car: 0.9232, IoU.Column_Pole: 0.1621, IoU.Fence: 0.7783, IoU.Pedestrian: 0.5798, IoU.Road: 0.9722, IoU.Sidewalk: 0.9075, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9376, IoU.Tree: 0.9011, Acc.Bicyclist: 0.9027, Acc.Building: 0.9384, Acc.Car: 0.9581, Acc.Column_Pole: 0.1866, Acc.Fence: 0.9050, Acc.Pedestrian: 0.8021, Acc.Road: 0.9804, Acc.Sidewalk: 0.9661, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9660, Acc.Tree: 0.9814
2023-03-29 20:56:20,166 - mmseg - INFO - Iter [4050/10000]	lr: 6.268e-03, eta: 2:10:30, time: 1.358, data_time: 0.371, memory: 9073, decode.loss_ce: 0.0805, decode.acc_seg: 95.5521, aux_0.loss_ce: 0.0847, aux_0.acc_seg: 95.3974, aux_1.loss_ce: 0.0957, aux_1.acc_seg: 94.8194, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 95.9063, aux_3.loss_ce: 0.1154, aux_3.acc_seg: 94.6761, loss: 0.7672
2023-03-29 20:57:25,947 - mmseg - INFO - Iter [4100/10000]	lr: 6.221e-03, eta: 2:09:24, time: 1.316, data_time: 0.333, memory: 9073, decode.loss_ce: 0.0812, decode.acc_seg: 95.6008, aux_0.loss_ce: 0.0847, aux_0.acc_seg: 95.4548, aux_1.loss_ce: 0.0966, aux_1.acc_seg: 94.8610, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2651, aux_2.acc_seg: 95.8633, aux_3.loss_ce: 0.1164, aux_3.acc_seg: 94.6852, loss: 0.7708
2023-03-29 20:58:30,381 - mmseg - INFO - Iter [4150/10000]	lr: 6.174e-03, eta: 2:08:17, time: 1.289, data_time: 0.266, memory: 9073, decode.loss_ce: 0.0820, decode.acc_seg: 95.5593, aux_0.loss_ce: 0.0858, aux_0.acc_seg: 95.4091, aux_1.loss_ce: 0.0976, aux_1.acc_seg: 94.8059, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2664, aux_2.acc_seg: 95.8371, aux_3.loss_ce: 0.1181, aux_3.acc_seg: 94.6617, loss: 0.7774
2023-03-29 20:59:33,604 - mmseg - INFO - Iter [4200/10000]	lr: 6.126e-03, eta: 2:07:07, time: 1.265, data_time: 0.269, memory: 9073, decode.loss_ce: 0.0853, decode.acc_seg: 95.4326, aux_0.loss_ce: 0.0905, aux_0.acc_seg: 95.2720, aux_1.loss_ce: 0.1022, aux_1.acc_seg: 94.6725, aux_2.loss_ce: 0.1291, aux_2.loss_dice: 0.2672, aux_2.acc_seg: 95.7803, aux_3.loss_ce: 0.1215, aux_3.acc_seg: 94.5285, loss: 0.7958
2023-03-29 21:00:39,640 - mmseg - INFO - Iter [4250/10000]	lr: 6.079e-03, eta: 2:06:02, time: 1.321, data_time: 0.336, memory: 9073, decode.loss_ce: 0.0824, decode.acc_seg: 95.4917, aux_0.loss_ce: 0.0860, aux_0.acc_seg: 95.3515, aux_1.loss_ce: 0.0979, aux_1.acc_seg: 94.7637, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2654, aux_2.acc_seg: 95.8836, aux_3.loss_ce: 0.1172, aux_3.acc_seg: 94.6260, loss: 0.7756
2023-03-29 21:01:42,271 - mmseg - INFO - Iter [4300/10000]	lr: 6.031e-03, eta: 2:04:52, time: 1.252, data_time: 0.259, memory: 9073, decode.loss_ce: 0.0815, decode.acc_seg: 95.5049, aux_0.loss_ce: 0.0859, aux_0.acc_seg: 95.3396, aux_1.loss_ce: 0.0972, aux_1.acc_seg: 94.7458, aux_2.loss_ce: 0.1274, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 95.8253, aux_3.loss_ce: 0.1164, aux_3.acc_seg: 94.5917, loss: 0.7734
2023-03-29 21:02:45,747 - mmseg - INFO - Iter [4350/10000]	lr: 5.983e-03, eta: 2:03:43, time: 1.270, data_time: 0.261, memory: 9073, decode.loss_ce: 0.0831, decode.acc_seg: 95.5159, aux_0.loss_ce: 0.0875, aux_0.acc_seg: 95.3536, aux_1.loss_ce: 0.0994, aux_1.acc_seg: 94.7426, aux_2.loss_ce: 0.1288, aux_2.loss_dice: 0.2671, aux_2.acc_seg: 95.7876, aux_3.loss_ce: 0.1173, aux_3.acc_seg: 94.6232, loss: 0.7831
2023-03-29 21:03:50,084 - mmseg - INFO - Iter [4400/10000]	lr: 5.936e-03, eta: 2:02:36, time: 1.287, data_time: 0.320, memory: 9073, decode.loss_ce: 0.0820, decode.acc_seg: 95.6090, aux_0.loss_ce: 0.0858, aux_0.acc_seg: 95.4609, aux_1.loss_ce: 0.0970, aux_1.acc_seg: 94.8764, aux_2.loss_ce: 0.1277, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8528, aux_3.loss_ce: 0.1167, aux_3.acc_seg: 94.7255, loss: 0.7757
2023-03-29 21:04:54,584 - mmseg - INFO - Iter [4450/10000]	lr: 5.888e-03, eta: 2:01:29, time: 1.290, data_time: 0.265, memory: 9073, decode.loss_ce: 0.0793, decode.acc_seg: 95.6020, aux_0.loss_ce: 0.0831, aux_0.acc_seg: 95.4511, aux_1.loss_ce: 0.0955, aux_1.acc_seg: 94.8543, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2662, aux_2.acc_seg: 95.8077, aux_3.loss_ce: 0.1131, aux_3.acc_seg: 94.7102, loss: 0.7654
2023-03-29 21:05:57,534 - mmseg - INFO - Iter [4500/10000]	lr: 5.840e-03, eta: 2:00:20, time: 1.259, data_time: 0.267, memory: 9073, decode.loss_ce: 0.0806, decode.acc_seg: 95.5891, aux_0.loss_ce: 0.0848, aux_0.acc_seg: 95.4229, aux_1.loss_ce: 0.0956, aux_1.acc_seg: 94.8284, aux_2.loss_ce: 0.1283, aux_2.loss_dice: 0.2657, aux_2.acc_seg: 95.7981, aux_3.loss_ce: 0.1147, aux_3.acc_seg: 94.6993, loss: 0.7697
2023-03-29 21:07:02,977 - mmseg - INFO - Iter [4550/10000]	lr: 5.792e-03, eta: 1:59:14, time: 1.309, data_time: 0.330, memory: 9073, decode.loss_ce: 0.0786, decode.acc_seg: 95.6229, aux_0.loss_ce: 0.0820, aux_0.acc_seg: 95.4765, aux_1.loss_ce: 0.0950, aux_1.acc_seg: 94.8816, aux_2.loss_ce: 0.1274, aux_2.loss_dice: 0.2642, aux_2.acc_seg: 95.8086, aux_3.loss_ce: 0.1117, aux_3.acc_seg: 94.7467, loss: 0.7588
2023-03-29 21:08:06,457 - mmseg - INFO - Iter [4600/10000]	lr: 5.745e-03, eta: 1:58:06, time: 1.269, data_time: 0.264, memory: 9073, decode.loss_ce: 0.0800, decode.acc_seg: 95.5644, aux_0.loss_ce: 0.0846, aux_0.acc_seg: 95.4201, aux_1.loss_ce: 0.0957, aux_1.acc_seg: 94.8257, aux_2.loss_ce: 0.1278, aux_2.loss_dice: 0.2657, aux_2.acc_seg: 95.7941, aux_3.loss_ce: 0.1140, aux_3.acc_seg: 94.6770, loss: 0.7677
2023-03-29 21:09:11,466 - mmseg - INFO - Iter [4650/10000]	lr: 5.697e-03, eta: 1:56:59, time: 1.300, data_time: 0.277, memory: 9073, decode.loss_ce: 0.0793, decode.acc_seg: 95.6489, aux_0.loss_ce: 0.0834, aux_0.acc_seg: 95.4980, aux_1.loss_ce: 0.0955, aux_1.acc_seg: 94.8774, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2638, aux_2.acc_seg: 95.8194, aux_3.loss_ce: 0.1129, aux_3.acc_seg: 94.7674, loss: 0.7621
2023-03-29 21:10:20,074 - mmseg - INFO - Iter [4700/10000]	lr: 5.649e-03, eta: 1:55:57, time: 1.372, data_time: 0.364, memory: 9073, decode.loss_ce: 0.0783, decode.acc_seg: 95.6242, aux_0.loss_ce: 0.0828, aux_0.acc_seg: 95.4749, aux_1.loss_ce: 0.0936, aux_1.acc_seg: 94.8702, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 95.8915, aux_3.loss_ce: 0.1118, aux_3.acc_seg: 94.7187, loss: 0.7558
2023-03-29 21:11:21,964 - mmseg - INFO - Iter [4750/10000]	lr: 5.601e-03, eta: 1:54:47, time: 1.238, data_time: 0.257, memory: 9073, decode.loss_ce: 0.0784, decode.acc_seg: 95.7675, aux_0.loss_ce: 0.0821, aux_0.acc_seg: 95.6321, aux_1.loss_ce: 0.0930, aux_1.acc_seg: 95.0465, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2648, aux_2.acc_seg: 95.8945, aux_3.loss_ce: 0.1114, aux_3.acc_seg: 94.8808, loss: 0.7556
2023-03-29 21:12:26,097 - mmseg - INFO - Iter [4800/10000]	lr: 5.553e-03, eta: 1:53:40, time: 1.283, data_time: 0.270, memory: 9073, decode.loss_ce: 0.0785, decode.acc_seg: 95.6947, aux_0.loss_ce: 0.0827, aux_0.acc_seg: 95.5521, aux_1.loss_ce: 0.0944, aux_1.acc_seg: 94.9441, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2651, aux_2.acc_seg: 95.7758, aux_3.loss_ce: 0.1114, aux_3.acc_seg: 94.8000, loss: 0.7601
2023-03-29 21:13:35,539 - mmseg - INFO - Iter [4850/10000]	lr: 5.505e-03, eta: 1:52:39, time: 1.389, data_time: 0.364, memory: 9073, decode.loss_ce: 0.0808, decode.acc_seg: 95.5590, aux_0.loss_ce: 0.0849, aux_0.acc_seg: 95.4121, aux_1.loss_ce: 0.0963, aux_1.acc_seg: 94.7988, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8952, aux_3.loss_ce: 0.1126, aux_3.acc_seg: 94.6908, loss: 0.7642
2023-03-29 21:14:37,111 - mmseg - INFO - Iter [4900/10000]	lr: 5.457e-03, eta: 1:51:29, time: 1.231, data_time: 0.280, memory: 9073, decode.loss_ce: 0.0782, decode.acc_seg: 95.7252, aux_0.loss_ce: 0.0821, aux_0.acc_seg: 95.5757, aux_1.loss_ce: 0.0937, aux_1.acc_seg: 94.9789, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2645, aux_2.acc_seg: 95.8508, aux_3.loss_ce: 0.1106, aux_3.acc_seg: 94.8506, loss: 0.7555
2023-03-29 21:15:41,787 - mmseg - INFO - Iter [4950/10000]	lr: 5.408e-03, eta: 1:50:22, time: 1.294, data_time: 0.271, memory: 9073, decode.loss_ce: 0.0776, decode.acc_seg: 95.7149, aux_0.loss_ce: 0.0815, aux_0.acc_seg: 95.5886, aux_1.loss_ce: 0.0934, aux_1.acc_seg: 94.9851, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 95.8636, aux_3.loss_ce: 0.1099, aux_3.acc_seg: 94.8528, loss: 0.7537
2023-03-29 21:16:50,893 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-03-29 21:16:54,296 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 21:16:54,297 - mmseg - INFO - Iter [5000/10000]	lr: 5.360e-03, eta: 1:49:24, time: 1.450, data_time: 0.354, memory: 9073, decode.loss_ce: 0.0786, decode.acc_seg: 95.7020, aux_0.loss_ce: 0.0824, aux_0.acc_seg: 95.5581, aux_1.loss_ce: 0.0938, aux_1.acc_seg: 94.9669, aux_2.loss_ce: 0.1266, aux_2.loss_dice: 0.2643, aux_2.acc_seg: 95.8466, aux_3.loss_ce: 0.1101, aux_3.acc_seg: 94.8431, loss: 0.7557
2023-03-29 21:16:58,342 - mmseg - INFO - per class results:
2023-03-29 21:16:58,344 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.17 | 89.96 |
|   Building  | 91.76 | 93.91 |
|     Car     | 92.43 | 95.24 |
| Column_Pole | 15.91 | 19.06 |
|    Fence    | 77.63 | 91.37 |
|  Pedestrian | 58.98 | 78.98 |
|     Road    | 97.27 | 98.12 |
|   Sidewalk  | 90.92 |  96.9 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.75 | 96.57 |
|     Tree    | 90.47 | 98.06 |
+-------------+-------+-------+
2023-03-29 21:16:58,344 - mmseg - INFO - Summary:
2023-03-29 21:16:58,344 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 95.6 | 72.03 | 78.02 |
+------+-------+-------+
2023-03-29 21:16:58,344 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 21:16:58,344 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9560, mIoU: 0.7203, mAcc: 0.7802, IoU.Bicyclist: 0.8317, IoU.Building: 0.9176, IoU.Car: 0.9243, IoU.Column_Pole: 0.1591, IoU.Fence: 0.7763, IoU.Pedestrian: 0.5898, IoU.Road: 0.9727, IoU.Sidewalk: 0.9092, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9375, IoU.Tree: 0.9047, Acc.Bicyclist: 0.8996, Acc.Building: 0.9391, Acc.Car: 0.9524, Acc.Column_Pole: 0.1906, Acc.Fence: 0.9137, Acc.Pedestrian: 0.7898, Acc.Road: 0.9812, Acc.Sidewalk: 0.9690, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9657, Acc.Tree: 0.9806
2023-03-29 21:18:01,999 - mmseg - INFO - Iter [5050/10000]	lr: 5.312e-03, eta: 1:48:20, time: 1.354, data_time: 0.345, memory: 9073, decode.loss_ce: 0.0797, decode.acc_seg: 95.6369, aux_0.loss_ce: 0.0834, aux_0.acc_seg: 95.5040, aux_1.loss_ce: 0.0952, aux_1.acc_seg: 94.8971, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2661, aux_2.acc_seg: 95.8579, aux_3.loss_ce: 0.1123, aux_3.acc_seg: 94.7447, loss: 0.7641
2023-03-29 21:19:05,504 - mmseg - INFO - Iter [5100/10000]	lr: 5.264e-03, eta: 1:47:12, time: 1.270, data_time: 0.278, memory: 9073, decode.loss_ce: 0.0801, decode.acc_seg: 95.6892, aux_0.loss_ce: 0.0846, aux_0.acc_seg: 95.5503, aux_1.loss_ce: 0.0966, aux_1.acc_seg: 94.9533, aux_2.loss_ce: 0.1284, aux_2.loss_dice: 0.2658, aux_2.acc_seg: 95.7929, aux_3.loss_ce: 0.1125, aux_3.acc_seg: 94.8418, loss: 0.7680
2023-03-29 21:20:13,127 - mmseg - INFO - Iter [5150/10000]	lr: 5.215e-03, eta: 1:46:09, time: 1.352, data_time: 0.348, memory: 9073, decode.loss_ce: 0.0763, decode.acc_seg: 95.7304, aux_0.loss_ce: 0.0799, aux_0.acc_seg: 95.5931, aux_1.loss_ce: 0.0915, aux_1.acc_seg: 94.9880, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8394, aux_3.loss_ce: 0.1073, aux_3.acc_seg: 94.8464, loss: 0.7455
2023-03-29 21:21:17,627 - mmseg - INFO - Iter [5200/10000]	lr: 5.167e-03, eta: 1:45:02, time: 1.290, data_time: 0.303, memory: 9073, decode.loss_ce: 0.0774, decode.acc_seg: 95.7019, aux_0.loss_ce: 0.0816, aux_0.acc_seg: 95.5842, aux_1.loss_ce: 0.0929, aux_1.acc_seg: 94.9895, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 95.9062, aux_3.loss_ce: 0.1083, aux_3.acc_seg: 94.8596, loss: 0.7494
2023-03-29 21:22:22,544 - mmseg - INFO - Iter [5250/10000]	lr: 5.119e-03, eta: 1:43:56, time: 1.298, data_time: 0.289, memory: 9073, decode.loss_ce: 0.0791, decode.acc_seg: 95.6555, aux_0.loss_ce: 0.0823, aux_0.acc_seg: 95.5056, aux_1.loss_ce: 0.0941, aux_1.acc_seg: 94.9017, aux_2.loss_ce: 0.1282, aux_2.loss_dice: 0.2645, aux_2.acc_seg: 95.7790, aux_3.loss_ce: 0.1110, aux_3.acc_seg: 94.7626, loss: 0.7591
2023-03-29 21:23:32,605 - mmseg - INFO - Iter [5300/10000]	lr: 5.070e-03, eta: 1:42:54, time: 1.401, data_time: 0.391, memory: 9073, decode.loss_ce: 0.0763, decode.acc_seg: 95.8366, aux_0.loss_ce: 0.0804, aux_0.acc_seg: 95.7124, aux_1.loss_ce: 0.0912, aux_1.acc_seg: 95.1315, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.8731, aux_3.loss_ce: 0.1076, aux_3.acc_seg: 94.9708, loss: 0.7446
2023-03-29 21:24:35,579 - mmseg - INFO - Iter [5350/10000]	lr: 5.022e-03, eta: 1:41:46, time: 1.259, data_time: 0.310, memory: 9073, decode.loss_ce: 0.0745, decode.acc_seg: 95.7994, aux_0.loss_ce: 0.0774, aux_0.acc_seg: 95.6837, aux_1.loss_ce: 0.0895, aux_1.acc_seg: 95.0662, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8912, aux_3.loss_ce: 0.1046, aux_3.acc_seg: 94.9379, loss: 0.7339
2023-03-29 21:25:39,990 - mmseg - INFO - Iter [5400/10000]	lr: 4.973e-03, eta: 1:40:39, time: 1.288, data_time: 0.273, memory: 9073, decode.loss_ce: 0.0795, decode.acc_seg: 95.6517, aux_0.loss_ce: 0.0837, aux_0.acc_seg: 95.5246, aux_1.loss_ce: 0.0948, aux_1.acc_seg: 94.9175, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 95.8087, aux_3.loss_ce: 0.1111, aux_3.acc_seg: 94.7598, loss: 0.7616
2023-03-29 21:26:50,709 - mmseg - INFO - Iter [5450/10000]	lr: 4.924e-03, eta: 1:39:38, time: 1.414, data_time: 0.378, memory: 9073, decode.loss_ce: 0.0769, decode.acc_seg: 95.7689, aux_0.loss_ce: 0.0805, aux_0.acc_seg: 95.6531, aux_1.loss_ce: 0.0925, aux_1.acc_seg: 95.0324, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2638, aux_2.acc_seg: 95.8348, aux_3.loss_ce: 0.1075, aux_3.acc_seg: 94.9047, loss: 0.7479
2023-03-29 21:27:54,408 - mmseg - INFO - Iter [5500/10000]	lr: 4.876e-03, eta: 1:38:30, time: 1.274, data_time: 0.301, memory: 9073, decode.loss_ce: 0.0752, decode.acc_seg: 95.8118, aux_0.loss_ce: 0.0788, aux_0.acc_seg: 95.6775, aux_1.loss_ce: 0.0903, aux_1.acc_seg: 95.0711, aux_2.loss_ce: 0.1266, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 95.8197, aux_3.loss_ce: 0.1053, aux_3.acc_seg: 94.9349, loss: 0.7396
2023-03-29 21:28:59,463 - mmseg - INFO - Iter [5550/10000]	lr: 4.827e-03, eta: 1:37:24, time: 1.301, data_time: 0.299, memory: 9073, decode.loss_ce: 0.0750, decode.acc_seg: 95.8004, aux_0.loss_ce: 0.0789, aux_0.acc_seg: 95.6719, aux_1.loss_ce: 0.0903, aux_1.acc_seg: 95.0587, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2631, aux_2.acc_seg: 95.8491, aux_3.loss_ce: 0.1046, aux_3.acc_seg: 94.9490, loss: 0.7378
2023-03-29 21:30:08,356 - mmseg - INFO - Iter [5600/10000]	lr: 4.778e-03, eta: 1:36:21, time: 1.378, data_time: 0.372, memory: 9073, decode.loss_ce: 0.0774, decode.acc_seg: 95.7602, aux_0.loss_ce: 0.0814, aux_0.acc_seg: 95.6291, aux_1.loss_ce: 0.0932, aux_1.acc_seg: 94.9981, aux_2.loss_ce: 0.1271, aux_2.loss_dice: 0.2647, aux_2.acc_seg: 95.8366, aux_3.loss_ce: 0.1083, aux_3.acc_seg: 94.8664, loss: 0.7521
2023-03-29 21:31:13,059 - mmseg - INFO - Iter [5650/10000]	lr: 4.729e-03, eta: 1:35:15, time: 1.294, data_time: 0.273, memory: 9073, decode.loss_ce: 0.0761, decode.acc_seg: 95.7726, aux_0.loss_ce: 0.0794, aux_0.acc_seg: 95.6458, aux_1.loss_ce: 0.0914, aux_1.acc_seg: 95.0467, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.8734, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 94.8963, loss: 0.7423
2023-03-29 21:32:16,533 - mmseg - INFO - Iter [5700/10000]	lr: 4.680e-03, eta: 1:34:07, time: 1.269, data_time: 0.285, memory: 9073, decode.loss_ce: 0.0758, decode.acc_seg: 95.8036, aux_0.loss_ce: 0.0790, aux_0.acc_seg: 95.6965, aux_1.loss_ce: 0.0900, aux_1.acc_seg: 95.0681, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2629, aux_2.acc_seg: 95.8966, aux_3.loss_ce: 0.1058, aux_3.acc_seg: 94.9235, loss: 0.7386
2023-03-29 21:33:23,719 - mmseg - INFO - Iter [5750/10000]	lr: 4.631e-03, eta: 1:33:03, time: 1.344, data_time: 0.356, memory: 9073, decode.loss_ce: 0.0757, decode.acc_seg: 95.8038, aux_0.loss_ce: 0.0796, aux_0.acc_seg: 95.6785, aux_1.loss_ce: 0.0906, aux_1.acc_seg: 95.0781, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 95.8329, aux_3.loss_ce: 0.1050, aux_3.acc_seg: 94.9268, loss: 0.7398
2023-03-29 21:34:25,622 - mmseg - INFO - Iter [5800/10000]	lr: 4.582e-03, eta: 1:31:54, time: 1.238, data_time: 0.261, memory: 9073, decode.loss_ce: 0.0732, decode.acc_seg: 95.8397, aux_0.loss_ce: 0.0766, aux_0.acc_seg: 95.7188, aux_1.loss_ce: 0.0884, aux_1.acc_seg: 95.0938, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8998, aux_3.loss_ce: 0.1029, aux_3.acc_seg: 94.9742, loss: 0.7261
2023-03-29 21:35:30,363 - mmseg - INFO - Iter [5850/10000]	lr: 4.533e-03, eta: 1:30:48, time: 1.295, data_time: 0.280, memory: 9073, decode.loss_ce: 0.0739, decode.acc_seg: 95.8597, aux_0.loss_ce: 0.0786, aux_0.acc_seg: 95.7171, aux_1.loss_ce: 0.0888, aux_1.acc_seg: 95.1210, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2618, aux_2.acc_seg: 95.8717, aux_3.loss_ce: 0.1034, aux_3.acc_seg: 94.9704, loss: 0.7314
2023-03-29 21:36:38,645 - mmseg - INFO - Iter [5900/10000]	lr: 4.484e-03, eta: 1:29:44, time: 1.366, data_time: 0.352, memory: 9073, decode.loss_ce: 0.0742, decode.acc_seg: 95.8933, aux_0.loss_ce: 0.0775, aux_0.acc_seg: 95.7717, aux_1.loss_ce: 0.0887, aux_1.acc_seg: 95.1487, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 95.8742, aux_3.loss_ce: 0.1032, aux_3.acc_seg: 95.0238, loss: 0.7318
2023-03-29 21:37:39,740 - mmseg - INFO - Iter [5950/10000]	lr: 4.435e-03, eta: 1:28:35, time: 1.222, data_time: 0.269, memory: 9073, decode.loss_ce: 0.0758, decode.acc_seg: 95.8109, aux_0.loss_ce: 0.0788, aux_0.acc_seg: 95.6966, aux_1.loss_ce: 0.0905, aux_1.acc_seg: 95.0861, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8503, aux_3.loss_ce: 0.1052, aux_3.acc_seg: 94.9541, loss: 0.7406
2023-03-29 21:38:43,205 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-03-29 21:38:47,083 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 21:38:47,084 - mmseg - INFO - Iter [6000/10000]	lr: 4.385e-03, eta: 1:27:31, time: 1.347, data_time: 0.241, memory: 9073, decode.loss_ce: 0.0727, decode.acc_seg: 95.8784, aux_0.loss_ce: 0.0764, aux_0.acc_seg: 95.7423, aux_1.loss_ce: 0.0871, aux_1.acc_seg: 95.1392, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.9354, aux_3.loss_ce: 0.1012, aux_3.acc_seg: 95.0054, loss: 0.7230
2023-03-29 21:38:51,425 - mmseg - INFO - per class results:
2023-03-29 21:38:51,426 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.02 | 89.08 |
|   Building  | 91.78 | 94.04 |
|     Car     | 92.95 | 96.02 |
| Column_Pole | 11.32 |  12.4 |
|    Fence    | 78.36 | 89.42 |
|  Pedestrian | 60.81 | 79.84 |
|     Road    | 97.23 | 97.97 |
|   Sidewalk  |  90.8 |  97.3 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.72 |  96.2 |
|     Tree    | 89.62 | 98.43 |
+-------------+-------+-------+
2023-03-29 21:38:51,426 - mmseg - INFO - Summary:
2023-03-29 21:38:51,426 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.55 | 71.78 | 77.33 |
+-------+-------+-------+
2023-03-29 21:38:51,427 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 21:38:51,427 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9555, mIoU: 0.7178, mAcc: 0.7733, IoU.Bicyclist: 0.8302, IoU.Building: 0.9178, IoU.Car: 0.9295, IoU.Column_Pole: 0.1132, IoU.Fence: 0.7836, IoU.Pedestrian: 0.6081, IoU.Road: 0.9723, IoU.Sidewalk: 0.9080, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9372, IoU.Tree: 0.8962, Acc.Bicyclist: 0.8908, Acc.Building: 0.9404, Acc.Car: 0.9602, Acc.Column_Pole: 0.1240, Acc.Fence: 0.8942, Acc.Pedestrian: 0.7984, Acc.Road: 0.9797, Acc.Sidewalk: 0.9730, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9620, Acc.Tree: 0.9843
2023-03-29 21:39:57,386 - mmseg - INFO - Iter [6050/10000]	lr: 4.336e-03, eta: 1:26:28, time: 1.406, data_time: 0.415, memory: 9073, decode.loss_ce: 0.0727, decode.acc_seg: 95.9340, aux_0.loss_ce: 0.0758, aux_0.acc_seg: 95.8184, aux_1.loss_ce: 0.0886, aux_1.acc_seg: 95.1869, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 95.8846, aux_3.loss_ce: 0.1009, aux_3.acc_seg: 95.0946, loss: 0.7253
2023-03-29 21:41:01,481 - mmseg - INFO - Iter [6100/10000]	lr: 4.287e-03, eta: 1:25:22, time: 1.282, data_time: 0.270, memory: 9073, decode.loss_ce: 0.0764, decode.acc_seg: 95.8221, aux_0.loss_ce: 0.0791, aux_0.acc_seg: 95.7224, aux_1.loss_ce: 0.0903, aux_1.acc_seg: 95.0942, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 95.7815, aux_3.loss_ce: 0.1051, aux_3.acc_seg: 94.9572, loss: 0.7416
2023-03-29 21:42:04,818 - mmseg - INFO - Iter [6150/10000]	lr: 4.237e-03, eta: 1:24:14, time: 1.267, data_time: 0.266, memory: 9073, decode.loss_ce: 0.0760, decode.acc_seg: 95.8129, aux_0.loss_ce: 0.0797, aux_0.acc_seg: 95.6792, aux_1.loss_ce: 0.0912, aux_1.acc_seg: 95.0887, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2632, aux_2.acc_seg: 95.8549, aux_3.loss_ce: 0.1047, aux_3.acc_seg: 94.9345, loss: 0.7411
2023-03-29 21:43:13,348 - mmseg - INFO - Iter [6200/10000]	lr: 4.188e-03, eta: 1:23:11, time: 1.370, data_time: 0.331, memory: 9073, decode.loss_ce: 0.0736, decode.acc_seg: 95.8722, aux_0.loss_ce: 0.0780, aux_0.acc_seg: 95.7419, aux_1.loss_ce: 0.0889, aux_1.acc_seg: 95.1268, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2617, aux_2.acc_seg: 95.8343, aux_3.loss_ce: 0.1022, aux_3.acc_seg: 95.0053, loss: 0.7298
2023-03-29 21:44:14,318 - mmseg - INFO - Iter [6250/10000]	lr: 4.138e-03, eta: 1:22:02, time: 1.220, data_time: 0.254, memory: 9073, decode.loss_ce: 0.0723, decode.acc_seg: 96.0121, aux_0.loss_ce: 0.0760, aux_0.acc_seg: 95.8806, aux_1.loss_ce: 0.0880, aux_1.acc_seg: 95.2625, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8791, aux_3.loss_ce: 0.1005, aux_3.acc_seg: 95.1308, loss: 0.7225
2023-03-29 21:45:18,116 - mmseg - INFO - Iter [6300/10000]	lr: 4.088e-03, eta: 1:20:55, time: 1.276, data_time: 0.266, memory: 9073, decode.loss_ce: 0.0748, decode.acc_seg: 95.8777, aux_0.loss_ce: 0.0780, aux_0.acc_seg: 95.7630, aux_1.loss_ce: 0.0895, aux_1.acc_seg: 95.1442, aux_2.loss_ce: 0.1270, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 95.8143, aux_3.loss_ce: 0.1029, aux_3.acc_seg: 95.0069, loss: 0.7355
2023-03-29 21:46:26,624 - mmseg - INFO - Iter [6350/10000]	lr: 4.039e-03, eta: 1:19:51, time: 1.370, data_time: 0.340, memory: 9073, decode.loss_ce: 0.0728, decode.acc_seg: 95.9440, aux_0.loss_ce: 0.0768, aux_0.acc_seg: 95.7986, aux_1.loss_ce: 0.0881, aux_1.acc_seg: 95.2108, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2624, aux_2.acc_seg: 95.8693, aux_3.loss_ce: 0.1006, aux_3.acc_seg: 95.0692, loss: 0.7258
2023-03-29 21:47:27,038 - mmseg - INFO - Iter [6400/10000]	lr: 3.989e-03, eta: 1:18:43, time: 1.208, data_time: 0.242, memory: 9073, decode.loss_ce: 0.0738, decode.acc_seg: 95.9150, aux_0.loss_ce: 0.0779, aux_0.acc_seg: 95.7830, aux_1.loss_ce: 0.0890, aux_1.acc_seg: 95.1932, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.8584, aux_3.loss_ce: 0.1018, aux_3.acc_seg: 95.0421, loss: 0.7319
2023-03-29 21:48:30,263 - mmseg - INFO - Iter [6450/10000]	lr: 3.939e-03, eta: 1:17:36, time: 1.265, data_time: 0.256, memory: 9073, decode.loss_ce: 0.0726, decode.acc_seg: 95.9693, aux_0.loss_ce: 0.0764, aux_0.acc_seg: 95.8333, aux_1.loss_ce: 0.0877, aux_1.acc_seg: 95.2298, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2623, aux_2.acc_seg: 95.8320, aux_3.loss_ce: 0.1004, aux_3.acc_seg: 95.1073, loss: 0.7254
2023-03-29 21:49:34,925 - mmseg - INFO - Iter [6500/10000]	lr: 3.889e-03, eta: 1:16:30, time: 1.293, data_time: 0.305, memory: 9073, decode.loss_ce: 0.0729, decode.acc_seg: 95.8984, aux_0.loss_ce: 0.0764, aux_0.acc_seg: 95.7615, aux_1.loss_ce: 0.0870, aux_1.acc_seg: 95.1732, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8614, aux_3.loss_ce: 0.1012, aux_3.acc_seg: 94.9981, loss: 0.7256
2023-03-29 21:50:36,034 - mmseg - INFO - Iter [6550/10000]	lr: 3.839e-03, eta: 1:15:22, time: 1.222, data_time: 0.251, memory: 9073, decode.loss_ce: 0.0763, decode.acc_seg: 95.8047, aux_0.loss_ce: 0.0795, aux_0.acc_seg: 95.6712, aux_1.loss_ce: 0.0912, aux_1.acc_seg: 95.0735, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 95.8394, aux_3.loss_ce: 0.1047, aux_3.acc_seg: 94.9297, loss: 0.7402
2023-03-29 21:51:38,560 - mmseg - INFO - Iter [6600/10000]	lr: 3.789e-03, eta: 1:14:15, time: 1.251, data_time: 0.237, memory: 9073, decode.loss_ce: 0.0727, decode.acc_seg: 95.9425, aux_0.loss_ce: 0.0769, aux_0.acc_seg: 95.8042, aux_1.loss_ce: 0.0878, aux_1.acc_seg: 95.2109, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8559, aux_3.loss_ce: 0.1009, aux_3.acc_seg: 95.0598, loss: 0.7266
2023-03-29 21:52:43,799 - mmseg - INFO - Iter [6650/10000]	lr: 3.739e-03, eta: 1:13:09, time: 1.305, data_time: 0.286, memory: 9073, decode.loss_ce: 0.0748, decode.acc_seg: 95.9055, aux_0.loss_ce: 0.0777, aux_0.acc_seg: 95.7919, aux_1.loss_ce: 0.0895, aux_1.acc_seg: 95.2068, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 95.8627, aux_3.loss_ce: 0.1020, aux_3.acc_seg: 95.0454, loss: 0.7328
2023-03-29 21:53:44,295 - mmseg - INFO - Iter [6700/10000]	lr: 3.689e-03, eta: 1:12:01, time: 1.210, data_time: 0.226, memory: 9073, decode.loss_ce: 0.0705, decode.acc_seg: 96.0222, aux_0.loss_ce: 0.0738, aux_0.acc_seg: 95.8919, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.3034, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.9163, aux_3.loss_ce: 0.0975, aux_3.acc_seg: 95.1654, loss: 0.7119
2023-03-29 21:54:45,873 - mmseg - INFO - Iter [6750/10000]	lr: 3.638e-03, eta: 1:10:54, time: 1.232, data_time: 0.223, memory: 9073, decode.loss_ce: 0.0734, decode.acc_seg: 95.9244, aux_0.loss_ce: 0.0770, aux_0.acc_seg: 95.7731, aux_1.loss_ce: 0.0887, aux_1.acc_seg: 95.1843, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 95.8528, aux_3.loss_ce: 0.1007, aux_3.acc_seg: 95.0425, loss: 0.7285
2023-03-29 21:55:49,318 - mmseg - INFO - Iter [6800/10000]	lr: 3.588e-03, eta: 1:09:47, time: 1.269, data_time: 0.299, memory: 9073, decode.loss_ce: 0.0736, decode.acc_seg: 95.8935, aux_0.loss_ce: 0.0774, aux_0.acc_seg: 95.7663, aux_1.loss_ce: 0.0883, aux_1.acc_seg: 95.1498, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8398, aux_3.loss_ce: 0.1011, aux_3.acc_seg: 94.9905, loss: 0.7274
2023-03-29 21:56:53,635 - mmseg - INFO - Iter [6850/10000]	lr: 3.537e-03, eta: 1:08:41, time: 1.286, data_time: 0.230, memory: 9073, decode.loss_ce: 0.0717, decode.acc_seg: 95.9842, aux_0.loss_ce: 0.0766, aux_0.acc_seg: 95.8323, aux_1.loss_ce: 0.0866, aux_1.acc_seg: 95.2557, aux_2.loss_ce: 0.1242, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 95.9116, aux_3.loss_ce: 0.0989, aux_3.acc_seg: 95.1143, loss: 0.7194
2023-03-29 21:57:53,688 - mmseg - INFO - Iter [6900/10000]	lr: 3.487e-03, eta: 1:07:34, time: 1.201, data_time: 0.226, memory: 9073, decode.loss_ce: 0.0719, decode.acc_seg: 95.9921, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 95.8831, aux_1.loss_ce: 0.0865, aux_1.acc_seg: 95.2672, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.8955, aux_3.loss_ce: 0.0988, aux_3.acc_seg: 95.1112, loss: 0.7176
2023-03-29 21:58:58,384 - mmseg - INFO - Iter [6950/10000]	lr: 3.436e-03, eta: 1:06:28, time: 1.294, data_time: 0.292, memory: 9073, decode.loss_ce: 0.0729, decode.acc_seg: 96.0226, aux_0.loss_ce: 0.0760, aux_0.acc_seg: 95.8981, aux_1.loss_ce: 0.0875, aux_1.acc_seg: 95.3367, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8774, aux_3.loss_ce: 0.1002, aux_3.acc_seg: 95.1593, loss: 0.7239
2023-03-29 22:00:01,158 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-03-29 22:00:04,609 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 22:00:04,610 - mmseg - INFO - Iter [7000/10000]	lr: 3.386e-03, eta: 1:05:23, time: 1.325, data_time: 0.236, memory: 9073, decode.loss_ce: 0.0700, decode.acc_seg: 95.9925, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.8789, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.2782, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 95.9108, aux_3.loss_ce: 0.0966, aux_3.acc_seg: 95.1117, loss: 0.7085
2023-03-29 22:00:08,009 - mmseg - INFO - per class results:
2023-03-29 22:00:08,010 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.95 |  90.8 |
|   Building  | 91.14 | 93.23 |
|     Car     | 92.68 | 95.75 |
| Column_Pole | 15.44 | 18.41 |
|    Fence    | 77.46 | 88.89 |
|  Pedestrian | 61.62 | 79.98 |
|     Road    | 97.42 | 98.29 |
|   Sidewalk  | 91.37 | 96.77 |
|  SignSymbol |  0.03 |  0.03 |
|     Sky     | 93.82 | 96.74 |
|     Tree    | 89.11 | 98.27 |
+-------------+-------+-------+
2023-03-29 22:00:08,010 - mmseg - INFO - Summary:
2023-03-29 22:00:08,010 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.46 | 72.19 | 77.92 |
+-------+-------+-------+
2023-03-29 22:00:08,011 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 22:00:08,011 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9546, mIoU: 0.7219, mAcc: 0.7792, IoU.Bicyclist: 0.8395, IoU.Building: 0.9114, IoU.Car: 0.9268, IoU.Column_Pole: 0.1544, IoU.Fence: 0.7746, IoU.Pedestrian: 0.6162, IoU.Road: 0.9742, IoU.Sidewalk: 0.9137, IoU.SignSymbol: 0.0003, IoU.Sky: 0.9382, IoU.Tree: 0.8911, Acc.Bicyclist: 0.9080, Acc.Building: 0.9323, Acc.Car: 0.9575, Acc.Column_Pole: 0.1841, Acc.Fence: 0.8889, Acc.Pedestrian: 0.7998, Acc.Road: 0.9829, Acc.Sidewalk: 0.9677, Acc.SignSymbol: 0.0003, Acc.Sky: 0.9674, Acc.Tree: 0.9827
2023-03-29 22:01:10,082 - mmseg - INFO - Iter [7050/10000]	lr: 3.335e-03, eta: 1:04:18, time: 1.309, data_time: 0.303, memory: 9073, decode.loss_ce: 0.0723, decode.acc_seg: 95.9151, aux_0.loss_ce: 0.0758, aux_0.acc_seg: 95.7951, aux_1.loss_ce: 0.0870, aux_1.acc_seg: 95.2039, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 95.8475, aux_3.loss_ce: 0.0989, aux_3.acc_seg: 95.0474, loss: 0.7214
2023-03-29 22:02:12,924 - mmseg - INFO - Iter [7100/10000]	lr: 3.284e-03, eta: 1:03:11, time: 1.257, data_time: 0.294, memory: 9073, decode.loss_ce: 0.0714, decode.acc_seg: 95.9775, aux_0.loss_ce: 0.0751, aux_0.acc_seg: 95.8591, aux_1.loss_ce: 0.0859, aux_1.acc_seg: 95.2416, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.8470, aux_3.loss_ce: 0.0981, aux_3.acc_seg: 95.0954, loss: 0.7164
2023-03-29 22:03:18,157 - mmseg - INFO - Iter [7150/10000]	lr: 3.233e-03, eta: 1:02:06, time: 1.305, data_time: 0.242, memory: 9073, decode.loss_ce: 0.0711, decode.acc_seg: 96.0153, aux_0.loss_ce: 0.0750, aux_0.acc_seg: 95.8643, aux_1.loss_ce: 0.0863, aux_1.acc_seg: 95.2596, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8300, aux_3.loss_ce: 0.0977, aux_3.acc_seg: 95.1371, loss: 0.7172
2023-03-29 22:04:00,932 - mmseg - INFO - Iter [7200/10000]	lr: 3.182e-03, eta: 1:00:51, time: 0.855, data_time: 0.228, memory: 9073, decode.loss_ce: 0.0714, decode.acc_seg: 96.0415, aux_0.loss_ce: 0.0750, aux_0.acc_seg: 95.9004, aux_1.loss_ce: 0.0861, aux_1.acc_seg: 95.3159, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 95.8522, aux_3.loss_ce: 0.0980, aux_3.acc_seg: 95.1575, loss: 0.7187
2023-03-29 22:04:45,580 - mmseg - INFO - Iter [7250/10000]	lr: 3.131e-03, eta: 0:59:38, time: 0.893, data_time: 0.286, memory: 9073, decode.loss_ce: 0.0719, decode.acc_seg: 95.9212, aux_0.loss_ce: 0.0758, aux_0.acc_seg: 95.7839, aux_1.loss_ce: 0.0864, aux_1.acc_seg: 95.1856, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.9057, aux_3.loss_ce: 0.0988, aux_3.acc_seg: 95.0076, loss: 0.7193
2023-03-29 22:05:26,671 - mmseg - INFO - Iter [7300/10000]	lr: 3.079e-03, eta: 0:58:25, time: 0.822, data_time: 0.223, memory: 9073, decode.loss_ce: 0.0709, decode.acc_seg: 96.0497, aux_0.loss_ce: 0.0746, aux_0.acc_seg: 95.9170, aux_1.loss_ce: 0.0855, aux_1.acc_seg: 95.3251, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8685, aux_3.loss_ce: 0.0975, aux_3.acc_seg: 95.1683, loss: 0.7146
2023-03-29 22:06:07,833 - mmseg - INFO - Iter [7350/10000]	lr: 3.028e-03, eta: 0:57:11, time: 0.823, data_time: 0.226, memory: 9073, decode.loss_ce: 0.0719, decode.acc_seg: 95.9967, aux_0.loss_ce: 0.0747, aux_0.acc_seg: 95.8785, aux_1.loss_ce: 0.0863, aux_1.acc_seg: 95.2780, aux_2.loss_ce: 0.1243, aux_2.loss_dice: 0.2618, aux_2.acc_seg: 95.9161, aux_3.loss_ce: 0.0981, aux_3.acc_seg: 95.1252, loss: 0.7173
2023-03-29 22:06:52,200 - mmseg - INFO - Iter [7400/10000]	lr: 2.977e-03, eta: 0:55:59, time: 0.887, data_time: 0.284, memory: 9073, decode.loss_ce: 0.0700, decode.acc_seg: 96.0629, aux_0.loss_ce: 0.0740, aux_0.acc_seg: 95.9151, aux_1.loss_ce: 0.0847, aux_1.acc_seg: 95.3120, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 95.8904, aux_3.loss_ce: 0.0967, aux_3.acc_seg: 95.1577, loss: 0.7100
2023-03-29 22:07:33,419 - mmseg - INFO - Iter [7450/10000]	lr: 2.925e-03, eta: 0:54:47, time: 0.824, data_time: 0.223, memory: 9073, decode.loss_ce: 0.0713, decode.acc_seg: 95.9962, aux_0.loss_ce: 0.0746, aux_0.acc_seg: 95.8727, aux_1.loss_ce: 0.0860, aux_1.acc_seg: 95.2697, aux_2.loss_ce: 0.1243, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8886, aux_3.loss_ce: 0.0971, aux_3.acc_seg: 95.1122, loss: 0.7145
2023-03-29 22:08:15,136 - mmseg - INFO - Iter [7500/10000]	lr: 2.873e-03, eta: 0:53:35, time: 0.834, data_time: 0.229, memory: 9073, decode.loss_ce: 0.0706, decode.acc_seg: 96.0047, aux_0.loss_ce: 0.0742, aux_0.acc_seg: 95.8782, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.2730, aux_2.loss_ce: 0.1243, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.8924, aux_3.loss_ce: 0.0963, aux_3.acc_seg: 95.1245, loss: 0.7111
2023-03-29 22:08:59,695 - mmseg - INFO - Iter [7550/10000]	lr: 2.822e-03, eta: 0:52:24, time: 0.891, data_time: 0.289, memory: 9073, decode.loss_ce: 0.0711, decode.acc_seg: 96.0335, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 95.8919, aux_1.loss_ce: 0.0855, aux_1.acc_seg: 95.2974, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2602, aux_2.acc_seg: 95.9064, aux_3.loss_ce: 0.0973, aux_3.acc_seg: 95.1250, loss: 0.7122
2023-03-29 22:09:41,096 - mmseg - INFO - Iter [7600/10000]	lr: 2.770e-03, eta: 0:51:12, time: 0.828, data_time: 0.227, memory: 9073, decode.loss_ce: 0.0721, decode.acc_seg: 95.9712, aux_0.loss_ce: 0.0750, aux_0.acc_seg: 95.8480, aux_1.loss_ce: 0.0867, aux_1.acc_seg: 95.2476, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8686, aux_3.loss_ce: 0.0977, aux_3.acc_seg: 95.0924, loss: 0.7180
2023-03-29 22:10:22,028 - mmseg - INFO - Iter [7650/10000]	lr: 2.718e-03, eta: 0:50:01, time: 0.819, data_time: 0.221, memory: 9073, decode.loss_ce: 0.0707, decode.acc_seg: 96.1070, aux_0.loss_ce: 0.0747, aux_0.acc_seg: 95.9748, aux_1.loss_ce: 0.0851, aux_1.acc_seg: 95.3901, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2617, aux_2.acc_seg: 95.8364, aux_3.loss_ce: 0.0961, aux_3.acc_seg: 95.2457, loss: 0.7138
2023-03-29 22:11:06,293 - mmseg - INFO - Iter [7700/10000]	lr: 2.666e-03, eta: 0:48:52, time: 0.885, data_time: 0.286, memory: 9073, decode.loss_ce: 0.0702, decode.acc_seg: 96.0833, aux_0.loss_ce: 0.0748, aux_0.acc_seg: 95.9582, aux_1.loss_ce: 0.0854, aux_1.acc_seg: 95.3596, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 95.8444, aux_3.loss_ce: 0.0960, aux_3.acc_seg: 95.2061, loss: 0.7130
2023-03-29 22:11:47,878 - mmseg - INFO - Iter [7750/10000]	lr: 2.614e-03, eta: 0:47:41, time: 0.832, data_time: 0.223, memory: 9073, decode.loss_ce: 0.0692, decode.acc_seg: 96.0793, aux_0.loss_ce: 0.0736, aux_0.acc_seg: 95.9401, aux_1.loss_ce: 0.0840, aux_1.acc_seg: 95.3430, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8727, aux_3.loss_ce: 0.0952, aux_3.acc_seg: 95.1755, loss: 0.7078
2023-03-29 22:12:29,311 - mmseg - INFO - Iter [7800/10000]	lr: 2.561e-03, eta: 0:46:32, time: 0.829, data_time: 0.226, memory: 9073, decode.loss_ce: 0.0706, decode.acc_seg: 96.0757, aux_0.loss_ce: 0.0737, aux_0.acc_seg: 95.9529, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.3638, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8622, aux_3.loss_ce: 0.0962, aux_3.acc_seg: 95.2046, loss: 0.7111
2023-03-29 22:13:15,870 - mmseg - INFO - Iter [7850/10000]	lr: 2.509e-03, eta: 0:45:24, time: 0.931, data_time: 0.318, memory: 9073, decode.loss_ce: 0.0705, decode.acc_seg: 96.0540, aux_0.loss_ce: 0.0746, aux_0.acc_seg: 95.9162, aux_1.loss_ce: 0.0857, aux_1.acc_seg: 95.3097, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8319, aux_3.loss_ce: 0.0962, aux_3.acc_seg: 95.1872, loss: 0.7137
2023-03-29 22:13:57,733 - mmseg - INFO - Iter [7900/10000]	lr: 2.457e-03, eta: 0:44:14, time: 0.837, data_time: 0.233, memory: 9073, decode.loss_ce: 0.0703, decode.acc_seg: 96.0627, aux_0.loss_ce: 0.0736, aux_0.acc_seg: 95.9385, aux_1.loss_ce: 0.0857, aux_1.acc_seg: 95.3464, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8621, aux_3.loss_ce: 0.0955, aux_3.acc_seg: 95.2100, loss: 0.7111
2023-03-29 22:14:39,212 - mmseg - INFO - Iter [7950/10000]	lr: 2.404e-03, eta: 0:43:06, time: 0.830, data_time: 0.226, memory: 9073, decode.loss_ce: 0.0697, decode.acc_seg: 96.0423, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.9149, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.3297, aux_2.loss_ce: 0.1231, aux_2.loss_dice: 0.2588, aux_2.acc_seg: 95.9377, aux_3.loss_ce: 0.0954, aux_3.acc_seg: 95.1626, loss: 0.7049
2023-03-29 22:15:25,610 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-03-29 22:15:29,495 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 22:15:29,495 - mmseg - INFO - Iter [8000/10000]	lr: 2.351e-03, eta: 0:41:59, time: 1.006, data_time: 0.310, memory: 9073, decode.loss_ce: 0.0698, decode.acc_seg: 96.0939, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 95.9615, aux_1.loss_ce: 0.0851, aux_1.acc_seg: 95.3608, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2619, aux_2.acc_seg: 95.8642, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.2143, loss: 0.7104
2023-03-29 22:15:32,658 - mmseg - INFO - per class results:
2023-03-29 22:15:32,659 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.84 | 90.04 |
|   Building  | 91.38 | 93.47 |
|     Car     | 92.73 | 95.65 |
| Column_Pole | 14.05 | 16.26 |
|    Fence    | 78.69 |  90.1 |
|  Pedestrian | 61.52 | 81.29 |
|     Road    |  97.4 |  98.2 |
|   Sidewalk  | 91.35 | 97.23 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.77 |  96.3 |
|     Tree    | 89.32 | 98.35 |
+-------------+-------+-------+
2023-03-29 22:15:32,659 - mmseg - INFO - Summary:
2023-03-29 22:15:32,660 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 95.53 | 72.19 | 77.9 |
+-------+-------+------+
2023-03-29 22:15:32,660 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 22:15:32,660 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9553, mIoU: 0.7219, mAcc: 0.7790, IoU.Bicyclist: 0.8384, IoU.Building: 0.9138, IoU.Car: 0.9273, IoU.Column_Pole: 0.1405, IoU.Fence: 0.7869, IoU.Pedestrian: 0.6152, IoU.Road: 0.9740, IoU.Sidewalk: 0.9135, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9377, IoU.Tree: 0.8932, Acc.Bicyclist: 0.9004, Acc.Building: 0.9347, Acc.Car: 0.9565, Acc.Column_Pole: 0.1626, Acc.Fence: 0.9010, Acc.Pedestrian: 0.8129, Acc.Road: 0.9820, Acc.Sidewalk: 0.9723, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9630, Acc.Tree: 0.9835
2023-03-29 22:16:14,571 - mmseg - INFO - Iter [8050/10000]	lr: 2.298e-03, eta: 0:40:52, time: 0.901, data_time: 0.298, memory: 9073, decode.loss_ce: 0.0716, decode.acc_seg: 95.9771, aux_0.loss_ce: 0.0757, aux_0.acc_seg: 95.8298, aux_1.loss_ce: 0.0860, aux_1.acc_seg: 95.2349, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 95.8413, aux_3.loss_ce: 0.0972, aux_3.acc_seg: 95.0814, loss: 0.7184
2023-03-29 22:16:56,790 - mmseg - INFO - Iter [8100/10000]	lr: 2.245e-03, eta: 0:39:44, time: 0.844, data_time: 0.240, memory: 9073, decode.loss_ce: 0.0696, decode.acc_seg: 96.1043, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.9552, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.3631, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 95.8316, aux_3.loss_ce: 0.0947, aux_3.acc_seg: 95.2226, loss: 0.7071
2023-03-29 22:17:42,644 - mmseg - INFO - Iter [8150/10000]	lr: 2.192e-03, eta: 0:38:38, time: 0.917, data_time: 0.305, memory: 9073, decode.loss_ce: 0.0703, decode.acc_seg: 95.9941, aux_0.loss_ce: 0.0741, aux_0.acc_seg: 95.8487, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.2575, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.8653, aux_3.loss_ce: 0.0954, aux_3.acc_seg: 95.0852, loss: 0.7097
2023-03-29 22:18:24,677 - mmseg - INFO - Iter [8200/10000]	lr: 2.139e-03, eta: 0:37:31, time: 0.841, data_time: 0.233, memory: 9073, decode.loss_ce: 0.0689, decode.acc_seg: 96.1020, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 95.9785, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.3667, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8555, aux_3.loss_ce: 0.0948, aux_3.acc_seg: 95.1868, loss: 0.7052
2023-03-29 22:19:07,311 - mmseg - INFO - Iter [8250/10000]	lr: 2.085e-03, eta: 0:36:24, time: 0.853, data_time: 0.239, memory: 9073, decode.loss_ce: 0.0704, decode.acc_seg: 96.0521, aux_0.loss_ce: 0.0741, aux_0.acc_seg: 95.9082, aux_1.loss_ce: 0.0851, aux_1.acc_seg: 95.3078, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8310, aux_3.loss_ce: 0.0958, aux_3.acc_seg: 95.1353, loss: 0.7119
2023-03-29 22:19:56,066 - mmseg - INFO - Iter [8300/10000]	lr: 2.031e-03, eta: 0:35:19, time: 0.975, data_time: 0.354, memory: 9073, decode.loss_ce: 0.0678, decode.acc_seg: 96.1853, aux_0.loss_ce: 0.0709, aux_0.acc_seg: 96.0677, aux_1.loss_ce: 0.0823, aux_1.acc_seg: 95.4787, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2599, aux_2.acc_seg: 95.8846, aux_3.loss_ce: 0.0931, aux_3.acc_seg: 95.2829, loss: 0.6981
2023-03-29 22:20:37,793 - mmseg - INFO - Iter [8350/10000]	lr: 1.978e-03, eta: 0:34:12, time: 0.834, data_time: 0.229, memory: 9073, decode.loss_ce: 0.0692, decode.acc_seg: 96.0667, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.9381, aux_1.loss_ce: 0.0832, aux_1.acc_seg: 95.3438, aux_2.loss_ce: 0.1227, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 95.9460, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.1946, loss: 0.7018
2023-03-29 22:21:19,573 - mmseg - INFO - Iter [8400/10000]	lr: 1.924e-03, eta: 0:33:06, time: 0.836, data_time: 0.232, memory: 9073, decode.loss_ce: 0.0686, decode.acc_seg: 96.1377, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 96.0073, aux_1.loss_ce: 0.0825, aux_1.acc_seg: 95.4272, aux_2.loss_ce: 0.1243, aux_2.loss_dice: 0.2599, aux_2.acc_seg: 95.8895, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.2746, loss: 0.7005
2023-03-29 22:22:06,747 - mmseg - INFO - Iter [8450/10000]	lr: 1.870e-03, eta: 0:32:01, time: 0.943, data_time: 0.323, memory: 9073, decode.loss_ce: 0.0700, decode.acc_seg: 96.0543, aux_0.loss_ce: 0.0737, aux_0.acc_seg: 95.9245, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.3150, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8953, aux_3.loss_ce: 0.0943, aux_3.acc_seg: 95.1817, loss: 0.7081
2023-03-29 22:22:49,092 - mmseg - INFO - Iter [8500/10000]	lr: 1.815e-03, eta: 0:30:56, time: 0.847, data_time: 0.239, memory: 9073, decode.loss_ce: 0.0679, decode.acc_seg: 96.1674, aux_0.loss_ce: 0.0718, aux_0.acc_seg: 96.0331, aux_1.loss_ce: 0.0818, aux_1.acc_seg: 95.4540, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2606, aux_2.acc_seg: 95.9050, aux_3.loss_ce: 0.0927, aux_3.acc_seg: 95.3031, loss: 0.6987
2023-03-29 22:23:54,035 - mmseg - INFO - Iter [8550/10000]	lr: 1.761e-03, eta: 0:29:54, time: 1.299, data_time: 0.227, memory: 9073, decode.loss_ce: 0.0690, decode.acc_seg: 96.0893, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 95.9589, aux_1.loss_ce: 0.0836, aux_1.acc_seg: 95.3482, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8528, aux_3.loss_ce: 0.0937, aux_3.acc_seg: 95.2017, loss: 0.7046
2023-03-29 22:25:12,827 - mmseg - INFO - Iter [8600/10000]	lr: 1.706e-03, eta: 0:28:55, time: 1.576, data_time: 0.317, memory: 9073, decode.loss_ce: 0.0680, decode.acc_seg: 96.1773, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 96.0561, aux_1.loss_ce: 0.0826, aux_1.acc_seg: 95.4719, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8650, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.2818, loss: 0.7015
2023-03-29 22:26:28,767 - mmseg - INFO - Iter [8650/10000]	lr: 1.651e-03, eta: 0:27:55, time: 1.519, data_time: 0.237, memory: 9073, decode.loss_ce: 0.0694, decode.acc_seg: 96.1146, aux_0.loss_ce: 0.0729, aux_0.acc_seg: 95.9831, aux_1.loss_ce: 0.0843, aux_1.acc_seg: 95.3951, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2598, aux_2.acc_seg: 95.8734, aux_3.loss_ce: 0.0936, aux_3.acc_seg: 95.2389, loss: 0.7045
2023-03-29 22:27:44,179 - mmseg - INFO - Iter [8700/10000]	lr: 1.596e-03, eta: 0:26:55, time: 1.508, data_time: 0.228, memory: 9073, decode.loss_ce: 0.0701, decode.acc_seg: 96.0647, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.9473, aux_1.loss_ce: 0.0839, aux_1.acc_seg: 95.3549, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 95.8234, aux_3.loss_ce: 0.0946, aux_3.acc_seg: 95.1898, loss: 0.7091
2023-03-29 22:29:03,648 - mmseg - INFO - Iter [8750/10000]	lr: 1.541e-03, eta: 0:25:56, time: 1.589, data_time: 0.305, memory: 9073, decode.loss_ce: 0.0686, decode.acc_seg: 96.1082, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 95.9791, aux_1.loss_ce: 0.0829, aux_1.acc_seg: 95.3920, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2590, aux_2.acc_seg: 95.8701, aux_3.loss_ce: 0.0925, aux_3.acc_seg: 95.2399, loss: 0.6982
2023-03-29 22:30:18,366 - mmseg - INFO - Iter [8800/10000]	lr: 1.485e-03, eta: 0:24:55, time: 1.494, data_time: 0.222, memory: 9073, decode.loss_ce: 0.0699, decode.acc_seg: 96.0607, aux_0.loss_ce: 0.0739, aux_0.acc_seg: 95.9402, aux_1.loss_ce: 0.0850, aux_1.acc_seg: 95.3692, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8730, aux_3.loss_ce: 0.0940, aux_3.acc_seg: 95.1913, loss: 0.7087
2023-03-29 22:31:34,022 - mmseg - INFO - Iter [8850/10000]	lr: 1.430e-03, eta: 0:23:55, time: 1.513, data_time: 0.232, memory: 9073, decode.loss_ce: 0.0703, decode.acc_seg: 96.0330, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 95.9071, aux_1.loss_ce: 0.0847, aux_1.acc_seg: 95.2985, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2600, aux_2.acc_seg: 95.8433, aux_3.loss_ce: 0.0944, aux_3.acc_seg: 95.1528, loss: 0.7077
2023-03-29 22:32:54,549 - mmseg - INFO - Iter [8900/10000]	lr: 1.374e-03, eta: 0:22:54, time: 1.611, data_time: 0.327, memory: 9073, decode.loss_ce: 0.0670, decode.acc_seg: 96.1812, aux_0.loss_ce: 0.0703, aux_0.acc_seg: 96.0692, aux_1.loss_ce: 0.0812, aux_1.acc_seg: 95.4776, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2588, aux_2.acc_seg: 95.9462, aux_3.loss_ce: 0.0904, aux_3.acc_seg: 95.3442, loss: 0.6901
2023-03-29 22:34:08,984 - mmseg - INFO - Iter [8950/10000]	lr: 1.317e-03, eta: 0:21:53, time: 1.489, data_time: 0.216, memory: 9073, decode.loss_ce: 0.0694, decode.acc_seg: 96.0944, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 95.9721, aux_1.loss_ce: 0.0840, aux_1.acc_seg: 95.3707, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8086, aux_3.loss_ce: 0.0932, aux_3.acc_seg: 95.2049, loss: 0.7053
2023-03-29 22:35:23,453 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-03-29 22:35:26,965 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 22:35:26,965 - mmseg - INFO - Iter [9000/10000]	lr: 1.261e-03, eta: 0:20:52, time: 1.560, data_time: 0.220, memory: 9073, decode.loss_ce: 0.0690, decode.acc_seg: 96.0968, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 95.9794, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.3859, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2589, aux_2.acc_seg: 95.9017, aux_3.loss_ce: 0.0927, aux_3.acc_seg: 95.2162, loss: 0.6994
2023-03-29 22:35:30,254 - mmseg - INFO - per class results:
2023-03-29 22:35:30,255 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  |  84.3 | 91.87 |
|   Building  |  92.0 | 93.97 |
|     Car     | 92.84 | 95.69 |
| Column_Pole | 15.44 |  17.9 |
|    Fence    | 79.31 | 91.15 |
|  Pedestrian | 63.36 | 81.48 |
|     Road    | 97.47 | 98.31 |
|   Sidewalk  | 91.69 |  97.0 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.91 | 96.81 |
|     Tree    | 90.17 | 98.14 |
+-------------+-------+-------+
2023-03-29 22:35:30,255 - mmseg - INFO - Summary:
2023-03-29 22:35:30,255 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.78 | 72.77 | 78.39 |
+-------+-------+-------+
2023-03-29 22:35:30,256 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 22:35:30,256 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9578, mIoU: 0.7277, mAcc: 0.7839, IoU.Bicyclist: 0.8430, IoU.Building: 0.9200, IoU.Car: 0.9284, IoU.Column_Pole: 0.1544, IoU.Fence: 0.7931, IoU.Pedestrian: 0.6336, IoU.Road: 0.9747, IoU.Sidewalk: 0.9169, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9391, IoU.Tree: 0.9017, Acc.Bicyclist: 0.9187, Acc.Building: 0.9397, Acc.Car: 0.9569, Acc.Column_Pole: 0.1790, Acc.Fence: 0.9115, Acc.Pedestrian: 0.8148, Acc.Road: 0.9831, Acc.Sidewalk: 0.9700, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9681, Acc.Tree: 0.9814
2023-03-29 22:36:50,099 - mmseg - INFO - Iter [9050/10000]	lr: 1.204e-03, eta: 0:19:52, time: 1.663, data_time: 0.387, memory: 9073, decode.loss_ce: 0.0688, decode.acc_seg: 96.1292, aux_0.loss_ce: 0.0717, aux_0.acc_seg: 96.0098, aux_1.loss_ce: 0.0828, aux_1.acc_seg: 95.4149, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2601, aux_2.acc_seg: 95.8726, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.2436, loss: 0.7008
2023-03-29 22:38:05,271 - mmseg - INFO - Iter [9100/10000]	lr: 1.147e-03, eta: 0:18:50, time: 1.503, data_time: 0.230, memory: 9073, decode.loss_ce: 0.0679, decode.acc_seg: 96.1464, aux_0.loss_ce: 0.0710, aux_0.acc_seg: 96.0169, aux_1.loss_ce: 0.0830, aux_1.acc_seg: 95.4190, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2592, aux_2.acc_seg: 95.8825, aux_3.loss_ce: 0.0918, aux_3.acc_seg: 95.2701, loss: 0.6967
2023-03-29 22:39:21,188 - mmseg - INFO - Iter [9150/10000]	lr: 1.090e-03, eta: 0:17:49, time: 1.518, data_time: 0.242, memory: 9073, decode.loss_ce: 0.0684, decode.acc_seg: 96.1043, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 95.9752, aux_1.loss_ce: 0.0829, aux_1.acc_seg: 95.3827, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 95.9027, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.2312, loss: 0.6986
2023-03-29 22:40:40,455 - mmseg - INFO - Iter [9200/10000]	lr: 1.032e-03, eta: 0:16:47, time: 1.585, data_time: 0.305, memory: 9073, decode.loss_ce: 0.0687, decode.acc_seg: 96.1150, aux_0.loss_ce: 0.0724, aux_0.acc_seg: 95.9905, aux_1.loss_ce: 0.0826, aux_1.acc_seg: 95.3982, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 95.8694, aux_3.loss_ce: 0.0926, aux_3.acc_seg: 95.2300, loss: 0.7013
2023-03-29 22:41:55,651 - mmseg - INFO - Iter [9250/10000]	lr: 9.738e-04, eta: 0:15:45, time: 1.504, data_time: 0.223, memory: 9073, decode.loss_ce: 0.0688, decode.acc_seg: 96.0952, aux_0.loss_ce: 0.0721, aux_0.acc_seg: 95.9793, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.3741, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 95.9131, aux_3.loss_ce: 0.0926, aux_3.acc_seg: 95.2034, loss: 0.7009
2023-03-29 22:43:11,461 - mmseg - INFO - Iter [9300/10000]	lr: 9.153e-04, eta: 0:14:43, time: 1.516, data_time: 0.240, memory: 9073, decode.loss_ce: 0.0682, decode.acc_seg: 96.1760, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 96.0538, aux_1.loss_ce: 0.0819, aux_1.acc_seg: 95.4712, aux_2.loss_ce: 0.1242, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 95.8743, aux_3.loss_ce: 0.0924, aux_3.acc_seg: 95.2859, loss: 0.6985
2023-03-29 22:44:30,092 - mmseg - INFO - Iter [9350/10000]	lr: 8.564e-04, eta: 0:13:41, time: 1.573, data_time: 0.298, memory: 9073, decode.loss_ce: 0.0669, decode.acc_seg: 96.1929, aux_0.loss_ce: 0.0706, aux_0.acc_seg: 96.0737, aux_1.loss_ce: 0.0809, aux_1.acc_seg: 95.4996, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2597, aux_2.acc_seg: 95.8948, aux_3.loss_ce: 0.0910, aux_3.acc_seg: 95.3068, loss: 0.6932
2023-03-29 22:45:44,792 - mmseg - INFO - Iter [9400/10000]	lr: 7.971e-04, eta: 0:12:39, time: 1.494, data_time: 0.220, memory: 9073, decode.loss_ce: 0.0686, decode.acc_seg: 96.1252, aux_0.loss_ce: 0.0727, aux_0.acc_seg: 95.9913, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.3964, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.8656, aux_3.loss_ce: 0.0926, aux_3.acc_seg: 95.2351, loss: 0.7033
2023-03-29 22:46:59,852 - mmseg - INFO - Iter [9450/10000]	lr: 7.372e-04, eta: 0:11:36, time: 1.501, data_time: 0.225, memory: 9073, decode.loss_ce: 0.0676, decode.acc_seg: 96.1623, aux_0.loss_ce: 0.0702, aux_0.acc_seg: 96.0517, aux_1.loss_ce: 0.0819, aux_1.acc_seg: 95.4569, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 95.8371, aux_3.loss_ce: 0.0909, aux_3.acc_seg: 95.2893, loss: 0.6947
2023-03-29 22:48:20,413 - mmseg - INFO - Iter [9500/10000]	lr: 6.768e-04, eta: 0:10:34, time: 1.611, data_time: 0.312, memory: 9073, decode.loss_ce: 0.0683, decode.acc_seg: 96.1527, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 96.0282, aux_1.loss_ce: 0.0826, aux_1.acc_seg: 95.4334, aux_2.loss_ce: 0.1234, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 95.9171, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.2685, loss: 0.6979
2023-03-29 22:49:35,174 - mmseg - INFO - Iter [9550/10000]	lr: 6.158e-04, eta: 0:09:31, time: 1.495, data_time: 0.222, memory: 9073, decode.loss_ce: 0.0684, decode.acc_seg: 96.1136, aux_0.loss_ce: 0.0718, aux_0.acc_seg: 95.9904, aux_1.loss_ce: 0.0827, aux_1.acc_seg: 95.4104, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2601, aux_2.acc_seg: 95.8181, aux_3.loss_ce: 0.0919, aux_3.acc_seg: 95.2369, loss: 0.7003
2023-03-29 22:50:49,865 - mmseg - INFO - Iter [9600/10000]	lr: 5.541e-04, eta: 0:08:28, time: 1.494, data_time: 0.220, memory: 9073, decode.loss_ce: 0.0694, decode.acc_seg: 96.1626, aux_0.loss_ce: 0.0719, aux_0.acc_seg: 96.0585, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.4710, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2598, aux_2.acc_seg: 95.8913, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.2782, loss: 0.7016
2023-03-29 22:52:08,950 - mmseg - INFO - Iter [9650/10000]	lr: 4.916e-04, eta: 0:07:25, time: 1.582, data_time: 0.292, memory: 9073, decode.loss_ce: 0.0670, decode.acc_seg: 96.2351, aux_0.loss_ce: 0.0696, aux_0.acc_seg: 96.1115, aux_1.loss_ce: 0.0809, aux_1.acc_seg: 95.5211, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 95.8819, aux_3.loss_ce: 0.0903, aux_3.acc_seg: 95.3506, loss: 0.6907
2023-03-29 22:53:23,413 - mmseg - INFO - Iter [9700/10000]	lr: 4.282e-04, eta: 0:06:22, time: 1.489, data_time: 0.222, memory: 9073, decode.loss_ce: 0.0681, decode.acc_seg: 96.1451, aux_0.loss_ce: 0.0721, aux_0.acc_seg: 96.0229, aux_1.loss_ce: 0.0828, aux_1.acc_seg: 95.4146, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2602, aux_2.acc_seg: 95.8377, aux_3.loss_ce: 0.0914, aux_3.acc_seg: 95.2549, loss: 0.6997
2023-03-29 22:54:38,057 - mmseg - INFO - Iter [9750/10000]	lr: 3.638e-04, eta: 0:05:18, time: 1.493, data_time: 0.217, memory: 9073, decode.loss_ce: 0.0685, decode.acc_seg: 96.1154, aux_0.loss_ce: 0.0724, aux_0.acc_seg: 95.9807, aux_1.loss_ce: 0.0832, aux_1.acc_seg: 95.3982, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2600, aux_2.acc_seg: 95.8143, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.2313, loss: 0.7012
2023-03-29 22:55:55,706 - mmseg - INFO - Iter [9800/10000]	lr: 2.981e-04, eta: 0:04:15, time: 1.553, data_time: 0.277, memory: 9073, decode.loss_ce: 0.0681, decode.acc_seg: 96.1323, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 96.0232, aux_1.loss_ce: 0.0824, aux_1.acc_seg: 95.4294, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2597, aux_2.acc_seg: 95.8843, aux_3.loss_ce: 0.0913, aux_3.acc_seg: 95.2516, loss: 0.6971
2023-03-29 22:57:11,216 - mmseg - INFO - Iter [9850/10000]	lr: 2.306e-04, eta: 0:03:11, time: 1.510, data_time: 0.236, memory: 9073, decode.loss_ce: 0.0673, decode.acc_seg: 96.1934, aux_0.loss_ce: 0.0711, aux_0.acc_seg: 96.0632, aux_1.loss_ce: 0.0814, aux_1.acc_seg: 95.4663, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2592, aux_2.acc_seg: 95.8829, aux_3.loss_ce: 0.0905, aux_3.acc_seg: 95.2997, loss: 0.6933
2023-03-29 22:58:28,240 - mmseg - INFO - Iter [9900/10000]	lr: 1.609e-04, eta: 0:02:07, time: 1.540, data_time: 0.269, memory: 9073, decode.loss_ce: 0.0691, decode.acc_seg: 96.1835, aux_0.loss_ce: 0.0724, aux_0.acc_seg: 96.0606, aux_1.loss_ce: 0.0830, aux_1.acc_seg: 95.4708, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2619, aux_2.acc_seg: 95.8627, aux_3.loss_ce: 0.0919, aux_3.acc_seg: 95.3125, loss: 0.7038
2023-03-29 22:59:48,272 - mmseg - INFO - Iter [9950/10000]	lr: 8.745e-05, eta: 0:01:04, time: 1.601, data_time: 0.307, memory: 9073, decode.loss_ce: 0.0668, decode.acc_seg: 96.2027, aux_0.loss_ce: 0.0709, aux_0.acc_seg: 96.0771, aux_1.loss_ce: 0.0820, aux_1.acc_seg: 95.4690, aux_2.loss_ce: 0.1234, aux_2.loss_dice: 0.2592, aux_2.acc_seg: 95.8881, aux_3.loss_ce: 0.0899, aux_3.acc_seg: 95.3200, loss: 0.6922
2023-03-29 23:01:03,026 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-03-29 23:01:07,366 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 23:01:07,366 - mmseg - INFO - Iter [10000/10000]	lr: 3.512e-06, eta: 0:00:00, time: 1.582, data_time: 0.220, memory: 9073, decode.loss_ce: 0.0672, decode.acc_seg: 96.1774, aux_0.loss_ce: 0.0713, aux_0.acc_seg: 96.0470, aux_1.loss_ce: 0.0826, aux_1.acc_seg: 95.4712, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2590, aux_2.acc_seg: 95.8543, aux_3.loss_ce: 0.0903, aux_3.acc_seg: 95.3167, loss: 0.6943
2023-03-29 23:01:11,036 - mmseg - INFO - per class results:
2023-03-29 23:01:11,037 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 84.01 | 90.66 |
|   Building  | 91.54 | 93.45 |
|     Car     | 92.65 | 95.37 |
| Column_Pole | 15.29 | 18.04 |
|    Fence    | 78.81 | 91.27 |
|  Pedestrian | 61.55 | 81.41 |
|     Road    | 97.44 | 98.31 |
|   Sidewalk  | 91.57 | 97.24 |
|  SignSymbol |  0.02 |  0.02 |
|     Sky     | 93.67 | 96.41 |
|     Tree    | 89.77 | 98.26 |
+-------------+-------+-------+
2023-03-29 23:01:11,037 - mmseg - INFO - Summary:
2023-03-29 23:01:11,037 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.62 | 72.39 | 78.22 |
+-------+-------+-------+
2023-03-29 23:01:11,038 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 23:01:11,038 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9562, mIoU: 0.7239, mAcc: 0.7822, IoU.Bicyclist: 0.8401, IoU.Building: 0.9154, IoU.Car: 0.9265, IoU.Column_Pole: 0.1529, IoU.Fence: 0.7881, IoU.Pedestrian: 0.6155, IoU.Road: 0.9744, IoU.Sidewalk: 0.9157, IoU.SignSymbol: 0.0002, IoU.Sky: 0.9367, IoU.Tree: 0.8977, Acc.Bicyclist: 0.9066, Acc.Building: 0.9345, Acc.Car: 0.9537, Acc.Column_Pole: 0.1804, Acc.Fence: 0.9127, Acc.Pedestrian: 0.8141, Acc.Road: 0.9831, Acc.Sidewalk: 0.9724, Acc.SignSymbol: 0.0002, Acc.Sky: 0.9641, Acc.Tree: 0.9826
