2023-03-29 14:42:10,810 - mmseg - INFO - Multi-processing start method is `None`
2023-03-29 14:42:10,889 - mmseg - INFO - OpenCV num_threads is `96
2023-03-29 14:42:10,890 - mmseg - INFO - OMP num threads is 1
2023-03-29 14:42:11,049 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+792c24a
------------------------------------------------------------

2023-03-29 14:42:11,050 - mmseg - INFO - Distributed training: True
2023-03-29 14:42:12,150 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1035, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=13,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='CSC',
        CLASSES=None),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=10000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CamVidDataset'
data_root = 'data/CamVid/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (720, 960)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 720), ratio_range=(0.5, 2.5)),
    dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 720),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=12,
    workers_per_gpu=4,
    train=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='train',
        ann_dir='train_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(2048, 720), ratio_range=(0.5, 2.5)),
            dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.01,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            text_encoder=dict(lr_mult=0.0, decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=200,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/stdc1-csctext_2x12_720x960_10k_camvid'
gpu_ids = range(0, 2)
auto_resume = False

2023-03-29 14:42:14,982 - mmseg - INFO - Set random seed to 849823780, deterministic: False
2023-03-29 14:42:14,988 - mmseg - INFO - Loaded 367 images
2023-03-29 14:42:16,811 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-03-29 14:42:18,681 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.contexts - torch.Size([11, 8, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.text_encoder.positional_embedding - torch.Size([13, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.text_projection - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.token_embedding.weight - torch.Size([49408, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1035, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1035, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-03-29 14:42:18,792 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1035, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1035, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-03-29 14:42:18,953 - mmseg - INFO - Loaded 101 images
2023-03-29 14:42:18,954 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1-csctext_2x12_720x960_10k_camvid
2023-03-29 14:42:18,954 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-03-29 14:42:18,955 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-03-29 14:42:18,955 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1-csctext_2x12_720x960_10k_camvid by HardDiskBackend.
2023-03-29 14:44:19,125 - mmseg - INFO - Iter [50/10000]	lr: 2.439e-03, eta: 6:36:47, time: 2.393, data_time: 1.213, memory: 9072, decode.loss_ce: 1.9148, decode.acc_seg: 32.2460, aux_0.loss_ce: 1.7795, aux_0.acc_seg: 24.5787, aux_1.loss_ce: 1.7641, aux_1.acc_seg: 21.1196, aux_2.loss_ce: 0.5522, aux_2.loss_dice: 0.4839, aux_2.acc_seg: 78.3319, aux_3.loss_ce: 1.8793, aux_3.acc_seg: 17.1907, loss: 8.3738
2023-03-29 14:45:26,351 - mmseg - INFO - Iter [100/10000]	lr: 4.906e-03, eta: 5:08:19, time: 1.344, data_time: 0.290, memory: 9072, decode.loss_ce: 0.9929, decode.acc_seg: 64.4877, aux_0.loss_ce: 0.9441, aux_0.acc_seg: 67.3204, aux_1.loss_ce: 0.9855, aux_1.acc_seg: 64.7879, aux_2.loss_ce: 0.2554, aux_2.loss_dice: 0.4551, aux_2.acc_seg: 95.8094, aux_3.loss_ce: 1.3423, aux_3.acc_seg: 68.8354, loss: 4.9753
2023-03-29 14:46:30,645 - mmseg - INFO - Iter [150/10000]	lr: 7.350e-03, eta: 4:34:52, time: 1.286, data_time: 0.281, memory: 9072, decode.loss_ce: 0.5924, decode.acc_seg: 78.1112, aux_0.loss_ce: 0.5070, aux_0.acc_seg: 81.0662, aux_1.loss_ce: 0.5299, aux_1.acc_seg: 81.0033, aux_2.loss_ce: 0.2140, aux_2.loss_dice: 0.4043, aux_2.acc_seg: 95.8624, aux_3.loss_ce: 0.7750, aux_3.acc_seg: 82.5752, loss: 3.0227
2023-03-29 14:47:38,632 - mmseg - INFO - Iter [200/10000]	lr: 9.772e-03, eta: 4:20:37, time: 1.360, data_time: 0.370, memory: 9072, decode.loss_ce: 0.3868, decode.acc_seg: 84.8698, aux_0.loss_ce: 0.3755, aux_0.acc_seg: 85.6039, aux_1.loss_ce: 0.3959, aux_1.acc_seg: 84.8402, aux_2.loss_ce: 0.1839, aux_2.loss_dice: 0.3556, aux_2.acc_seg: 95.7755, aux_3.loss_ce: 0.5367, aux_3.acc_seg: 84.8400, loss: 2.2343
2023-03-29 14:48:45,824 - mmseg - INFO - Iter [250/10000]	lr: 9.776e-03, eta: 4:11:07, time: 1.344, data_time: 0.316, memory: 9072, decode.loss_ce: 0.3188, decode.acc_seg: 87.1135, aux_0.loss_ce: 0.3191, aux_0.acc_seg: 87.3953, aux_1.loss_ce: 0.3399, aux_1.acc_seg: 86.8886, aux_2.loss_ce: 0.1624, aux_2.loss_dice: 0.3273, aux_2.acc_seg: 95.7895, aux_3.loss_ce: 0.4462, aux_3.acc_seg: 86.8968, loss: 1.9138
2023-03-29 14:49:50,373 - mmseg - INFO - Iter [300/10000]	lr: 9.731e-03, eta: 4:02:58, time: 1.291, data_time: 0.302, memory: 9072, decode.loss_ce: 0.2651, decode.acc_seg: 88.7877, aux_0.loss_ce: 0.2714, aux_0.acc_seg: 88.5711, aux_1.loss_ce: 0.2876, aux_1.acc_seg: 88.2846, aux_2.loss_ce: 0.1503, aux_2.loss_dice: 0.3159, aux_2.acc_seg: 95.7806, aux_3.loss_ce: 0.3740, aux_3.acc_seg: 88.4166, loss: 1.6643
2023-03-29 14:51:02,432 - mmseg - INFO - Iter [350/10000]	lr: 9.685e-03, eta: 4:00:18, time: 1.441, data_time: 0.406, memory: 9072, decode.loss_ce: 0.2397, decode.acc_seg: 89.6740, aux_0.loss_ce: 0.2479, aux_0.acc_seg: 89.5036, aux_1.loss_ce: 0.2651, aux_1.acc_seg: 89.0778, aux_2.loss_ce: 0.1481, aux_2.loss_dice: 0.3114, aux_2.acc_seg: 95.6063, aux_3.loss_ce: 0.3348, aux_3.acc_seg: 89.3415, loss: 1.5470
2023-03-29 14:51:54,200 - mmseg - INFO - Iter [400/10000]	lr: 9.640e-03, eta: 3:49:53, time: 1.035, data_time: 0.260, memory: 9072, decode.loss_ce: 0.2180, decode.acc_seg: 90.3879, aux_0.loss_ce: 0.2258, aux_0.acc_seg: 90.3327, aux_1.loss_ce: 0.2404, aux_1.acc_seg: 89.8833, aux_2.loss_ce: 0.1438, aux_2.loss_dice: 0.3053, aux_2.acc_seg: 95.6932, aux_3.loss_ce: 0.3036, aux_3.acc_seg: 90.0496, loss: 1.4368
2023-03-29 14:52:49,498 - mmseg - INFO - Iter [450/10000]	lr: 9.595e-03, eta: 3:42:50, time: 1.106, data_time: 0.281, memory: 9072, decode.loss_ce: 0.2078, decode.acc_seg: 90.8848, aux_0.loss_ce: 0.2124, aux_0.acc_seg: 90.6922, aux_1.loss_ce: 0.2280, aux_1.acc_seg: 90.3310, aux_2.loss_ce: 0.1421, aux_2.loss_dice: 0.3045, aux_2.acc_seg: 95.6936, aux_3.loss_ce: 0.2878, aux_3.acc_seg: 90.4189, loss: 1.3826
2023-03-29 14:54:00,025 - mmseg - INFO - Iter [500/10000]	lr: 9.550e-03, eta: 3:41:50, time: 1.411, data_time: 0.397, memory: 9072, decode.loss_ce: 0.1983, decode.acc_seg: 91.1495, aux_0.loss_ce: 0.2039, aux_0.acc_seg: 91.0413, aux_1.loss_ce: 0.2227, aux_1.acc_seg: 90.4317, aux_2.loss_ce: 0.1415, aux_2.loss_dice: 0.3014, aux_2.acc_seg: 95.7426, aux_3.loss_ce: 0.2729, aux_3.acc_seg: 90.6698, loss: 1.3408
2023-03-29 14:55:01,800 - mmseg - INFO - Iter [550/10000]	lr: 9.505e-03, eta: 3:38:17, time: 1.236, data_time: 0.277, memory: 9072, decode.loss_ce: 0.1844, decode.acc_seg: 91.6140, aux_0.loss_ce: 0.1940, aux_0.acc_seg: 91.4196, aux_1.loss_ce: 0.2103, aux_1.acc_seg: 90.7988, aux_2.loss_ce: 0.1411, aux_2.loss_dice: 0.2999, aux_2.acc_seg: 95.7117, aux_3.loss_ce: 0.2578, aux_3.acc_seg: 90.9637, loss: 1.2876
2023-03-29 14:56:06,864 - mmseg - INFO - Iter [600/10000]	lr: 9.459e-03, eta: 3:36:02, time: 1.301, data_time: 0.289, memory: 9072, decode.loss_ce: 0.1779, decode.acc_seg: 92.0302, aux_0.loss_ce: 0.1854, aux_0.acc_seg: 91.8141, aux_1.loss_ce: 0.2023, aux_1.acc_seg: 91.2336, aux_2.loss_ce: 0.1390, aux_2.loss_dice: 0.2955, aux_2.acc_seg: 95.7271, aux_3.loss_ce: 0.2495, aux_3.acc_seg: 91.3313, loss: 1.2496
2023-03-29 14:57:14,486 - mmseg - INFO - Iter [650/10000]	lr: 9.414e-03, eta: 3:34:34, time: 1.352, data_time: 0.354, memory: 9072, decode.loss_ce: 0.1680, decode.acc_seg: 92.1870, aux_0.loss_ce: 0.1772, aux_0.acc_seg: 91.8830, aux_1.loss_ce: 0.1930, aux_1.acc_seg: 91.4004, aux_2.loss_ce: 0.1380, aux_2.loss_dice: 0.2942, aux_2.acc_seg: 95.7899, aux_3.loss_ce: 0.2380, aux_3.acc_seg: 91.4631, loss: 1.2084
2023-03-29 14:58:19,496 - mmseg - INFO - Iter [700/10000]	lr: 9.369e-03, eta: 3:32:34, time: 1.300, data_time: 0.280, memory: 9072, decode.loss_ce: 0.1586, decode.acc_seg: 92.5509, aux_0.loss_ce: 0.1682, aux_0.acc_seg: 92.2200, aux_1.loss_ce: 0.1836, aux_1.acc_seg: 91.7880, aux_2.loss_ce: 0.1371, aux_2.loss_dice: 0.2939, aux_2.acc_seg: 95.8203, aux_3.loss_ce: 0.2265, aux_3.acc_seg: 91.8057, loss: 1.1679
2023-03-29 14:59:22,036 - mmseg - INFO - Iter [750/10000]	lr: 9.323e-03, eta: 3:30:11, time: 1.251, data_time: 0.282, memory: 9072, decode.loss_ce: 0.1675, decode.acc_seg: 92.3276, aux_0.loss_ce: 0.1770, aux_0.acc_seg: 92.0009, aux_1.loss_ce: 0.1926, aux_1.acc_seg: 91.6137, aux_2.loss_ce: 0.1371, aux_2.loss_dice: 0.2932, aux_2.acc_seg: 95.8125, aux_3.loss_ce: 0.2359, aux_3.acc_seg: 91.5450, loss: 1.2034
2023-03-29 15:00:28,080 - mmseg - INFO - Iter [800/10000]	lr: 9.278e-03, eta: 3:28:38, time: 1.321, data_time: 0.349, memory: 9072, decode.loss_ce: 0.1485, decode.acc_seg: 92.9992, aux_0.loss_ce: 0.1572, aux_0.acc_seg: 92.6491, aux_1.loss_ce: 0.1732, aux_1.acc_seg: 92.2269, aux_2.loss_ce: 0.1385, aux_2.loss_dice: 0.2907, aux_2.acc_seg: 95.6757, aux_3.loss_ce: 0.2145, aux_3.acc_seg: 92.1742, loss: 1.1226
2023-03-29 15:01:36,343 - mmseg - INFO - Iter [850/10000]	lr: 9.233e-03, eta: 3:27:33, time: 1.365, data_time: 0.297, memory: 9072, decode.loss_ce: 0.1443, decode.acc_seg: 93.0335, aux_0.loss_ce: 0.1537, aux_0.acc_seg: 92.7326, aux_1.loss_ce: 0.1682, aux_1.acc_seg: 92.2750, aux_2.loss_ce: 0.1350, aux_2.loss_dice: 0.2891, aux_2.acc_seg: 95.8623, aux_3.loss_ce: 0.2102, aux_3.acc_seg: 92.2158, loss: 1.1005
2023-03-29 15:02:38,472 - mmseg - INFO - Iter [900/10000]	lr: 9.187e-03, eta: 3:25:25, time: 1.242, data_time: 0.282, memory: 9072, decode.loss_ce: 0.1467, decode.acc_seg: 92.9073, aux_0.loss_ce: 0.1554, aux_0.acc_seg: 92.6100, aux_1.loss_ce: 0.1681, aux_1.acc_seg: 92.1499, aux_2.loss_ce: 0.1358, aux_2.loss_dice: 0.2887, aux_2.acc_seg: 95.8299, aux_3.loss_ce: 0.2103, aux_3.acc_seg: 92.0117, loss: 1.1049
2023-03-29 15:03:44,184 - mmseg - INFO - Iter [950/10000]	lr: 9.142e-03, eta: 3:23:58, time: 1.314, data_time: 0.351, memory: 9072, decode.loss_ce: 0.1353, decode.acc_seg: 93.4089, aux_0.loss_ce: 0.1448, aux_0.acc_seg: 93.0469, aux_1.loss_ce: 0.1595, aux_1.acc_seg: 92.6148, aux_2.loss_ce: 0.1365, aux_2.loss_dice: 0.2868, aux_2.acc_seg: 95.7837, aux_3.loss_ce: 0.1987, aux_3.acc_seg: 92.4916, loss: 1.0616
2023-03-29 15:04:49,687 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-03-29 15:04:51,530 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 15:04:51,530 - mmseg - INFO - Iter [1000/10000]	lr: 9.096e-03, eta: 3:22:48, time: 1.347, data_time: 0.278, memory: 9072, decode.loss_ce: 0.1343, decode.acc_seg: 93.3974, aux_0.loss_ce: 0.1446, aux_0.acc_seg: 93.0648, aux_1.loss_ce: 0.1579, aux_1.acc_seg: 92.5844, aux_2.loss_ce: 0.1360, aux_2.loss_dice: 0.2857, aux_2.acc_seg: 95.7784, aux_3.loss_ce: 0.1965, aux_3.acc_seg: 92.4962, loss: 1.0550
2023-03-29 15:05:39,083 - mmseg - INFO - per class results:
2023-03-29 15:05:39,084 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 16.51 | 16.67 |
|   Building  | 85.74 |  87.4 |
|     Car     | 81.46 |  93.6 |
| Column_Pole |  4.65 |  6.44 |
|    Fence    | 63.18 | 97.91 |
|  Pedestrian | 18.64 | 63.42 |
|     Road    | 96.08 | 97.72 |
|   Sidewalk  | 85.53 | 96.68 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.35 | 96.04 |
|     Tree    | 88.69 | 97.35 |
+-------------+-------+-------+
2023-03-29 15:05:39,084 - mmseg - INFO - Summary:
2023-03-29 15:05:39,085 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 91.87 | 57.62 | 68.47 |
+-------+-------+-------+
2023-03-29 15:05:39,085 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 15:05:39,085 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9187, mIoU: 0.5762, mAcc: 0.6847, IoU.Bicyclist: 0.1651, IoU.Building: 0.8574, IoU.Car: 0.8146, IoU.Column_Pole: 0.0465, IoU.Fence: 0.6318, IoU.Pedestrian: 0.1864, IoU.Road: 0.9608, IoU.Sidewalk: 0.8553, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9335, IoU.Tree: 0.8869, Acc.Bicyclist: 0.1667, Acc.Building: 0.8740, Acc.Car: 0.9360, Acc.Column_Pole: 0.0644, Acc.Fence: 0.9791, Acc.Pedestrian: 0.6342, Acc.Road: 0.9772, Acc.Sidewalk: 0.9668, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9604, Acc.Tree: 0.9735
2023-03-29 15:06:43,743 - mmseg - INFO - Iter [1050/10000]	lr: 9.051e-03, eta: 3:28:00, time: 2.244, data_time: 1.227, memory: 9072, decode.loss_ce: 0.1298, decode.acc_seg: 93.6130, aux_0.loss_ce: 0.1405, aux_0.acc_seg: 93.3068, aux_1.loss_ce: 0.1525, aux_1.acc_seg: 92.8220, aux_2.loss_ce: 0.1338, aux_2.loss_dice: 0.2841, aux_2.acc_seg: 95.8716, aux_3.loss_ce: 0.1893, aux_3.acc_seg: 92.7230, loss: 1.0299
2023-03-29 15:07:51,972 - mmseg - INFO - Iter [1100/10000]	lr: 9.005e-03, eta: 3:26:39, time: 1.365, data_time: 0.365, memory: 9072, decode.loss_ce: 0.1251, decode.acc_seg: 93.8464, aux_0.loss_ce: 0.1346, aux_0.acc_seg: 93.5178, aux_1.loss_ce: 0.1476, aux_1.acc_seg: 93.0272, aux_2.loss_ce: 0.1346, aux_2.loss_dice: 0.2833, aux_2.acc_seg: 95.8143, aux_3.loss_ce: 0.1836, aux_3.acc_seg: 92.9195, loss: 1.0088
2023-03-29 15:08:54,524 - mmseg - INFO - Iter [1150/10000]	lr: 8.960e-03, eta: 3:24:34, time: 1.251, data_time: 0.276, memory: 9072, decode.loss_ce: 0.1248, decode.acc_seg: 93.9299, aux_0.loss_ce: 0.1342, aux_0.acc_seg: 93.6100, aux_1.loss_ce: 0.1487, aux_1.acc_seg: 93.0978, aux_2.loss_ce: 0.1353, aux_2.loss_dice: 0.2838, aux_2.acc_seg: 95.7878, aux_3.loss_ce: 0.1859, aux_3.acc_seg: 92.9374, loss: 1.0127
2023-03-29 15:09:57,976 - mmseg - INFO - Iter [1200/10000]	lr: 8.914e-03, eta: 3:22:42, time: 1.269, data_time: 0.264, memory: 9072, decode.loss_ce: 0.1266, decode.acc_seg: 93.8054, aux_0.loss_ce: 0.1356, aux_0.acc_seg: 93.5117, aux_1.loss_ce: 0.1506, aux_1.acc_seg: 92.9783, aux_2.loss_ce: 0.1354, aux_2.loss_dice: 0.2834, aux_2.acc_seg: 95.7809, aux_3.loss_ce: 0.1850, aux_3.acc_seg: 92.9009, loss: 1.0165
2023-03-29 15:11:03,035 - mmseg - INFO - Iter [1250/10000]	lr: 8.869e-03, eta: 3:21:04, time: 1.301, data_time: 0.317, memory: 9072, decode.loss_ce: 0.1199, decode.acc_seg: 94.0779, aux_0.loss_ce: 0.1270, aux_0.acc_seg: 93.8192, aux_1.loss_ce: 0.1409, aux_1.acc_seg: 93.2413, aux_2.loss_ce: 0.1349, aux_2.loss_dice: 0.2811, aux_2.acc_seg: 95.7632, aux_3.loss_ce: 0.1766, aux_3.acc_seg: 93.1480, loss: 0.9804
2023-03-29 15:12:10,299 - mmseg - INFO - Iter [1300/10000]	lr: 8.823e-03, eta: 3:19:44, time: 1.345, data_time: 0.273, memory: 9072, decode.loss_ce: 0.1160, decode.acc_seg: 94.2120, aux_0.loss_ce: 0.1242, aux_0.acc_seg: 93.9268, aux_1.loss_ce: 0.1386, aux_1.acc_seg: 93.3348, aux_2.loss_ce: 0.1345, aux_2.loss_dice: 0.2799, aux_2.acc_seg: 95.7251, aux_3.loss_ce: 0.1724, aux_3.acc_seg: 93.2371, loss: 0.9656
2023-03-29 15:13:13,011 - mmseg - INFO - Iter [1350/10000]	lr: 8.777e-03, eta: 3:17:56, time: 1.254, data_time: 0.281, memory: 9072, decode.loss_ce: 0.1164, decode.acc_seg: 94.2140, aux_0.loss_ce: 0.1244, aux_0.acc_seg: 93.9224, aux_1.loss_ce: 0.1398, aux_1.acc_seg: 93.3343, aux_2.loss_ce: 0.1344, aux_2.loss_dice: 0.2801, aux_2.acc_seg: 95.7846, aux_3.loss_ce: 0.1735, aux_3.acc_seg: 93.2338, loss: 0.9686
2023-03-29 15:14:19,339 - mmseg - INFO - Iter [1400/10000]	lr: 8.732e-03, eta: 3:16:33, time: 1.327, data_time: 0.359, memory: 9072, decode.loss_ce: 0.1153, decode.acc_seg: 94.2297, aux_0.loss_ce: 0.1223, aux_0.acc_seg: 93.9633, aux_1.loss_ce: 0.1363, aux_1.acc_seg: 93.3285, aux_2.loss_ce: 0.1332, aux_2.loss_dice: 0.2790, aux_2.acc_seg: 95.7926, aux_3.loss_ce: 0.1713, aux_3.acc_seg: 93.2548, loss: 0.9574
2023-03-29 15:15:26,394 - mmseg - INFO - Iter [1450/10000]	lr: 8.686e-03, eta: 3:15:15, time: 1.341, data_time: 0.273, memory: 9072, decode.loss_ce: 0.1160, decode.acc_seg: 94.2119, aux_0.loss_ce: 0.1224, aux_0.acc_seg: 93.9385, aux_1.loss_ce: 0.1374, aux_1.acc_seg: 93.3753, aux_2.loss_ce: 0.1319, aux_2.loss_dice: 0.2783, aux_2.acc_seg: 95.8652, aux_3.loss_ce: 0.1699, aux_3.acc_seg: 93.2716, loss: 0.9559
2023-03-29 15:16:29,593 - mmseg - INFO - Iter [1500/10000]	lr: 8.640e-03, eta: 3:13:37, time: 1.264, data_time: 0.295, memory: 9072, decode.loss_ce: 0.1102, decode.acc_seg: 94.3317, aux_0.loss_ce: 0.1180, aux_0.acc_seg: 94.0612, aux_1.loss_ce: 0.1304, aux_1.acc_seg: 93.4986, aux_2.loss_ce: 0.1320, aux_2.loss_dice: 0.2775, aux_2.acc_seg: 95.8399, aux_3.loss_ce: 0.1648, aux_3.acc_seg: 93.3909, loss: 0.9329
2023-03-29 15:17:36,192 - mmseg - INFO - Iter [1550/10000]	lr: 8.595e-03, eta: 3:12:19, time: 1.332, data_time: 0.352, memory: 9072, decode.loss_ce: 0.1081, decode.acc_seg: 94.4335, aux_0.loss_ce: 0.1152, aux_0.acc_seg: 94.1591, aux_1.loss_ce: 0.1284, aux_1.acc_seg: 93.6127, aux_2.loss_ce: 0.1309, aux_2.loss_dice: 0.2755, aux_2.acc_seg: 95.8929, aux_3.loss_ce: 0.1598, aux_3.acc_seg: 93.5288, loss: 0.9179
2023-03-29 15:18:41,710 - mmseg - INFO - Iter [1600/10000]	lr: 8.549e-03, eta: 3:10:56, time: 1.310, data_time: 0.283, memory: 9072, decode.loss_ce: 0.1091, decode.acc_seg: 94.4727, aux_0.loss_ce: 0.1160, aux_0.acc_seg: 94.2462, aux_1.loss_ce: 0.1285, aux_1.acc_seg: 93.7102, aux_2.loss_ce: 0.1314, aux_2.loss_dice: 0.2770, aux_2.acc_seg: 95.8650, aux_3.loss_ce: 0.1608, aux_3.acc_seg: 93.5827, loss: 0.9227
2023-03-29 15:19:45,342 - mmseg - INFO - Iter [1650/10000]	lr: 8.503e-03, eta: 3:09:25, time: 1.273, data_time: 0.278, memory: 9072, decode.loss_ce: 0.1073, decode.acc_seg: 94.4400, aux_0.loss_ce: 0.1136, aux_0.acc_seg: 94.1998, aux_1.loss_ce: 0.1269, aux_1.acc_seg: 93.6171, aux_2.loss_ce: 0.1314, aux_2.loss_dice: 0.2761, aux_2.acc_seg: 95.8419, aux_3.loss_ce: 0.1571, aux_3.acc_seg: 93.5756, loss: 0.9124
2023-03-29 15:20:53,765 - mmseg - INFO - Iter [1700/10000]	lr: 8.457e-03, eta: 3:08:19, time: 1.368, data_time: 0.365, memory: 9072, decode.loss_ce: 0.1062, decode.acc_seg: 94.5651, aux_0.loss_ce: 0.1127, aux_0.acc_seg: 94.3230, aux_1.loss_ce: 0.1257, aux_1.acc_seg: 93.7383, aux_2.loss_ce: 0.1325, aux_2.loss_dice: 0.2760, aux_2.acc_seg: 95.7897, aux_3.loss_ce: 0.1580, aux_3.acc_seg: 93.6629, loss: 0.9111
2023-03-29 15:21:55,758 - mmseg - INFO - Iter [1750/10000]	lr: 8.411e-03, eta: 3:06:42, time: 1.240, data_time: 0.277, memory: 9072, decode.loss_ce: 0.1082, decode.acc_seg: 94.4678, aux_0.loss_ce: 0.1132, aux_0.acc_seg: 94.2369, aux_1.loss_ce: 0.1265, aux_1.acc_seg: 93.6599, aux_2.loss_ce: 0.1302, aux_2.loss_dice: 0.2762, aux_2.acc_seg: 95.8913, aux_3.loss_ce: 0.1585, aux_3.acc_seg: 93.5347, loss: 0.9129
2023-03-29 15:23:00,498 - mmseg - INFO - Iter [1800/10000]	lr: 8.365e-03, eta: 3:05:20, time: 1.295, data_time: 0.282, memory: 9072, decode.loss_ce: 0.1077, decode.acc_seg: 94.5813, aux_0.loss_ce: 0.1126, aux_0.acc_seg: 94.3809, aux_1.loss_ce: 0.1264, aux_1.acc_seg: 93.7882, aux_2.loss_ce: 0.1319, aux_2.loss_dice: 0.2754, aux_2.acc_seg: 95.8284, aux_3.loss_ce: 0.1587, aux_3.acc_seg: 93.6742, loss: 0.9127
2023-03-29 15:24:04,500 - mmseg - INFO - Iter [1850/10000]	lr: 8.320e-03, eta: 3:03:55, time: 1.280, data_time: 0.344, memory: 9072, decode.loss_ce: 0.1062, decode.acc_seg: 94.5321, aux_0.loss_ce: 0.1114, aux_0.acc_seg: 94.3085, aux_1.loss_ce: 0.1255, aux_1.acc_seg: 93.7025, aux_2.loss_ce: 0.1310, aux_2.loss_dice: 0.2746, aux_2.acc_seg: 95.8509, aux_3.loss_ce: 0.1556, aux_3.acc_seg: 93.5969, loss: 0.9043
2023-03-29 15:25:11,870 - mmseg - INFO - Iter [1900/10000]	lr: 8.274e-03, eta: 3:02:46, time: 1.348, data_time: 0.302, memory: 9072, decode.loss_ce: 0.1031, decode.acc_seg: 94.7040, aux_0.loss_ce: 0.1081, aux_0.acc_seg: 94.4766, aux_1.loss_ce: 0.1212, aux_1.acc_seg: 93.9194, aux_2.loss_ce: 0.1304, aux_2.loss_dice: 0.2736, aux_2.acc_seg: 95.8322, aux_3.loss_ce: 0.1512, aux_3.acc_seg: 93.8053, loss: 0.8877
2023-03-29 15:26:14,323 - mmseg - INFO - Iter [1950/10000]	lr: 8.228e-03, eta: 3:01:17, time: 1.249, data_time: 0.285, memory: 9072, decode.loss_ce: 0.1038, decode.acc_seg: 94.7185, aux_0.loss_ce: 0.1106, aux_0.acc_seg: 94.4758, aux_1.loss_ce: 0.1225, aux_1.acc_seg: 93.9226, aux_2.loss_ce: 0.1311, aux_2.loss_dice: 0.2745, aux_2.acc_seg: 95.8293, aux_3.loss_ce: 0.1535, aux_3.acc_seg: 93.7920, loss: 0.8960
2023-03-29 15:27:21,688 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-03-29 15:27:23,640 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 15:27:23,641 - mmseg - INFO - Iter [2000/10000]	lr: 8.182e-03, eta: 3:00:16, time: 1.386, data_time: 0.360, memory: 9072, decode.loss_ce: 0.1035, decode.acc_seg: 94.7487, aux_0.loss_ce: 0.1087, aux_0.acc_seg: 94.5284, aux_1.loss_ce: 0.1222, aux_1.acc_seg: 93.9475, aux_2.loss_ce: 0.1311, aux_2.loss_dice: 0.2752, aux_2.acc_seg: 95.8279, aux_3.loss_ce: 0.1523, aux_3.acc_seg: 93.8268, loss: 0.8930
2023-03-29 15:27:30,255 - mmseg - INFO - per class results:
2023-03-29 15:27:30,256 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 72.07 | 75.43 |
|   Building  | 91.87 | 93.99 |
|     Car     | 89.14 | 95.45 |
| Column_Pole |  6.25 |  6.82 |
|    Fence    | 76.15 | 96.38 |
|  Pedestrian | 43.87 | 71.05 |
|     Road    | 96.88 | 98.24 |
|   Sidewalk  |  89.6 | 96.05 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.51 | 95.89 |
|     Tree    | 91.36 |  98.1 |
+-------------+-------+-------+
2023-03-29 15:27:30,256 - mmseg - INFO - Summary:
2023-03-29 15:27:30,256 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.22 | 68.25 | 75.22 |
+-------+-------+-------+
2023-03-29 15:27:30,257 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 15:27:30,257 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9522, mIoU: 0.6825, mAcc: 0.7522, IoU.Bicyclist: 0.7207, IoU.Building: 0.9187, IoU.Car: 0.8914, IoU.Column_Pole: 0.0625, IoU.Fence: 0.7615, IoU.Pedestrian: 0.4387, IoU.Road: 0.9688, IoU.Sidewalk: 0.8960, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9351, IoU.Tree: 0.9136, Acc.Bicyclist: 0.7543, Acc.Building: 0.9399, Acc.Car: 0.9545, Acc.Column_Pole: 0.0682, Acc.Fence: 0.9638, Acc.Pedestrian: 0.7105, Acc.Road: 0.9824, Acc.Sidewalk: 0.9605, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9589, Acc.Tree: 0.9810
2023-03-29 15:28:32,724 - mmseg - INFO - Iter [2050/10000]	lr: 8.136e-03, eta: 2:59:14, time: 1.382, data_time: 0.410, memory: 9072, decode.loss_ce: 0.0991, decode.acc_seg: 94.7958, aux_0.loss_ce: 0.1057, aux_0.acc_seg: 94.5803, aux_1.loss_ce: 0.1174, aux_1.acc_seg: 94.0166, aux_2.loss_ce: 0.1299, aux_2.loss_dice: 0.2721, aux_2.acc_seg: 95.8602, aux_3.loss_ce: 0.1471, aux_3.acc_seg: 93.8511, loss: 0.8714
2023-03-29 15:29:38,313 - mmseg - INFO - Iter [2100/10000]	lr: 8.090e-03, eta: 2:57:59, time: 1.312, data_time: 0.297, memory: 9072, decode.loss_ce: 0.0999, decode.acc_seg: 94.8087, aux_0.loss_ce: 0.1058, aux_0.acc_seg: 94.5935, aux_1.loss_ce: 0.1182, aux_1.acc_seg: 94.0143, aux_2.loss_ce: 0.1303, aux_2.loss_dice: 0.2735, aux_2.acc_seg: 95.8923, aux_3.loss_ce: 0.1469, aux_3.acc_seg: 93.9057, loss: 0.8746
2023-03-29 15:30:46,877 - mmseg - INFO - Iter [2150/10000]	lr: 8.043e-03, eta: 2:56:55, time: 1.371, data_time: 0.367, memory: 9072, decode.loss_ce: 0.0979, decode.acc_seg: 94.9039, aux_0.loss_ce: 0.1027, aux_0.acc_seg: 94.7003, aux_1.loss_ce: 0.1164, aux_1.acc_seg: 94.0816, aux_2.loss_ce: 0.1310, aux_2.loss_dice: 0.2732, aux_2.acc_seg: 95.8029, aux_3.loss_ce: 0.1444, aux_3.acc_seg: 94.0020, loss: 0.8656
2023-03-29 15:31:48,575 - mmseg - INFO - Iter [2200/10000]	lr: 7.997e-03, eta: 2:55:26, time: 1.234, data_time: 0.272, memory: 9072, decode.loss_ce: 0.0980, decode.acc_seg: 94.8650, aux_0.loss_ce: 0.1029, aux_0.acc_seg: 94.6592, aux_1.loss_ce: 0.1165, aux_1.acc_seg: 94.0661, aux_2.loss_ce: 0.1296, aux_2.loss_dice: 0.2724, aux_2.acc_seg: 95.8740, aux_3.loss_ce: 0.1438, aux_3.acc_seg: 93.9611, loss: 0.8632
2023-03-29 15:32:53,289 - mmseg - INFO - Iter [2250/10000]	lr: 7.951e-03, eta: 2:54:09, time: 1.294, data_time: 0.280, memory: 9072, decode.loss_ce: 0.0993, decode.acc_seg: 94.8451, aux_0.loss_ce: 0.1041, aux_0.acc_seg: 94.6394, aux_1.loss_ce: 0.1167, aux_1.acc_seg: 94.0368, aux_2.loss_ce: 0.1300, aux_2.loss_dice: 0.2725, aux_2.acc_seg: 95.8431, aux_3.loss_ce: 0.1453, aux_3.acc_seg: 93.9117, loss: 0.8681
2023-03-29 15:33:59,829 - mmseg - INFO - Iter [2300/10000]	lr: 7.905e-03, eta: 2:52:59, time: 1.331, data_time: 0.326, memory: 9072, decode.loss_ce: 0.0955, decode.acc_seg: 95.0271, aux_0.loss_ce: 0.1015, aux_0.acc_seg: 94.8139, aux_1.loss_ce: 0.1140, aux_1.acc_seg: 94.2569, aux_2.loss_ce: 0.1299, aux_2.loss_dice: 0.2715, aux_2.acc_seg: 95.8337, aux_3.loss_ce: 0.1413, aux_3.acc_seg: 94.1368, loss: 0.8537
2023-03-29 15:35:05,867 - mmseg - INFO - Iter [2350/10000]	lr: 7.859e-03, eta: 2:51:47, time: 1.321, data_time: 0.274, memory: 9072, decode.loss_ce: 0.0970, decode.acc_seg: 94.9562, aux_0.loss_ce: 0.1033, aux_0.acc_seg: 94.7327, aux_1.loss_ce: 0.1150, aux_1.acc_seg: 94.1590, aux_2.loss_ce: 0.1315, aux_2.loss_dice: 0.2724, aux_2.acc_seg: 95.7566, aux_3.loss_ce: 0.1416, aux_3.acc_seg: 94.0942, loss: 0.8609
2023-03-29 15:36:08,713 - mmseg - INFO - Iter [2400/10000]	lr: 7.813e-03, eta: 2:50:25, time: 1.257, data_time: 0.292, memory: 9072, decode.loss_ce: 0.0937, decode.acc_seg: 95.0710, aux_0.loss_ce: 0.0987, aux_0.acc_seg: 94.8921, aux_1.loss_ce: 0.1113, aux_1.acc_seg: 94.2848, aux_2.loss_ce: 0.1288, aux_2.loss_dice: 0.2713, aux_2.acc_seg: 95.8717, aux_3.loss_ce: 0.1384, aux_3.acc_seg: 94.1554, loss: 0.8421
2023-03-29 15:37:15,458 - mmseg - INFO - Iter [2450/10000]	lr: 7.766e-03, eta: 2:49:16, time: 1.335, data_time: 0.359, memory: 9072, decode.loss_ce: 0.0959, decode.acc_seg: 94.9951, aux_0.loss_ce: 0.1011, aux_0.acc_seg: 94.7940, aux_1.loss_ce: 0.1129, aux_1.acc_seg: 94.2118, aux_2.loss_ce: 0.1301, aux_2.loss_dice: 0.2714, aux_2.acc_seg: 95.8027, aux_3.loss_ce: 0.1395, aux_3.acc_seg: 94.1019, loss: 0.8509
2023-03-29 15:38:23,369 - mmseg - INFO - Iter [2500/10000]	lr: 7.720e-03, eta: 2:48:11, time: 1.359, data_time: 0.291, memory: 9072, decode.loss_ce: 0.0929, decode.acc_seg: 95.1230, aux_0.loss_ce: 0.0990, aux_0.acc_seg: 94.9050, aux_1.loss_ce: 0.1102, aux_1.acc_seg: 94.3429, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2705, aux_2.acc_seg: 95.8785, aux_3.loss_ce: 0.1368, aux_3.acc_seg: 94.2161, loss: 0.8381
2023-03-29 15:39:25,526 - mmseg - INFO - Iter [2550/10000]	lr: 7.674e-03, eta: 2:46:49, time: 1.243, data_time: 0.285, memory: 9072, decode.loss_ce: 0.0949, decode.acc_seg: 95.0124, aux_0.loss_ce: 0.1003, aux_0.acc_seg: 94.8146, aux_1.loss_ce: 0.1119, aux_1.acc_seg: 94.2523, aux_2.loss_ce: 0.1300, aux_2.loss_dice: 0.2717, aux_2.acc_seg: 95.8414, aux_3.loss_ce: 0.1382, aux_3.acc_seg: 94.1419, loss: 0.8470
2023-03-29 15:40:33,784 - mmseg - INFO - Iter [2600/10000]	lr: 7.627e-03, eta: 2:45:45, time: 1.365, data_time: 0.353, memory: 9072, decode.loss_ce: 0.0946, decode.acc_seg: 94.9539, aux_0.loss_ce: 0.1006, aux_0.acc_seg: 94.7265, aux_1.loss_ce: 0.1115, aux_1.acc_seg: 94.1599, aux_2.loss_ce: 0.1290, aux_2.loss_dice: 0.2703, aux_2.acc_seg: 95.8771, aux_3.loss_ce: 0.1380, aux_3.acc_seg: 94.0380, loss: 0.8439
2023-03-29 15:41:36,676 - mmseg - INFO - Iter [2650/10000]	lr: 7.581e-03, eta: 2:44:26, time: 1.258, data_time: 0.275, memory: 9072, decode.loss_ce: 0.0941, decode.acc_seg: 95.0303, aux_0.loss_ce: 0.0998, aux_0.acc_seg: 94.7955, aux_1.loss_ce: 0.1115, aux_1.acc_seg: 94.2136, aux_2.loss_ce: 0.1302, aux_2.loss_dice: 0.2716, aux_2.acc_seg: 95.8094, aux_3.loss_ce: 0.1373, aux_3.acc_seg: 94.1345, loss: 0.8446
2023-03-29 15:42:42,077 - mmseg - INFO - Iter [2700/10000]	lr: 7.535e-03, eta: 2:43:14, time: 1.308, data_time: 0.307, memory: 9072, decode.loss_ce: 0.0923, decode.acc_seg: 95.1434, aux_0.loss_ce: 0.0983, aux_0.acc_seg: 94.9169, aux_1.loss_ce: 0.1110, aux_1.acc_seg: 94.3267, aux_2.loss_ce: 0.1303, aux_2.loss_dice: 0.2714, aux_2.acc_seg: 95.8354, aux_3.loss_ce: 0.1358, aux_3.acc_seg: 94.2386, loss: 0.8391
2023-03-29 15:43:51,809 - mmseg - INFO - Iter [2750/10000]	lr: 7.488e-03, eta: 2:42:14, time: 1.395, data_time: 0.373, memory: 9072, decode.loss_ce: 0.0917, decode.acc_seg: 95.1215, aux_0.loss_ce: 0.0961, aux_0.acc_seg: 94.9454, aux_1.loss_ce: 0.1091, aux_1.acc_seg: 94.3343, aux_2.loss_ce: 0.1307, aux_2.loss_dice: 0.2706, aux_2.acc_seg: 95.7710, aux_3.loss_ce: 0.1348, aux_3.acc_seg: 94.2404, loss: 0.8330
2023-03-29 15:44:55,778 - mmseg - INFO - Iter [2800/10000]	lr: 7.442e-03, eta: 2:40:58, time: 1.279, data_time: 0.333, memory: 9072, decode.loss_ce: 0.0914, decode.acc_seg: 95.1515, aux_0.loss_ce: 0.0963, aux_0.acc_seg: 94.9304, aux_1.loss_ce: 0.1098, aux_1.acc_seg: 94.3170, aux_2.loss_ce: 0.1290, aux_2.loss_dice: 0.2693, aux_2.acc_seg: 95.8255, aux_3.loss_ce: 0.1333, aux_3.acc_seg: 94.2353, loss: 0.8291
2023-03-29 15:46:01,436 - mmseg - INFO - Iter [2850/10000]	lr: 7.395e-03, eta: 2:39:48, time: 1.313, data_time: 0.301, memory: 9072, decode.loss_ce: 0.0917, decode.acc_seg: 95.1219, aux_0.loss_ce: 0.0965, aux_0.acc_seg: 94.9343, aux_1.loss_ce: 0.1081, aux_1.acc_seg: 94.3583, aux_2.loss_ce: 0.1293, aux_2.loss_dice: 0.2704, aux_2.acc_seg: 95.8358, aux_3.loss_ce: 0.1332, aux_3.acc_seg: 94.2509, loss: 0.8292
2023-03-29 15:47:09,979 - mmseg - INFO - Iter [2900/10000]	lr: 7.349e-03, eta: 2:38:44, time: 1.371, data_time: 0.369, memory: 9072, decode.loss_ce: 0.0924, decode.acc_seg: 95.1782, aux_0.loss_ce: 0.0969, aux_0.acc_seg: 94.9909, aux_1.loss_ce: 0.1092, aux_1.acc_seg: 94.4028, aux_2.loss_ce: 0.1287, aux_2.loss_dice: 0.2703, aux_2.acc_seg: 95.8733, aux_3.loss_ce: 0.1332, aux_3.acc_seg: 94.3103, loss: 0.8307
2023-03-29 15:48:14,544 - mmseg - INFO - Iter [2950/10000]	lr: 7.302e-03, eta: 2:37:31, time: 1.291, data_time: 0.286, memory: 9072, decode.loss_ce: 0.0884, decode.acc_seg: 95.2570, aux_0.loss_ce: 0.0942, aux_0.acc_seg: 95.0507, aux_1.loss_ce: 0.1043, aux_1.acc_seg: 94.4945, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2684, aux_2.acc_seg: 95.9087, aux_3.loss_ce: 0.1301, aux_3.acc_seg: 94.3324, loss: 0.8126
2023-03-29 15:49:18,588 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-03-29 15:49:20,307 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 15:49:20,308 - mmseg - INFO - Iter [3000/10000]	lr: 7.255e-03, eta: 2:36:21, time: 1.315, data_time: 0.317, memory: 9072, decode.loss_ce: 0.0909, decode.acc_seg: 95.2156, aux_0.loss_ce: 0.0954, aux_0.acc_seg: 95.0125, aux_1.loss_ce: 0.1083, aux_1.acc_seg: 94.4302, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2697, aux_2.acc_seg: 95.8524, aux_3.loss_ce: 0.1314, aux_3.acc_seg: 94.3304, loss: 0.8245
2023-03-29 15:49:24,176 - mmseg - INFO - per class results:
2023-03-29 15:49:24,179 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 80.53 | 86.87 |
|   Building  | 92.34 | 94.19 |
|     Car     | 90.61 | 94.03 |
| Column_Pole | 12.59 |  13.7 |
|    Fence    | 77.72 | 94.27 |
|  Pedestrian | 53.91 | 82.38 |
|     Road    | 97.17 | 98.39 |
|   Sidewalk  | 89.98 | 96.57 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.77 | 96.42 |
|     Tree    | 92.17 | 98.02 |
+-------------+-------+-------+
2023-03-29 15:49:24,179 - mmseg - INFO - Summary:
2023-03-29 15:49:24,180 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 95.7 | 70.98 | 77.71 |
+------+-------+-------+
2023-03-29 15:49:24,181 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 15:49:24,181 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9570, mIoU: 0.7098, mAcc: 0.7771, IoU.Bicyclist: 0.8053, IoU.Building: 0.9234, IoU.Car: 0.9061, IoU.Column_Pole: 0.1259, IoU.Fence: 0.7772, IoU.Pedestrian: 0.5391, IoU.Road: 0.9717, IoU.Sidewalk: 0.8998, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9377, IoU.Tree: 0.9217, Acc.Bicyclist: 0.8687, Acc.Building: 0.9419, Acc.Car: 0.9403, Acc.Column_Pole: 0.1370, Acc.Fence: 0.9427, Acc.Pedestrian: 0.8238, Acc.Road: 0.9839, Acc.Sidewalk: 0.9657, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9642, Acc.Tree: 0.9802
2023-03-29 15:50:34,541 - mmseg - INFO - Iter [3050/10000]	lr: 7.209e-03, eta: 2:35:31, time: 1.485, data_time: 0.472, memory: 9072, decode.loss_ce: 0.0895, decode.acc_seg: 95.2636, aux_0.loss_ce: 0.0949, aux_0.acc_seg: 95.0563, aux_1.loss_ce: 0.1061, aux_1.acc_seg: 94.4837, aux_2.loss_ce: 0.1291, aux_2.loss_dice: 0.2698, aux_2.acc_seg: 95.8433, aux_3.loss_ce: 0.1307, aux_3.acc_seg: 94.3457, loss: 0.8201
2023-03-29 15:51:37,316 - mmseg - INFO - Iter [3100/10000]	lr: 7.162e-03, eta: 2:34:14, time: 1.256, data_time: 0.279, memory: 9072, decode.loss_ce: 0.0905, decode.acc_seg: 95.0986, aux_0.loss_ce: 0.0954, aux_0.acc_seg: 94.8977, aux_1.loss_ce: 0.1065, aux_1.acc_seg: 94.3059, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2678, aux_2.acc_seg: 95.9231, aux_3.loss_ce: 0.1314, aux_3.acc_seg: 94.2010, loss: 0.8184
2023-03-29 15:52:41,496 - mmseg - INFO - Iter [3150/10000]	lr: 7.115e-03, eta: 2:33:01, time: 1.283, data_time: 0.303, memory: 9072, decode.loss_ce: 0.0944, decode.acc_seg: 95.0572, aux_0.loss_ce: 0.0994, aux_0.acc_seg: 94.8737, aux_1.loss_ce: 0.1117, aux_1.acc_seg: 94.2696, aux_2.loss_ce: 0.1299, aux_2.loss_dice: 0.2704, aux_2.acc_seg: 95.8376, aux_3.loss_ce: 0.1356, aux_3.acc_seg: 94.1640, loss: 0.8414
2023-03-29 15:53:51,950 - mmseg - INFO - Iter [3200/10000]	lr: 7.069e-03, eta: 2:32:01, time: 1.409, data_time: 0.409, memory: 9072, decode.loss_ce: 0.0860, decode.acc_seg: 95.3643, aux_0.loss_ce: 0.0907, aux_0.acc_seg: 95.1695, aux_1.loss_ce: 0.1028, aux_1.acc_seg: 94.6080, aux_2.loss_ce: 0.1278, aux_2.loss_dice: 0.2680, aux_2.acc_seg: 95.8518, aux_3.loss_ce: 0.1255, aux_3.acc_seg: 94.4737, loss: 0.8008
2023-03-29 15:54:55,882 - mmseg - INFO - Iter [3250/10000]	lr: 7.022e-03, eta: 2:30:47, time: 1.279, data_time: 0.269, memory: 9072, decode.loss_ce: 0.0902, decode.acc_seg: 95.2955, aux_0.loss_ce: 0.0945, aux_0.acc_seg: 95.1117, aux_1.loss_ce: 0.1063, aux_1.acc_seg: 94.5417, aux_2.loss_ce: 0.1292, aux_2.loss_dice: 0.2695, aux_2.acc_seg: 95.8232, aux_3.loss_ce: 0.1303, aux_3.acc_seg: 94.3978, loss: 0.8200
2023-03-29 15:55:56,020 - mmseg - INFO - Iter [3300/10000]	lr: 6.975e-03, eta: 2:29:26, time: 1.203, data_time: 0.265, memory: 9072, decode.loss_ce: 0.0869, decode.acc_seg: 95.3248, aux_0.loss_ce: 0.0919, aux_0.acc_seg: 95.1425, aux_1.loss_ce: 0.1024, aux_1.acc_seg: 94.5791, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2676, aux_2.acc_seg: 95.8688, aux_3.loss_ce: 0.1256, aux_3.acc_seg: 94.4349, loss: 0.8021
2023-03-29 15:57:04,675 - mmseg - INFO - Iter [3350/10000]	lr: 6.928e-03, eta: 2:28:23, time: 1.373, data_time: 0.353, memory: 9072, decode.loss_ce: 0.0869, decode.acc_seg: 95.3385, aux_0.loss_ce: 0.0933, aux_0.acc_seg: 95.1124, aux_1.loss_ce: 0.1037, aux_1.acc_seg: 94.5320, aux_2.loss_ce: 0.1297, aux_2.loss_dice: 0.2685, aux_2.acc_seg: 95.7757, aux_3.loss_ce: 0.1272, aux_3.acc_seg: 94.4278, loss: 0.8093
2023-03-29 15:58:06,229 - mmseg - INFO - Iter [3400/10000]	lr: 6.881e-03, eta: 2:27:05, time: 1.231, data_time: 0.270, memory: 9072, decode.loss_ce: 0.0850, decode.acc_seg: 95.4771, aux_0.loss_ce: 0.0907, aux_0.acc_seg: 95.2586, aux_1.loss_ce: 0.1019, aux_1.acc_seg: 94.6926, aux_2.loss_ce: 0.1287, aux_2.loss_dice: 0.2690, aux_2.acc_seg: 95.8473, aux_3.loss_ce: 0.1242, aux_3.acc_seg: 94.5881, loss: 0.7995
2023-03-29 15:59:10,074 - mmseg - INFO - Iter [3450/10000]	lr: 6.834e-03, eta: 2:25:53, time: 1.277, data_time: 0.265, memory: 9072, decode.loss_ce: 0.0839, decode.acc_seg: 95.4286, aux_0.loss_ce: 0.0892, aux_0.acc_seg: 95.2376, aux_1.loss_ce: 0.0995, aux_1.acc_seg: 94.6520, aux_2.loss_ce: 0.1273, aux_2.loss_dice: 0.2668, aux_2.acc_seg: 95.8754, aux_3.loss_ce: 0.1222, aux_3.acc_seg: 94.5324, loss: 0.7889
2023-03-29 16:00:19,720 - mmseg - INFO - Iter [3500/10000]	lr: 6.787e-03, eta: 2:24:51, time: 1.393, data_time: 0.356, memory: 9072, decode.loss_ce: 0.0876, decode.acc_seg: 95.2896, aux_0.loss_ce: 0.0913, aux_0.acc_seg: 95.1201, aux_1.loss_ce: 0.1037, aux_1.acc_seg: 94.5019, aux_2.loss_ce: 0.1287, aux_2.loss_dice: 0.2690, aux_2.acc_seg: 95.8638, aux_3.loss_ce: 0.1259, aux_3.acc_seg: 94.3932, loss: 0.8061
2023-03-29 16:01:21,482 - mmseg - INFO - Iter [3550/10000]	lr: 6.740e-03, eta: 2:23:35, time: 1.235, data_time: 0.273, memory: 9072, decode.loss_ce: 0.0849, decode.acc_seg: 95.4619, aux_0.loss_ce: 0.0900, aux_0.acc_seg: 95.2802, aux_1.loss_ce: 0.1016, aux_1.acc_seg: 94.6611, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.9330, aux_3.loss_ce: 0.1228, aux_3.acc_seg: 94.5735, loss: 0.7925
2023-03-29 16:02:25,961 - mmseg - INFO - Iter [3600/10000]	lr: 6.693e-03, eta: 2:22:24, time: 1.290, data_time: 0.264, memory: 9072, decode.loss_ce: 0.0857, decode.acc_seg: 95.3897, aux_0.loss_ce: 0.0905, aux_0.acc_seg: 95.1832, aux_1.loss_ce: 0.1021, aux_1.acc_seg: 94.5953, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2672, aux_2.acc_seg: 95.8148, aux_3.loss_ce: 0.1239, aux_3.acc_seg: 94.4772, loss: 0.7980
2023-03-29 16:03:35,789 - mmseg - INFO - Iter [3650/10000]	lr: 6.646e-03, eta: 2:21:23, time: 1.397, data_time: 0.355, memory: 9072, decode.loss_ce: 0.0850, decode.acc_seg: 95.4027, aux_0.loss_ce: 0.0906, aux_0.acc_seg: 95.2029, aux_1.loss_ce: 0.1016, aux_1.acc_seg: 94.6299, aux_2.loss_ce: 0.1284, aux_2.loss_dice: 0.2677, aux_2.acc_seg: 95.8621, aux_3.loss_ce: 0.1224, aux_3.acc_seg: 94.5268, loss: 0.7957
2023-03-29 16:04:38,248 - mmseg - INFO - Iter [3700/10000]	lr: 6.599e-03, eta: 2:20:09, time: 1.249, data_time: 0.290, memory: 9072, decode.loss_ce: 0.0832, decode.acc_seg: 95.5095, aux_0.loss_ce: 0.0876, aux_0.acc_seg: 95.3216, aux_1.loss_ce: 0.0996, aux_1.acc_seg: 94.6946, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2672, aux_2.acc_seg: 95.8199, aux_3.loss_ce: 0.1209, aux_3.acc_seg: 94.6119, loss: 0.7866
2023-03-29 16:05:42,270 - mmseg - INFO - Iter [3750/10000]	lr: 6.552e-03, eta: 2:18:57, time: 1.280, data_time: 0.264, memory: 9072, decode.loss_ce: 0.0853, decode.acc_seg: 95.3984, aux_0.loss_ce: 0.0904, aux_0.acc_seg: 95.2086, aux_1.loss_ce: 0.1028, aux_1.acc_seg: 94.5918, aux_2.loss_ce: 0.1287, aux_2.loss_dice: 0.2675, aux_2.acc_seg: 95.8146, aux_3.loss_ce: 0.1236, aux_3.acc_seg: 94.4793, loss: 0.7984
2023-03-29 16:06:51,744 - mmseg - INFO - Iter [3800/10000]	lr: 6.505e-03, eta: 2:17:55, time: 1.389, data_time: 0.378, memory: 9072, decode.loss_ce: 0.0851, decode.acc_seg: 95.3687, aux_0.loss_ce: 0.0902, aux_0.acc_seg: 95.1824, aux_1.loss_ce: 0.1017, aux_1.acc_seg: 94.5709, aux_2.loss_ce: 0.1282, aux_2.loss_dice: 0.2677, aux_2.acc_seg: 95.8587, aux_3.loss_ce: 0.1235, aux_3.acc_seg: 94.4522, loss: 0.7964
2023-03-29 16:07:54,308 - mmseg - INFO - Iter [3850/10000]	lr: 6.458e-03, eta: 2:16:42, time: 1.251, data_time: 0.267, memory: 9072, decode.loss_ce: 0.0837, decode.acc_seg: 95.5499, aux_0.loss_ce: 0.0879, aux_0.acc_seg: 95.3716, aux_1.loss_ce: 0.1008, aux_1.acc_seg: 94.7577, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2670, aux_2.acc_seg: 95.8296, aux_3.loss_ce: 0.1209, aux_3.acc_seg: 94.6842, loss: 0.7883
2023-03-29 16:08:58,350 - mmseg - INFO - Iter [3900/10000]	lr: 6.410e-03, eta: 2:15:31, time: 1.281, data_time: 0.284, memory: 9072, decode.loss_ce: 0.0845, decode.acc_seg: 95.4457, aux_0.loss_ce: 0.0889, aux_0.acc_seg: 95.2642, aux_1.loss_ce: 0.1016, aux_1.acc_seg: 94.6637, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2673, aux_2.acc_seg: 95.8763, aux_3.loss_ce: 0.1204, aux_3.acc_seg: 94.5686, loss: 0.7901
2023-03-29 16:10:05,413 - mmseg - INFO - Iter [3950/10000]	lr: 6.363e-03, eta: 2:14:25, time: 1.341, data_time: 0.328, memory: 9072, decode.loss_ce: 0.0802, decode.acc_seg: 95.5994, aux_0.loss_ce: 0.0851, aux_0.acc_seg: 95.4110, aux_1.loss_ce: 0.0965, aux_1.acc_seg: 94.8093, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2654, aux_2.acc_seg: 95.8980, aux_3.loss_ce: 0.1169, aux_3.acc_seg: 94.6725, loss: 0.7703
2023-03-29 16:11:08,573 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-03-29 16:11:10,506 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 16:11:10,506 - mmseg - INFO - Iter [4000/10000]	lr: 6.316e-03, eta: 2:13:16, time: 1.302, data_time: 0.258, memory: 9072, decode.loss_ce: 0.0837, decode.acc_seg: 95.5273, aux_0.loss_ce: 0.0885, aux_0.acc_seg: 95.3403, aux_1.loss_ce: 0.1001, aux_1.acc_seg: 94.7428, aux_2.loss_ce: 0.1292, aux_2.loss_dice: 0.2669, aux_2.acc_seg: 95.7575, aux_3.loss_ce: 0.1202, aux_3.acc_seg: 94.6201, loss: 0.7887
2023-03-29 16:11:14,057 - mmseg - INFO - per class results:
2023-03-29 16:11:14,059 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 81.79 | 90.13 |
|   Building  | 92.39 | 94.21 |
|     Car     | 91.03 | 94.38 |
| Column_Pole |  9.9  | 10.59 |
|    Fence    | 78.62 | 95.17 |
|  Pedestrian | 59.42 | 81.24 |
|     Road    | 97.18 | 98.09 |
|   Sidewalk  | 90.22 | 96.93 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.72 | 96.38 |
|     Tree    | 91.84 | 98.19 |
+-------------+-------+-------+
2023-03-29 16:11:14,059 - mmseg - INFO - Summary:
2023-03-29 16:11:14,059 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.76 | 71.46 | 77.76 |
+-------+-------+-------+
2023-03-29 16:11:14,059 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 16:11:14,060 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9576, mIoU: 0.7146, mAcc: 0.7776, IoU.Bicyclist: 0.8179, IoU.Building: 0.9239, IoU.Car: 0.9103, IoU.Column_Pole: 0.0990, IoU.Fence: 0.7862, IoU.Pedestrian: 0.5942, IoU.Road: 0.9718, IoU.Sidewalk: 0.9022, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9372, IoU.Tree: 0.9184, Acc.Bicyclist: 0.9013, Acc.Building: 0.9421, Acc.Car: 0.9438, Acc.Column_Pole: 0.1059, Acc.Fence: 0.9517, Acc.Pedestrian: 0.8124, Acc.Road: 0.9809, Acc.Sidewalk: 0.9693, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9638, Acc.Tree: 0.9819
2023-03-29 16:12:19,284 - mmseg - INFO - Iter [4050/10000]	lr: 6.268e-03, eta: 2:12:12, time: 1.375, data_time: 0.360, memory: 9072, decode.loss_ce: 0.0829, decode.acc_seg: 95.4910, aux_0.loss_ce: 0.0875, aux_0.acc_seg: 95.3131, aux_1.loss_ce: 0.0991, aux_1.acc_seg: 94.7280, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2668, aux_2.acc_seg: 95.8994, aux_3.loss_ce: 0.1188, aux_3.acc_seg: 94.6139, loss: 0.7820
2023-03-29 16:13:28,857 - mmseg - INFO - Iter [4100/10000]	lr: 6.221e-03, eta: 2:11:10, time: 1.391, data_time: 0.357, memory: 9072, decode.loss_ce: 0.0822, decode.acc_seg: 95.5254, aux_0.loss_ce: 0.0868, aux_0.acc_seg: 95.3384, aux_1.loss_ce: 0.0978, aux_1.acc_seg: 94.7768, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2670, aux_2.acc_seg: 95.8706, aux_3.loss_ce: 0.1182, aux_3.acc_seg: 94.6408, loss: 0.7797
2023-03-29 16:14:31,699 - mmseg - INFO - Iter [4150/10000]	lr: 6.174e-03, eta: 2:09:58, time: 1.257, data_time: 0.278, memory: 9072, decode.loss_ce: 0.0823, decode.acc_seg: 95.5375, aux_0.loss_ce: 0.0867, aux_0.acc_seg: 95.3589, aux_1.loss_ce: 0.0986, aux_1.acc_seg: 94.7364, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2660, aux_2.acc_seg: 95.8180, aux_3.loss_ce: 0.1187, aux_3.acc_seg: 94.6134, loss: 0.7804
2023-03-29 16:15:35,015 - mmseg - INFO - Iter [4200/10000]	lr: 6.126e-03, eta: 2:08:47, time: 1.266, data_time: 0.268, memory: 9072, decode.loss_ce: 0.0811, decode.acc_seg: 95.5821, aux_0.loss_ce: 0.0856, aux_0.acc_seg: 95.4140, aux_1.loss_ce: 0.0964, aux_1.acc_seg: 94.8300, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2660, aux_2.acc_seg: 95.9023, aux_3.loss_ce: 0.1159, aux_3.acc_seg: 94.7079, loss: 0.7719
2023-03-29 16:16:41,663 - mmseg - INFO - Iter [4250/10000]	lr: 6.079e-03, eta: 2:07:40, time: 1.333, data_time: 0.313, memory: 9072, decode.loss_ce: 0.0871, decode.acc_seg: 95.3036, aux_0.loss_ce: 0.0911, aux_0.acc_seg: 95.1345, aux_1.loss_ce: 0.1031, aux_1.acc_seg: 94.5323, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8722, aux_3.loss_ce: 0.1228, aux_3.acc_seg: 94.4090, loss: 0.7979
2023-03-29 16:17:44,421 - mmseg - INFO - Iter [4300/10000]	lr: 6.031e-03, eta: 2:06:28, time: 1.255, data_time: 0.257, memory: 9072, decode.loss_ce: 0.0927, decode.acc_seg: 95.0759, aux_0.loss_ce: 0.0977, aux_0.acc_seg: 94.8881, aux_1.loss_ce: 0.1093, aux_1.acc_seg: 94.2746, aux_2.loss_ce: 0.1295, aux_2.loss_dice: 0.2703, aux_2.acc_seg: 95.8523, aux_3.loss_ce: 0.1300, aux_3.acc_seg: 94.1589, loss: 0.8293
2023-03-29 16:18:48,500 - mmseg - INFO - Iter [4350/10000]	lr: 5.983e-03, eta: 2:05:18, time: 1.281, data_time: 0.268, memory: 9072, decode.loss_ce: 0.0858, decode.acc_seg: 95.3537, aux_0.loss_ce: 0.0910, aux_0.acc_seg: 95.1760, aux_1.loss_ce: 0.1013, aux_1.acc_seg: 94.6219, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2667, aux_2.acc_seg: 95.8020, aux_3.loss_ce: 0.1218, aux_3.acc_seg: 94.4513, loss: 0.7951
2023-03-29 16:19:56,541 - mmseg - INFO - Iter [4400/10000]	lr: 5.936e-03, eta: 2:04:14, time: 1.361, data_time: 0.329, memory: 9072, decode.loss_ce: 0.0856, decode.acc_seg: 95.3694, aux_0.loss_ce: 0.0896, aux_0.acc_seg: 95.1798, aux_1.loss_ce: 0.1016, aux_1.acc_seg: 94.6062, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2661, aux_2.acc_seg: 95.8720, aux_3.loss_ce: 0.1206, aux_3.acc_seg: 94.4640, loss: 0.7902
2023-03-29 16:20:58,293 - mmseg - INFO - Iter [4450/10000]	lr: 5.888e-03, eta: 2:03:01, time: 1.235, data_time: 0.254, memory: 9072, decode.loss_ce: 0.0845, decode.acc_seg: 95.3993, aux_0.loss_ce: 0.0887, aux_0.acc_seg: 95.2187, aux_1.loss_ce: 0.1016, aux_1.acc_seg: 94.5954, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2662, aux_2.acc_seg: 95.8666, aux_3.loss_ce: 0.1197, aux_3.acc_seg: 94.5152, loss: 0.7879
2023-03-29 16:22:01,294 - mmseg - INFO - Iter [4500/10000]	lr: 5.840e-03, eta: 2:01:51, time: 1.260, data_time: 0.247, memory: 9072, decode.loss_ce: 0.0808, decode.acc_seg: 95.5821, aux_0.loss_ce: 0.0855, aux_0.acc_seg: 95.3979, aux_1.loss_ce: 0.0969, aux_1.acc_seg: 94.7962, aux_2.loss_ce: 0.1281, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8231, aux_3.loss_ce: 0.1160, aux_3.acc_seg: 94.6852, loss: 0.7739
2023-03-29 16:23:09,362 - mmseg - INFO - Iter [4550/10000]	lr: 5.792e-03, eta: 2:00:46, time: 1.361, data_time: 0.317, memory: 9072, decode.loss_ce: 0.0807, decode.acc_seg: 95.6286, aux_0.loss_ce: 0.0856, aux_0.acc_seg: 95.4579, aux_1.loss_ce: 0.0979, aux_1.acc_seg: 94.8671, aux_2.loss_ce: 0.1280, aux_2.loss_dice: 0.2661, aux_2.acc_seg: 95.8201, aux_3.loss_ce: 0.1153, aux_3.acc_seg: 94.7624, loss: 0.7734
2023-03-29 16:24:10,940 - mmseg - INFO - Iter [4600/10000]	lr: 5.745e-03, eta: 1:59:34, time: 1.232, data_time: 0.249, memory: 9072, decode.loss_ce: 0.0808, decode.acc_seg: 95.6143, aux_0.loss_ce: 0.0858, aux_0.acc_seg: 95.4409, aux_1.loss_ce: 0.0959, aux_1.acc_seg: 94.8399, aux_2.loss_ce: 0.1271, aux_2.loss_dice: 0.2654, aux_2.acc_seg: 95.8593, aux_3.loss_ce: 0.1153, aux_3.acc_seg: 94.7163, loss: 0.7702
2023-03-29 16:25:14,939 - mmseg - INFO - Iter [4650/10000]	lr: 5.697e-03, eta: 1:58:25, time: 1.280, data_time: 0.249, memory: 9072, decode.loss_ce: 0.0830, decode.acc_seg: 95.4442, aux_0.loss_ce: 0.0879, aux_0.acc_seg: 95.2913, aux_1.loss_ce: 0.0979, aux_1.acc_seg: 94.7095, aux_2.loss_ce: 0.1277, aux_2.loss_dice: 0.2658, aux_2.acc_seg: 95.8510, aux_3.loss_ce: 0.1170, aux_3.acc_seg: 94.5554, loss: 0.7792
2023-03-29 16:26:21,418 - mmseg - INFO - Iter [4700/10000]	lr: 5.649e-03, eta: 1:57:18, time: 1.329, data_time: 0.322, memory: 9072, decode.loss_ce: 0.0821, decode.acc_seg: 95.4736, aux_0.loss_ce: 0.0860, aux_0.acc_seg: 95.3022, aux_1.loss_ce: 0.0979, aux_1.acc_seg: 94.6873, aux_2.loss_ce: 0.1270, aux_2.loss_dice: 0.2670, aux_2.acc_seg: 95.8892, aux_3.loss_ce: 0.1164, aux_3.acc_seg: 94.5748, loss: 0.7763
2023-03-29 16:27:23,924 - mmseg - INFO - Iter [4750/10000]	lr: 5.601e-03, eta: 1:56:07, time: 1.250, data_time: 0.260, memory: 9072, decode.loss_ce: 0.0774, decode.acc_seg: 95.7368, aux_0.loss_ce: 0.0818, aux_0.acc_seg: 95.5606, aux_1.loss_ce: 0.0926, aux_1.acc_seg: 94.9719, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2637, aux_2.acc_seg: 95.9199, aux_3.loss_ce: 0.1113, aux_3.acc_seg: 94.8377, loss: 0.7517
2023-03-29 16:28:26,078 - mmseg - INFO - Iter [4800/10000]	lr: 5.553e-03, eta: 1:54:57, time: 1.243, data_time: 0.267, memory: 9072, decode.loss_ce: 0.0801, decode.acc_seg: 95.5861, aux_0.loss_ce: 0.0855, aux_0.acc_seg: 95.4089, aux_1.loss_ce: 0.0963, aux_1.acc_seg: 94.8413, aux_2.loss_ce: 0.1282, aux_2.loss_dice: 0.2665, aux_2.acc_seg: 95.8147, aux_3.loss_ce: 0.1144, aux_3.acc_seg: 94.6672, loss: 0.7710
2023-03-29 16:29:33,548 - mmseg - INFO - Iter [4850/10000]	lr: 5.505e-03, eta: 1:53:51, time: 1.349, data_time: 0.358, memory: 9072, decode.loss_ce: 0.0773, decode.acc_seg: 95.7565, aux_0.loss_ce: 0.0806, aux_0.acc_seg: 95.5875, aux_1.loss_ce: 0.0930, aux_1.acc_seg: 94.9796, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2641, aux_2.acc_seg: 95.8482, aux_3.loss_ce: 0.1110, aux_3.acc_seg: 94.8431, loss: 0.7523
2023-03-29 16:30:40,486 - mmseg - INFO - Iter [4900/10000]	lr: 5.457e-03, eta: 1:52:46, time: 1.339, data_time: 0.287, memory: 9072, decode.loss_ce: 0.0789, decode.acc_seg: 95.6924, aux_0.loss_ce: 0.0829, aux_0.acc_seg: 95.5284, aux_1.loss_ce: 0.0944, aux_1.acc_seg: 94.9295, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 95.8902, aux_3.loss_ce: 0.1119, aux_3.acc_seg: 94.7962, loss: 0.7594
2023-03-29 16:31:42,754 - mmseg - INFO - Iter [4950/10000]	lr: 5.408e-03, eta: 1:51:35, time: 1.245, data_time: 0.256, memory: 9072, decode.loss_ce: 0.0781, decode.acc_seg: 95.6621, aux_0.loss_ce: 0.0837, aux_0.acc_seg: 95.4673, aux_1.loss_ce: 0.0935, aux_1.acc_seg: 94.8802, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2652, aux_2.acc_seg: 95.8205, aux_3.loss_ce: 0.1117, aux_3.acc_seg: 94.7426, loss: 0.7598
2023-03-29 16:32:46,498 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-03-29 16:32:48,656 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 16:32:48,656 - mmseg - INFO - Iter [5000/10000]	lr: 5.360e-03, eta: 1:50:29, time: 1.318, data_time: 0.303, memory: 9072, decode.loss_ce: 0.0780, decode.acc_seg: 95.6612, aux_0.loss_ce: 0.0824, aux_0.acc_seg: 95.4901, aux_1.loss_ce: 0.0938, aux_1.acc_seg: 94.8699, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2644, aux_2.acc_seg: 95.9049, aux_3.loss_ce: 0.1111, aux_3.acc_seg: 94.7514, loss: 0.7556
2023-03-29 16:32:52,303 - mmseg - INFO - per class results:
2023-03-29 16:32:52,304 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.98 | 90.25 |
|   Building  |  92.2 | 93.89 |
|     Car     | 91.41 |  94.5 |
| Column_Pole | 12.89 | 14.08 |
|    Fence    | 78.77 | 92.29 |
|  Pedestrian | 62.16 |  81.5 |
|     Road    |  97.3 | 98.18 |
|   Sidewalk  | 90.26 | 97.55 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.79 | 97.23 |
|     Tree    | 91.29 | 98.12 |
+-------------+-------+-------+
2023-03-29 16:32:52,304 - mmseg - INFO - Summary:
2023-03-29 16:32:52,304 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.76 | 72.09 | 77.96 |
+-------+-------+-------+
2023-03-29 16:32:52,304 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 16:32:52,305 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9576, mIoU: 0.7209, mAcc: 0.7796, IoU.Bicyclist: 0.8298, IoU.Building: 0.9220, IoU.Car: 0.9141, IoU.Column_Pole: 0.1289, IoU.Fence: 0.7877, IoU.Pedestrian: 0.6216, IoU.Road: 0.9730, IoU.Sidewalk: 0.9026, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9379, IoU.Tree: 0.9129, Acc.Bicyclist: 0.9025, Acc.Building: 0.9389, Acc.Car: 0.9450, Acc.Column_Pole: 0.1408, Acc.Fence: 0.9229, Acc.Pedestrian: 0.8150, Acc.Road: 0.9818, Acc.Sidewalk: 0.9755, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9723, Acc.Tree: 0.9812
2023-03-29 16:33:53,233 - mmseg - INFO - Iter [5050/10000]	lr: 5.312e-03, eta: 1:49:21, time: 1.291, data_time: 0.334, memory: 9072, decode.loss_ce: 0.0779, decode.acc_seg: 95.7292, aux_0.loss_ce: 0.0827, aux_0.acc_seg: 95.5481, aux_1.loss_ce: 0.0937, aux_1.acc_seg: 94.9650, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2653, aux_2.acc_seg: 95.8982, aux_3.loss_ce: 0.1108, aux_3.acc_seg: 94.8296, loss: 0.7565
2023-03-29 16:34:56,944 - mmseg - INFO - Iter [5100/10000]	lr: 5.264e-03, eta: 1:48:12, time: 1.274, data_time: 0.263, memory: 9072, decode.loss_ce: 0.0777, decode.acc_seg: 95.6734, aux_0.loss_ce: 0.0820, aux_0.acc_seg: 95.5043, aux_1.loss_ce: 0.0940, aux_1.acc_seg: 94.8882, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 95.8583, aux_3.loss_ce: 0.1100, aux_3.acc_seg: 94.7924, loss: 0.7531
2023-03-29 16:36:06,233 - mmseg - INFO - Iter [5150/10000]	lr: 5.215e-03, eta: 1:47:09, time: 1.386, data_time: 0.371, memory: 9072, decode.loss_ce: 0.0771, decode.acc_seg: 95.6898, aux_0.loss_ce: 0.0819, aux_0.acc_seg: 95.5289, aux_1.loss_ce: 0.0920, aux_1.acc_seg: 94.9422, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.9083, aux_3.loss_ce: 0.1086, aux_3.acc_seg: 94.8186, loss: 0.7481
2023-03-29 16:37:08,146 - mmseg - INFO - Iter [5200/10000]	lr: 5.167e-03, eta: 1:45:58, time: 1.238, data_time: 0.274, memory: 9072, decode.loss_ce: 0.0764, decode.acc_seg: 95.7291, aux_0.loss_ce: 0.0811, aux_0.acc_seg: 95.5581, aux_1.loss_ce: 0.0924, aux_1.acc_seg: 94.9591, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.9205, aux_3.loss_ce: 0.1081, aux_3.acc_seg: 94.8261, loss: 0.7454
2023-03-29 16:38:11,756 - mmseg - INFO - Iter [5250/10000]	lr: 5.119e-03, eta: 1:44:50, time: 1.272, data_time: 0.248, memory: 9072, decode.loss_ce: 0.0773, decode.acc_seg: 95.7913, aux_0.loss_ce: 0.0814, aux_0.acc_seg: 95.6357, aux_1.loss_ce: 0.0928, aux_1.acc_seg: 95.0357, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8737, aux_3.loss_ce: 0.1091, aux_3.acc_seg: 94.9190, loss: 0.7507
2023-03-29 16:39:20,089 - mmseg - INFO - Iter [5300/10000]	lr: 5.070e-03, eta: 1:43:45, time: 1.367, data_time: 0.343, memory: 9072, decode.loss_ce: 0.0773, decode.acc_seg: 95.7020, aux_0.loss_ce: 0.0814, aux_0.acc_seg: 95.5053, aux_1.loss_ce: 0.0921, aux_1.acc_seg: 94.9338, aux_2.loss_ce: 0.1276, aux_2.loss_dice: 0.2648, aux_2.acc_seg: 95.7838, aux_3.loss_ce: 0.1090, aux_3.acc_seg: 94.8175, loss: 0.7521
2023-03-29 16:40:20,225 - mmseg - INFO - Iter [5350/10000]	lr: 5.022e-03, eta: 1:42:34, time: 1.203, data_time: 0.241, memory: 9072, decode.loss_ce: 0.0774, decode.acc_seg: 95.7296, aux_0.loss_ce: 0.0809, aux_0.acc_seg: 95.5931, aux_1.loss_ce: 0.0942, aux_1.acc_seg: 94.9660, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2638, aux_2.acc_seg: 95.8615, aux_3.loss_ce: 0.1093, aux_3.acc_seg: 94.8501, loss: 0.7522
2023-03-29 16:41:24,066 - mmseg - INFO - Iter [5400/10000]	lr: 4.973e-03, eta: 1:41:26, time: 1.277, data_time: 0.252, memory: 9072, decode.loss_ce: 0.0800, decode.acc_seg: 95.6620, aux_0.loss_ce: 0.0844, aux_0.acc_seg: 95.4895, aux_1.loss_ce: 0.0953, aux_1.acc_seg: 94.9201, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8592, aux_3.loss_ce: 0.1119, aux_3.acc_seg: 94.7794, loss: 0.7617
2023-03-29 16:42:26,807 - mmseg - INFO - Iter [5450/10000]	lr: 4.924e-03, eta: 1:40:17, time: 1.255, data_time: 0.325, memory: 9072, decode.loss_ce: 0.0774, decode.acc_seg: 95.8017, aux_0.loss_ce: 0.0819, aux_0.acc_seg: 95.6420, aux_1.loss_ce: 0.0931, aux_1.acc_seg: 95.0593, aux_2.loss_ce: 0.1266, aux_2.loss_dice: 0.2648, aux_2.acc_seg: 95.8606, aux_3.loss_ce: 0.1091, aux_3.acc_seg: 94.9362, loss: 0.7530
2023-03-29 16:43:30,394 - mmseg - INFO - Iter [5500/10000]	lr: 4.876e-03, eta: 1:39:08, time: 1.272, data_time: 0.252, memory: 9072, decode.loss_ce: 0.0769, decode.acc_seg: 95.7530, aux_0.loss_ce: 0.0815, aux_0.acc_seg: 95.5819, aux_1.loss_ce: 0.0929, aux_1.acc_seg: 94.9899, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2641, aux_2.acc_seg: 95.8251, aux_3.loss_ce: 0.1081, aux_3.acc_seg: 94.8869, loss: 0.7501
2023-03-29 16:44:32,806 - mmseg - INFO - Iter [5550/10000]	lr: 4.827e-03, eta: 1:37:59, time: 1.248, data_time: 0.266, memory: 9072, decode.loss_ce: 0.0783, decode.acc_seg: 95.7060, aux_0.loss_ce: 0.0828, aux_0.acc_seg: 95.5242, aux_1.loss_ce: 0.0937, aux_1.acc_seg: 94.9363, aux_2.loss_ce: 0.1273, aux_2.loss_dice: 0.2648, aux_2.acc_seg: 95.8212, aux_3.loss_ce: 0.1099, aux_3.acc_seg: 94.8179, loss: 0.7568
2023-03-29 16:45:40,955 - mmseg - INFO - Iter [5600/10000]	lr: 4.778e-03, eta: 1:36:55, time: 1.363, data_time: 0.352, memory: 9072, decode.loss_ce: 0.0761, decode.acc_seg: 95.7563, aux_0.loss_ce: 0.0798, aux_0.acc_seg: 95.6002, aux_1.loss_ce: 0.0908, aux_1.acc_seg: 95.0157, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 95.8725, aux_3.loss_ce: 0.1074, aux_3.acc_seg: 94.8623, loss: 0.7434
2023-03-29 16:46:43,439 - mmseg - INFO - Iter [5650/10000]	lr: 4.729e-03, eta: 1:35:46, time: 1.250, data_time: 0.275, memory: 9072, decode.loss_ce: 0.0753, decode.acc_seg: 95.7635, aux_0.loss_ce: 0.0804, aux_0.acc_seg: 95.6007, aux_1.loss_ce: 0.0909, aux_1.acc_seg: 94.9949, aux_2.loss_ce: 0.1271, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 95.8064, aux_3.loss_ce: 0.1063, aux_3.acc_seg: 94.8808, loss: 0.7434
2023-03-29 16:47:46,259 - mmseg - INFO - Iter [5700/10000]	lr: 4.680e-03, eta: 1:34:38, time: 1.256, data_time: 0.249, memory: 9072, decode.loss_ce: 0.0776, decode.acc_seg: 95.7809, aux_0.loss_ce: 0.0810, aux_0.acc_seg: 95.6126, aux_1.loss_ce: 0.0932, aux_1.acc_seg: 95.0205, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.9458, aux_3.loss_ce: 0.1083, aux_3.acc_seg: 94.9022, loss: 0.7485
2023-03-29 16:48:53,501 - mmseg - INFO - Iter [5750/10000]	lr: 4.631e-03, eta: 1:33:32, time: 1.345, data_time: 0.340, memory: 9072, decode.loss_ce: 0.0771, decode.acc_seg: 95.7500, aux_0.loss_ce: 0.0821, aux_0.acc_seg: 95.5688, aux_1.loss_ce: 0.0929, aux_1.acc_seg: 94.9704, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2637, aux_2.acc_seg: 95.8848, aux_3.loss_ce: 0.1080, aux_3.acc_seg: 94.8433, loss: 0.7500
2023-03-29 16:49:53,631 - mmseg - INFO - Iter [5800/10000]	lr: 4.582e-03, eta: 1:32:22, time: 1.203, data_time: 0.237, memory: 9072, decode.loss_ce: 0.0757, decode.acc_seg: 95.7987, aux_0.loss_ce: 0.0794, aux_0.acc_seg: 95.6379, aux_1.loss_ce: 0.0909, aux_1.acc_seg: 95.0495, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8937, aux_3.loss_ce: 0.1065, aux_3.acc_seg: 94.9203, loss: 0.7420
2023-03-29 16:50:58,017 - mmseg - INFO - Iter [5850/10000]	lr: 4.533e-03, eta: 1:31:15, time: 1.288, data_time: 0.290, memory: 9072, decode.loss_ce: 0.0758, decode.acc_seg: 95.7642, aux_0.loss_ce: 0.0798, aux_0.acc_seg: 95.6180, aux_1.loss_ce: 0.0905, aux_1.acc_seg: 95.0134, aux_2.loss_ce: 0.1268, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.8288, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 94.9021, loss: 0.7433
2023-03-29 16:52:03,935 - mmseg - INFO - Iter [5900/10000]	lr: 4.484e-03, eta: 1:30:09, time: 1.318, data_time: 0.318, memory: 9072, decode.loss_ce: 0.0762, decode.acc_seg: 95.7863, aux_0.loss_ce: 0.0802, aux_0.acc_seg: 95.6258, aux_1.loss_ce: 0.0915, aux_1.acc_seg: 95.0190, aux_2.loss_ce: 0.1266, aux_2.loss_dice: 0.2642, aux_2.acc_seg: 95.8417, aux_3.loss_ce: 0.1072, aux_3.acc_seg: 94.9047, loss: 0.7459
2023-03-29 16:53:07,294 - mmseg - INFO - Iter [5950/10000]	lr: 4.435e-03, eta: 1:29:01, time: 1.267, data_time: 0.297, memory: 9072, decode.loss_ce: 0.0735, decode.acc_seg: 95.8991, aux_0.loss_ce: 0.0779, aux_0.acc_seg: 95.7503, aux_1.loss_ce: 0.0889, aux_1.acc_seg: 95.1435, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8614, aux_3.loss_ce: 0.1037, aux_3.acc_seg: 95.0340, loss: 0.7326
2023-03-29 16:54:10,691 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-03-29 16:54:12,507 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 16:54:12,507 - mmseg - INFO - Iter [6000/10000]	lr: 4.385e-03, eta: 1:27:55, time: 1.304, data_time: 0.271, memory: 9072, decode.loss_ce: 0.0753, decode.acc_seg: 95.8341, aux_0.loss_ce: 0.0796, aux_0.acc_seg: 95.6784, aux_1.loss_ce: 0.0904, aux_1.acc_seg: 95.0778, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 95.8558, aux_3.loss_ce: 0.1059, aux_3.acc_seg: 94.9505, loss: 0.7410
2023-03-29 16:54:15,976 - mmseg - INFO - per class results:
2023-03-29 16:54:15,978 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.11 | 89.73 |
|   Building  | 92.43 | 94.21 |
|     Car     | 91.51 | 94.25 |
| Column_Pole | 12.54 | 13.64 |
|    Fence    | 78.76 | 94.54 |
|  Pedestrian | 62.11 | 81.14 |
|     Road    |  97.4 | 98.35 |
|   Sidewalk  |  90.8 |  97.4 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.72 | 96.49 |
|     Tree    | 91.82 | 98.24 |
+-------------+-------+-------+
2023-03-29 16:54:15,978 - mmseg - INFO - Summary:
2023-03-29 16:54:15,979 - mmseg - INFO - 
+-------+------+------+
|  aAcc | mIoU | mAcc |
+-------+------+------+
| 95.88 | 72.2 | 78.0 |
+-------+------+------+
2023-03-29 16:54:15,979 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 16:54:15,979 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9588, mIoU: 0.7220, mAcc: 0.7800, IoU.Bicyclist: 0.8311, IoU.Building: 0.9243, IoU.Car: 0.9151, IoU.Column_Pole: 0.1254, IoU.Fence: 0.7876, IoU.Pedestrian: 0.6211, IoU.Road: 0.9740, IoU.Sidewalk: 0.9080, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9372, IoU.Tree: 0.9182, Acc.Bicyclist: 0.8973, Acc.Building: 0.9421, Acc.Car: 0.9425, Acc.Column_Pole: 0.1364, Acc.Fence: 0.9454, Acc.Pedestrian: 0.8114, Acc.Road: 0.9835, Acc.Sidewalk: 0.9740, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9649, Acc.Tree: 0.9824
2023-03-29 16:55:22,295 - mmseg - INFO - Iter [6050/10000]	lr: 4.336e-03, eta: 1:26:51, time: 1.396, data_time: 0.384, memory: 9072, decode.loss_ce: 0.0750, decode.acc_seg: 95.8663, aux_0.loss_ce: 0.0794, aux_0.acc_seg: 95.7022, aux_1.loss_ce: 0.0918, aux_1.acc_seg: 95.0937, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2638, aux_2.acc_seg: 95.8584, aux_3.loss_ce: 0.1050, aux_3.acc_seg: 95.0028, loss: 0.7409
2023-03-29 16:56:24,724 - mmseg - INFO - Iter [6100/10000]	lr: 4.287e-03, eta: 1:25:43, time: 1.248, data_time: 0.244, memory: 9072, decode.loss_ce: 0.0720, decode.acc_seg: 95.9444, aux_0.loss_ce: 0.0767, aux_0.acc_seg: 95.7702, aux_1.loss_ce: 0.0862, aux_1.acc_seg: 95.1981, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2625, aux_2.acc_seg: 95.8859, aux_3.loss_ce: 0.1025, aux_3.acc_seg: 95.0581, loss: 0.7249
2023-03-29 16:57:26,023 - mmseg - INFO - Iter [6150/10000]	lr: 4.237e-03, eta: 1:24:34, time: 1.226, data_time: 0.256, memory: 9072, decode.loss_ce: 0.0764, decode.acc_seg: 95.7966, aux_0.loss_ce: 0.0808, aux_0.acc_seg: 95.6426, aux_1.loss_ce: 0.0926, aux_1.acc_seg: 95.0228, aux_2.loss_ce: 0.1273, aux_2.loss_dice: 0.2640, aux_2.acc_seg: 95.7865, aux_3.loss_ce: 0.1073, aux_3.acc_seg: 94.8977, loss: 0.7484
2023-03-29 16:58:32,383 - mmseg - INFO - Iter [6200/10000]	lr: 4.188e-03, eta: 1:23:29, time: 1.327, data_time: 0.311, memory: 9072, decode.loss_ce: 0.0728, decode.acc_seg: 95.9280, aux_0.loss_ce: 0.0768, aux_0.acc_seg: 95.7712, aux_1.loss_ce: 0.0881, aux_1.acc_seg: 95.1801, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 95.8083, aux_3.loss_ce: 0.1024, aux_3.acc_seg: 95.0688, loss: 0.7305
2023-03-29 16:59:34,351 - mmseg - INFO - Iter [6250/10000]	lr: 4.138e-03, eta: 1:22:20, time: 1.239, data_time: 0.257, memory: 9072, decode.loss_ce: 0.0744, decode.acc_seg: 95.8907, aux_0.loss_ce: 0.0793, aux_0.acc_seg: 95.7236, aux_1.loss_ce: 0.0899, aux_1.acc_seg: 95.1440, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8562, aux_3.loss_ce: 0.1041, aux_3.acc_seg: 95.0127, loss: 0.7362
2023-03-29 17:00:38,019 - mmseg - INFO - Iter [6300/10000]	lr: 4.088e-03, eta: 1:21:13, time: 1.273, data_time: 0.246, memory: 9072, decode.loss_ce: 0.0735, decode.acc_seg: 95.9198, aux_0.loss_ce: 0.0777, aux_0.acc_seg: 95.7477, aux_1.loss_ce: 0.0894, aux_1.acc_seg: 95.1490, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 95.8283, aux_3.loss_ce: 0.1031, aux_3.acc_seg: 95.0407, loss: 0.7324
2023-03-29 17:01:45,196 - mmseg - INFO - Iter [6350/10000]	lr: 4.039e-03, eta: 1:20:08, time: 1.343, data_time: 0.336, memory: 9072, decode.loss_ce: 0.0749, decode.acc_seg: 95.8219, aux_0.loss_ce: 0.0791, aux_0.acc_seg: 95.6711, aux_1.loss_ce: 0.0905, aux_1.acc_seg: 95.0781, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 95.8501, aux_3.loss_ce: 0.1057, aux_3.acc_seg: 94.9364, loss: 0.7379
2023-03-29 17:02:45,834 - mmseg - INFO - Iter [6400/10000]	lr: 3.989e-03, eta: 1:18:59, time: 1.213, data_time: 0.254, memory: 9072, decode.loss_ce: 0.0729, decode.acc_seg: 95.9650, aux_0.loss_ce: 0.0774, aux_0.acc_seg: 95.8094, aux_1.loss_ce: 0.0887, aux_1.acc_seg: 95.2113, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2629, aux_2.acc_seg: 95.8878, aux_3.loss_ce: 0.1025, aux_3.acc_seg: 95.0932, loss: 0.7301
2023-03-29 17:03:48,239 - mmseg - INFO - Iter [6450/10000]	lr: 3.939e-03, eta: 1:17:52, time: 1.248, data_time: 0.236, memory: 9072, decode.loss_ce: 0.0732, decode.acc_seg: 95.9388, aux_0.loss_ce: 0.0766, aux_0.acc_seg: 95.7904, aux_1.loss_ce: 0.0883, aux_1.acc_seg: 95.1910, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2629, aux_2.acc_seg: 95.8448, aux_3.loss_ce: 0.1022, aux_3.acc_seg: 95.0689, loss: 0.7291
2023-03-29 17:04:54,980 - mmseg - INFO - Iter [6500/10000]	lr: 3.889e-03, eta: 1:16:46, time: 1.335, data_time: 0.313, memory: 9072, decode.loss_ce: 0.0734, decode.acc_seg: 95.9749, aux_0.loss_ce: 0.0780, aux_0.acc_seg: 95.8051, aux_1.loss_ce: 0.0887, aux_1.acc_seg: 95.2292, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 95.8324, aux_3.loss_ce: 0.1025, aux_3.acc_seg: 95.1185, loss: 0.7325
2023-03-29 17:05:55,568 - mmseg - INFO - Iter [6550/10000]	lr: 3.839e-03, eta: 1:15:38, time: 1.212, data_time: 0.258, memory: 9072, decode.loss_ce: 0.0734, decode.acc_seg: 95.9378, aux_0.loss_ce: 0.0773, aux_0.acc_seg: 95.7992, aux_1.loss_ce: 0.0891, aux_1.acc_seg: 95.1745, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2632, aux_2.acc_seg: 95.8515, aux_3.loss_ce: 0.1026, aux_3.acc_seg: 95.0562, loss: 0.7317
2023-03-29 17:06:57,886 - mmseg - INFO - Iter [6600/10000]	lr: 3.789e-03, eta: 1:14:30, time: 1.246, data_time: 0.240, memory: 9072, decode.loss_ce: 0.0711, decode.acc_seg: 95.9927, aux_0.loss_ce: 0.0757, aux_0.acc_seg: 95.8353, aux_1.loss_ce: 0.0861, aux_1.acc_seg: 95.2539, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.8834, aux_3.loss_ce: 0.1000, aux_3.acc_seg: 95.1223, loss: 0.7195
2023-03-29 17:08:05,556 - mmseg - INFO - Iter [6650/10000]	lr: 3.739e-03, eta: 1:13:25, time: 1.353, data_time: 0.319, memory: 9072, decode.loss_ce: 0.0714, decode.acc_seg: 95.9335, aux_0.loss_ce: 0.0751, aux_0.acc_seg: 95.7811, aux_1.loss_ce: 0.0861, aux_1.acc_seg: 95.1840, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 95.8630, aux_3.loss_ce: 0.1006, aux_3.acc_seg: 95.0466, loss: 0.7218
2023-03-29 17:09:05,743 - mmseg - INFO - Iter [6700/10000]	lr: 3.689e-03, eta: 1:12:17, time: 1.204, data_time: 0.239, memory: 9072, decode.loss_ce: 0.0726, decode.acc_seg: 95.9598, aux_0.loss_ce: 0.0765, aux_0.acc_seg: 95.8197, aux_1.loss_ce: 0.0874, aux_1.acc_seg: 95.2045, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2619, aux_2.acc_seg: 95.8669, aux_3.loss_ce: 0.1010, aux_3.acc_seg: 95.0851, loss: 0.7249
2023-03-29 17:10:08,687 - mmseg - INFO - Iter [6750/10000]	lr: 3.638e-03, eta: 1:11:10, time: 1.259, data_time: 0.250, memory: 9072, decode.loss_ce: 0.0724, decode.acc_seg: 95.9945, aux_0.loss_ce: 0.0773, aux_0.acc_seg: 95.8248, aux_1.loss_ce: 0.0878, aux_1.acc_seg: 95.2501, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.9005, aux_3.loss_ce: 0.1015, aux_3.acc_seg: 95.1253, loss: 0.7265
2023-03-29 17:11:16,784 - mmseg - INFO - Iter [6800/10000]	lr: 3.588e-03, eta: 1:10:05, time: 1.362, data_time: 0.343, memory: 9072, decode.loss_ce: 0.0735, decode.acc_seg: 95.9067, aux_0.loss_ce: 0.0777, aux_0.acc_seg: 95.7492, aux_1.loss_ce: 0.0894, aux_1.acc_seg: 95.1458, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 95.8549, aux_3.loss_ce: 0.1026, aux_3.acc_seg: 95.0185, loss: 0.7325
2023-03-29 17:12:16,303 - mmseg - INFO - Iter [6850/10000]	lr: 3.537e-03, eta: 1:08:57, time: 1.190, data_time: 0.243, memory: 9072, decode.loss_ce: 0.0718, decode.acc_seg: 96.0232, aux_0.loss_ce: 0.0763, aux_0.acc_seg: 95.8780, aux_1.loss_ce: 0.0872, aux_1.acc_seg: 95.2651, aux_2.loss_ce: 0.1259, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 95.8674, aux_3.loss_ce: 0.1005, aux_3.acc_seg: 95.1485, loss: 0.7247
2023-03-29 17:13:01,714 - mmseg - INFO - Iter [6900/10000]	lr: 3.487e-03, eta: 1:07:42, time: 0.908, data_time: 0.241, memory: 9072, decode.loss_ce: 0.0717, decode.acc_seg: 95.9767, aux_0.loss_ce: 0.0761, aux_0.acc_seg: 95.8243, aux_1.loss_ce: 0.0873, aux_1.acc_seg: 95.2126, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.9040, aux_3.loss_ce: 0.1002, aux_3.acc_seg: 95.0993, loss: 0.7208
2023-03-29 17:13:47,519 - mmseg - INFO - Iter [6950/10000]	lr: 3.436e-03, eta: 1:06:28, time: 0.916, data_time: 0.306, memory: 9072, decode.loss_ce: 0.0713, decode.acc_seg: 95.9862, aux_0.loss_ce: 0.0754, aux_0.acc_seg: 95.8173, aux_1.loss_ce: 0.0871, aux_1.acc_seg: 95.2060, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8497, aux_3.loss_ce: 0.1007, aux_3.acc_seg: 95.0924, loss: 0.7207
2023-03-29 17:14:29,729 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-03-29 17:14:31,498 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 17:14:31,499 - mmseg - INFO - Iter [7000/10000]	lr: 3.386e-03, eta: 1:05:13, time: 0.880, data_time: 0.235, memory: 9072, decode.loss_ce: 0.0720, decode.acc_seg: 95.9223, aux_0.loss_ce: 0.0753, aux_0.acc_seg: 95.7788, aux_1.loss_ce: 0.0868, aux_1.acc_seg: 95.1541, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2618, aux_2.acc_seg: 95.8864, aux_3.loss_ce: 0.1009, aux_3.acc_seg: 95.0169, loss: 0.7219
2023-03-29 17:14:34,545 - mmseg - INFO - per class results:
2023-03-29 17:14:34,546 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.81 | 90.32 |
|   Building  | 92.29 | 93.99 |
|     Car     | 91.51 | 94.14 |
| Column_Pole | 14.71 | 16.32 |
|    Fence    | 79.29 | 94.17 |
|  Pedestrian | 62.46 | 83.65 |
|     Road    | 97.49 | 98.49 |
|   Sidewalk  | 91.05 | 97.18 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.71 | 96.45 |
|     Tree    | 91.61 | 98.25 |
+-------------+-------+-------+
2023-03-29 17:14:34,546 - mmseg - INFO - Summary:
2023-03-29 17:14:34,546 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.88 | 72.45 | 78.45 |
+-------+-------+-------+
2023-03-29 17:14:34,546 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 17:14:34,546 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9588, mIoU: 0.7245, mAcc: 0.7845, IoU.Bicyclist: 0.8281, IoU.Building: 0.9229, IoU.Car: 0.9151, IoU.Column_Pole: 0.1471, IoU.Fence: 0.7929, IoU.Pedestrian: 0.6246, IoU.Road: 0.9749, IoU.Sidewalk: 0.9105, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9371, IoU.Tree: 0.9161, Acc.Bicyclist: 0.9032, Acc.Building: 0.9399, Acc.Car: 0.9414, Acc.Column_Pole: 0.1632, Acc.Fence: 0.9417, Acc.Pedestrian: 0.8365, Acc.Road: 0.9849, Acc.Sidewalk: 0.9718, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9645, Acc.Tree: 0.9825
2023-03-29 17:15:16,367 - mmseg - INFO - Iter [7050/10000]	lr: 3.335e-03, eta: 1:03:59, time: 0.897, data_time: 0.291, memory: 9072, decode.loss_ce: 0.0725, decode.acc_seg: 95.9908, aux_0.loss_ce: 0.0759, aux_0.acc_seg: 95.8450, aux_1.loss_ce: 0.0883, aux_1.acc_seg: 95.2368, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2618, aux_2.acc_seg: 95.9018, aux_3.loss_ce: 0.1005, aux_3.acc_seg: 95.1154, loss: 0.7235
2023-03-29 17:16:02,098 - mmseg - INFO - Iter [7100/10000]	lr: 3.284e-03, eta: 1:02:46, time: 0.915, data_time: 0.305, memory: 9072, decode.loss_ce: 0.0720, decode.acc_seg: 95.9456, aux_0.loss_ce: 0.0768, aux_0.acc_seg: 95.7938, aux_1.loss_ce: 0.0867, aux_1.acc_seg: 95.2000, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2619, aux_2.acc_seg: 95.8555, aux_3.loss_ce: 0.1004, aux_3.acc_seg: 95.0756, loss: 0.7233
2023-03-29 17:16:44,109 - mmseg - INFO - Iter [7150/10000]	lr: 3.233e-03, eta: 1:01:32, time: 0.840, data_time: 0.233, memory: 9072, decode.loss_ce: 0.0715, decode.acc_seg: 96.0172, aux_0.loss_ce: 0.0752, aux_0.acc_seg: 95.8889, aux_1.loss_ce: 0.0863, aux_1.acc_seg: 95.2507, aux_2.loss_ce: 0.1243, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 95.9085, aux_3.loss_ce: 0.0997, aux_3.acc_seg: 95.1538, loss: 0.7185
2023-03-29 17:17:25,277 - mmseg - INFO - Iter [7200/10000]	lr: 3.182e-03, eta: 1:00:18, time: 0.823, data_time: 0.225, memory: 9072, decode.loss_ce: 0.0720, decode.acc_seg: 96.0259, aux_0.loss_ce: 0.0756, aux_0.acc_seg: 95.8862, aux_1.loss_ce: 0.0870, aux_1.acc_seg: 95.2774, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 95.8228, aux_3.loss_ce: 0.0996, aux_3.acc_seg: 95.1423, loss: 0.7230
2023-03-29 17:18:10,882 - mmseg - INFO - Iter [7250/10000]	lr: 3.131e-03, eta: 0:59:07, time: 0.912, data_time: 0.302, memory: 9072, decode.loss_ce: 0.0701, decode.acc_seg: 96.0633, aux_0.loss_ce: 0.0741, aux_0.acc_seg: 95.9201, aux_1.loss_ce: 0.0844, aux_1.acc_seg: 95.3522, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 95.9208, aux_3.loss_ce: 0.0979, aux_3.acc_seg: 95.2068, loss: 0.7119
2023-03-29 17:18:52,935 - mmseg - INFO - Iter [7300/10000]	lr: 3.079e-03, eta: 0:57:54, time: 0.841, data_time: 0.242, memory: 9072, decode.loss_ce: 0.0722, decode.acc_seg: 95.9481, aux_0.loss_ce: 0.0771, aux_0.acc_seg: 95.7918, aux_1.loss_ce: 0.0876, aux_1.acc_seg: 95.1860, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8386, aux_3.loss_ce: 0.1006, aux_3.acc_seg: 95.0487, loss: 0.7243
2023-03-29 17:19:34,177 - mmseg - INFO - Iter [7350/10000]	lr: 3.028e-03, eta: 0:56:41, time: 0.825, data_time: 0.223, memory: 9072, decode.loss_ce: 0.0716, decode.acc_seg: 95.9804, aux_0.loss_ce: 0.0763, aux_0.acc_seg: 95.8208, aux_1.loss_ce: 0.0872, aux_1.acc_seg: 95.2167, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8906, aux_3.loss_ce: 0.1001, aux_3.acc_seg: 95.0797, loss: 0.7211
2023-03-29 17:20:18,918 - mmseg - INFO - Iter [7400/10000]	lr: 2.977e-03, eta: 0:55:30, time: 0.895, data_time: 0.292, memory: 9072, decode.loss_ce: 0.0707, decode.acc_seg: 96.0601, aux_0.loss_ce: 0.0749, aux_0.acc_seg: 95.8963, aux_1.loss_ce: 0.0851, aux_1.acc_seg: 95.3054, aux_2.loss_ce: 0.1230, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 95.9486, aux_3.loss_ce: 0.0980, aux_3.acc_seg: 95.1806, loss: 0.7121
2023-03-29 17:21:00,464 - mmseg - INFO - Iter [7450/10000]	lr: 2.925e-03, eta: 0:54:18, time: 0.831, data_time: 0.226, memory: 9072, decode.loss_ce: 0.0717, decode.acc_seg: 96.0001, aux_0.loss_ce: 0.0760, aux_0.acc_seg: 95.8517, aux_1.loss_ce: 0.0872, aux_1.acc_seg: 95.2238, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8290, aux_3.loss_ce: 0.1005, aux_3.acc_seg: 95.0643, loss: 0.7237
2023-03-29 17:21:42,598 - mmseg - INFO - Iter [7500/10000]	lr: 2.873e-03, eta: 0:53:07, time: 0.843, data_time: 0.233, memory: 9072, decode.loss_ce: 0.0711, decode.acc_seg: 96.0222, aux_0.loss_ce: 0.0751, aux_0.acc_seg: 95.8840, aux_1.loss_ce: 0.0853, aux_1.acc_seg: 95.2870, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 95.8674, aux_3.loss_ce: 0.0994, aux_3.acc_seg: 95.1301, loss: 0.7180
2023-03-29 17:22:28,204 - mmseg - INFO - Iter [7550/10000]	lr: 2.822e-03, eta: 0:51:58, time: 0.912, data_time: 0.301, memory: 9072, decode.loss_ce: 0.0721, decode.acc_seg: 96.0402, aux_0.loss_ce: 0.0765, aux_0.acc_seg: 95.8905, aux_1.loss_ce: 0.0880, aux_1.acc_seg: 95.2713, aux_2.loss_ce: 0.1255, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8500, aux_3.loss_ce: 0.1001, aux_3.acc_seg: 95.1465, loss: 0.7242
2023-03-29 17:23:09,765 - mmseg - INFO - Iter [7600/10000]	lr: 2.770e-03, eta: 0:50:47, time: 0.831, data_time: 0.224, memory: 9072, decode.loss_ce: 0.0695, decode.acc_seg: 96.0658, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 95.9167, aux_1.loss_ce: 0.0844, aux_1.acc_seg: 95.3077, aux_2.loss_ce: 0.1257, aux_2.loss_dice: 0.2617, aux_2.acc_seg: 95.8222, aux_3.loss_ce: 0.0972, aux_3.acc_seg: 95.1727, loss: 0.7117
2023-03-29 17:23:52,682 - mmseg - INFO - Iter [7650/10000]	lr: 2.718e-03, eta: 0:49:37, time: 0.858, data_time: 0.244, memory: 9072, decode.loss_ce: 0.0690, decode.acc_seg: 96.0524, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 95.8975, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.2823, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8213, aux_3.loss_ce: 0.0968, aux_3.acc_seg: 95.1714, loss: 0.7098
2023-03-29 17:24:37,795 - mmseg - INFO - Iter [7700/10000]	lr: 2.666e-03, eta: 0:48:28, time: 0.902, data_time: 0.296, memory: 9072, decode.loss_ce: 0.0716, decode.acc_seg: 95.9979, aux_0.loss_ce: 0.0757, aux_0.acc_seg: 95.8262, aux_1.loss_ce: 0.0870, aux_1.acc_seg: 95.2185, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8266, aux_3.loss_ce: 0.0990, aux_3.acc_seg: 95.1016, loss: 0.7204
2023-03-29 17:25:20,021 - mmseg - INFO - Iter [7750/10000]	lr: 2.614e-03, eta: 0:47:19, time: 0.844, data_time: 0.231, memory: 9072, decode.loss_ce: 0.0697, decode.acc_seg: 96.0719, aux_0.loss_ce: 0.0739, aux_0.acc_seg: 95.9231, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.3134, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 95.9141, aux_3.loss_ce: 0.0973, aux_3.acc_seg: 95.1791, loss: 0.7102
2023-03-29 17:26:02,566 - mmseg - INFO - Iter [7800/10000]	lr: 2.561e-03, eta: 0:46:10, time: 0.851, data_time: 0.235, memory: 9072, decode.loss_ce: 0.0700, decode.acc_seg: 96.0677, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 95.9057, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.3005, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.8273, aux_3.loss_ce: 0.0977, aux_3.acc_seg: 95.1500, loss: 0.7128
2023-03-29 17:26:47,414 - mmseg - INFO - Iter [7850/10000]	lr: 2.509e-03, eta: 0:45:02, time: 0.897, data_time: 0.290, memory: 9072, decode.loss_ce: 0.0689, decode.acc_seg: 96.0786, aux_0.loss_ce: 0.0727, aux_0.acc_seg: 95.9361, aux_1.loss_ce: 0.0833, aux_1.acc_seg: 95.3371, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 95.8832, aux_3.loss_ce: 0.0962, aux_3.acc_seg: 95.1949, loss: 0.7069
2023-03-29 17:27:29,089 - mmseg - INFO - Iter [7900/10000]	lr: 2.457e-03, eta: 0:43:54, time: 0.833, data_time: 0.227, memory: 9072, decode.loss_ce: 0.0691, decode.acc_seg: 96.0957, aux_0.loss_ce: 0.0725, aux_0.acc_seg: 95.9570, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.3815, aux_2.loss_ce: 0.1241, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8902, aux_3.loss_ce: 0.0962, aux_3.acc_seg: 95.2255, loss: 0.7060
2023-03-29 17:28:10,517 - mmseg - INFO - Iter [7950/10000]	lr: 2.404e-03, eta: 0:42:45, time: 0.829, data_time: 0.227, memory: 9072, decode.loss_ce: 0.0715, decode.acc_seg: 96.0640, aux_0.loss_ce: 0.0751, aux_0.acc_seg: 95.9122, aux_1.loss_ce: 0.0864, aux_1.acc_seg: 95.3064, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8612, aux_3.loss_ce: 0.0996, aux_3.acc_seg: 95.1470, loss: 0.7196
2023-03-29 17:28:55,466 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-03-29 17:28:57,317 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 17:28:57,317 - mmseg - INFO - Iter [8000/10000]	lr: 2.351e-03, eta: 0:41:39, time: 0.936, data_time: 0.288, memory: 9072, decode.loss_ce: 0.0704, decode.acc_seg: 96.0616, aux_0.loss_ce: 0.0748, aux_0.acc_seg: 95.9242, aux_1.loss_ce: 0.0854, aux_1.acc_seg: 95.3204, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2619, aux_2.acc_seg: 95.8770, aux_3.loss_ce: 0.0980, aux_3.acc_seg: 95.1540, loss: 0.7157
2023-03-29 17:29:00,596 - mmseg - INFO - per class results:
2023-03-29 17:29:00,597 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.23 |  88.5 |
|   Building  | 92.74 | 94.53 |
|     Car     | 92.02 | 94.78 |
| Column_Pole | 15.38 | 16.89 |
|    Fence    | 79.58 |  94.7 |
|  Pedestrian | 61.73 |  82.5 |
|     Road    | 97.42 | 98.37 |
|   Sidewalk  | 91.09 | 97.37 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.73 | 96.62 |
|     Tree    | 92.09 | 98.18 |
+-------------+-------+-------+
2023-03-29 17:29:00,597 - mmseg - INFO - Summary:
2023-03-29 17:29:00,597 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 95.98 | 72.55 | 78.4 |
+-------+-------+------+
2023-03-29 17:29:00,597 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 17:29:00,597 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9598, mIoU: 0.7255, mAcc: 0.7840, IoU.Bicyclist: 0.8223, IoU.Building: 0.9274, IoU.Car: 0.9202, IoU.Column_Pole: 0.1538, IoU.Fence: 0.7958, IoU.Pedestrian: 0.6173, IoU.Road: 0.9742, IoU.Sidewalk: 0.9109, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9373, IoU.Tree: 0.9209, Acc.Bicyclist: 0.8850, Acc.Building: 0.9453, Acc.Car: 0.9478, Acc.Column_Pole: 0.1689, Acc.Fence: 0.9470, Acc.Pedestrian: 0.8250, Acc.Road: 0.9837, Acc.Sidewalk: 0.9737, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9662, Acc.Tree: 0.9818
2023-03-29 17:29:42,158 - mmseg - INFO - Iter [8050/10000]	lr: 2.298e-03, eta: 0:40:32, time: 0.897, data_time: 0.294, memory: 9072, decode.loss_ce: 0.0702, decode.acc_seg: 96.0508, aux_0.loss_ce: 0.0744, aux_0.acc_seg: 95.9016, aux_1.loss_ce: 0.0851, aux_1.acc_seg: 95.3019, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.9058, aux_3.loss_ce: 0.0979, aux_3.acc_seg: 95.1478, loss: 0.7133
2023-03-29 17:30:24,279 - mmseg - INFO - Iter [8100/10000]	lr: 2.245e-03, eta: 0:39:25, time: 0.842, data_time: 0.238, memory: 9072, decode.loss_ce: 0.0717, decode.acc_seg: 96.0400, aux_0.loss_ce: 0.0766, aux_0.acc_seg: 95.8980, aux_1.loss_ce: 0.0871, aux_1.acc_seg: 95.2919, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 95.8178, aux_3.loss_ce: 0.0995, aux_3.acc_seg: 95.1374, loss: 0.7242
2023-03-29 17:31:09,695 - mmseg - INFO - Iter [8150/10000]	lr: 2.192e-03, eta: 0:38:19, time: 0.908, data_time: 0.301, memory: 9072, decode.loss_ce: 0.0685, decode.acc_seg: 96.0737, aux_0.loss_ce: 0.0724, aux_0.acc_seg: 95.9270, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.3100, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 95.9177, aux_3.loss_ce: 0.0958, aux_3.acc_seg: 95.1671, loss: 0.7044
2023-03-29 17:31:51,875 - mmseg - INFO - Iter [8200/10000]	lr: 2.139e-03, eta: 0:37:12, time: 0.844, data_time: 0.236, memory: 9072, decode.loss_ce: 0.0704, decode.acc_seg: 96.0787, aux_0.loss_ce: 0.0746, aux_0.acc_seg: 95.9313, aux_1.loss_ce: 0.0860, aux_1.acc_seg: 95.3179, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8813, aux_3.loss_ce: 0.0975, aux_3.acc_seg: 95.1552, loss: 0.7139
2023-03-29 17:32:34,062 - mmseg - INFO - Iter [8250/10000]	lr: 2.085e-03, eta: 0:36:06, time: 0.844, data_time: 0.237, memory: 9072, decode.loss_ce: 0.0705, decode.acc_seg: 96.0704, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 95.9194, aux_1.loss_ce: 0.0859, aux_1.acc_seg: 95.2988, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8335, aux_3.loss_ce: 0.0978, aux_3.acc_seg: 95.1551, loss: 0.7150
2023-03-29 17:33:19,310 - mmseg - INFO - Iter [8300/10000]	lr: 2.031e-03, eta: 0:35:01, time: 0.905, data_time: 0.295, memory: 9072, decode.loss_ce: 0.0688, decode.acc_seg: 96.1167, aux_0.loss_ce: 0.0729, aux_0.acc_seg: 95.9643, aux_1.loss_ce: 0.0839, aux_1.acc_seg: 95.3489, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 95.8681, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.2316, loss: 0.7067
2023-03-29 17:34:01,527 - mmseg - INFO - Iter [8350/10000]	lr: 1.978e-03, eta: 0:33:55, time: 0.844, data_time: 0.237, memory: 9072, decode.loss_ce: 0.0701, decode.acc_seg: 96.0611, aux_0.loss_ce: 0.0742, aux_0.acc_seg: 95.9222, aux_1.loss_ce: 0.0855, aux_1.acc_seg: 95.3063, aux_2.loss_ce: 0.1250, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8308, aux_3.loss_ce: 0.0967, aux_3.acc_seg: 95.1801, loss: 0.7123
2023-03-29 17:34:43,747 - mmseg - INFO - Iter [8400/10000]	lr: 1.924e-03, eta: 0:32:50, time: 0.844, data_time: 0.237, memory: 9072, decode.loss_ce: 0.0688, decode.acc_seg: 96.1072, aux_0.loss_ce: 0.0729, aux_0.acc_seg: 95.9624, aux_1.loss_ce: 0.0844, aux_1.acc_seg: 95.3359, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8673, aux_3.loss_ce: 0.0960, aux_3.acc_seg: 95.2069, loss: 0.7075
2023-03-29 17:35:29,076 - mmseg - INFO - Iter [8450/10000]	lr: 1.870e-03, eta: 0:31:45, time: 0.907, data_time: 0.292, memory: 9072, decode.loss_ce: 0.0689, decode.acc_seg: 96.1187, aux_0.loss_ce: 0.0730, aux_0.acc_seg: 95.9722, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.3668, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2606, aux_2.acc_seg: 95.8629, aux_3.loss_ce: 0.0957, aux_3.acc_seg: 95.2272, loss: 0.7066
2023-03-29 17:36:12,196 - mmseg - INFO - Iter [8500/10000]	lr: 1.815e-03, eta: 0:30:41, time: 0.862, data_time: 0.253, memory: 9072, decode.loss_ce: 0.0705, decode.acc_seg: 96.0286, aux_0.loss_ce: 0.0749, aux_0.acc_seg: 95.8781, aux_1.loss_ce: 0.0853, aux_1.acc_seg: 95.2853, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2624, aux_2.acc_seg: 95.8363, aux_3.loss_ce: 0.0978, aux_3.acc_seg: 95.1281, loss: 0.7167
2023-03-29 17:36:53,666 - mmseg - INFO - Iter [8550/10000]	lr: 1.761e-03, eta: 0:29:36, time: 0.829, data_time: 0.231, memory: 9072, decode.loss_ce: 0.0683, decode.acc_seg: 96.1256, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 95.9789, aux_1.loss_ce: 0.0826, aux_1.acc_seg: 95.3565, aux_2.loss_ce: 0.1234, aux_2.loss_dice: 0.2598, aux_2.acc_seg: 95.9118, aux_3.loss_ce: 0.0949, aux_3.acc_seg: 95.2267, loss: 0.7013
2023-03-29 17:37:39,384 - mmseg - INFO - Iter [8600/10000]	lr: 1.706e-03, eta: 0:28:32, time: 0.914, data_time: 0.312, memory: 9072, decode.loss_ce: 0.0703, decode.acc_seg: 96.0900, aux_0.loss_ce: 0.0747, aux_0.acc_seg: 95.9510, aux_1.loss_ce: 0.0847, aux_1.acc_seg: 95.3559, aux_2.loss_ce: 0.1236, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.9083, aux_3.loss_ce: 0.0965, aux_3.acc_seg: 95.2156, loss: 0.7101
2023-03-29 17:38:21,099 - mmseg - INFO - Iter [8650/10000]	lr: 1.651e-03, eta: 0:27:28, time: 0.834, data_time: 0.234, memory: 9072, decode.loss_ce: 0.0688, decode.acc_seg: 96.1588, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 96.0099, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.4274, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8336, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.2876, loss: 0.7068
2023-03-29 17:39:02,119 - mmseg - INFO - Iter [8700/10000]	lr: 1.596e-03, eta: 0:26:24, time: 0.820, data_time: 0.224, memory: 9072, decode.loss_ce: 0.0694, decode.acc_seg: 96.0575, aux_0.loss_ce: 0.0730, aux_0.acc_seg: 95.9159, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.3069, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8584, aux_3.loss_ce: 0.0962, aux_3.acc_seg: 95.1576, loss: 0.7087
2023-03-29 17:39:47,509 - mmseg - INFO - Iter [8750/10000]	lr: 1.541e-03, eta: 0:25:21, time: 0.908, data_time: 0.298, memory: 9072, decode.loss_ce: 0.0669, decode.acc_seg: 96.1616, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 95.9999, aux_1.loss_ce: 0.0817, aux_1.acc_seg: 95.4081, aux_2.loss_ce: 0.1230, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 95.9038, aux_3.loss_ce: 0.0938, aux_3.acc_seg: 95.2421, loss: 0.6960
2023-03-29 17:40:29,540 - mmseg - INFO - Iter [8800/10000]	lr: 1.485e-03, eta: 0:24:17, time: 0.841, data_time: 0.235, memory: 9072, decode.loss_ce: 0.0676, decode.acc_seg: 96.1483, aux_0.loss_ce: 0.0714, aux_0.acc_seg: 96.0062, aux_1.loss_ce: 0.0816, aux_1.acc_seg: 95.4403, aux_2.loss_ce: 0.1232, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 95.9151, aux_3.loss_ce: 0.0938, aux_3.acc_seg: 95.2788, loss: 0.6970
2023-03-29 17:41:11,186 - mmseg - INFO - Iter [8850/10000]	lr: 1.430e-03, eta: 0:23:14, time: 0.833, data_time: 0.234, memory: 9072, decode.loss_ce: 0.0669, decode.acc_seg: 96.1819, aux_0.loss_ce: 0.0701, aux_0.acc_seg: 96.0497, aux_1.loss_ce: 0.0809, aux_1.acc_seg: 95.4455, aux_2.loss_ce: 0.1230, aux_2.loss_dice: 0.2595, aux_2.acc_seg: 95.9360, aux_3.loss_ce: 0.0934, aux_3.acc_seg: 95.2727, loss: 0.6939
2023-03-29 17:41:56,891 - mmseg - INFO - Iter [8900/10000]	lr: 1.374e-03, eta: 0:22:12, time: 0.914, data_time: 0.309, memory: 9072, decode.loss_ce: 0.0693, decode.acc_seg: 96.1152, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.9652, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.3811, aux_2.loss_ce: 0.1249, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.8713, aux_3.loss_ce: 0.0955, aux_3.acc_seg: 95.2319, loss: 0.7094
2023-03-29 17:42:55,386 - mmseg - INFO - Iter [8950/10000]	lr: 1.317e-03, eta: 0:21:11, time: 1.170, data_time: 0.228, memory: 9072, decode.loss_ce: 0.0682, decode.acc_seg: 96.1076, aux_0.loss_ce: 0.0725, aux_0.acc_seg: 95.9580, aux_1.loss_ce: 0.0836, aux_1.acc_seg: 95.3547, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2599, aux_2.acc_seg: 95.8708, aux_3.loss_ce: 0.0952, aux_3.acc_seg: 95.2092, loss: 0.7033
2023-03-29 17:44:10,674 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-03-29 17:44:12,046 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 17:44:12,046 - mmseg - INFO - Iter [9000/10000]	lr: 1.261e-03, eta: 0:20:12, time: 1.533, data_time: 0.239, memory: 9072, decode.loss_ce: 0.0688, decode.acc_seg: 96.1311, aux_0.loss_ce: 0.0726, aux_0.acc_seg: 95.9859, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.3945, aux_2.loss_ce: 0.1243, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.8701, aux_3.loss_ce: 0.0947, aux_3.acc_seg: 95.2549, loss: 0.7051
2023-03-29 17:44:15,080 - mmseg - INFO - per class results:
2023-03-29 17:44:15,080 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.81 | 89.58 |
|   Building  | 92.38 | 94.09 |
|     Car     | 91.62 | 94.12 |
| Column_Pole | 15.55 | 17.19 |
|    Fence    | 79.68 |  94.3 |
|  Pedestrian | 62.33 | 83.75 |
|     Road    | 97.47 | 98.45 |
|   Sidewalk  | 91.21 | 97.38 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.73 | 96.69 |
|     Tree    |  91.7 | 98.23 |
+-------------+-------+-------+
2023-03-29 17:44:15,080 - mmseg - INFO - Summary:
2023-03-29 17:44:15,081 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.92 | 72.59 | 78.52 |
+-------+-------+-------+
2023-03-29 17:44:15,081 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 17:44:15,081 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9592, mIoU: 0.7259, mAcc: 0.7852, IoU.Bicyclist: 0.8281, IoU.Building: 0.9238, IoU.Car: 0.9162, IoU.Column_Pole: 0.1555, IoU.Fence: 0.7968, IoU.Pedestrian: 0.6233, IoU.Road: 0.9747, IoU.Sidewalk: 0.9121, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9373, IoU.Tree: 0.9170, Acc.Bicyclist: 0.8958, Acc.Building: 0.9409, Acc.Car: 0.9412, Acc.Column_Pole: 0.1719, Acc.Fence: 0.9430, Acc.Pedestrian: 0.8375, Acc.Road: 0.9845, Acc.Sidewalk: 0.9738, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9669, Acc.Tree: 0.9823
2023-03-29 17:45:34,056 - mmseg - INFO - Iter [9050/10000]	lr: 1.204e-03, eta: 0:19:14, time: 1.640, data_time: 0.368, memory: 9072, decode.loss_ce: 0.0694, decode.acc_seg: 96.1020, aux_0.loss_ce: 0.0736, aux_0.acc_seg: 95.9672, aux_1.loss_ce: 0.0836, aux_1.acc_seg: 95.3642, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8600, aux_3.loss_ce: 0.0954, aux_3.acc_seg: 95.2155, loss: 0.7079
2023-03-29 17:46:49,965 - mmseg - INFO - Iter [9100/10000]	lr: 1.147e-03, eta: 0:18:14, time: 1.518, data_time: 0.249, memory: 9072, decode.loss_ce: 0.0690, decode.acc_seg: 96.0875, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 95.9452, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.3314, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8253, aux_3.loss_ce: 0.0957, aux_3.acc_seg: 95.1829, loss: 0.7083
2023-03-29 17:48:05,420 - mmseg - INFO - Iter [9150/10000]	lr: 1.090e-03, eta: 0:17:15, time: 1.509, data_time: 0.234, memory: 9072, decode.loss_ce: 0.0684, decode.acc_seg: 96.1722, aux_0.loss_ce: 0.0722, aux_0.acc_seg: 96.0218, aux_1.loss_ce: 0.0840, aux_1.acc_seg: 95.4121, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 95.8897, aux_3.loss_ce: 0.0952, aux_3.acc_seg: 95.2388, loss: 0.7057
2023-03-29 17:49:24,408 - mmseg - INFO - Iter [9200/10000]	lr: 1.032e-03, eta: 0:16:16, time: 1.580, data_time: 0.310, memory: 9072, decode.loss_ce: 0.0676, decode.acc_seg: 96.1194, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 95.9555, aux_1.loss_ce: 0.0818, aux_1.acc_seg: 95.3796, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 95.8962, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.2159, loss: 0.6989
2023-03-29 17:50:39,974 - mmseg - INFO - Iter [9250/10000]	lr: 9.738e-04, eta: 0:15:16, time: 1.511, data_time: 0.235, memory: 9072, decode.loss_ce: 0.0703, decode.acc_seg: 96.0743, aux_0.loss_ce: 0.0745, aux_0.acc_seg: 95.9222, aux_1.loss_ce: 0.0852, aux_1.acc_seg: 95.3249, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2614, aux_2.acc_seg: 95.8344, aux_3.loss_ce: 0.0966, aux_3.acc_seg: 95.1688, loss: 0.7136
2023-03-29 17:51:54,529 - mmseg - INFO - Iter [9300/10000]	lr: 9.153e-04, eta: 0:14:16, time: 1.491, data_time: 0.229, memory: 9072, decode.loss_ce: 0.0672, decode.acc_seg: 96.2202, aux_0.loss_ce: 0.0712, aux_0.acc_seg: 96.0585, aux_1.loss_ce: 0.0820, aux_1.acc_seg: 95.4727, aux_2.loss_ce: 0.1242, aux_2.loss_dice: 0.2597, aux_2.acc_seg: 95.8628, aux_3.loss_ce: 0.0930, aux_3.acc_seg: 95.3263, loss: 0.6972
2023-03-29 17:53:11,898 - mmseg - INFO - Iter [9350/10000]	lr: 8.564e-04, eta: 0:13:16, time: 1.547, data_time: 0.284, memory: 9072, decode.loss_ce: 0.0671, decode.acc_seg: 96.1431, aux_0.loss_ce: 0.0707, aux_0.acc_seg: 96.0089, aux_1.loss_ce: 0.0814, aux_1.acc_seg: 95.4239, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.9363, aux_3.loss_ce: 0.0931, aux_3.acc_seg: 95.2585, loss: 0.6960
2023-03-29 17:54:26,874 - mmseg - INFO - Iter [9400/10000]	lr: 7.971e-04, eta: 0:12:15, time: 1.499, data_time: 0.226, memory: 9072, decode.loss_ce: 0.0695, decode.acc_seg: 96.1176, aux_0.loss_ce: 0.0738, aux_0.acc_seg: 95.9812, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.3493, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8172, aux_3.loss_ce: 0.0952, aux_3.acc_seg: 95.2121, loss: 0.7093
2023-03-29 17:55:41,049 - mmseg - INFO - Iter [9450/10000]	lr: 7.372e-04, eta: 0:11:15, time: 1.484, data_time: 0.219, memory: 9072, decode.loss_ce: 0.0685, decode.acc_seg: 96.1285, aux_0.loss_ce: 0.0727, aux_0.acc_seg: 95.9835, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.4064, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 95.8648, aux_3.loss_ce: 0.0945, aux_3.acc_seg: 95.2361, loss: 0.7045
2023-03-29 17:56:58,599 - mmseg - INFO - Iter [9500/10000]	lr: 6.768e-04, eta: 0:10:14, time: 1.551, data_time: 0.283, memory: 9072, decode.loss_ce: 0.0677, decode.acc_seg: 96.1584, aux_0.loss_ce: 0.0718, aux_0.acc_seg: 96.0029, aux_1.loss_ce: 0.0826, aux_1.acc_seg: 95.3982, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2598, aux_2.acc_seg: 95.8672, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.2467, loss: 0.7004
2023-03-29 17:58:13,497 - mmseg - INFO - Iter [9550/10000]	lr: 6.158e-04, eta: 0:09:13, time: 1.498, data_time: 0.225, memory: 9072, decode.loss_ce: 0.0700, decode.acc_seg: 96.0501, aux_0.loss_ce: 0.0749, aux_0.acc_seg: 95.9097, aux_1.loss_ce: 0.0854, aux_1.acc_seg: 95.3121, aux_2.loss_ce: 0.1251, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 95.8432, aux_3.loss_ce: 0.0961, aux_3.acc_seg: 95.1559, loss: 0.7125
2023-03-29 17:59:27,727 - mmseg - INFO - Iter [9600/10000]	lr: 5.541e-04, eta: 0:08:12, time: 1.485, data_time: 0.220, memory: 9072, decode.loss_ce: 0.0693, decode.acc_seg: 96.1500, aux_0.loss_ce: 0.0732, aux_0.acc_seg: 96.0053, aux_1.loss_ce: 0.0844, aux_1.acc_seg: 95.3950, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.8786, aux_3.loss_ce: 0.0945, aux_3.acc_seg: 95.2640, loss: 0.7070
2023-03-29 18:00:44,927 - mmseg - INFO - Iter [9650/10000]	lr: 4.916e-04, eta: 0:07:11, time: 1.544, data_time: 0.279, memory: 9072, decode.loss_ce: 0.0684, decode.acc_seg: 96.1540, aux_0.loss_ce: 0.0716, aux_0.acc_seg: 96.0256, aux_1.loss_ce: 0.0832, aux_1.acc_seg: 95.4168, aux_2.loss_ce: 0.1232, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 95.9118, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.2477, loss: 0.6999
2023-03-29 18:01:58,721 - mmseg - INFO - Iter [9700/10000]	lr: 4.282e-04, eta: 0:06:10, time: 1.476, data_time: 0.219, memory: 9072, decode.loss_ce: 0.0682, decode.acc_seg: 96.1381, aux_0.loss_ce: 0.0718, aux_0.acc_seg: 95.9889, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.3953, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 95.8451, aux_3.loss_ce: 0.0936, aux_3.acc_seg: 95.2629, loss: 0.7027
2023-03-29 18:03:12,523 - mmseg - INFO - Iter [9750/10000]	lr: 3.638e-04, eta: 0:05:09, time: 1.476, data_time: 0.215, memory: 9072, decode.loss_ce: 0.0694, decode.acc_seg: 96.1287, aux_0.loss_ce: 0.0737, aux_0.acc_seg: 95.9792, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.3772, aux_2.loss_ce: 0.1267, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 95.7551, aux_3.loss_ce: 0.0948, aux_3.acc_seg: 95.2392, loss: 0.7105
2023-03-29 18:04:29,776 - mmseg - INFO - Iter [9800/10000]	lr: 2.981e-04, eta: 0:04:07, time: 1.545, data_time: 0.279, memory: 9072, decode.loss_ce: 0.0673, decode.acc_seg: 96.1797, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 96.0555, aux_1.loss_ce: 0.0817, aux_1.acc_seg: 95.4601, aux_2.loss_ce: 0.1245, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 95.8499, aux_3.loss_ce: 0.0926, aux_3.acc_seg: 95.3047, loss: 0.6984
2023-03-29 18:05:44,050 - mmseg - INFO - Iter [9850/10000]	lr: 2.306e-04, eta: 0:03:05, time: 1.485, data_time: 0.222, memory: 9072, decode.loss_ce: 0.0688, decode.acc_seg: 96.1350, aux_0.loss_ce: 0.0728, aux_0.acc_seg: 95.9883, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.3775, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2598, aux_2.acc_seg: 95.8978, aux_3.loss_ce: 0.0943, aux_3.acc_seg: 95.2423, loss: 0.7042
2023-03-29 18:06:58,291 - mmseg - INFO - Iter [9900/10000]	lr: 1.609e-04, eta: 0:02:04, time: 1.485, data_time: 0.220, memory: 9072, decode.loss_ce: 0.0685, decode.acc_seg: 96.1869, aux_0.loss_ce: 0.0723, aux_0.acc_seg: 96.0500, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.4538, aux_2.loss_ce: 0.1258, aux_2.loss_dice: 0.2622, aux_2.acc_seg: 95.8191, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.2826, loss: 0.7057
2023-03-29 18:08:17,260 - mmseg - INFO - Iter [9950/10000]	lr: 8.745e-05, eta: 0:01:02, time: 1.579, data_time: 0.302, memory: 9072, decode.loss_ce: 0.0682, decode.acc_seg: 96.1600, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 96.0133, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.4107, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 95.8828, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.2545, loss: 0.7048
2023-03-29 18:09:32,309 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-03-29 18:09:33,696 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 18:09:33,697 - mmseg - INFO - Iter [10000/10000]	lr: 3.512e-06, eta: 0:00:00, time: 1.529, data_time: 0.240, memory: 9072, decode.loss_ce: 0.0662, decode.acc_seg: 96.2150, aux_0.loss_ce: 0.0708, aux_0.acc_seg: 96.0634, aux_1.loss_ce: 0.0806, aux_1.acc_seg: 95.4828, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2593, aux_2.acc_seg: 95.8693, aux_3.loss_ce: 0.0916, aux_3.acc_seg: 95.3109, loss: 0.6926
2023-03-29 18:09:36,923 - mmseg - INFO - per class results:
2023-03-29 18:09:36,924 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 82.35 | 88.18 |
|   Building  | 92.72 | 94.53 |
|     Car     | 91.92 | 94.43 |
| Column_Pole | 16.38 | 18.14 |
|    Fence    |  79.6 | 94.73 |
|  Pedestrian |  62.1 | 83.53 |
|     Road    | 97.43 | 98.42 |
|   Sidewalk  |  91.2 | 97.38 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.79 | 96.63 |
|     Tree    | 92.08 | 98.13 |
+-------------+-------+-------+
2023-03-29 18:09:36,924 - mmseg - INFO - Summary:
2023-03-29 18:09:36,924 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 96.0 | 72.69 | 78.56 |
+------+-------+-------+
2023-03-29 18:09:36,925 - mmseg - INFO - Exp name: stdc1-csctext_2x12_720x960_10k_camvid.py
2023-03-29 18:09:36,925 - mmseg - INFO - Iter(val) [51]	aAcc: 0.9600, mIoU: 0.7269, mAcc: 0.7856, IoU.Bicyclist: 0.8235, IoU.Building: 0.9272, IoU.Car: 0.9192, IoU.Column_Pole: 0.1638, IoU.Fence: 0.7960, IoU.Pedestrian: 0.6210, IoU.Road: 0.9743, IoU.Sidewalk: 0.9120, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9379, IoU.Tree: 0.9208, Acc.Bicyclist: 0.8818, Acc.Building: 0.9453, Acc.Car: 0.9443, Acc.Column_Pole: 0.1814, Acc.Fence: 0.9473, Acc.Pedestrian: 0.8353, Acc.Road: 0.9842, Acc.Sidewalk: 0.9738, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9663, Acc.Tree: 0.9813
