2023-05-23 20:24:09,808 - mmseg - INFO - Multi-processing start method is `None`
2023-05-23 20:24:09,815 - mmseg - INFO - OpenCV num_threads is `96
2023-05-23 20:24:09,900 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+7bf68e5
------------------------------------------------------------

2023-05-23 20:24:09,901 - mmseg - INFO - Distributed training: False
2023-05-23 20:24:10,922 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False),
        last_in_channels=(1035, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=16,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='CSC',
        CLASSES=('Bicyclist', 'Building', 'Car', 'Column_Pole', 'Fence',
                 'Pedestrian', 'Road', 'Sidewalk', 'SignSymbol', 'Sky',
                 'Tree')),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'),
    init_cfg=dict(
        type='Pretrained',
        checkpoint=
        './work_dirs/entextnet_stdc1_1x16_720x960_10k_camvid_trainval/latest.pth'
    ))
dataset_type = 'CamVidDataset'
data_root = 'data/CamVid/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (720, 960)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        img_scale=(960, 720),
        ratio_range=(0.5, 2.5),
        scale_step_size=0.25),
    dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(960, 720),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='trainval',
        ann_dir='trainval_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize',
                img_scale=(960, 720),
                ratio_range=(0.5, 2.5),
                scale_step_size=0.25),
            dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='test',
        ann_dir='test_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='test',
        ann_dir='test_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.1,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            {
                'backbone.backbone': dict(lr_mult=0.0),
                'backbone.text_encoder': dict(lr_mult=0.0, decay_mult=0.0),
                'backbone.contexts': dict(decay_mult=0.0),
                '.bn.': dict(decay_mult=0.0)
            })))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=200,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(
    interval=1000, metric='mIoU', pre_eval=True, save_best='mIoU')
checkpoint = './work_dirs/entextnet_stdc1_1x16_720x960_10k_camvid_trainval/latest.pth'
work_dir = './work_dirs/tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone'
gpu_ids = [0]
auto_resume = False

2023-05-23 20:24:10,923 - mmseg - INFO - Set random seed to 1045073588, deterministic: False
2023-05-23 20:24:10,930 - mmseg - INFO - Loaded 468 images
2023-05-23 20:24:13,841 - mmseg - INFO - initialize EncoderDecoder with init_cfg {'type': 'Pretrained', 'checkpoint': './work_dirs/entextnet_stdc1_1x16_720x960_10k_camvid_trainval/latest.pth'}
2023-05-23 20:24:16,691 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1035, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1035, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
init_cfg={'type': 'Pretrained', 'checkpoint': './work_dirs/entextnet_stdc1_1x16_720x960_10k_camvid_trainval/latest.pth'}
2023-05-23 20:24:16,836 - mmseg - INFO - Loaded 233 images
2023-05-23 20:24:16,837 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone
2023-05-23 20:24:16,837 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-05-23 20:24:16,837 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-05-23 20:24:16,837 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone by HardDiskBackend.
2023-05-23 20:25:19,210 - mmseg - INFO - Iter [50/10000]	lr: 2.439e-02, eta: 3:25:41, time: 1.240, data_time: 0.387, memory: 14777, decode.loss_ce: 0.0575, decode.acc_seg: 96.9444, aux_0.loss_ce: 0.0595, aux_0.acc_seg: 96.8989, aux_1.loss_ce: 0.0751, aux_1.acc_seg: 96.1080, aux_2.loss_ce: 0.1119, aux_2.loss_dice: 0.2456, aux_2.acc_seg: 96.2359, aux_3.loss_ce: 0.2623, aux_3.acc_seg: 92.0808, loss: 0.8120
2023-05-23 20:26:03,882 - mmseg - INFO - Iter [100/10000]	lr: 4.906e-02, eta: 2:56:02, time: 0.893, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0594, decode.acc_seg: 96.9219, aux_0.loss_ce: 0.0610, aux_0.acc_seg: 96.8944, aux_1.loss_ce: 0.0767, aux_1.acc_seg: 96.1206, aux_2.loss_ce: 0.1139, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.2098, aux_3.loss_ce: 0.1149, aux_3.acc_seg: 95.0105, loss: 0.6744
2023-05-23 20:26:48,314 - mmseg - INFO - Iter [150/10000]	lr: 7.350e-02, eta: 2:45:23, time: 0.889, data_time: 0.193, memory: 14777, decode.loss_ce: 0.0675, decode.acc_seg: 96.5986, aux_0.loss_ce: 0.0690, aux_0.acc_seg: 96.5890, aux_1.loss_ce: 0.0847, aux_1.acc_seg: 95.8009, aux_2.loss_ce: 0.1171, aux_2.loss_dice: 0.2514, aux_2.acc_seg: 96.0932, aux_3.loss_ce: 0.1201, aux_3.acc_seg: 94.8243, loss: 0.7097
2023-05-23 20:27:28,779 - mmseg - INFO - Iter [200/10000]	lr: 9.772e-02, eta: 2:36:27, time: 0.809, data_time: 0.117, memory: 14777, decode.loss_ce: 0.0722, decode.acc_seg: 96.3901, aux_0.loss_ce: 0.0733, aux_0.acc_seg: 96.3726, aux_1.loss_ce: 0.0886, aux_1.acc_seg: 95.6255, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 96.1520, aux_3.loss_ce: 0.1145, aux_3.acc_seg: 94.8873, loss: 0.7136
2023-05-23 20:28:13,383 - mmseg - INFO - Iter [250/10000]	lr: 9.776e-02, eta: 2:33:31, time: 0.892, data_time: 0.190, memory: 14777, decode.loss_ce: 0.0700, decode.acc_seg: 96.5139, aux_0.loss_ce: 0.0708, aux_0.acc_seg: 96.5082, aux_1.loss_ce: 0.0873, aux_1.acc_seg: 95.7065, aux_2.loss_ce: 0.1143, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.2110, aux_3.loss_ce: 0.1112, aux_3.acc_seg: 94.9996, loss: 0.7031
2023-05-23 20:28:57,627 - mmseg - INFO - Iter [300/10000]	lr: 9.730e-02, eta: 2:31:07, time: 0.885, data_time: 0.186, memory: 14777, decode.loss_ce: 0.0689, decode.acc_seg: 96.5286, aux_0.loss_ce: 0.0700, aux_0.acc_seg: 96.5143, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.7575, aux_2.loss_ce: 0.1152, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.1810, aux_3.loss_ce: 0.1105, aux_3.acc_seg: 94.9936, loss: 0.6999
2023-05-23 20:29:41,685 - mmseg - INFO - Iter [350/10000]	lr: 9.685e-02, eta: 2:29:06, time: 0.881, data_time: 0.183, memory: 14777, decode.loss_ce: 0.0724, decode.acc_seg: 96.4778, aux_0.loss_ce: 0.0736, aux_0.acc_seg: 96.4748, aux_1.loss_ce: 0.0887, aux_1.acc_seg: 95.7475, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 96.1665, aux_3.loss_ce: 0.1141, aux_3.acc_seg: 94.9933, loss: 0.7164
2023-05-23 20:30:22,587 - mmseg - INFO - Iter [400/10000]	lr: 9.640e-02, eta: 2:26:09, time: 0.818, data_time: 0.115, memory: 14777, decode.loss_ce: 0.0710, decode.acc_seg: 96.4153, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 96.4240, aux_1.loss_ce: 0.0860, aux_1.acc_seg: 95.6854, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.2802, aux_3.loss_ce: 0.1092, aux_3.acc_seg: 94.9626, loss: 0.7009
2023-05-23 20:31:07,751 - mmseg - INFO - Iter [450/10000]	lr: 9.595e-02, eta: 2:25:12, time: 0.903, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0703, decode.acc_seg: 96.5253, aux_0.loss_ce: 0.0707, aux_0.acc_seg: 96.5437, aux_1.loss_ce: 0.0870, aux_1.acc_seg: 95.7634, aux_2.loss_ce: 0.1154, aux_2.loss_dice: 0.2507, aux_2.acc_seg: 96.1753, aux_3.loss_ce: 0.1109, aux_3.acc_seg: 95.0361, loss: 0.7050
2023-05-23 20:31:52,558 - mmseg - INFO - Iter [500/10000]	lr: 9.550e-02, eta: 2:24:11, time: 0.896, data_time: 0.189, memory: 14777, decode.loss_ce: 0.0678, decode.acc_seg: 96.6394, aux_0.loss_ce: 0.0684, aux_0.acc_seg: 96.6332, aux_1.loss_ce: 0.0839, aux_1.acc_seg: 95.8724, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.2186, aux_3.loss_ce: 0.1088, aux_3.acc_seg: 95.0944, loss: 0.6932
2023-05-23 20:32:32,651 - mmseg - INFO - Iter [550/10000]	lr: 9.505e-02, eta: 2:21:52, time: 0.802, data_time: 0.113, memory: 14777, decode.loss_ce: 0.0667, decode.acc_seg: 96.6288, aux_0.loss_ce: 0.0676, aux_0.acc_seg: 96.6236, aux_1.loss_ce: 0.0825, aux_1.acc_seg: 95.8942, aux_2.loss_ce: 0.1124, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.3130, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 95.1812, loss: 0.6846
2023-05-23 20:33:16,287 - mmseg - INFO - Iter [600/10000]	lr: 9.459e-02, eta: 2:20:45, time: 0.873, data_time: 0.182, memory: 14777, decode.loss_ce: 0.0670, decode.acc_seg: 96.6721, aux_0.loss_ce: 0.0684, aux_0.acc_seg: 96.6658, aux_1.loss_ce: 0.0839, aux_1.acc_seg: 95.9296, aux_2.loss_ce: 0.1148, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.2002, aux_3.loss_ce: 0.1088, aux_3.acc_seg: 95.1637, loss: 0.6927
2023-05-23 20:34:00,081 - mmseg - INFO - Iter [650/10000]	lr: 9.414e-02, eta: 2:19:44, time: 0.876, data_time: 0.183, memory: 14777, decode.loss_ce: 0.0643, decode.acc_seg: 96.7291, aux_0.loss_ce: 0.0657, aux_0.acc_seg: 96.7160, aux_1.loss_ce: 0.0822, aux_1.acc_seg: 95.9317, aux_2.loss_ce: 0.1140, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.2212, aux_3.loss_ce: 0.1052, aux_3.acc_seg: 95.1932, loss: 0.6812
2023-05-23 20:34:44,060 - mmseg - INFO - Iter [700/10000]	lr: 9.369e-02, eta: 2:18:48, time: 0.880, data_time: 0.182, memory: 14777, decode.loss_ce: 0.0660, decode.acc_seg: 96.6150, aux_0.loss_ce: 0.0668, aux_0.acc_seg: 96.6211, aux_1.loss_ce: 0.0825, aux_1.acc_seg: 95.8418, aux_2.loss_ce: 0.1134, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.2925, aux_3.loss_ce: 0.1071, aux_3.acc_seg: 95.0667, loss: 0.6848
2023-05-23 20:35:25,222 - mmseg - INFO - Iter [750/10000]	lr: 9.323e-02, eta: 2:17:18, time: 0.823, data_time: 0.119, memory: 14777, decode.loss_ce: 0.0679, decode.acc_seg: 96.5954, aux_0.loss_ce: 0.0689, aux_0.acc_seg: 96.5969, aux_1.loss_ce: 0.0840, aux_1.acc_seg: 95.8736, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 96.2034, aux_3.loss_ce: 0.1082, aux_3.acc_seg: 95.1058, loss: 0.6977
2023-05-23 20:36:08,933 - mmseg - INFO - Iter [800/10000]	lr: 9.278e-02, eta: 2:16:24, time: 0.874, data_time: 0.179, memory: 14777, decode.loss_ce: 0.0684, decode.acc_seg: 96.6185, aux_0.loss_ce: 0.0695, aux_0.acc_seg: 96.6192, aux_1.loss_ce: 0.0850, aux_1.acc_seg: 95.8403, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 96.1604, aux_3.loss_ce: 0.1113, aux_3.acc_seg: 95.0386, loss: 0.7015
2023-05-23 20:36:53,750 - mmseg - INFO - Iter [850/10000]	lr: 9.233e-02, eta: 2:15:44, time: 0.896, data_time: 0.191, memory: 14777, decode.loss_ce: 0.0678, decode.acc_seg: 96.6220, aux_0.loss_ce: 0.0691, aux_0.acc_seg: 96.6222, aux_1.loss_ce: 0.0839, aux_1.acc_seg: 95.8853, aux_2.loss_ce: 0.1144, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.2189, aux_3.loss_ce: 0.1093, aux_3.acc_seg: 95.0727, loss: 0.6940
2023-05-23 20:37:37,822 - mmseg - INFO - Iter [900/10000]	lr: 9.187e-02, eta: 2:14:55, time: 0.881, data_time: 0.184, memory: 14777, decode.loss_ce: 0.0654, decode.acc_seg: 96.5991, aux_0.loss_ce: 0.0667, aux_0.acc_seg: 96.5823, aux_1.loss_ce: 0.0817, aux_1.acc_seg: 95.8355, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.2485, aux_3.loss_ce: 0.1059, aux_3.acc_seg: 95.0529, loss: 0.6813
2023-05-23 20:38:18,262 - mmseg - INFO - Iter [950/10000]	lr: 9.142e-02, eta: 2:13:32, time: 0.809, data_time: 0.117, memory: 14777, decode.loss_ce: 0.0684, decode.acc_seg: 96.6072, aux_0.loss_ce: 0.0696, aux_0.acc_seg: 96.5994, aux_1.loss_ce: 0.0855, aux_1.acc_seg: 95.8311, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 96.1768, aux_3.loss_ce: 0.1096, aux_3.acc_seg: 95.0912, loss: 0.7006
2023-05-23 20:39:02,220 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-05-23 20:39:04,033 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 20:39:04,034 - mmseg - INFO - Iter [1000/10000]	lr: 9.096e-02, eta: 2:13:01, time: 0.916, data_time: 0.187, memory: 14777, decode.loss_ce: 0.0696, decode.acc_seg: 96.5023, aux_0.loss_ce: 0.0702, aux_0.acc_seg: 96.5164, aux_1.loss_ce: 0.0854, aux_1.acc_seg: 95.8003, aux_2.loss_ce: 0.1144, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.2896, aux_3.loss_ce: 0.1082, aux_3.acc_seg: 95.1071, loss: 0.6983
2023-05-23 20:39:31,003 - mmseg - INFO - per class results:
2023-05-23 20:39:31,004 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 65.25 | 73.26 |
|   Building  | 88.43 | 94.84 |
|     Car     | 92.34 | 95.26 |
| Column_Pole | 32.15 | 39.85 |
|    Fence    | 47.05 | 49.68 |
|  Pedestrian | 66.96 | 76.93 |
|     Road    | 96.39 |  98.2 |
|   Sidewalk  | 89.33 | 95.69 |
|  SignSymbol | 22.52 | 23.31 |
|     Sky     |  90.7 | 92.48 |
|     Tree    | 79.04 | 94.45 |
+-------------+-------+-------+
2023-05-23 20:39:31,004 - mmseg - INFO - Summary:
2023-05-23 20:39:31,004 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.65 | 70.01 | 75.81 |
+-------+-------+-------+
2023-05-23 20:39:32,567 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1000.pth.
2023-05-23 20:39:32,568 - mmseg - INFO - Best mIoU is 0.7001 at 1000 iter.
2023-05-23 20:39:32,568 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 20:39:32,568 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9365, mIoU: 0.7001, mAcc: 0.7581, IoU.Bicyclist: 0.6525, IoU.Building: 0.8843, IoU.Car: 0.9234, IoU.Column_Pole: 0.3215, IoU.Fence: 0.4705, IoU.Pedestrian: 0.6696, IoU.Road: 0.9639, IoU.Sidewalk: 0.8933, IoU.SignSymbol: 0.2252, IoU.Sky: 0.9070, IoU.Tree: 0.7904, Acc.Bicyclist: 0.7326, Acc.Building: 0.9484, Acc.Car: 0.9526, Acc.Column_Pole: 0.3985, Acc.Fence: 0.4968, Acc.Pedestrian: 0.7693, Acc.Road: 0.9820, Acc.Sidewalk: 0.9569, Acc.SignSymbol: 0.2331, Acc.Sky: 0.9248, Acc.Tree: 0.9445
2023-05-23 20:40:15,985 - mmseg - INFO - Iter [1050/10000]	lr: 9.051e-02, eta: 2:16:12, time: 1.438, data_time: 0.746, memory: 14777, decode.loss_ce: 0.0652, decode.acc_seg: 96.6795, aux_0.loss_ce: 0.0665, aux_0.acc_seg: 96.6693, aux_1.loss_ce: 0.0830, aux_1.acc_seg: 95.8552, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2514, aux_2.acc_seg: 96.0683, aux_3.loss_ce: 0.1082, aux_3.acc_seg: 95.0697, loss: 0.6916
2023-05-23 20:40:56,497 - mmseg - INFO - Iter [1100/10000]	lr: 9.005e-02, eta: 2:14:45, time: 0.810, data_time: 0.116, memory: 14777, decode.loss_ce: 0.0656, decode.acc_seg: 96.6676, aux_0.loss_ce: 0.0666, aux_0.acc_seg: 96.6578, aux_1.loss_ce: 0.0812, aux_1.acc_seg: 95.9206, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 96.2484, aux_3.loss_ce: 0.1057, aux_3.acc_seg: 95.1269, loss: 0.6816
2023-05-23 20:41:40,620 - mmseg - INFO - Iter [1150/10000]	lr: 8.960e-02, eta: 2:13:49, time: 0.882, data_time: 0.184, memory: 14777, decode.loss_ce: 0.0634, decode.acc_seg: 96.7487, aux_0.loss_ce: 0.0644, aux_0.acc_seg: 96.7430, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 95.9973, aux_2.loss_ce: 0.1135, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.2662, aux_3.loss_ce: 0.1049, aux_3.acc_seg: 95.1605, loss: 0.6742
2023-05-23 20:42:24,008 - mmseg - INFO - Iter [1200/10000]	lr: 8.914e-02, eta: 2:12:49, time: 0.868, data_time: 0.178, memory: 14777, decode.loss_ce: 0.0655, decode.acc_seg: 96.6648, aux_0.loss_ce: 0.0666, aux_0.acc_seg: 96.6596, aux_1.loss_ce: 0.0818, aux_1.acc_seg: 95.9327, aux_2.loss_ce: 0.1148, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.2433, aux_3.loss_ce: 0.1081, aux_3.acc_seg: 95.0651, loss: 0.6873
2023-05-23 20:43:07,623 - mmseg - INFO - Iter [1250/10000]	lr: 8.869e-02, eta: 2:11:52, time: 0.872, data_time: 0.179, memory: 14777, decode.loss_ce: 0.0649, decode.acc_seg: 96.6765, aux_0.loss_ce: 0.0660, aux_0.acc_seg: 96.6625, aux_1.loss_ce: 0.0805, aux_1.acc_seg: 95.9488, aux_2.loss_ce: 0.1126, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.2822, aux_3.loss_ce: 0.1056, aux_3.acc_seg: 95.1264, loss: 0.6780
2023-05-23 20:43:47,909 - mmseg - INFO - Iter [1300/10000]	lr: 8.823e-02, eta: 2:10:34, time: 0.806, data_time: 0.112, memory: 14777, decode.loss_ce: 0.0674, decode.acc_seg: 96.6168, aux_0.loss_ce: 0.0684, aux_0.acc_seg: 96.6012, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.8868, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.1555, aux_3.loss_ce: 0.1096, aux_3.acc_seg: 95.0445, loss: 0.6960
2023-05-23 20:44:32,727 - mmseg - INFO - Iter [1350/10000]	lr: 8.777e-02, eta: 2:09:48, time: 0.896, data_time: 0.189, memory: 14777, decode.loss_ce: 0.0637, decode.acc_seg: 96.6782, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.6746, aux_1.loss_ce: 0.0795, aux_1.acc_seg: 95.9232, aux_2.loss_ce: 0.1129, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 96.2574, aux_3.loss_ce: 0.1033, aux_3.acc_seg: 95.1314, loss: 0.6727
2023-05-23 20:45:16,673 - mmseg - INFO - Iter [1400/10000]	lr: 8.732e-02, eta: 2:08:56, time: 0.879, data_time: 0.185, memory: 14777, decode.loss_ce: 0.0629, decode.acc_seg: 96.7978, aux_0.loss_ce: 0.0641, aux_0.acc_seg: 96.7897, aux_1.loss_ce: 0.0791, aux_1.acc_seg: 96.0523, aux_2.loss_ce: 0.1133, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.2519, aux_3.loss_ce: 0.1044, aux_3.acc_seg: 95.2296, loss: 0.6729
2023-05-23 20:45:58,701 - mmseg - INFO - Iter [1450/10000]	lr: 8.686e-02, eta: 2:07:54, time: 0.841, data_time: 0.125, memory: 14777, decode.loss_ce: 0.0659, decode.acc_seg: 96.6522, aux_0.loss_ce: 0.0673, aux_0.acc_seg: 96.6356, aux_1.loss_ce: 0.0830, aux_1.acc_seg: 95.8662, aux_2.loss_ce: 0.1149, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.1829, aux_3.loss_ce: 0.1082, aux_3.acc_seg: 95.0528, loss: 0.6882
2023-05-23 20:46:43,501 - mmseg - INFO - Iter [1500/10000]	lr: 8.640e-02, eta: 2:07:08, time: 0.896, data_time: 0.187, memory: 14777, decode.loss_ce: 0.0657, decode.acc_seg: 96.7078, aux_0.loss_ce: 0.0670, aux_0.acc_seg: 96.6960, aux_1.loss_ce: 0.0822, aux_1.acc_seg: 95.9490, aux_2.loss_ce: 0.1141, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.2382, aux_3.loss_ce: 0.1074, aux_3.acc_seg: 95.1488, loss: 0.6858
2023-05-23 20:47:28,125 - mmseg - INFO - Iter [1550/10000]	lr: 8.594e-02, eta: 2:06:22, time: 0.892, data_time: 0.188, memory: 14777, decode.loss_ce: 0.0640, decode.acc_seg: 96.7217, aux_0.loss_ce: 0.0650, aux_0.acc_seg: 96.7206, aux_1.loss_ce: 0.0811, aux_1.acc_seg: 95.9150, aux_2.loss_ce: 0.1129, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 96.2631, aux_3.loss_ce: 0.1055, aux_3.acc_seg: 95.1260, loss: 0.6772
2023-05-23 20:48:12,751 - mmseg - INFO - Iter [1600/10000]	lr: 8.549e-02, eta: 2:05:36, time: 0.893, data_time: 0.190, memory: 14777, decode.loss_ce: 0.0656, decode.acc_seg: 96.6711, aux_0.loss_ce: 0.0666, aux_0.acc_seg: 96.6684, aux_1.loss_ce: 0.0823, aux_1.acc_seg: 95.9006, aux_2.loss_ce: 0.1149, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.2007, aux_3.loss_ce: 0.1080, aux_3.acc_seg: 95.0569, loss: 0.6878
2023-05-23 20:48:54,090 - mmseg - INFO - Iter [1650/10000]	lr: 8.503e-02, eta: 2:04:33, time: 0.827, data_time: 0.121, memory: 14777, decode.loss_ce: 0.0648, decode.acc_seg: 96.7229, aux_0.loss_ce: 0.0659, aux_0.acc_seg: 96.7056, aux_1.loss_ce: 0.0812, aux_1.acc_seg: 95.9662, aux_2.loss_ce: 0.1144, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 96.2037, aux_3.loss_ce: 0.1058, aux_3.acc_seg: 95.1647, loss: 0.6812
2023-05-23 20:49:39,392 - mmseg - INFO - Iter [1700/10000]	lr: 8.457e-02, eta: 2:03:51, time: 0.906, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0693, decode.acc_seg: 96.5845, aux_0.loss_ce: 0.0701, aux_0.acc_seg: 96.5802, aux_1.loss_ce: 0.0855, aux_1.acc_seg: 95.8266, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.1616, aux_3.loss_ce: 0.1116, aux_3.acc_seg: 94.9984, loss: 0.7037
2023-05-23 20:50:24,239 - mmseg - INFO - Iter [1750/10000]	lr: 8.411e-02, eta: 2:03:07, time: 0.897, data_time: 0.189, memory: 14777, decode.loss_ce: 0.0706, decode.acc_seg: 96.4973, aux_0.loss_ce: 0.0713, aux_0.acc_seg: 96.5079, aux_1.loss_ce: 0.0864, aux_1.acc_seg: 95.7469, aux_2.loss_ce: 0.1144, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.2267, aux_3.loss_ce: 0.1084, aux_3.acc_seg: 95.0544, loss: 0.7008
2023-05-23 20:51:09,946 - mmseg - INFO - Iter [1800/10000]	lr: 8.365e-02, eta: 2:02:26, time: 0.914, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0666, decode.acc_seg: 96.6381, aux_0.loss_ce: 0.0676, aux_0.acc_seg: 96.6435, aux_1.loss_ce: 0.0830, aux_1.acc_seg: 95.8790, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.1600, aux_3.loss_ce: 0.1073, aux_3.acc_seg: 95.1179, loss: 0.6901
2023-05-23 20:51:51,126 - mmseg - INFO - Iter [1850/10000]	lr: 8.319e-02, eta: 2:01:26, time: 0.824, data_time: 0.123, memory: 14777, decode.loss_ce: 0.0633, decode.acc_seg: 96.7380, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.7144, aux_1.loss_ce: 0.0802, aux_1.acc_seg: 95.9526, aux_2.loss_ce: 0.1147, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 96.2322, aux_3.loss_ce: 0.1048, aux_3.acc_seg: 95.1391, loss: 0.6780
2023-05-23 20:52:36,409 - mmseg - INFO - Iter [1900/10000]	lr: 8.273e-02, eta: 2:00:43, time: 0.906, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0653, decode.acc_seg: 96.6678, aux_0.loss_ce: 0.0664, aux_0.acc_seg: 96.6708, aux_1.loss_ce: 0.0825, aux_1.acc_seg: 95.8986, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2513, aux_2.acc_seg: 96.1795, aux_3.loss_ce: 0.1088, aux_3.acc_seg: 95.0223, loss: 0.6903
2023-05-23 20:53:22,200 - mmseg - INFO - Iter [1950/10000]	lr: 8.227e-02, eta: 2:00:03, time: 0.916, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0670, decode.acc_seg: 96.6461, aux_0.loss_ce: 0.0683, aux_0.acc_seg: 96.6265, aux_1.loss_ce: 0.0841, aux_1.acc_seg: 95.8725, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2529, aux_2.acc_seg: 96.1453, aux_3.loss_ce: 0.1105, aux_3.acc_seg: 95.0346, loss: 0.7004
2023-05-23 20:54:04,525 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-05-23 20:54:06,149 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 20:54:06,149 - mmseg - INFO - Iter [2000/10000]	lr: 8.181e-02, eta: 1:59:15, time: 0.880, data_time: 0.132, memory: 14777, decode.loss_ce: 0.0646, decode.acc_seg: 96.6876, aux_0.loss_ce: 0.0655, aux_0.acc_seg: 96.6680, aux_1.loss_ce: 0.0802, aux_1.acc_seg: 95.9179, aux_2.loss_ce: 0.1112, aux_2.loss_dice: 0.2461, aux_2.acc_seg: 96.3118, aux_3.loss_ce: 0.1043, aux_3.acc_seg: 95.0965, loss: 0.6720
2023-05-23 20:54:24,445 - mmseg - INFO - per class results:
2023-05-23 20:54:24,446 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 65.33 | 73.74 |
|   Building  | 88.22 | 95.06 |
|     Car     | 92.56 | 94.57 |
| Column_Pole | 29.94 | 34.94 |
|    Fence    | 43.25 | 44.81 |
|  Pedestrian |  67.9 |  80.5 |
|     Road    | 96.12 | 98.69 |
|   Sidewalk  | 88.58 | 93.83 |
|  SignSymbol | 16.06 | 16.27 |
|     Sky     | 91.93 | 95.08 |
|     Tree    | 80.23 | 92.56 |
+-------------+-------+-------+
2023-05-23 20:54:24,446 - mmseg - INFO - Summary:
2023-05-23 20:54:24,446 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 93.78 | 69.1 | 74.55 |
+-------+------+-------+
2023-05-23 20:54:24,447 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 20:54:24,447 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9378, mIoU: 0.6910, mAcc: 0.7455, IoU.Bicyclist: 0.6533, IoU.Building: 0.8822, IoU.Car: 0.9256, IoU.Column_Pole: 0.2994, IoU.Fence: 0.4325, IoU.Pedestrian: 0.6790, IoU.Road: 0.9612, IoU.Sidewalk: 0.8858, IoU.SignSymbol: 0.1606, IoU.Sky: 0.9193, IoU.Tree: 0.8023, Acc.Bicyclist: 0.7374, Acc.Building: 0.9506, Acc.Car: 0.9457, Acc.Column_Pole: 0.3494, Acc.Fence: 0.4481, Acc.Pedestrian: 0.8050, Acc.Road: 0.9869, Acc.Sidewalk: 0.9383, Acc.SignSymbol: 0.1627, Acc.Sky: 0.9508, Acc.Tree: 0.9256
2023-05-23 20:55:09,152 - mmseg - INFO - Iter [2050/10000]	lr: 8.135e-02, eta: 1:59:41, time: 1.259, data_time: 0.552, memory: 14777, decode.loss_ce: 0.0638, decode.acc_seg: 96.7544, aux_0.loss_ce: 0.0653, aux_0.acc_seg: 96.7280, aux_1.loss_ce: 0.0808, aux_1.acc_seg: 95.9646, aux_2.loss_ce: 0.1154, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.1703, aux_3.loss_ce: 0.1056, aux_3.acc_seg: 95.1455, loss: 0.6810
2023-05-23 20:55:53,084 - mmseg - INFO - Iter [2100/10000]	lr: 8.089e-02, eta: 1:58:52, time: 0.879, data_time: 0.186, memory: 14777, decode.loss_ce: 0.0694, decode.acc_seg: 96.5663, aux_0.loss_ce: 0.0704, aux_0.acc_seg: 96.5781, aux_1.loss_ce: 0.0860, aux_1.acc_seg: 95.8205, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.1286, aux_3.loss_ce: 0.1126, aux_3.acc_seg: 94.9757, loss: 0.7093
2023-05-23 20:56:38,229 - mmseg - INFO - Iter [2150/10000]	lr: 8.043e-02, eta: 1:58:06, time: 0.903, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0643, decode.acc_seg: 96.6657, aux_0.loss_ce: 0.0653, aux_0.acc_seg: 96.6699, aux_1.loss_ce: 0.0803, aux_1.acc_seg: 95.9348, aux_2.loss_ce: 0.1145, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.2220, aux_3.loss_ce: 0.1049, aux_3.acc_seg: 95.1107, loss: 0.6785
2023-05-23 20:57:19,460 - mmseg - INFO - Iter [2200/10000]	lr: 7.997e-02, eta: 1:57:07, time: 0.825, data_time: 0.120, memory: 14777, decode.loss_ce: 0.0668, decode.acc_seg: 96.6303, aux_0.loss_ce: 0.0683, aux_0.acc_seg: 96.6080, aux_1.loss_ce: 0.0841, aux_1.acc_seg: 95.8358, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.1564, aux_3.loss_ce: 0.1100, aux_3.acc_seg: 95.0106, loss: 0.6994
2023-05-23 20:58:03,276 - mmseg - INFO - Iter [2250/10000]	lr: 7.951e-02, eta: 1:56:18, time: 0.876, data_time: 0.183, memory: 14777, decode.loss_ce: 0.0634, decode.acc_seg: 96.7366, aux_0.loss_ce: 0.0643, aux_0.acc_seg: 96.7282, aux_1.loss_ce: 0.0800, aux_1.acc_seg: 95.9711, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 96.1984, aux_3.loss_ce: 0.1055, aux_3.acc_seg: 95.1191, loss: 0.6747
2023-05-23 20:58:48,623 - mmseg - INFO - Iter [2300/10000]	lr: 7.905e-02, eta: 1:55:34, time: 0.907, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0642, decode.acc_seg: 96.7635, aux_0.loss_ce: 0.0658, aux_0.acc_seg: 96.7352, aux_1.loss_ce: 0.0810, aux_1.acc_seg: 95.9833, aux_2.loss_ce: 0.1123, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.3167, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 95.1241, loss: 0.6786
2023-05-23 20:59:33,903 - mmseg - INFO - Iter [2350/10000]	lr: 7.859e-02, eta: 1:54:50, time: 0.906, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0639, decode.acc_seg: 96.7440, aux_0.loss_ce: 0.0653, aux_0.acc_seg: 96.7226, aux_1.loss_ce: 0.0811, aux_1.acc_seg: 95.9564, aux_2.loss_ce: 0.1141, aux_2.loss_dice: 0.2481, aux_2.acc_seg: 96.1882, aux_3.loss_ce: 0.1049, aux_3.acc_seg: 95.1661, loss: 0.6775
2023-05-23 21:00:14,947 - mmseg - INFO - Iter [2400/10000]	lr: 7.812e-02, eta: 1:53:52, time: 0.821, data_time: 0.122, memory: 14777, decode.loss_ce: 0.0644, decode.acc_seg: 96.6364, aux_0.loss_ce: 0.0653, aux_0.acc_seg: 96.6211, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 95.8832, aux_2.loss_ce: 0.1141, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.1823, aux_3.loss_ce: 0.1060, aux_3.acc_seg: 95.0541, loss: 0.6779
2023-05-23 21:01:00,200 - mmseg - INFO - Iter [2450/10000]	lr: 7.766e-02, eta: 1:53:08, time: 0.905, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0638, decode.acc_seg: 96.7547, aux_0.loss_ce: 0.0646, aux_0.acc_seg: 96.7494, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 95.9824, aux_2.loss_ce: 0.1147, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.2086, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 95.1121, loss: 0.6786
2023-05-23 21:01:44,523 - mmseg - INFO - Iter [2500/10000]	lr: 7.720e-02, eta: 1:52:21, time: 0.886, data_time: 0.187, memory: 14777, decode.loss_ce: 0.0687, decode.acc_seg: 96.5715, aux_0.loss_ce: 0.0696, aux_0.acc_seg: 96.5753, aux_1.loss_ce: 0.0859, aux_1.acc_seg: 95.7838, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2516, aux_2.acc_seg: 96.1797, aux_3.loss_ce: 0.1109, aux_3.acc_seg: 95.0328, loss: 0.7027
2023-05-23 21:02:26,028 - mmseg - INFO - Iter [2550/10000]	lr: 7.674e-02, eta: 1:51:26, time: 0.830, data_time: 0.127, memory: 14777, decode.loss_ce: 0.0625, decode.acc_seg: 96.8051, aux_0.loss_ce: 0.0638, aux_0.acc_seg: 96.7771, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 96.0173, aux_2.loss_ce: 0.1131, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 96.2370, aux_3.loss_ce: 0.1033, aux_3.acc_seg: 95.2427, loss: 0.6697
2023-05-23 21:03:11,293 - mmseg - INFO - Iter [2600/10000]	lr: 7.627e-02, eta: 1:50:43, time: 0.905, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0634, decode.acc_seg: 96.7975, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.7735, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 96.0158, aux_2.loss_ce: 0.1130, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 96.2545, aux_3.loss_ce: 0.1048, aux_3.acc_seg: 95.1986, loss: 0.6739
2023-05-23 21:03:55,202 - mmseg - INFO - Iter [2650/10000]	lr: 7.581e-02, eta: 1:49:55, time: 0.878, data_time: 0.184, memory: 14777, decode.loss_ce: 0.0626, decode.acc_seg: 96.8322, aux_0.loss_ce: 0.0640, aux_0.acc_seg: 96.8113, aux_1.loss_ce: 0.0795, aux_1.acc_seg: 96.0452, aux_2.loss_ce: 0.1159, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.1772, aux_3.loss_ce: 0.1052, aux_3.acc_seg: 95.2222, loss: 0.6778
2023-05-23 21:04:40,220 - mmseg - INFO - Iter [2700/10000]	lr: 7.534e-02, eta: 1:49:11, time: 0.900, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0617, decode.acc_seg: 96.8249, aux_0.loss_ce: 0.0628, aux_0.acc_seg: 96.8085, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 96.0386, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.2639, aux_3.loss_ce: 0.1042, aux_3.acc_seg: 95.1644, loss: 0.6699
2023-05-23 21:05:21,746 - mmseg - INFO - Iter [2750/10000]	lr: 7.488e-02, eta: 1:48:17, time: 0.831, data_time: 0.123, memory: 14777, decode.loss_ce: 0.0634, decode.acc_seg: 96.6979, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.6883, aux_1.loss_ce: 0.0795, aux_1.acc_seg: 95.9467, aux_2.loss_ce: 0.1130, aux_2.loss_dice: 0.2475, aux_2.acc_seg: 96.2553, aux_3.loss_ce: 0.1048, aux_3.acc_seg: 95.1352, loss: 0.6728
2023-05-23 21:06:07,119 - mmseg - INFO - Iter [2800/10000]	lr: 7.441e-02, eta: 1:47:34, time: 0.907, data_time: 0.197, memory: 14777, decode.loss_ce: 0.0658, decode.acc_seg: 96.6844, aux_0.loss_ce: 0.0668, aux_0.acc_seg: 96.6671, aux_1.loss_ce: 0.0815, aux_1.acc_seg: 95.9174, aux_2.loss_ce: 0.1138, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.2460, aux_3.loss_ce: 0.1066, aux_3.acc_seg: 95.0995, loss: 0.6836
2023-05-23 21:06:51,356 - mmseg - INFO - Iter [2850/10000]	lr: 7.395e-02, eta: 1:46:47, time: 0.885, data_time: 0.185, memory: 14777, decode.loss_ce: 0.0647, decode.acc_seg: 96.6899, aux_0.loss_ce: 0.0661, aux_0.acc_seg: 96.6709, aux_1.loss_ce: 0.0812, aux_1.acc_seg: 95.9317, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.2465, aux_3.loss_ce: 0.1066, aux_3.acc_seg: 95.0870, loss: 0.6812
2023-05-23 21:07:33,338 - mmseg - INFO - Iter [2900/10000]	lr: 7.348e-02, eta: 1:45:55, time: 0.840, data_time: 0.128, memory: 14777, decode.loss_ce: 0.0650, decode.acc_seg: 96.6338, aux_0.loss_ce: 0.0657, aux_0.acc_seg: 96.6370, aux_1.loss_ce: 0.0800, aux_1.acc_seg: 95.9329, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.2603, aux_3.loss_ce: 0.1053, aux_3.acc_seg: 95.0816, loss: 0.6786
2023-05-23 21:08:17,792 - mmseg - INFO - Iter [2950/10000]	lr: 7.302e-02, eta: 1:45:10, time: 0.889, data_time: 0.187, memory: 14777, decode.loss_ce: 0.0610, decode.acc_seg: 96.8161, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.8071, aux_1.loss_ce: 0.0780, aux_1.acc_seg: 96.0307, aux_2.loss_ce: 0.1130, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.2363, aux_3.loss_ce: 0.1030, aux_3.acc_seg: 95.1910, loss: 0.6652
2023-05-23 21:09:02,427 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-05-23 21:09:04,937 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:09:04,937 - mmseg - INFO - Iter [3000/10000]	lr: 7.255e-02, eta: 1:44:31, time: 0.944, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0638, decode.acc_seg: 96.7934, aux_0.loss_ce: 0.0651, aux_0.acc_seg: 96.7723, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 96.0308, aux_2.loss_ce: 0.1154, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.1918, aux_3.loss_ce: 0.1074, aux_3.acc_seg: 95.1451, loss: 0.6823
2023-05-23 21:09:21,908 - mmseg - INFO - per class results:
2023-05-23 21:09:21,909 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 65.32 |  70.8 |
|   Building  | 88.88 | 95.19 |
|     Car     | 92.26 | 95.54 |
| Column_Pole | 36.51 | 46.75 |
|    Fence    | 51.19 |  55.4 |
|  Pedestrian | 67.67 | 76.09 |
|     Road    | 96.25 | 98.63 |
|   Sidewalk  | 89.28 | 93.98 |
|  SignSymbol | 19.41 |  20.0 |
|     Sky     | 92.25 | 95.48 |
|     Tree    | 80.61 | 91.47 |
+-------------+-------+-------+
2023-05-23 21:09:21,910 - mmseg - INFO - Summary:
2023-05-23 21:09:21,910 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 94.06 | 70.87 | 76.3 |
+-------+-------+------+
2023-05-23 21:09:21,921 - mmseg - INFO - The previous best checkpoint /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone/best_mIoU_iter_1000.pth was removed
2023-05-23 21:09:23,471 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_3000.pth.
2023-05-23 21:09:23,471 - mmseg - INFO - Best mIoU is 0.7087 at 3000 iter.
2023-05-23 21:09:23,471 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:09:23,471 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9406, mIoU: 0.7087, mAcc: 0.7630, IoU.Bicyclist: 0.6532, IoU.Building: 0.8888, IoU.Car: 0.9226, IoU.Column_Pole: 0.3651, IoU.Fence: 0.5119, IoU.Pedestrian: 0.6767, IoU.Road: 0.9625, IoU.Sidewalk: 0.8928, IoU.SignSymbol: 0.1941, IoU.Sky: 0.9225, IoU.Tree: 0.8061, Acc.Bicyclist: 0.7080, Acc.Building: 0.9519, Acc.Car: 0.9554, Acc.Column_Pole: 0.4675, Acc.Fence: 0.5540, Acc.Pedestrian: 0.7609, Acc.Road: 0.9863, Acc.Sidewalk: 0.9398, Acc.SignSymbol: 0.2000, Acc.Sky: 0.9548, Acc.Tree: 0.9147
2023-05-23 21:10:08,157 - mmseg - INFO - Iter [3050/10000]	lr: 7.208e-02, eta: 1:44:28, time: 1.264, data_time: 0.558, memory: 14777, decode.loss_ce: 0.0637, decode.acc_seg: 96.7553, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.7442, aux_1.loss_ce: 0.0802, aux_1.acc_seg: 95.9774, aux_2.loss_ce: 0.1133, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.2633, aux_3.loss_ce: 0.1057, aux_3.acc_seg: 95.1326, loss: 0.6759
2023-05-23 21:10:48,989 - mmseg - INFO - Iter [3100/10000]	lr: 7.162e-02, eta: 1:43:33, time: 0.817, data_time: 0.120, memory: 14777, decode.loss_ce: 0.0649, decode.acc_seg: 96.7422, aux_0.loss_ce: 0.0655, aux_0.acc_seg: 96.7500, aux_1.loss_ce: 0.0814, aux_1.acc_seg: 95.9580, aux_2.loss_ce: 0.1142, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 96.2141, aux_3.loss_ce: 0.1049, aux_3.acc_seg: 95.1507, loss: 0.6797
2023-05-23 21:11:33,995 - mmseg - INFO - Iter [3150/10000]	lr: 7.115e-02, eta: 1:42:48, time: 0.900, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0631, decode.acc_seg: 96.8100, aux_0.loss_ce: 0.0641, aux_0.acc_seg: 96.8037, aux_1.loss_ce: 0.0792, aux_1.acc_seg: 96.0581, aux_2.loss_ce: 0.1121, aux_2.loss_dice: 0.2473, aux_2.acc_seg: 96.3055, aux_3.loss_ce: 0.1033, aux_3.acc_seg: 95.2447, loss: 0.6691
2023-05-23 21:12:18,353 - mmseg - INFO - Iter [3200/10000]	lr: 7.068e-02, eta: 1:42:02, time: 0.887, data_time: 0.188, memory: 14777, decode.loss_ce: 0.0629, decode.acc_seg: 96.8194, aux_0.loss_ce: 0.0645, aux_0.acc_seg: 96.7926, aux_1.loss_ce: 0.0802, aux_1.acc_seg: 96.0311, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.1745, aux_3.loss_ce: 0.1059, aux_3.acc_seg: 95.1994, loss: 0.6800
2023-05-23 21:13:02,231 - mmseg - INFO - Iter [3250/10000]	lr: 7.022e-02, eta: 1:41:14, time: 0.878, data_time: 0.183, memory: 14777, decode.loss_ce: 0.0629, decode.acc_seg: 96.7243, aux_0.loss_ce: 0.0639, aux_0.acc_seg: 96.7088, aux_1.loss_ce: 0.0795, aux_1.acc_seg: 95.9552, aux_2.loss_ce: 0.1125, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.2949, aux_3.loss_ce: 0.1040, aux_3.acc_seg: 95.1297, loss: 0.6713
2023-05-23 21:13:42,897 - mmseg - INFO - Iter [3300/10000]	lr: 6.975e-02, eta: 1:40:21, time: 0.813, data_time: 0.120, memory: 14777, decode.loss_ce: 0.0634, decode.acc_seg: 96.7146, aux_0.loss_ce: 0.0650, aux_0.acc_seg: 96.6745, aux_1.loss_ce: 0.0803, aux_1.acc_seg: 95.8960, aux_2.loss_ce: 0.1152, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.1860, aux_3.loss_ce: 0.1060, aux_3.acc_seg: 95.0440, loss: 0.6789
2023-05-23 21:14:27,549 - mmseg - INFO - Iter [3350/10000]	lr: 6.928e-02, eta: 1:39:35, time: 0.893, data_time: 0.193, memory: 14777, decode.loss_ce: 0.0627, decode.acc_seg: 96.7637, aux_0.loss_ce: 0.0638, aux_0.acc_seg: 96.7520, aux_1.loss_ce: 0.0793, aux_1.acc_seg: 95.9889, aux_2.loss_ce: 0.1134, aux_2.loss_dice: 0.2472, aux_2.acc_seg: 96.2178, aux_3.loss_ce: 0.1053, aux_3.acc_seg: 95.1008, loss: 0.6716
2023-05-23 21:15:12,592 - mmseg - INFO - Iter [3400/10000]	lr: 6.881e-02, eta: 1:38:50, time: 0.901, data_time: 0.197, memory: 14777, decode.loss_ce: 0.0630, decode.acc_seg: 96.8254, aux_0.loss_ce: 0.0643, aux_0.acc_seg: 96.8076, aux_1.loss_ce: 0.0800, aux_1.acc_seg: 96.0406, aux_2.loss_ce: 0.1144, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.2235, aux_3.loss_ce: 0.1059, aux_3.acc_seg: 95.1931, loss: 0.6774
2023-05-23 21:15:54,030 - mmseg - INFO - Iter [3450/10000]	lr: 6.834e-02, eta: 1:37:59, time: 0.829, data_time: 0.121, memory: 14777, decode.loss_ce: 0.0632, decode.acc_seg: 96.7076, aux_0.loss_ce: 0.0646, aux_0.acc_seg: 96.6897, aux_1.loss_ce: 0.0799, aux_1.acc_seg: 95.9256, aux_2.loss_ce: 0.1140, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 96.2332, aux_3.loss_ce: 0.1053, aux_3.acc_seg: 95.0514, loss: 0.6758
2023-05-23 21:16:38,323 - mmseg - INFO - Iter [3500/10000]	lr: 6.787e-02, eta: 1:37:13, time: 0.886, data_time: 0.186, memory: 14777, decode.loss_ce: 0.0646, decode.acc_seg: 96.6734, aux_0.loss_ce: 0.0656, aux_0.acc_seg: 96.6717, aux_1.loss_ce: 0.0803, aux_1.acc_seg: 95.9428, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 96.2422, aux_3.loss_ce: 0.1065, aux_3.acc_seg: 95.0623, loss: 0.6799
2023-05-23 21:17:23,262 - mmseg - INFO - Iter [3550/10000]	lr: 6.740e-02, eta: 1:36:28, time: 0.899, data_time: 0.190, memory: 14777, decode.loss_ce: 0.0641, decode.acc_seg: 96.7441, aux_0.loss_ce: 0.0649, aux_0.acc_seg: 96.7439, aux_1.loss_ce: 0.0807, aux_1.acc_seg: 95.9656, aux_2.loss_ce: 0.1142, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.2366, aux_3.loss_ce: 0.1061, aux_3.acc_seg: 95.1198, loss: 0.6794
2023-05-23 21:18:06,695 - mmseg - INFO - Iter [3600/10000]	lr: 6.693e-02, eta: 1:35:41, time: 0.869, data_time: 0.180, memory: 14777, decode.loss_ce: 0.0622, decode.acc_seg: 96.8446, aux_0.loss_ce: 0.0633, aux_0.acc_seg: 96.8268, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 96.0918, aux_2.loss_ce: 0.1126, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.3050, aux_3.loss_ce: 0.1042, aux_3.acc_seg: 95.2260, loss: 0.6697
2023-05-23 21:18:47,087 - mmseg - INFO - Iter [3650/10000]	lr: 6.646e-02, eta: 1:34:48, time: 0.808, data_time: 0.118, memory: 14777, decode.loss_ce: 0.0631, decode.acc_seg: 96.7638, aux_0.loss_ce: 0.0646, aux_0.acc_seg: 96.7432, aux_1.loss_ce: 0.0802, aux_1.acc_seg: 95.9798, aux_2.loss_ce: 0.1156, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.1651, aux_3.loss_ce: 0.1072, aux_3.acc_seg: 95.0760, loss: 0.6797
2023-05-23 21:19:31,804 - mmseg - INFO - Iter [3700/10000]	lr: 6.599e-02, eta: 1:34:03, time: 0.894, data_time: 0.192, memory: 14777, decode.loss_ce: 0.0633, decode.acc_seg: 96.7712, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.7532, aux_1.loss_ce: 0.0803, aux_1.acc_seg: 95.9811, aux_2.loss_ce: 0.1148, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.2218, aux_3.loss_ce: 0.1066, aux_3.acc_seg: 95.1093, loss: 0.6806
2023-05-23 21:20:15,673 - mmseg - INFO - Iter [3750/10000]	lr: 6.552e-02, eta: 1:33:17, time: 0.877, data_time: 0.185, memory: 14777, decode.loss_ce: 0.0651, decode.acc_seg: 96.7042, aux_0.loss_ce: 0.0664, aux_0.acc_seg: 96.7018, aux_1.loss_ce: 0.0828, aux_1.acc_seg: 95.8931, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 96.1745, aux_3.loss_ce: 0.1067, aux_3.acc_seg: 95.1199, loss: 0.6860
2023-05-23 21:21:01,335 - mmseg - INFO - Iter [3800/10000]	lr: 6.505e-02, eta: 1:32:34, time: 0.913, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0706, decode.acc_seg: 96.5282, aux_0.loss_ce: 0.0695, aux_0.acc_seg: 96.5841, aux_1.loss_ce: 0.0850, aux_1.acc_seg: 95.7962, aux_2.loss_ce: 0.1133, aux_2.loss_dice: 0.2468, aux_2.acc_seg: 96.1805, aux_3.loss_ce: 0.1070, aux_3.acc_seg: 95.0700, loss: 0.6920
2023-05-23 21:21:42,528 - mmseg - INFO - Iter [3850/10000]	lr: 6.457e-02, eta: 1:31:43, time: 0.824, data_time: 0.119, memory: 14777, decode.loss_ce: 0.0696, decode.acc_seg: 96.4862, aux_0.loss_ce: 0.0693, aux_0.acc_seg: 96.5317, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.8025, aux_2.loss_ce: 0.1138, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.2740, aux_3.loss_ce: 0.1054, aux_3.acc_seg: 95.0801, loss: 0.6906
2023-05-23 21:22:27,639 - mmseg - INFO - Iter [3900/10000]	lr: 6.410e-02, eta: 1:30:59, time: 0.902, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0649, decode.acc_seg: 96.6500, aux_0.loss_ce: 0.0658, aux_0.acc_seg: 96.6488, aux_1.loss_ce: 0.0805, aux_1.acc_seg: 95.9000, aux_2.loss_ce: 0.1131, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 96.2322, aux_3.loss_ce: 0.1047, aux_3.acc_seg: 95.0911, loss: 0.6769
2023-05-23 21:23:12,412 - mmseg - INFO - Iter [3950/10000]	lr: 6.363e-02, eta: 1:30:14, time: 0.895, data_time: 0.190, memory: 14777, decode.loss_ce: 0.0663, decode.acc_seg: 96.6768, aux_0.loss_ce: 0.0674, aux_0.acc_seg: 96.6555, aux_1.loss_ce: 0.0832, aux_1.acc_seg: 95.8899, aux_2.loss_ce: 0.1161, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 96.1392, aux_3.loss_ce: 0.1090, aux_3.acc_seg: 95.0559, loss: 0.6919
2023-05-23 21:23:53,784 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-05-23 21:23:55,352 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:23:55,352 - mmseg - INFO - Iter [4000/10000]	lr: 6.315e-02, eta: 1:29:27, time: 0.859, data_time: 0.121, memory: 14777, decode.loss_ce: 0.0661, decode.acc_seg: 96.6716, aux_0.loss_ce: 0.0671, aux_0.acc_seg: 96.6700, aux_1.loss_ce: 0.0822, aux_1.acc_seg: 95.9235, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 96.2229, aux_3.loss_ce: 0.1062, aux_3.acc_seg: 95.1443, loss: 0.6830
2023-05-23 21:24:09,600 - mmseg - INFO - per class results:
2023-05-23 21:24:09,601 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 65.47 | 71.88 |
|   Building  | 88.74 | 96.14 |
|     Car     | 91.79 | 94.87 |
| Column_Pole | 33.67 | 41.73 |
|    Fence    | 47.31 |  50.1 |
|  Pedestrian | 67.13 | 86.08 |
|     Road    |  96.2 | 98.75 |
|   Sidewalk  | 89.24 | 93.69 |
|  SignSymbol | 20.17 | 21.11 |
|     Sky     | 89.16 | 90.21 |
|     Tree    | 78.16 | 93.45 |
+-------------+-------+-------+
2023-05-23 21:24:09,601 - mmseg - INFO - Summary:
2023-05-23 21:24:09,602 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.44 | 69.73 | 76.18 |
+-------+-------+-------+
2023-05-23 21:24:09,602 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:24:09,602 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9344, mIoU: 0.6973, mAcc: 0.7618, IoU.Bicyclist: 0.6547, IoU.Building: 0.8874, IoU.Car: 0.9179, IoU.Column_Pole: 0.3367, IoU.Fence: 0.4731, IoU.Pedestrian: 0.6713, IoU.Road: 0.9620, IoU.Sidewalk: 0.8924, IoU.SignSymbol: 0.2017, IoU.Sky: 0.8916, IoU.Tree: 0.7816, Acc.Bicyclist: 0.7188, Acc.Building: 0.9614, Acc.Car: 0.9487, Acc.Column_Pole: 0.4173, Acc.Fence: 0.5010, Acc.Pedestrian: 0.8608, Acc.Road: 0.9875, Acc.Sidewalk: 0.9369, Acc.SignSymbol: 0.2111, Acc.Sky: 0.9021, Acc.Tree: 0.9345
2023-05-23 21:24:55,365 - mmseg - INFO - Iter [4050/10000]	lr: 6.268e-02, eta: 1:29:04, time: 1.200, data_time: 0.484, memory: 14777, decode.loss_ce: 0.0684, decode.acc_seg: 96.6289, aux_0.loss_ce: 0.0692, aux_0.acc_seg: 96.6322, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.8963, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2524, aux_2.acc_seg: 96.1319, aux_3.loss_ce: 0.1092, aux_3.acc_seg: 95.1004, loss: 0.7013
2023-05-23 21:25:40,062 - mmseg - INFO - Iter [4100/10000]	lr: 6.221e-02, eta: 1:28:19, time: 0.894, data_time: 0.191, memory: 14777, decode.loss_ce: 0.0678, decode.acc_seg: 96.5554, aux_0.loss_ce: 0.0687, aux_0.acc_seg: 96.5500, aux_1.loss_ce: 0.0827, aux_1.acc_seg: 95.8441, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 96.2170, aux_3.loss_ce: 0.1080, aux_3.acc_seg: 94.9571, loss: 0.6893
2023-05-23 21:26:24,543 - mmseg - INFO - Iter [4150/10000]	lr: 6.173e-02, eta: 1:27:34, time: 0.890, data_time: 0.186, memory: 14777, decode.loss_ce: 0.0653, decode.acc_seg: 96.7244, aux_0.loss_ce: 0.0666, aux_0.acc_seg: 96.7145, aux_1.loss_ce: 0.0810, aux_1.acc_seg: 95.9938, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 96.2777, aux_3.loss_ce: 0.1048, aux_3.acc_seg: 95.2055, loss: 0.6816
2023-05-23 21:27:05,223 - mmseg - INFO - Iter [4200/10000]	lr: 6.126e-02, eta: 1:26:43, time: 0.814, data_time: 0.119, memory: 14777, decode.loss_ce: 0.0631, decode.acc_seg: 96.7664, aux_0.loss_ce: 0.0643, aux_0.acc_seg: 96.7519, aux_1.loss_ce: 0.0795, aux_1.acc_seg: 96.0147, aux_2.loss_ce: 0.1135, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.2011, aux_3.loss_ce: 0.1041, aux_3.acc_seg: 95.1989, loss: 0.6726
2023-05-23 21:27:49,120 - mmseg - INFO - Iter [4250/10000]	lr: 6.078e-02, eta: 1:25:57, time: 0.878, data_time: 0.184, memory: 14777, decode.loss_ce: 0.0625, decode.acc_seg: 96.8032, aux_0.loss_ce: 0.0636, aux_0.acc_seg: 96.7881, aux_1.loss_ce: 0.0787, aux_1.acc_seg: 96.0360, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 96.2030, aux_3.loss_ce: 0.1038, aux_3.acc_seg: 95.1825, loss: 0.6704
2023-05-23 21:28:33,374 - mmseg - INFO - Iter [4300/10000]	lr: 6.031e-02, eta: 1:25:11, time: 0.885, data_time: 0.186, memory: 14777, decode.loss_ce: 0.0617, decode.acc_seg: 96.8097, aux_0.loss_ce: 0.0626, aux_0.acc_seg: 96.8063, aux_1.loss_ce: 0.0779, aux_1.acc_seg: 96.0411, aux_2.loss_ce: 0.1128, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 96.2593, aux_3.loss_ce: 0.1030, aux_3.acc_seg: 95.1974, loss: 0.6657
2023-05-23 21:29:14,595 - mmseg - INFO - Iter [4350/10000]	lr: 5.983e-02, eta: 1:24:22, time: 0.824, data_time: 0.125, memory: 14777, decode.loss_ce: 0.0615, decode.acc_seg: 96.8517, aux_0.loss_ce: 0.0627, aux_0.acc_seg: 96.8348, aux_1.loss_ce: 0.0782, aux_1.acc_seg: 96.0682, aux_2.loss_ce: 0.1143, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 96.2068, aux_3.loss_ce: 0.1045, aux_3.acc_seg: 95.1903, loss: 0.6697
2023-05-23 21:29:59,907 - mmseg - INFO - Iter [4400/10000]	lr: 5.935e-02, eta: 1:23:37, time: 0.906, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0637, decode.acc_seg: 96.7737, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.7654, aux_1.loss_ce: 0.0800, aux_1.acc_seg: 96.0150, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.1392, aux_3.loss_ce: 0.1070, aux_3.acc_seg: 95.1171, loss: 0.6814
2023-05-23 21:30:45,165 - mmseg - INFO - Iter [4450/10000]	lr: 5.888e-02, eta: 1:22:53, time: 0.905, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0656, decode.acc_seg: 96.6494, aux_0.loss_ce: 0.0661, aux_0.acc_seg: 96.6538, aux_1.loss_ce: 0.0813, aux_1.acc_seg: 95.9094, aux_2.loss_ce: 0.1135, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.2367, aux_3.loss_ce: 0.1074, aux_3.acc_seg: 95.0575, loss: 0.6822
2023-05-23 21:31:29,473 - mmseg - INFO - Iter [4500/10000]	lr: 5.840e-02, eta: 1:22:08, time: 0.886, data_time: 0.184, memory: 14777, decode.loss_ce: 0.0621, decode.acc_seg: 96.8200, aux_0.loss_ce: 0.0633, aux_0.acc_seg: 96.8050, aux_1.loss_ce: 0.0792, aux_1.acc_seg: 96.0366, aux_2.loss_ce: 0.1153, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.1470, aux_3.loss_ce: 0.1054, aux_3.acc_seg: 95.1620, loss: 0.6744
2023-05-23 21:32:11,335 - mmseg - INFO - Iter [4550/10000]	lr: 5.792e-02, eta: 1:21:19, time: 0.837, data_time: 0.128, memory: 14777, decode.loss_ce: 0.0627, decode.acc_seg: 96.7544, aux_0.loss_ce: 0.0641, aux_0.acc_seg: 96.7234, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 95.9691, aux_2.loss_ce: 0.1116, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.3099, aux_3.loss_ce: 0.1040, aux_3.acc_seg: 95.1460, loss: 0.6688
2023-05-23 21:32:55,834 - mmseg - INFO - Iter [4600/10000]	lr: 5.744e-02, eta: 1:20:34, time: 0.890, data_time: 0.191, memory: 14777, decode.loss_ce: 0.0655, decode.acc_seg: 96.6949, aux_0.loss_ce: 0.0672, aux_0.acc_seg: 96.6792, aux_1.loss_ce: 0.0824, aux_1.acc_seg: 95.9093, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.1286, aux_3.loss_ce: 0.1079, aux_3.acc_seg: 95.1154, loss: 0.6915
2023-05-23 21:33:40,407 - mmseg - INFO - Iter [4650/10000]	lr: 5.696e-02, eta: 1:19:49, time: 0.891, data_time: 0.192, memory: 14777, decode.loss_ce: 0.0637, decode.acc_seg: 96.7564, aux_0.loss_ce: 0.0646, aux_0.acc_seg: 96.7423, aux_1.loss_ce: 0.0799, aux_1.acc_seg: 95.9892, aux_2.loss_ce: 0.1138, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.2111, aux_3.loss_ce: 0.1026, aux_3.acc_seg: 95.2237, loss: 0.6732
2023-05-23 21:34:24,183 - mmseg - INFO - Iter [4700/10000]	lr: 5.648e-02, eta: 1:19:03, time: 0.876, data_time: 0.182, memory: 14777, decode.loss_ce: 0.0614, decode.acc_seg: 96.8209, aux_0.loss_ce: 0.0630, aux_0.acc_seg: 96.7952, aux_1.loss_ce: 0.0782, aux_1.acc_seg: 96.0195, aux_2.loss_ce: 0.1131, aux_2.loss_dice: 0.2473, aux_2.acc_seg: 96.2100, aux_3.loss_ce: 0.1038, aux_3.acc_seg: 95.1469, loss: 0.6667
2023-05-23 21:35:05,232 - mmseg - INFO - Iter [4750/10000]	lr: 5.600e-02, eta: 1:18:15, time: 0.821, data_time: 0.121, memory: 14777, decode.loss_ce: 0.0669, decode.acc_seg: 96.7212, aux_0.loss_ce: 0.0681, aux_0.acc_seg: 96.7006, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.9443, aux_2.loss_ce: 0.1157, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 96.1809, aux_3.loss_ce: 0.1089, aux_3.acc_seg: 95.1305, loss: 0.6949
2023-05-23 21:35:50,451 - mmseg - INFO - Iter [4800/10000]	lr: 5.552e-02, eta: 1:17:30, time: 0.904, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0622, decode.acc_seg: 96.8393, aux_0.loss_ce: 0.0638, aux_0.acc_seg: 96.8132, aux_1.loss_ce: 0.0792, aux_1.acc_seg: 96.0546, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 96.1656, aux_3.loss_ce: 0.1050, aux_3.acc_seg: 95.1999, loss: 0.6761
2023-05-23 21:36:36,132 - mmseg - INFO - Iter [4850/10000]	lr: 5.504e-02, eta: 1:16:47, time: 0.914, data_time: 0.197, memory: 14777, decode.loss_ce: 0.0614, decode.acc_seg: 96.7970, aux_0.loss_ce: 0.0629, aux_0.acc_seg: 96.7762, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 95.9898, aux_2.loss_ce: 0.1143, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 96.2046, aux_3.loss_ce: 0.1046, aux_3.acc_seg: 95.1205, loss: 0.6705
2023-05-23 21:37:17,660 - mmseg - INFO - Iter [4900/10000]	lr: 5.456e-02, eta: 1:15:59, time: 0.831, data_time: 0.127, memory: 14777, decode.loss_ce: 0.0615, decode.acc_seg: 96.9040, aux_0.loss_ce: 0.0630, aux_0.acc_seg: 96.8773, aux_1.loss_ce: 0.0785, aux_1.acc_seg: 96.1185, aux_2.loss_ce: 0.1141, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 96.1999, aux_3.loss_ce: 0.1057, aux_3.acc_seg: 95.2169, loss: 0.6712
2023-05-23 21:38:02,263 - mmseg - INFO - Iter [4950/10000]	lr: 5.408e-02, eta: 1:15:14, time: 0.892, data_time: 0.184, memory: 14777, decode.loss_ce: 0.0616, decode.acc_seg: 96.7928, aux_0.loss_ce: 0.0630, aux_0.acc_seg: 96.7683, aux_1.loss_ce: 0.0785, aux_1.acc_seg: 95.9908, aux_2.loss_ce: 0.1145, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.1840, aux_3.loss_ce: 0.1041, aux_3.acc_seg: 95.1296, loss: 0.6697
2023-05-23 21:38:46,942 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-05-23 21:38:49,187 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:38:49,188 - mmseg - INFO - Iter [5000/10000]	lr: 5.360e-02, eta: 1:14:31, time: 0.939, data_time: 0.193, memory: 14777, decode.loss_ce: 0.0613, decode.acc_seg: 96.8095, aux_0.loss_ce: 0.0629, aux_0.acc_seg: 96.7765, aux_1.loss_ce: 0.0781, aux_1.acc_seg: 96.0167, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.1621, aux_3.loss_ce: 0.1039, aux_3.acc_seg: 95.1618, loss: 0.6689
2023-05-23 21:39:07,012 - mmseg - INFO - per class results:
2023-05-23 21:39:07,013 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  |  65.8 |  72.6 |
|   Building  | 88.33 | 94.68 |
|     Car     | 93.24 |  96.3 |
| Column_Pole | 32.29 | 38.61 |
|    Fence    | 50.24 | 54.64 |
|  Pedestrian | 67.11 | 77.14 |
|     Road    | 96.53 | 98.27 |
|   Sidewalk  | 90.09 | 94.76 |
|  SignSymbol | 15.51 | 15.66 |
|     Sky     | 92.18 | 95.73 |
|     Tree    | 79.84 | 92.39 |
+-------------+-------+-------+
2023-05-23 21:39:07,013 - mmseg - INFO - Summary:
2023-05-23 21:39:07,014 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 93.99 | 70.1 | 75.53 |
+-------+------+-------+
2023-05-23 21:39:07,014 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:39:07,014 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9399, mIoU: 0.7010, mAcc: 0.7553, IoU.Bicyclist: 0.6580, IoU.Building: 0.8833, IoU.Car: 0.9324, IoU.Column_Pole: 0.3229, IoU.Fence: 0.5024, IoU.Pedestrian: 0.6711, IoU.Road: 0.9653, IoU.Sidewalk: 0.9009, IoU.SignSymbol: 0.1551, IoU.Sky: 0.9218, IoU.Tree: 0.7984, Acc.Bicyclist: 0.7260, Acc.Building: 0.9468, Acc.Car: 0.9630, Acc.Column_Pole: 0.3861, Acc.Fence: 0.5464, Acc.Pedestrian: 0.7714, Acc.Road: 0.9827, Acc.Sidewalk: 0.9476, Acc.SignSymbol: 0.1566, Acc.Sky: 0.9573, Acc.Tree: 0.9239
2023-05-23 21:39:52,176 - mmseg - INFO - Iter [5050/10000]	lr: 5.312e-02, eta: 1:14:05, time: 1.259, data_time: 0.550, memory: 14777, decode.loss_ce: 0.0617, decode.acc_seg: 96.9009, aux_0.loss_ce: 0.0631, aux_0.acc_seg: 96.8803, aux_1.loss_ce: 0.0791, aux_1.acc_seg: 96.0939, aux_2.loss_ce: 0.1156, aux_2.loss_dice: 0.2514, aux_2.acc_seg: 96.1845, aux_3.loss_ce: 0.1063, aux_3.acc_seg: 95.2193, loss: 0.6772
2023-05-23 21:40:33,262 - mmseg - INFO - Iter [5100/10000]	lr: 5.263e-02, eta: 1:13:16, time: 0.822, data_time: 0.124, memory: 14777, decode.loss_ce: 0.0623, decode.acc_seg: 96.7819, aux_0.loss_ce: 0.0636, aux_0.acc_seg: 96.7715, aux_1.loss_ce: 0.0792, aux_1.acc_seg: 96.0011, aux_2.loss_ce: 0.1140, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.2157, aux_3.loss_ce: 0.1066, aux_3.acc_seg: 95.0944, loss: 0.6748
2023-05-23 21:41:17,433 - mmseg - INFO - Iter [5150/10000]	lr: 5.215e-02, eta: 1:12:31, time: 0.883, data_time: 0.183, memory: 14777, decode.loss_ce: 0.0612, decode.acc_seg: 96.8862, aux_0.loss_ce: 0.0627, aux_0.acc_seg: 96.8567, aux_1.loss_ce: 0.0786, aux_1.acc_seg: 96.0878, aux_2.loss_ce: 0.1142, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.2308, aux_3.loss_ce: 0.1053, aux_3.acc_seg: 95.1702, loss: 0.6716
2023-05-23 21:42:01,927 - mmseg - INFO - Iter [5200/10000]	lr: 5.167e-02, eta: 1:11:45, time: 0.890, data_time: 0.189, memory: 14777, decode.loss_ce: 0.0642, decode.acc_seg: 96.7219, aux_0.loss_ce: 0.0648, aux_0.acc_seg: 96.7359, aux_1.loss_ce: 0.0803, aux_1.acc_seg: 95.9810, aux_2.loss_ce: 0.1165, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.1251, aux_3.loss_ce: 0.1063, aux_3.acc_seg: 95.1116, loss: 0.6831
2023-05-23 21:42:46,600 - mmseg - INFO - Iter [5250/10000]	lr: 5.118e-02, eta: 1:11:00, time: 0.893, data_time: 0.187, memory: 14777, decode.loss_ce: 0.0607, decode.acc_seg: 96.8028, aux_0.loss_ce: 0.0614, aux_0.acc_seg: 96.8041, aux_1.loss_ce: 0.0765, aux_1.acc_seg: 96.0460, aux_2.loss_ce: 0.1129, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 96.2500, aux_3.loss_ce: 0.1016, aux_3.acc_seg: 95.1623, loss: 0.6611
2023-05-23 21:43:27,747 - mmseg - INFO - Iter [5300/10000]	lr: 5.070e-02, eta: 1:10:12, time: 0.823, data_time: 0.121, memory: 14777, decode.loss_ce: 0.0619, decode.acc_seg: 96.7728, aux_0.loss_ce: 0.0633, aux_0.acc_seg: 96.7467, aux_1.loss_ce: 0.0790, aux_1.acc_seg: 95.9634, aux_2.loss_ce: 0.1133, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.2030, aux_3.loss_ce: 0.1050, aux_3.acc_seg: 95.0696, loss: 0.6694
2023-05-23 21:44:12,609 - mmseg - INFO - Iter [5350/10000]	lr: 5.021e-02, eta: 1:09:27, time: 0.897, data_time: 0.192, memory: 14777, decode.loss_ce: 0.0612, decode.acc_seg: 96.8687, aux_0.loss_ce: 0.0626, aux_0.acc_seg: 96.8394, aux_1.loss_ce: 0.0783, aux_1.acc_seg: 96.0637, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 96.2042, aux_3.loss_ce: 0.1053, aux_3.acc_seg: 95.1625, loss: 0.6709
2023-05-23 21:44:58,078 - mmseg - INFO - Iter [5400/10000]	lr: 4.972e-02, eta: 1:08:43, time: 0.909, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0645, decode.acc_seg: 96.7500, aux_0.loss_ce: 0.0655, aux_0.acc_seg: 96.7557, aux_1.loss_ce: 0.0811, aux_1.acc_seg: 95.9946, aux_2.loss_ce: 0.1151, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 96.2112, aux_3.loss_ce: 0.1081, aux_3.acc_seg: 95.1093, loss: 0.6845
2023-05-23 21:45:38,855 - mmseg - INFO - Iter [5450/10000]	lr: 4.924e-02, eta: 1:07:55, time: 0.816, data_time: 0.120, memory: 14777, decode.loss_ce: 0.0634, decode.acc_seg: 96.8167, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.8058, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 96.0510, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 96.2029, aux_3.loss_ce: 0.1068, aux_3.acc_seg: 95.1494, loss: 0.6816
2023-05-23 21:46:24,422 - mmseg - INFO - Iter [5500/10000]	lr: 4.875e-02, eta: 1:07:11, time: 0.911, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0606, decode.acc_seg: 96.8707, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.8330, aux_1.loss_ce: 0.0779, aux_1.acc_seg: 96.0405, aux_2.loss_ce: 0.1140, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.1864, aux_3.loss_ce: 0.1045, aux_3.acc_seg: 95.1555, loss: 0.6673
2023-05-23 21:47:10,125 - mmseg - INFO - Iter [5550/10000]	lr: 4.826e-02, eta: 1:06:27, time: 0.914, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0614, decode.acc_seg: 96.8038, aux_0.loss_ce: 0.0629, aux_0.acc_seg: 96.7829, aux_1.loss_ce: 0.0780, aux_1.acc_seg: 96.0177, aux_2.loss_ce: 0.1142, aux_2.loss_dice: 0.2483, aux_2.acc_seg: 96.1879, aux_3.loss_ce: 0.1050, aux_3.acc_seg: 95.1061, loss: 0.6698
2023-05-23 21:47:55,424 - mmseg - INFO - Iter [5600/10000]	lr: 4.778e-02, eta: 1:05:42, time: 0.906, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0608, decode.acc_seg: 96.9040, aux_0.loss_ce: 0.0619, aux_0.acc_seg: 96.9033, aux_1.loss_ce: 0.0775, aux_1.acc_seg: 96.1376, aux_2.loss_ce: 0.1143, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.2264, aux_3.loss_ce: 0.1040, aux_3.acc_seg: 95.2577, loss: 0.6676
2023-05-23 21:48:36,761 - mmseg - INFO - Iter [5650/10000]	lr: 4.729e-02, eta: 1:04:55, time: 0.827, data_time: 0.122, memory: 14777, decode.loss_ce: 0.0619, decode.acc_seg: 96.8111, aux_0.loss_ce: 0.0635, aux_0.acc_seg: 96.7682, aux_1.loss_ce: 0.0787, aux_1.acc_seg: 96.0066, aux_2.loss_ce: 0.1152, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.1618, aux_3.loss_ce: 0.1054, aux_3.acc_seg: 95.0897, loss: 0.6736
2023-05-23 21:49:22,054 - mmseg - INFO - Iter [5700/10000]	lr: 4.680e-02, eta: 1:04:10, time: 0.906, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0605, decode.acc_seg: 96.8816, aux_0.loss_ce: 0.0616, aux_0.acc_seg: 96.8714, aux_1.loss_ce: 0.0764, aux_1.acc_seg: 96.1227, aux_2.loss_ce: 0.1124, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.2734, aux_3.loss_ce: 0.1032, aux_3.acc_seg: 95.2315, loss: 0.6612
2023-05-23 21:50:06,731 - mmseg - INFO - Iter [5750/10000]	lr: 4.631e-02, eta: 1:03:26, time: 0.894, data_time: 0.189, memory: 14777, decode.loss_ce: 0.0607, decode.acc_seg: 96.8216, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.7967, aux_1.loss_ce: 0.0769, aux_1.acc_seg: 96.0524, aux_2.loss_ce: 0.1118, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 96.2965, aux_3.loss_ce: 0.1032, aux_3.acc_seg: 95.1558, loss: 0.6621
2023-05-23 21:50:47,405 - mmseg - INFO - Iter [5800/10000]	lr: 4.582e-02, eta: 1:02:38, time: 0.813, data_time: 0.116, memory: 14777, decode.loss_ce: 0.0638, decode.acc_seg: 96.7500, aux_0.loss_ce: 0.0645, aux_0.acc_seg: 96.7565, aux_1.loss_ce: 0.0798, aux_1.acc_seg: 96.0101, aux_2.loss_ce: 0.1143, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 96.2564, aux_3.loss_ce: 0.1058, aux_3.acc_seg: 95.1259, loss: 0.6782
2023-05-23 21:51:32,791 - mmseg - INFO - Iter [5850/10000]	lr: 4.533e-02, eta: 1:01:54, time: 0.908, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0591, decode.acc_seg: 96.8670, aux_0.loss_ce: 0.0606, aux_0.acc_seg: 96.8305, aux_1.loss_ce: 0.0756, aux_1.acc_seg: 96.0629, aux_2.loss_ce: 0.1118, aux_2.loss_dice: 0.2463, aux_2.acc_seg: 96.3000, aux_3.loss_ce: 0.1017, aux_3.acc_seg: 95.1594, loss: 0.6552
2023-05-23 21:52:17,183 - mmseg - INFO - Iter [5900/10000]	lr: 4.483e-02, eta: 1:01:09, time: 0.888, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0602, decode.acc_seg: 96.9239, aux_0.loss_ce: 0.0615, aux_0.acc_seg: 96.9025, aux_1.loss_ce: 0.0772, aux_1.acc_seg: 96.1462, aux_2.loss_ce: 0.1145, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.1907, aux_3.loss_ce: 0.1048, aux_3.acc_seg: 95.1958, loss: 0.6669
2023-05-23 21:53:02,295 - mmseg - INFO - Iter [5950/10000]	lr: 4.434e-02, eta: 1:00:24, time: 0.902, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0590, decode.acc_seg: 96.8854, aux_0.loss_ce: 0.0607, aux_0.acc_seg: 96.8477, aux_1.loss_ce: 0.0763, aux_1.acc_seg: 96.0710, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2471, aux_2.acc_seg: 96.1671, aux_3.loss_ce: 0.1031, aux_3.acc_seg: 95.1511, loss: 0.6598
2023-05-23 21:53:42,858 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-05-23 21:53:44,494 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:53:44,494 - mmseg - INFO - Iter [6000/10000]	lr: 4.385e-02, eta: 0:59:38, time: 0.845, data_time: 0.119, memory: 14777, decode.loss_ce: 0.0612, decode.acc_seg: 96.8643, aux_0.loss_ce: 0.0627, aux_0.acc_seg: 96.8314, aux_1.loss_ce: 0.0787, aux_1.acc_seg: 96.0546, aux_2.loss_ce: 0.1156, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.1779, aux_3.loss_ce: 0.1063, aux_3.acc_seg: 95.1127, loss: 0.6742
2023-05-23 21:54:02,086 - mmseg - INFO - per class results:
2023-05-23 21:54:02,087 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 66.92 | 74.32 |
|   Building  | 88.89 | 95.14 |
|     Car     | 92.51 | 95.24 |
| Column_Pole | 34.36 | 42.02 |
|    Fence    | 48.31 | 51.52 |
|  Pedestrian | 69.34 | 83.22 |
|     Road    | 96.53 |  98.5 |
|   Sidewalk  | 90.08 | 95.17 |
|  SignSymbol | 23.21 | 26.13 |
|     Sky     | 91.14 | 93.04 |
|     Tree    | 79.66 | 94.05 |
+-------------+-------+-------+
2023-05-23 21:54:02,087 - mmseg - INFO - Summary:
2023-05-23 21:54:02,088 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.92 | 70.99 | 77.12 |
+-------+-------+-------+
2023-05-23 21:54:02,099 - mmseg - INFO - The previous best checkpoint /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone/best_mIoU_iter_3000.pth was removed
2023-05-23 21:54:03,627 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_6000.pth.
2023-05-23 21:54:03,628 - mmseg - INFO - Best mIoU is 0.7099 at 6000 iter.
2023-05-23 21:54:03,628 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 21:54:03,628 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9392, mIoU: 0.7099, mAcc: 0.7712, IoU.Bicyclist: 0.6692, IoU.Building: 0.8889, IoU.Car: 0.9251, IoU.Column_Pole: 0.3436, IoU.Fence: 0.4831, IoU.Pedestrian: 0.6934, IoU.Road: 0.9653, IoU.Sidewalk: 0.9008, IoU.SignSymbol: 0.2321, IoU.Sky: 0.9114, IoU.Tree: 0.7966, Acc.Bicyclist: 0.7432, Acc.Building: 0.9514, Acc.Car: 0.9524, Acc.Column_Pole: 0.4202, Acc.Fence: 0.5152, Acc.Pedestrian: 0.8322, Acc.Road: 0.9850, Acc.Sidewalk: 0.9517, Acc.SignSymbol: 0.2613, Acc.Sky: 0.9304, Acc.Tree: 0.9405
2023-05-23 21:54:48,085 - mmseg - INFO - Iter [6050/10000]	lr: 4.336e-02, eta: 0:59:05, time: 1.271, data_time: 0.572, memory: 14777, decode.loss_ce: 0.0635, decode.acc_seg: 96.7632, aux_0.loss_ce: 0.0647, aux_0.acc_seg: 96.7472, aux_1.loss_ce: 0.0804, aux_1.acc_seg: 95.9705, aux_2.loss_ce: 0.1154, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.1526, aux_3.loss_ce: 0.1081, aux_3.acc_seg: 95.0486, loss: 0.6813
2023-05-23 21:55:31,867 - mmseg - INFO - Iter [6100/10000]	lr: 4.286e-02, eta: 0:58:20, time: 0.876, data_time: 0.182, memory: 14777, decode.loss_ce: 0.0610, decode.acc_seg: 96.9195, aux_0.loss_ce: 0.0626, aux_0.acc_seg: 96.8858, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 96.1284, aux_2.loss_ce: 0.1142, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.2223, aux_3.loss_ce: 0.1069, aux_3.acc_seg: 95.1863, loss: 0.6722
2023-05-23 21:56:17,290 - mmseg - INFO - Iter [6150/10000]	lr: 4.237e-02, eta: 0:57:35, time: 0.908, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0610, decode.acc_seg: 96.8103, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.7877, aux_1.loss_ce: 0.0778, aux_1.acc_seg: 96.0155, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.1837, aux_3.loss_ce: 0.1052, aux_3.acc_seg: 95.0809, loss: 0.6691
2023-05-23 21:56:59,716 - mmseg - INFO - Iter [6200/10000]	lr: 4.187e-02, eta: 0:56:49, time: 0.849, data_time: 0.131, memory: 14777, decode.loss_ce: 0.0608, decode.acc_seg: 96.8716, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.8478, aux_1.loss_ce: 0.0782, aux_1.acc_seg: 96.0553, aux_2.loss_ce: 0.1150, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 96.1829, aux_3.loss_ce: 0.1057, aux_3.acc_seg: 95.1260, loss: 0.6719
2023-05-23 21:57:44,210 - mmseg - INFO - Iter [6250/10000]	lr: 4.138e-02, eta: 0:56:04, time: 0.890, data_time: 0.192, memory: 14777, decode.loss_ce: 0.0610, decode.acc_seg: 96.8574, aux_0.loss_ce: 0.0626, aux_0.acc_seg: 96.8248, aux_1.loss_ce: 0.0787, aux_1.acc_seg: 96.0326, aux_2.loss_ce: 0.1133, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 96.2374, aux_3.loss_ce: 0.1048, aux_3.acc_seg: 95.1539, loss: 0.6683
2023-05-23 21:58:28,230 - mmseg - INFO - Iter [6300/10000]	lr: 4.088e-02, eta: 0:55:18, time: 0.880, data_time: 0.188, memory: 14777, decode.loss_ce: 0.0606, decode.acc_seg: 96.8651, aux_0.loss_ce: 0.0618, aux_0.acc_seg: 96.8429, aux_1.loss_ce: 0.0775, aux_1.acc_seg: 96.0768, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2476, aux_2.acc_seg: 96.2315, aux_3.loss_ce: 0.1055, aux_3.acc_seg: 95.1110, loss: 0.6666
2023-05-23 21:59:10,159 - mmseg - INFO - Iter [6350/10000]	lr: 4.038e-02, eta: 0:54:32, time: 0.839, data_time: 0.129, memory: 14777, decode.loss_ce: 0.0591, decode.acc_seg: 96.9050, aux_0.loss_ce: 0.0607, aux_0.acc_seg: 96.8727, aux_1.loss_ce: 0.0759, aux_1.acc_seg: 96.1132, aux_2.loss_ce: 0.1124, aux_2.loss_dice: 0.2475, aux_2.acc_seg: 96.2813, aux_3.loss_ce: 0.1035, aux_3.acc_seg: 95.1795, loss: 0.6591
2023-05-23 21:59:54,926 - mmseg - INFO - Iter [6400/10000]	lr: 3.988e-02, eta: 0:53:47, time: 0.895, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0587, decode.acc_seg: 96.9282, aux_0.loss_ce: 0.0603, aux_0.acc_seg: 96.8925, aux_1.loss_ce: 0.0757, aux_1.acc_seg: 96.1340, aux_2.loss_ce: 0.1147, aux_2.loss_dice: 0.2476, aux_2.acc_seg: 96.1537, aux_3.loss_ce: 0.1026, aux_3.acc_seg: 95.1977, loss: 0.6596
2023-05-23 22:00:39,486 - mmseg - INFO - Iter [6450/10000]	lr: 3.938e-02, eta: 0:53:02, time: 0.891, data_time: 0.187, memory: 14777, decode.loss_ce: 0.0627, decode.acc_seg: 96.8093, aux_0.loss_ce: 0.0640, aux_0.acc_seg: 96.7747, aux_1.loss_ce: 0.0804, aux_1.acc_seg: 95.9749, aux_2.loss_ce: 0.1172, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 96.0926, aux_3.loss_ce: 0.1082, aux_3.acc_seg: 95.0349, loss: 0.6833
2023-05-23 22:01:24,863 - mmseg - INFO - Iter [6500/10000]	lr: 3.888e-02, eta: 0:52:17, time: 0.908, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0605, decode.acc_seg: 96.8388, aux_0.loss_ce: 0.0623, aux_0.acc_seg: 96.7925, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 95.9847, aux_2.loss_ce: 0.1144, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.1886, aux_3.loss_ce: 0.1052, aux_3.acc_seg: 95.0754, loss: 0.6699
2023-05-23 22:02:06,184 - mmseg - INFO - Iter [6550/10000]	lr: 3.838e-02, eta: 0:51:31, time: 0.826, data_time: 0.128, memory: 14777, decode.loss_ce: 0.0595, decode.acc_seg: 96.9234, aux_0.loss_ce: 0.0610, aux_0.acc_seg: 96.8868, aux_1.loss_ce: 0.0772, aux_1.acc_seg: 96.1149, aux_2.loss_ce: 0.1132, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.2647, aux_3.loss_ce: 0.1041, aux_3.acc_seg: 95.2212, loss: 0.6637
2023-05-23 22:02:51,568 - mmseg - INFO - Iter [6600/10000]	lr: 3.788e-02, eta: 0:50:46, time: 0.908, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0605, decode.acc_seg: 96.8836, aux_0.loss_ce: 0.0621, aux_0.acc_seg: 96.8576, aux_1.loss_ce: 0.0779, aux_1.acc_seg: 96.0780, aux_2.loss_ce: 0.1130, aux_2.loss_dice: 0.2473, aux_2.acc_seg: 96.2511, aux_3.loss_ce: 0.1058, aux_3.acc_seg: 95.0960, loss: 0.6665
2023-05-23 22:03:36,676 - mmseg - INFO - Iter [6650/10000]	lr: 3.738e-02, eta: 0:50:02, time: 0.902, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0601, decode.acc_seg: 96.8698, aux_0.loss_ce: 0.0618, aux_0.acc_seg: 96.8343, aux_1.loss_ce: 0.0774, aux_1.acc_seg: 96.0719, aux_2.loss_ce: 0.1133, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 96.2322, aux_3.loss_ce: 0.1045, aux_3.acc_seg: 95.1354, loss: 0.6653
2023-05-23 22:04:23,045 - mmseg - INFO - Iter [6700/10000]	lr: 3.688e-02, eta: 0:49:18, time: 0.927, data_time: 0.212, memory: 14777, decode.loss_ce: 0.0607, decode.acc_seg: 96.9183, aux_0.loss_ce: 0.0624, aux_0.acc_seg: 96.8692, aux_1.loss_ce: 0.0777, aux_1.acc_seg: 96.1236, aux_2.loss_ce: 0.1149, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 96.1881, aux_3.loss_ce: 0.1058, aux_3.acc_seg: 95.1789, loss: 0.6704
2023-05-23 22:05:05,158 - mmseg - INFO - Iter [6750/10000]	lr: 3.638e-02, eta: 0:48:31, time: 0.842, data_time: 0.134, memory: 14777, decode.loss_ce: 0.0595, decode.acc_seg: 96.8879, aux_0.loss_ce: 0.0608, aux_0.acc_seg: 96.8643, aux_1.loss_ce: 0.0765, aux_1.acc_seg: 96.0817, aux_2.loss_ce: 0.1126, aux_2.loss_dice: 0.2473, aux_2.acc_seg: 96.2787, aux_3.loss_ce: 0.1050, aux_3.acc_seg: 95.1244, loss: 0.6617
2023-05-23 22:05:50,409 - mmseg - INFO - Iter [6800/10000]	lr: 3.587e-02, eta: 0:47:47, time: 0.905, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0611, decode.acc_seg: 96.8445, aux_0.loss_ce: 0.0627, aux_0.acc_seg: 96.8034, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 96.0277, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.1797, aux_3.loss_ce: 0.1071, aux_3.acc_seg: 95.0648, loss: 0.6731
2023-05-23 22:06:36,083 - mmseg - INFO - Iter [6850/10000]	lr: 3.537e-02, eta: 0:47:02, time: 0.913, data_time: 0.209, memory: 14777, decode.loss_ce: 0.0601, decode.acc_seg: 96.9289, aux_0.loss_ce: 0.0614, aux_0.acc_seg: 96.8985, aux_1.loss_ce: 0.0774, aux_1.acc_seg: 96.1164, aux_2.loss_ce: 0.1145, aux_2.loss_dice: 0.2473, aux_2.acc_seg: 96.1462, aux_3.loss_ce: 0.1054, aux_3.acc_seg: 95.1465, loss: 0.6660
2023-05-23 22:07:17,954 - mmseg - INFO - Iter [6900/10000]	lr: 3.486e-02, eta: 0:46:16, time: 0.837, data_time: 0.133, memory: 14777, decode.loss_ce: 0.0587, decode.acc_seg: 96.9512, aux_0.loss_ce: 0.0604, aux_0.acc_seg: 96.9013, aux_1.loss_ce: 0.0754, aux_1.acc_seg: 96.1355, aux_2.loss_ce: 0.1130, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 96.2221, aux_3.loss_ce: 0.1038, aux_3.acc_seg: 95.1651, loss: 0.6577
2023-05-23 22:08:03,855 - mmseg - INFO - Iter [6950/10000]	lr: 3.436e-02, eta: 0:45:32, time: 0.918, data_time: 0.210, memory: 14777, decode.loss_ce: 0.0618, decode.acc_seg: 96.8231, aux_0.loss_ce: 0.0633, aux_0.acc_seg: 96.7943, aux_1.loss_ce: 0.0787, aux_1.acc_seg: 96.0365, aux_2.loss_ce: 0.1139, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.2674, aux_3.loss_ce: 0.1071, aux_3.acc_seg: 95.0719, loss: 0.6745
2023-05-23 22:08:49,952 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-05-23 22:08:51,901 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 22:08:51,902 - mmseg - INFO - Iter [7000/10000]	lr: 3.385e-02, eta: 0:44:49, time: 0.962, data_time: 0.212, memory: 14777, decode.loss_ce: 0.0610, decode.acc_seg: 96.8689, aux_0.loss_ce: 0.0623, aux_0.acc_seg: 96.8444, aux_1.loss_ce: 0.0787, aux_1.acc_seg: 96.0544, aux_2.loss_ce: 0.1156, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 96.1578, aux_3.loss_ce: 0.1071, aux_3.acc_seg: 95.1100, loss: 0.6746
2023-05-23 22:09:20,893 - mmseg - INFO - per class results:
2023-05-23 22:09:20,912 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 65.69 | 72.42 |
|   Building  | 89.07 | 94.91 |
|     Car     | 92.56 | 96.02 |
| Column_Pole | 36.78 | 48.51 |
|    Fence    | 51.19 | 54.97 |
|  Pedestrian | 67.51 | 85.71 |
|     Road    | 96.48 | 98.48 |
|   Sidewalk  | 89.76 | 95.01 |
|  SignSymbol | 29.58 | 33.48 |
|     Sky     | 91.92 | 94.35 |
|     Tree    | 80.86 | 92.55 |
+-------------+-------+-------+
2023-05-23 22:09:20,912 - mmseg - INFO - Summary:
2023-05-23 22:09:20,912 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.11 | 71.95 | 78.76 |
+-------+-------+-------+
2023-05-23 22:09:20,920 - mmseg - INFO - The previous best checkpoint /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone/best_mIoU_iter_6000.pth was removed
2023-05-23 22:09:22,298 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_7000.pth.
2023-05-23 22:09:22,298 - mmseg - INFO - Best mIoU is 0.7195 at 7000 iter.
2023-05-23 22:09:22,298 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 22:09:22,298 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9411, mIoU: 0.7195, mAcc: 0.7876, IoU.Bicyclist: 0.6569, IoU.Building: 0.8907, IoU.Car: 0.9256, IoU.Column_Pole: 0.3678, IoU.Fence: 0.5119, IoU.Pedestrian: 0.6751, IoU.Road: 0.9648, IoU.Sidewalk: 0.8976, IoU.SignSymbol: 0.2958, IoU.Sky: 0.9192, IoU.Tree: 0.8086, Acc.Bicyclist: 0.7242, Acc.Building: 0.9491, Acc.Car: 0.9602, Acc.Column_Pole: 0.4851, Acc.Fence: 0.5497, Acc.Pedestrian: 0.8571, Acc.Road: 0.9848, Acc.Sidewalk: 0.9501, Acc.SignSymbol: 0.3348, Acc.Sky: 0.9435, Acc.Tree: 0.9255
2023-05-23 22:10:07,906 - mmseg - INFO - Iter [7050/10000]	lr: 3.334e-02, eta: 0:44:17, time: 1.519, data_time: 0.817, memory: 14777, decode.loss_ce: 0.0603, decode.acc_seg: 96.9249, aux_0.loss_ce: 0.0618, aux_0.acc_seg: 96.8965, aux_1.loss_ce: 0.0777, aux_1.acc_seg: 96.1164, aux_2.loss_ce: 0.1151, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.1669, aux_3.loss_ce: 0.1059, aux_3.acc_seg: 95.1368, loss: 0.6700
2023-05-23 22:10:49,738 - mmseg - INFO - Iter [7100/10000]	lr: 3.283e-02, eta: 0:43:30, time: 0.837, data_time: 0.139, memory: 14777, decode.loss_ce: 0.0553, decode.acc_seg: 97.0954, aux_0.loss_ce: 0.0566, aux_0.acc_seg: 97.0587, aux_1.loss_ce: 0.0717, aux_1.acc_seg: 96.3004, aux_2.loss_ce: 0.1106, aux_2.loss_dice: 0.2446, aux_2.acc_seg: 96.2902, aux_3.loss_ce: 0.0989, aux_3.acc_seg: 95.3489, loss: 0.6377
2023-05-23 22:11:35,225 - mmseg - INFO - Iter [7150/10000]	lr: 3.232e-02, eta: 0:42:46, time: 0.910, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0572, decode.acc_seg: 96.9383, aux_0.loss_ce: 0.0591, aux_0.acc_seg: 96.8908, aux_1.loss_ce: 0.0741, aux_1.acc_seg: 96.1172, aux_2.loss_ce: 0.1108, aux_2.loss_dice: 0.2440, aux_2.acc_seg: 96.2722, aux_3.loss_ce: 0.1015, aux_3.acc_seg: 95.1318, loss: 0.6467
2023-05-23 22:12:20,560 - mmseg - INFO - Iter [7200/10000]	lr: 3.181e-02, eta: 0:42:01, time: 0.907, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0564, decode.acc_seg: 96.9433, aux_0.loss_ce: 0.0581, aux_0.acc_seg: 96.8911, aux_1.loss_ce: 0.0737, aux_1.acc_seg: 96.0783, aux_2.loss_ce: 0.1113, aux_2.loss_dice: 0.2442, aux_2.acc_seg: 96.2538, aux_3.loss_ce: 0.1018, aux_3.acc_seg: 95.0922, loss: 0.6454
2023-05-23 22:13:02,389 - mmseg - INFO - Iter [7250/10000]	lr: 3.130e-02, eta: 0:41:15, time: 0.837, data_time: 0.136, memory: 14777, decode.loss_ce: 0.0572, decode.acc_seg: 96.9877, aux_0.loss_ce: 0.0588, aux_0.acc_seg: 96.9476, aux_1.loss_ce: 0.0742, aux_1.acc_seg: 96.1749, aux_2.loss_ce: 0.1125, aux_2.loss_dice: 0.2467, aux_2.acc_seg: 96.2572, aux_3.loss_ce: 0.1015, aux_3.acc_seg: 95.2427, loss: 0.6508
2023-05-23 22:13:48,753 - mmseg - INFO - Iter [7300/10000]	lr: 3.079e-02, eta: 0:40:30, time: 0.927, data_time: 0.213, memory: 14777, decode.loss_ce: 0.0578, decode.acc_seg: 96.9505, aux_0.loss_ce: 0.0595, aux_0.acc_seg: 96.9008, aux_1.loss_ce: 0.0753, aux_1.acc_seg: 96.1087, aux_2.loss_ce: 0.1123, aux_2.loss_dice: 0.2468, aux_2.acc_seg: 96.2584, aux_3.loss_ce: 0.1038, aux_3.acc_seg: 95.1028, loss: 0.6556
2023-05-23 22:14:34,855 - mmseg - INFO - Iter [7350/10000]	lr: 3.027e-02, eta: 0:39:45, time: 0.922, data_time: 0.211, memory: 14777, decode.loss_ce: 0.0588, decode.acc_seg: 96.9285, aux_0.loss_ce: 0.0607, aux_0.acc_seg: 96.8785, aux_1.loss_ce: 0.0764, aux_1.acc_seg: 96.0807, aux_2.loss_ce: 0.1142, aux_2.loss_dice: 0.2476, aux_2.acc_seg: 96.1520, aux_3.loss_ce: 0.1043, aux_3.acc_seg: 95.1534, loss: 0.6620
2023-05-23 22:15:20,636 - mmseg - INFO - Iter [7400/10000]	lr: 2.976e-02, eta: 0:39:01, time: 0.916, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0590, decode.acc_seg: 96.9516, aux_0.loss_ce: 0.0608, aux_0.acc_seg: 96.9066, aux_1.loss_ce: 0.0763, aux_1.acc_seg: 96.1468, aux_2.loss_ce: 0.1133, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.2513, aux_3.loss_ce: 0.1045, aux_3.acc_seg: 95.1953, loss: 0.6618
2023-05-23 22:16:02,841 - mmseg - INFO - Iter [7450/10000]	lr: 2.924e-02, eta: 0:38:15, time: 0.844, data_time: 0.139, memory: 14777, decode.loss_ce: 0.0574, decode.acc_seg: 96.9492, aux_0.loss_ce: 0.0589, aux_0.acc_seg: 96.9114, aux_1.loss_ce: 0.0745, aux_1.acc_seg: 96.1239, aux_2.loss_ce: 0.1118, aux_2.loss_dice: 0.2458, aux_2.acc_seg: 96.2867, aux_3.loss_ce: 0.1021, aux_3.acc_seg: 95.1730, loss: 0.6505
2023-05-23 22:16:49,390 - mmseg - INFO - Iter [7500/10000]	lr: 2.873e-02, eta: 0:37:30, time: 0.931, data_time: 0.213, memory: 14777, decode.loss_ce: 0.0609, decode.acc_seg: 96.8871, aux_0.loss_ce: 0.0621, aux_0.acc_seg: 96.8516, aux_1.loss_ce: 0.0780, aux_1.acc_seg: 96.0626, aux_2.loss_ce: 0.1140, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.2380, aux_3.loss_ce: 0.1073, aux_3.acc_seg: 95.0625, loss: 0.6713
2023-05-23 22:17:36,400 - mmseg - INFO - Iter [7550/10000]	lr: 2.821e-02, eta: 0:36:46, time: 0.940, data_time: 0.214, memory: 14777, decode.loss_ce: 0.0593, decode.acc_seg: 96.9428, aux_0.loss_ce: 0.0609, aux_0.acc_seg: 96.9032, aux_1.loss_ce: 0.0768, aux_1.acc_seg: 96.1161, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.2466, aux_3.loss_ce: 0.1054, aux_3.acc_seg: 95.1408, loss: 0.6666
2023-05-23 22:18:23,680 - mmseg - INFO - Iter [7600/10000]	lr: 2.769e-02, eta: 0:36:02, time: 0.946, data_time: 0.213, memory: 14777, decode.loss_ce: 0.0585, decode.acc_seg: 96.9209, aux_0.loss_ce: 0.0601, aux_0.acc_seg: 96.8794, aux_1.loss_ce: 0.0756, aux_1.acc_seg: 96.1070, aux_2.loss_ce: 0.1128, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.2453, aux_3.loss_ce: 0.1047, aux_3.acc_seg: 95.0702, loss: 0.6586
2023-05-23 22:19:07,653 - mmseg - INFO - Iter [7650/10000]	lr: 2.717e-02, eta: 0:35:16, time: 0.879, data_time: 0.147, memory: 14777, decode.loss_ce: 0.0582, decode.acc_seg: 97.0138, aux_0.loss_ce: 0.0599, aux_0.acc_seg: 96.9714, aux_1.loss_ce: 0.0759, aux_1.acc_seg: 96.1987, aux_2.loss_ce: 0.1153, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 96.1414, aux_3.loss_ce: 0.1046, aux_3.acc_seg: 95.2233, loss: 0.6625
2023-05-23 22:19:54,804 - mmseg - INFO - Iter [7700/10000]	lr: 2.665e-02, eta: 0:34:32, time: 0.943, data_time: 0.216, memory: 14777, decode.loss_ce: 0.0592, decode.acc_seg: 96.9479, aux_0.loss_ce: 0.0607, aux_0.acc_seg: 96.9146, aux_1.loss_ce: 0.0770, aux_1.acc_seg: 96.1136, aux_2.loss_ce: 0.1150, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.1654, aux_3.loss_ce: 0.1059, aux_3.acc_seg: 95.1433, loss: 0.6674
2023-05-23 22:20:41,394 - mmseg - INFO - Iter [7750/10000]	lr: 2.613e-02, eta: 0:33:47, time: 0.932, data_time: 0.210, memory: 14777, decode.loss_ce: 0.0583, decode.acc_seg: 96.9647, aux_0.loss_ce: 0.0601, aux_0.acc_seg: 96.9215, aux_1.loss_ce: 0.0758, aux_1.acc_seg: 96.1481, aux_2.loss_ce: 0.1128, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 96.2594, aux_3.loss_ce: 0.1046, aux_3.acc_seg: 95.1285, loss: 0.6593
2023-05-23 22:21:24,385 - mmseg - INFO - Iter [7800/10000]	lr: 2.561e-02, eta: 0:33:01, time: 0.860, data_time: 0.140, memory: 14777, decode.loss_ce: 0.0603, decode.acc_seg: 96.9230, aux_0.loss_ce: 0.0618, aux_0.acc_seg: 96.8926, aux_1.loss_ce: 0.0779, aux_1.acc_seg: 96.1154, aux_2.loss_ce: 0.1149, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.1732, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 95.1723, loss: 0.6704
2023-05-23 22:22:11,459 - mmseg - INFO - Iter [7850/10000]	lr: 2.508e-02, eta: 0:32:17, time: 0.941, data_time: 0.214, memory: 14777, decode.loss_ce: 0.0586, decode.acc_seg: 96.9633, aux_0.loss_ce: 0.0603, aux_0.acc_seg: 96.9236, aux_1.loss_ce: 0.0757, aux_1.acc_seg: 96.1572, aux_2.loss_ce: 0.1128, aux_2.loss_dice: 0.2467, aux_2.acc_seg: 96.2255, aux_3.loss_ce: 0.1047, aux_3.acc_seg: 95.1590, loss: 0.6587
2023-05-23 22:22:58,096 - mmseg - INFO - Iter [7900/10000]	lr: 2.456e-02, eta: 0:31:32, time: 0.933, data_time: 0.212, memory: 14777, decode.loss_ce: 0.0584, decode.acc_seg: 96.9840, aux_0.loss_ce: 0.0601, aux_0.acc_seg: 96.9454, aux_1.loss_ce: 0.0761, aux_1.acc_seg: 96.1558, aux_2.loss_ce: 0.1130, aux_2.loss_dice: 0.2472, aux_2.acc_seg: 96.2300, aux_3.loss_ce: 0.1047, aux_3.acc_seg: 95.2023, loss: 0.6596
2023-05-23 22:23:43,740 - mmseg - INFO - Iter [7950/10000]	lr: 2.403e-02, eta: 0:30:47, time: 0.913, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0555, decode.acc_seg: 97.0574, aux_0.loss_ce: 0.0574, aux_0.acc_seg: 96.9949, aux_1.loss_ce: 0.0733, aux_1.acc_seg: 96.2036, aux_2.loss_ce: 0.1127, aux_2.loss_dice: 0.2461, aux_2.acc_seg: 96.2061, aux_3.loss_ce: 0.1017, aux_3.acc_seg: 95.2226, loss: 0.6468
2023-05-23 22:24:27,073 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-05-23 22:24:29,521 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 22:24:29,522 - mmseg - INFO - Iter [8000/10000]	lr: 2.350e-02, eta: 0:30:03, time: 0.916, data_time: 0.139, memory: 14777, decode.loss_ce: 0.0593, decode.acc_seg: 96.9374, aux_0.loss_ce: 0.0608, aux_0.acc_seg: 96.8915, aux_1.loss_ce: 0.0766, aux_1.acc_seg: 96.1221, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2483, aux_2.acc_seg: 96.2275, aux_3.loss_ce: 0.1068, aux_3.acc_seg: 95.1153, loss: 0.6655
2023-05-23 22:24:45,292 - mmseg - INFO - per class results:
2023-05-23 22:24:45,293 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 66.71 | 73.99 |
|   Building  | 88.77 | 94.73 |
|     Car     | 93.13 | 95.32 |
| Column_Pole | 34.67 | 42.77 |
|    Fence    | 50.43 | 55.68 |
|  Pedestrian | 69.06 | 80.74 |
|     Road    | 96.61 | 98.24 |
|   Sidewalk  | 90.27 | 95.74 |
|  SignSymbol | 23.21 | 24.15 |
|     Sky     | 92.25 | 95.48 |
|     Tree    | 80.31 | 92.42 |
+-------------+-------+-------+
2023-05-23 22:24:45,293 - mmseg - INFO - Summary:
2023-05-23 22:24:45,293 - mmseg - INFO - 
+-------+------+------+
|  aAcc | mIoU | mAcc |
+-------+------+------+
| 94.13 | 71.4 | 77.2 |
+-------+------+------+
2023-05-23 22:24:45,294 - mmseg - INFO - Exp name: tuneprompt_1x16_720x960_10k_camvid_trainval_contextlength16_fixbackbone.py
2023-05-23 22:24:45,294 - mmseg - INFO - Iter(val) [233]	aAcc: 0.9413, mIoU: 0.7140, mAcc: 0.7720, IoU.Bicyclist: 0.6671, IoU.Building: 0.8877, IoU.Car: 0.9313, IoU.Column_Pole: 0.3467, IoU.Fence: 0.5043, IoU.Pedestrian: 0.6906, IoU.Road: 0.9661, IoU.Sidewalk: 0.9027, IoU.SignSymbol: 0.2321, IoU.Sky: 0.9225, IoU.Tree: 0.8031, Acc.Bicyclist: 0.7399, Acc.Building: 0.9473, Acc.Car: 0.9532, Acc.Column_Pole: 0.4277, Acc.Fence: 0.5568, Acc.Pedestrian: 0.8074, Acc.Road: 0.9824, Acc.Sidewalk: 0.9574, Acc.SignSymbol: 0.2415, Acc.Sky: 0.9548, Acc.Tree: 0.9242
2023-05-23 22:25:31,032 - mmseg - INFO - Iter [8050/10000]	lr: 2.297e-02, eta: 0:29:21, time: 1.230, data_time: 0.519, memory: 14777, decode.loss_ce: 0.0584, decode.acc_seg: 97.0209, aux_0.loss_ce: 0.0600, aux_0.acc_seg: 96.9871, aux_1.loss_ce: 0.0754, aux_1.acc_seg: 96.2301, aux_2.loss_ce: 0.1134, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.2664, aux_3.loss_ce: 0.1056, aux_3.acc_seg: 95.2094, loss: 0.6620
2023-05-23 22:26:18,017 - mmseg - INFO - Iter [8100/10000]	lr: 2.244e-02, eta: 0:28:37, time: 0.940, data_time: 0.216, memory: 14777, decode.loss_ce: 0.0580, decode.acc_seg: 96.9642, aux_0.loss_ce: 0.0599, aux_0.acc_seg: 96.9133, aux_1.loss_ce: 0.0760, aux_1.acc_seg: 96.1215, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 96.1173, aux_3.loss_ce: 0.1058, aux_3.acc_seg: 95.0906, loss: 0.6642
2023-05-23 22:27:05,074 - mmseg - INFO - Iter [8150/10000]	lr: 2.191e-02, eta: 0:27:52, time: 0.941, data_time: 0.217, memory: 14777, decode.loss_ce: 0.0595, decode.acc_seg: 96.9789, aux_0.loss_ce: 0.0613, aux_0.acc_seg: 96.9320, aux_1.loss_ce: 0.0771, aux_1.acc_seg: 96.1600, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 96.1464, aux_3.loss_ce: 0.1059, aux_3.acc_seg: 95.2105, loss: 0.6703
2023-05-23 22:27:47,744 - mmseg - INFO - Iter [8200/10000]	lr: 2.138e-02, eta: 0:27:06, time: 0.853, data_time: 0.144, memory: 14777, decode.loss_ce: 0.0557, decode.acc_seg: 97.0389, aux_0.loss_ce: 0.0574, aux_0.acc_seg: 96.9922, aux_1.loss_ce: 0.0729, aux_1.acc_seg: 96.2058, aux_2.loss_ce: 0.1112, aux_2.loss_dice: 0.2452, aux_2.acc_seg: 96.2795, aux_3.loss_ce: 0.1017, aux_3.acc_seg: 95.2041, loss: 0.6441
2023-05-23 22:28:34,586 - mmseg - INFO - Iter [8250/10000]	lr: 2.084e-02, eta: 0:26:21, time: 0.937, data_time: 0.216, memory: 14777, decode.loss_ce: 0.0589, decode.acc_seg: 96.9231, aux_0.loss_ce: 0.0603, aux_0.acc_seg: 96.8889, aux_1.loss_ce: 0.0765, aux_1.acc_seg: 96.0877, aux_2.loss_ce: 0.1151, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.1984, aux_3.loss_ce: 0.1065, aux_3.acc_seg: 95.0618, loss: 0.6666
2023-05-23 22:29:20,950 - mmseg - INFO - Iter [8300/10000]	lr: 2.031e-02, eta: 0:25:36, time: 0.927, data_time: 0.211, memory: 14777, decode.loss_ce: 0.0574, decode.acc_seg: 97.0273, aux_0.loss_ce: 0.0590, aux_0.acc_seg: 96.9812, aux_1.loss_ce: 0.0749, aux_1.acc_seg: 96.1900, aux_2.loss_ce: 0.1129, aux_2.loss_dice: 0.2473, aux_2.acc_seg: 96.2296, aux_3.loss_ce: 0.1038, aux_3.acc_seg: 95.2055, loss: 0.6552
2023-05-23 22:30:04,581 - mmseg - INFO - Iter [8350/10000]	lr: 1.977e-02, eta: 0:24:51, time: 0.873, data_time: 0.144, memory: 14777, decode.loss_ce: 0.0579, decode.acc_seg: 97.0159, aux_0.loss_ce: 0.0596, aux_0.acc_seg: 96.9705, aux_1.loss_ce: 0.0754, aux_1.acc_seg: 96.1845, aux_2.loss_ce: 0.1141, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.2170, aux_3.loss_ce: 0.1049, aux_3.acc_seg: 95.1784, loss: 0.6608
2023-05-23 22:30:51,387 - mmseg - INFO - Iter [8400/10000]	lr: 1.923e-02, eta: 0:24:06, time: 0.936, data_time: 0.217, memory: 14777, decode.loss_ce: 0.0581, decode.acc_seg: 96.9795, aux_0.loss_ce: 0.0598, aux_0.acc_seg: 96.9323, aux_1.loss_ce: 0.0758, aux_1.acc_seg: 96.1459, aux_2.loss_ce: 0.1136, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 96.2229, aux_3.loss_ce: 0.1052, aux_3.acc_seg: 95.1399, loss: 0.6606
2023-05-23 22:31:36,274 - mmseg - INFO - Iter [8450/10000]	lr: 1.869e-02, eta: 0:23:21, time: 0.898, data_time: 0.198, memory: 14777, decode.loss_ce: 0.0559, decode.acc_seg: 97.1200, aux_0.loss_ce: 0.0577, aux_0.acc_seg: 97.0805, aux_1.loss_ce: 0.0732, aux_1.acc_seg: 96.3089, aux_2.loss_ce: 0.1117, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 96.2868, aux_3.loss_ce: 0.1029, aux_3.acc_seg: 95.2967, loss: 0.6483
2023-05-23 22:32:21,683 - mmseg - INFO - Iter [8500/10000]	lr: 1.815e-02, eta: 0:22:36, time: 0.908, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0570, decode.acc_seg: 97.0156, aux_0.loss_ce: 0.0588, aux_0.acc_seg: 96.9611, aux_1.loss_ce: 0.0753, aux_1.acc_seg: 96.1462, aux_2.loss_ce: 0.1139, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 96.1509, aux_3.loss_ce: 0.1051, aux_3.acc_seg: 95.1033, loss: 0.6566
2023-05-23 22:33:03,528 - mmseg - INFO - Iter [8550/10000]	lr: 1.760e-02, eta: 0:21:50, time: 0.837, data_time: 0.136, memory: 14777, decode.loss_ce: 0.0590, decode.acc_seg: 96.9397, aux_0.loss_ce: 0.0606, aux_0.acc_seg: 96.8912, aux_1.loss_ce: 0.0773, aux_1.acc_seg: 96.0854, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2472, aux_2.acc_seg: 96.2156, aux_3.loss_ce: 0.1070, aux_3.acc_seg: 95.0912, loss: 0.6647
2023-05-23 22:33:48,373 - mmseg - INFO - Iter [8600/10000]	lr: 1.705e-02, eta: 0:21:05, time: 0.897, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0566, decode.acc_seg: 97.0334, aux_0.loss_ce: 0.0585, aux_0.acc_seg: 96.9769, aux_1.loss_ce: 0.0748, aux_1.acc_seg: 96.1830, aux_2.loss_ce: 0.1132, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.2246, aux_3.loss_ce: 0.1046, aux_3.acc_seg: 95.1558, loss: 0.6558
2023-05-23 22:34:34,033 - mmseg - INFO - Iter [8650/10000]	lr: 1.650e-02, eta: 0:20:19, time: 0.913, data_time: 0.208, memory: 14777, decode.loss_ce: 0.0581, decode.acc_seg: 97.0375, aux_0.loss_ce: 0.0598, aux_0.acc_seg: 96.9923, aux_1.loss_ce: 0.0759, aux_1.acc_seg: 96.1820, aux_2.loss_ce: 0.1137, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 96.1941, aux_3.loss_ce: 0.1054, aux_3.acc_seg: 95.1875, loss: 0.6606
