2023-05-03 09:55:33,378 - mmseg - INFO - Multi-processing start method is `None`
2023-05-03 09:55:33,381 - mmseg - INFO - OpenCV num_threads is `96
2023-05-03 09:55:33,590 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+e7ed570
------------------------------------------------------------

2023-05-03 09:55:33,590 - mmseg - INFO - Distributed training: False
2023-05-03 09:55:34,551 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1035, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=16,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='CSC',
        CLASSES=('Bicyclist', 'Building', 'Car', 'Column_Pole', 'Fence',
                 'Pedestrian', 'Road', 'Sidewalk', 'SignSymbol', 'Sky',
                 'Tree')),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CamVidDataset'
data_root = 'data/CamVid/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (720, 960)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        img_scale=(960, 720),
        ratio_range=(0.5, 2.5),
        scale_step_size=0.25),
    dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(960, 720),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='train',
        ann_dir='train_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize',
                img_scale=(960, 720),
                ratio_range=(0.5, 2.5),
                scale_step_size=0.25),
            dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.1,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            {
                'backbone.backbone': dict(lr_mult=0.1),
                'backbone.text_encoder': dict(lr_mult=0.0, decay_mult=0.0),
                'backbone.contexts': dict(decay_mult=0.0),
                '.bn.': dict(decay_mult=0.0)
            })))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=200,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16'
gpu_ids = [0]
auto_resume = False

2023-05-03 09:55:34,551 - mmseg - INFO - Set random seed to 2117245630, deterministic: False
2023-05-03 09:55:34,557 - mmseg - INFO - Loaded 367 images
2023-05-03 09:55:36,540 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-05-03 09:55:38,187 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.label_texts - torch.Size([11, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.contexts - torch.Size([11, 11, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.text_encoder.positional_embedding - torch.Size([16, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.text_projection - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.token_embedding.weight - torch.Size([49408, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1035, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1035, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-05-03 09:55:38,196 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1035, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1035, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-05-03 09:55:45,588 - mmseg - INFO - Loaded 101 images
2023-05-03 09:55:45,589 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16
2023-05-03 09:55:45,589 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-05-03 09:55:45,589 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-05-03 09:55:45,590 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16 by HardDiskBackend.
2023-05-03 09:56:55,314 - mmseg - INFO - Iter [50/10000]	lr: 2.439e-02, eta: 3:50:05, time: 1.388, data_time: 0.253, memory: 14777, decode.loss_ce: 1.3084, decode.acc_seg: 50.6439, aux_0.loss_ce: 1.2452, aux_0.acc_seg: 47.9063, aux_1.loss_ce: 1.3130, aux_1.acc_seg: 42.9239, aux_2.loss_ce: 0.3411, aux_2.loss_dice: 0.5042, aux_2.acc_seg: 85.1182, aux_3.loss_ce: 1.0043, aux_3.acc_seg: 60.5569, loss: 5.7163
2023-05-03 09:57:41,671 - mmseg - INFO - Iter [100/10000]	lr: 4.906e-02, eta: 3:10:57, time: 0.927, data_time: 0.200, memory: 14777, decode.loss_ce: 0.4363, decode.acc_seg: 83.0984, aux_0.loss_ce: 0.4476, aux_0.acc_seg: 83.3061, aux_1.loss_ce: 0.4756, aux_1.acc_seg: 81.9436, aux_2.loss_ce: 0.1649, aux_2.loss_dice: 0.4397, aux_2.acc_seg: 95.7636, aux_3.loss_ce: 0.4301, aux_3.acc_seg: 83.9213, loss: 2.3942
2023-05-03 09:58:27,642 - mmseg - INFO - Iter [150/10000]	lr: 7.350e-02, eta: 2:56:58, time: 0.919, data_time: 0.194, memory: 14777, decode.loss_ce: 0.3553, decode.acc_seg: 85.2625, aux_0.loss_ce: 0.3610, aux_0.acc_seg: 85.5138, aux_1.loss_ce: 0.3804, aux_1.acc_seg: 84.7566, aux_2.loss_ce: 0.1483, aux_2.loss_dice: 0.3291, aux_2.acc_seg: 95.9002, aux_3.loss_ce: 0.3654, aux_3.acc_seg: 85.2664, loss: 1.9394
2023-05-03 09:59:17,776 - mmseg - INFO - Iter [200/10000]	lr: 9.772e-02, eta: 2:52:59, time: 1.003, data_time: 0.271, memory: 14777, decode.loss_ce: 0.2723, decode.acc_seg: 88.6164, aux_0.loss_ce: 0.2798, aux_0.acc_seg: 88.4580, aux_1.loss_ce: 0.2966, aux_1.acc_seg: 87.8182, aux_2.loss_ce: 0.1406, aux_2.loss_dice: 0.3103, aux_2.acc_seg: 95.9354, aux_3.loss_ce: 0.2809, aux_3.acc_seg: 88.4056, loss: 1.5804
2023-05-03 10:00:04,294 - mmseg - INFO - Iter [250/10000]	lr: 9.776e-02, eta: 2:47:55, time: 0.930, data_time: 0.200, memory: 14777, decode.loss_ce: 0.2448, decode.acc_seg: 89.6588, aux_0.loss_ce: 0.2517, aux_0.acc_seg: 89.6429, aux_1.loss_ce: 0.2708, aux_1.acc_seg: 88.8772, aux_2.loss_ce: 0.1376, aux_2.loss_dice: 0.3021, aux_2.acc_seg: 95.9892, aux_3.loss_ce: 0.2651, aux_3.acc_seg: 89.0501, loss: 1.4721
2023-05-03 10:00:49,854 - mmseg - INFO - Iter [300/10000]	lr: 9.730e-02, eta: 2:43:46, time: 0.911, data_time: 0.189, memory: 14777, decode.loss_ce: 0.2122, decode.acc_seg: 90.8059, aux_0.loss_ce: 0.2190, aux_0.acc_seg: 90.5763, aux_1.loss_ce: 0.2361, aux_1.acc_seg: 89.9725, aux_2.loss_ce: 0.1353, aux_2.loss_dice: 0.2927, aux_2.acc_seg: 96.0157, aux_3.loss_ce: 0.2269, aux_3.acc_seg: 90.2818, loss: 1.3223
2023-05-03 10:01:36,169 - mmseg - INFO - Iter [350/10000]	lr: 9.685e-02, eta: 2:40:56, time: 0.926, data_time: 0.201, memory: 14777, decode.loss_ce: 0.1737, decode.acc_seg: 92.3003, aux_0.loss_ce: 0.1813, aux_0.acc_seg: 92.0301, aux_1.loss_ce: 0.2043, aux_1.acc_seg: 91.2216, aux_2.loss_ce: 0.1328, aux_2.loss_dice: 0.2898, aux_2.acc_seg: 96.0555, aux_3.loss_ce: 0.2026, aux_3.acc_seg: 91.2940, loss: 1.1845
2023-05-03 10:02:26,309 - mmseg - INFO - Iter [400/10000]	lr: 9.640e-02, eta: 2:40:08, time: 1.003, data_time: 0.273, memory: 14777, decode.loss_ce: 0.1972, decode.acc_seg: 91.3307, aux_0.loss_ce: 0.2004, aux_0.acc_seg: 91.2209, aux_1.loss_ce: 0.2190, aux_1.acc_seg: 90.5503, aux_2.loss_ce: 0.1324, aux_2.loss_dice: 0.2860, aux_2.acc_seg: 96.0595, aux_3.loss_ce: 0.2116, aux_3.acc_seg: 90.9793, loss: 1.2467
2023-05-03 10:03:12,892 - mmseg - INFO - Iter [450/10000]	lr: 9.595e-02, eta: 2:38:05, time: 0.932, data_time: 0.201, memory: 14777, decode.loss_ce: 0.1696, decode.acc_seg: 92.2967, aux_0.loss_ce: 0.1745, aux_0.acc_seg: 92.0580, aux_1.loss_ce: 0.1951, aux_1.acc_seg: 91.2974, aux_2.loss_ce: 0.1306, aux_2.loss_dice: 0.2827, aux_2.acc_seg: 96.0512, aux_3.loss_ce: 0.1911, aux_3.acc_seg: 91.5522, loss: 1.1436
2023-05-03 10:03:59,348 - mmseg - INFO - Iter [500/10000]	lr: 9.550e-02, eta: 2:36:14, time: 0.929, data_time: 0.201, memory: 14777, decode.loss_ce: 0.1719, decode.acc_seg: 92.4105, aux_0.loss_ce: 0.1744, aux_0.acc_seg: 92.2174, aux_1.loss_ce: 0.1942, aux_1.acc_seg: 91.5443, aux_2.loss_ce: 0.1329, aux_2.loss_dice: 0.2847, aux_2.acc_seg: 96.0031, aux_3.loss_ce: 0.1937, aux_3.acc_seg: 91.6637, loss: 1.1519
2023-05-03 10:04:46,049 - mmseg - INFO - Iter [550/10000]	lr: 9.505e-02, eta: 2:34:39, time: 0.934, data_time: 0.205, memory: 14777, decode.loss_ce: 0.1594, decode.acc_seg: 92.7682, aux_0.loss_ce: 0.1649, aux_0.acc_seg: 92.5347, aux_1.loss_ce: 0.1845, aux_1.acc_seg: 91.7406, aux_2.loss_ce: 0.1315, aux_2.loss_dice: 0.2816, aux_2.acc_seg: 95.9926, aux_3.loss_ce: 0.1851, aux_3.acc_seg: 91.8594, loss: 1.1070
2023-05-03 10:05:36,280 - mmseg - INFO - Iter [600/10000]	lr: 9.459e-02, eta: 2:34:08, time: 1.005, data_time: 0.275, memory: 14777, decode.loss_ce: 0.1427, decode.acc_seg: 93.4064, aux_0.loss_ce: 0.1486, aux_0.acc_seg: 93.1836, aux_1.loss_ce: 0.1667, aux_1.acc_seg: 92.4171, aux_2.loss_ce: 0.1311, aux_2.loss_dice: 0.2807, aux_2.acc_seg: 95.9535, aux_3.loss_ce: 0.1722, aux_3.acc_seg: 92.3880, loss: 1.0420
2023-05-03 10:06:23,111 - mmseg - INFO - Iter [650/10000]	lr: 9.414e-02, eta: 2:32:45, time: 0.937, data_time: 0.208, memory: 14777, decode.loss_ce: 0.1586, decode.acc_seg: 92.9203, aux_0.loss_ce: 0.1603, aux_0.acc_seg: 92.8065, aux_1.loss_ce: 0.1781, aux_1.acc_seg: 92.0730, aux_2.loss_ce: 0.1306, aux_2.loss_dice: 0.2796, aux_2.acc_seg: 96.0246, aux_3.loss_ce: 0.1793, aux_3.acc_seg: 92.2553, loss: 1.0866
2023-05-03 10:07:09,200 - mmseg - INFO - Iter [700/10000]	lr: 9.369e-02, eta: 2:31:17, time: 0.922, data_time: 0.197, memory: 14777, decode.loss_ce: 0.1403, decode.acc_seg: 93.6507, aux_0.loss_ce: 0.1439, aux_0.acc_seg: 93.4889, aux_1.loss_ce: 0.1617, aux_1.acc_seg: 92.7019, aux_2.loss_ce: 0.1269, aux_2.loss_dice: 0.2755, aux_2.acc_seg: 96.0963, aux_3.loss_ce: 0.1636, aux_3.acc_seg: 92.7539, loss: 1.0119
2023-05-03 10:07:59,288 - mmseg - INFO - Iter [750/10000]	lr: 9.323e-02, eta: 2:30:43, time: 1.000, data_time: 0.273, memory: 14777, decode.loss_ce: 0.1232, decode.acc_seg: 94.1911, aux_0.loss_ce: 0.1281, aux_0.acc_seg: 93.9733, aux_1.loss_ce: 0.1461, aux_1.acc_seg: 93.1577, aux_2.loss_ce: 0.1285, aux_2.loss_dice: 0.2733, aux_2.acc_seg: 95.9567, aux_3.loss_ce: 0.1530, aux_3.acc_seg: 93.0811, loss: 0.9522
2023-05-03 10:08:45,459 - mmseg - INFO - Iter [800/10000]	lr: 9.278e-02, eta: 2:29:24, time: 0.925, data_time: 0.201, memory: 14777, decode.loss_ce: 0.1145, decode.acc_seg: 94.6165, aux_0.loss_ce: 0.1201, aux_0.acc_seg: 94.3546, aux_1.loss_ce: 0.1375, aux_1.acc_seg: 93.5682, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2717, aux_2.acc_seg: 96.0282, aux_3.loss_ce: 0.1444, aux_3.acc_seg: 93.5175, loss: 0.9146
2023-05-03 10:09:31,380 - mmseg - INFO - Iter [850/10000]	lr: 9.233e-02, eta: 2:28:05, time: 0.918, data_time: 0.198, memory: 14777, decode.loss_ce: 0.1317, decode.acc_seg: 93.9771, aux_0.loss_ce: 0.1361, aux_0.acc_seg: 93.8005, aux_1.loss_ce: 0.1534, aux_1.acc_seg: 93.0172, aux_2.loss_ce: 0.1300, aux_2.loss_dice: 0.2757, aux_2.acc_seg: 95.9527, aux_3.loss_ce: 0.1569, aux_3.acc_seg: 93.0585, loss: 0.9839
2023-05-03 10:10:17,482 - mmseg - INFO - Iter [900/10000]	lr: 9.187e-02, eta: 2:26:52, time: 0.922, data_time: 0.202, memory: 14777, decode.loss_ce: 0.1271, decode.acc_seg: 94.1407, aux_0.loss_ce: 0.1307, aux_0.acc_seg: 93.9710, aux_1.loss_ce: 0.1479, aux_1.acc_seg: 93.1735, aux_2.loss_ce: 0.1283, aux_2.loss_dice: 0.2737, aux_2.acc_seg: 96.0160, aux_3.loss_ce: 0.1539, aux_3.acc_seg: 93.1518, loss: 0.9615
2023-05-03 10:11:07,588 - mmseg - INFO - Iter [950/10000]	lr: 9.142e-02, eta: 2:26:19, time: 1.002, data_time: 0.277, memory: 14777, decode.loss_ce: 0.1186, decode.acc_seg: 94.3805, aux_0.loss_ce: 0.1239, aux_0.acc_seg: 94.1672, aux_1.loss_ce: 0.1401, aux_1.acc_seg: 93.3864, aux_2.loss_ce: 0.1269, aux_2.loss_dice: 0.2722, aux_2.acc_seg: 96.0689, aux_3.loss_ce: 0.1497, aux_3.acc_seg: 93.2420, loss: 0.9315
2023-05-03 10:11:54,183 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-05-03 10:11:56,394 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:11:56,395 - mmseg - INFO - Iter [1000/10000]	lr: 9.096e-02, eta: 2:25:34, time: 0.977, data_time: 0.204, memory: 14777, decode.loss_ce: 0.1200, decode.acc_seg: 94.3944, aux_0.loss_ce: 0.1253, aux_0.acc_seg: 94.2068, aux_1.loss_ce: 0.1408, aux_1.acc_seg: 93.4246, aux_2.loss_ce: 0.1285, aux_2.loss_dice: 0.2743, aux_2.acc_seg: 96.0347, aux_3.loss_ce: 0.1535, aux_3.acc_seg: 93.1078, loss: 0.9425
2023-05-03 10:12:07,640 - mmseg - INFO - per class results:
2023-05-03 10:12:07,642 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 81.31 | 87.36 |
|   Building  | 89.93 | 92.32 |
|     Car     | 89.97 | 96.58 |
| Column_Pole | 16.21 | 21.55 |
|    Fence    | 61.54 | 71.86 |
|  Pedestrian | 55.19 | 81.36 |
|     Road    | 96.73 | 97.57 |
|   Sidewalk  | 87.88 | 96.22 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 93.17 | 98.51 |
|     Tree    |  88.8 | 97.87 |
+-------------+-------+-------+
2023-05-03 10:12:07,642 - mmseg - INFO - Summary:
2023-05-03 10:12:07,642 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.47 | 69.16 | 76.47 |
+-------+-------+-------+
2023-05-03 10:12:07,643 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:12:07,643 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9447, mIoU: 0.6916, mAcc: 0.7647, IoU.Bicyclist: 0.8131, IoU.Building: 0.8993, IoU.Car: 0.8997, IoU.Column_Pole: 0.1621, IoU.Fence: 0.6154, IoU.Pedestrian: 0.5519, IoU.Road: 0.9673, IoU.Sidewalk: 0.8788, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9317, IoU.Tree: 0.8880, Acc.Bicyclist: 0.8736, Acc.Building: 0.9232, Acc.Car: 0.9658, Acc.Column_Pole: 0.2155, Acc.Fence: 0.7186, Acc.Pedestrian: 0.8136, Acc.Road: 0.9757, Acc.Sidewalk: 0.9622, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9851, Acc.Tree: 0.9787
2023-05-03 10:12:53,576 - mmseg - INFO - Iter [1050/10000]	lr: 9.051e-02, eta: 2:25:59, time: 1.143, data_time: 0.418, memory: 14777, decode.loss_ce: 0.1141, decode.acc_seg: 94.6353, aux_0.loss_ce: 0.1192, aux_0.acc_seg: 94.4429, aux_1.loss_ce: 0.1355, aux_1.acc_seg: 93.6577, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2725, aux_2.acc_seg: 96.0479, aux_3.loss_ce: 0.1441, aux_3.acc_seg: 93.5337, loss: 0.9126
2023-05-03 10:13:39,847 - mmseg - INFO - Iter [1100/10000]	lr: 9.005e-02, eta: 2:24:48, time: 0.925, data_time: 0.200, memory: 14777, decode.loss_ce: 0.1107, decode.acc_seg: 94.7800, aux_0.loss_ce: 0.1156, aux_0.acc_seg: 94.5708, aux_1.loss_ce: 0.1311, aux_1.acc_seg: 93.8540, aux_2.loss_ce: 0.1263, aux_2.loss_dice: 0.2707, aux_2.acc_seg: 96.0573, aux_3.loss_ce: 0.1400, aux_3.acc_seg: 93.6724, loss: 0.8945
2023-05-03 10:14:29,905 - mmseg - INFO - Iter [1150/10000]	lr: 8.960e-02, eta: 2:24:09, time: 1.001, data_time: 0.272, memory: 14777, decode.loss_ce: 0.1091, decode.acc_seg: 94.7480, aux_0.loss_ce: 0.1145, aux_0.acc_seg: 94.5171, aux_1.loss_ce: 0.1302, aux_1.acc_seg: 93.7637, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2690, aux_2.acc_seg: 96.0166, aux_3.loss_ce: 0.1369, aux_3.acc_seg: 93.6933, loss: 0.8853
2023-05-03 10:15:16,123 - mmseg - INFO - Iter [1200/10000]	lr: 8.914e-02, eta: 2:23:01, time: 0.924, data_time: 0.200, memory: 14777, decode.loss_ce: 0.1113, decode.acc_seg: 94.7121, aux_0.loss_ce: 0.1167, aux_0.acc_seg: 94.4920, aux_1.loss_ce: 0.1327, aux_1.acc_seg: 93.7042, aux_2.loss_ce: 0.1272, aux_2.loss_dice: 0.2705, aux_2.acc_seg: 96.0081, aux_3.loss_ce: 0.1416, aux_3.acc_seg: 93.5564, loss: 0.9000
2023-05-03 10:16:02,585 - mmseg - INFO - Iter [1250/10000]	lr: 8.869e-02, eta: 2:21:56, time: 0.929, data_time: 0.202, memory: 14777, decode.loss_ce: 0.1030, decode.acc_seg: 95.0983, aux_0.loss_ce: 0.1087, aux_0.acc_seg: 94.8390, aux_1.loss_ce: 0.1251, aux_1.acc_seg: 94.0320, aux_2.loss_ce: 0.1260, aux_2.loss_dice: 0.2676, aux_2.acc_seg: 96.0209, aux_3.loss_ce: 0.1338, aux_3.acc_seg: 93.8993, loss: 0.8643
2023-05-03 10:16:52,510 - mmseg - INFO - Iter [1300/10000]	lr: 8.823e-02, eta: 2:21:16, time: 0.998, data_time: 0.270, memory: 14777, decode.loss_ce: 0.1061, decode.acc_seg: 94.9434, aux_0.loss_ce: 0.1111, aux_0.acc_seg: 94.7483, aux_1.loss_ce: 0.1266, aux_1.acc_seg: 93.9538, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2695, aux_2.acc_seg: 96.0198, aux_3.loss_ce: 0.1358, aux_3.acc_seg: 93.8153, loss: 0.8755
2023-05-03 10:17:39,171 - mmseg - INFO - Iter [1350/10000]	lr: 8.777e-02, eta: 2:20:14, time: 0.933, data_time: 0.205, memory: 14777, decode.loss_ce: 0.1043, decode.acc_seg: 95.0260, aux_0.loss_ce: 0.1083, aux_0.acc_seg: 94.8703, aux_1.loss_ce: 0.1246, aux_1.acc_seg: 94.0917, aux_2.loss_ce: 0.1277, aux_2.loss_dice: 0.2685, aux_2.acc_seg: 95.9728, aux_3.loss_ce: 0.1342, aux_3.acc_seg: 93.9292, loss: 0.8676
2023-05-03 10:18:25,532 - mmseg - INFO - Iter [1400/10000]	lr: 8.732e-02, eta: 2:19:11, time: 0.927, data_time: 0.199, memory: 14777, decode.loss_ce: 0.1115, decode.acc_seg: 94.6728, aux_0.loss_ce: 0.1156, aux_0.acc_seg: 94.4918, aux_1.loss_ce: 0.1315, aux_1.acc_seg: 93.7040, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2669, aux_2.acc_seg: 96.0505, aux_3.loss_ce: 0.1387, aux_3.acc_seg: 93.6264, loss: 0.8894
2023-05-03 10:19:11,034 - mmseg - INFO - Iter [1450/10000]	lr: 8.686e-02, eta: 2:18:05, time: 0.910, data_time: 0.191, memory: 14777, decode.loss_ce: 0.1028, decode.acc_seg: 95.0916, aux_0.loss_ce: 0.1069, aux_0.acc_seg: 94.9459, aux_1.loss_ce: 0.1223, aux_1.acc_seg: 94.1786, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2671, aux_2.acc_seg: 96.0491, aux_3.loss_ce: 0.1302, aux_3.acc_seg: 94.0102, loss: 0.8540
2023-05-03 10:20:01,037 - mmseg - INFO - Iter [1500/10000]	lr: 8.640e-02, eta: 2:17:25, time: 1.000, data_time: 0.273, memory: 14777, decode.loss_ce: 0.0966, decode.acc_seg: 95.2963, aux_0.loss_ce: 0.1017, aux_0.acc_seg: 95.1057, aux_1.loss_ce: 0.1160, aux_1.acc_seg: 94.3521, aux_2.loss_ce: 0.1226, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 96.1290, aux_3.loss_ce: 0.1277, aux_3.acc_seg: 94.0769, loss: 0.8282
2023-05-03 10:20:47,357 - mmseg - INFO - Iter [1550/10000]	lr: 8.594e-02, eta: 2:16:24, time: 0.926, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0994, decode.acc_seg: 95.1689, aux_0.loss_ce: 0.1032, aux_0.acc_seg: 95.0208, aux_1.loss_ce: 0.1196, aux_1.acc_seg: 94.2156, aux_2.loss_ce: 0.1253, aux_2.loss_dice: 0.2655, aux_2.acc_seg: 96.0111, aux_3.loss_ce: 0.1295, aux_3.acc_seg: 93.9768, loss: 0.8426
2023-05-03 10:21:33,470 - mmseg - INFO - Iter [1600/10000]	lr: 8.549e-02, eta: 2:15:24, time: 0.922, data_time: 0.197, memory: 14777, decode.loss_ce: 0.0973, decode.acc_seg: 95.3085, aux_0.loss_ce: 0.1016, aux_0.acc_seg: 95.1549, aux_1.loss_ce: 0.1160, aux_1.acc_seg: 94.4400, aux_2.loss_ce: 0.1227, aux_2.loss_dice: 0.2649, aux_2.acc_seg: 96.1527, aux_3.loss_ce: 0.1265, aux_3.acc_seg: 94.2119, loss: 0.8290
2023-05-03 10:22:18,843 - mmseg - INFO - Iter [1650/10000]	lr: 8.503e-02, eta: 2:14:20, time: 0.907, data_time: 0.189, memory: 14777, decode.loss_ce: 0.0942, decode.acc_seg: 95.4049, aux_0.loss_ce: 0.0979, aux_0.acc_seg: 95.2551, aux_1.loss_ce: 0.1133, aux_1.acc_seg: 94.4767, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2638, aux_2.acc_seg: 96.0343, aux_3.loss_ce: 0.1241, aux_3.acc_seg: 94.1999, loss: 0.8171
2023-05-03 10:23:07,831 - mmseg - INFO - Iter [1700/10000]	lr: 8.457e-02, eta: 2:13:36, time: 0.980, data_time: 0.261, memory: 14777, decode.loss_ce: 0.0928, decode.acc_seg: 95.5181, aux_0.loss_ce: 0.0967, aux_0.acc_seg: 95.3610, aux_1.loss_ce: 0.1125, aux_1.acc_seg: 94.5694, aux_2.loss_ce: 0.1253, aux_2.loss_dice: 0.2656, aux_2.acc_seg: 95.9967, aux_3.loss_ce: 0.1247, aux_3.acc_seg: 94.2552, loss: 0.8176
2023-05-03 10:23:53,783 - mmseg - INFO - Iter [1750/10000]	lr: 8.411e-02, eta: 2:12:36, time: 0.919, data_time: 0.198, memory: 14777, decode.loss_ce: 0.0926, decode.acc_seg: 95.4811, aux_0.loss_ce: 0.0963, aux_0.acc_seg: 95.3482, aux_1.loss_ce: 0.1111, aux_1.acc_seg: 94.6118, aux_2.loss_ce: 0.1232, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 96.0917, aux_3.loss_ce: 0.1239, aux_3.acc_seg: 94.2518, loss: 0.8105
2023-05-03 10:24:39,480 - mmseg - INFO - Iter [1800/10000]	lr: 8.365e-02, eta: 2:11:37, time: 0.914, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0943, decode.acc_seg: 95.3653, aux_0.loss_ce: 0.0980, aux_0.acc_seg: 95.2145, aux_1.loss_ce: 0.1137, aux_1.acc_seg: 94.4495, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2648, aux_2.acc_seg: 95.9584, aux_3.loss_ce: 0.1248, aux_3.acc_seg: 94.1757, loss: 0.8208
2023-05-03 10:25:28,812 - mmseg - INFO - Iter [1850/10000]	lr: 8.319e-02, eta: 2:10:54, time: 0.987, data_time: 0.266, memory: 14777, decode.loss_ce: 0.0918, decode.acc_seg: 95.5928, aux_0.loss_ce: 0.0955, aux_0.acc_seg: 95.4412, aux_1.loss_ce: 0.1106, aux_1.acc_seg: 94.6796, aux_2.loss_ce: 0.1239, aux_2.loss_dice: 0.2641, aux_2.acc_seg: 96.0461, aux_3.loss_ce: 0.1225, aux_3.acc_seg: 94.3745, loss: 0.8084
2023-05-03 10:26:15,335 - mmseg - INFO - Iter [1900/10000]	lr: 8.273e-02, eta: 2:09:58, time: 0.930, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0887, decode.acc_seg: 95.5196, aux_0.loss_ce: 0.0928, aux_0.acc_seg: 95.3597, aux_1.loss_ce: 0.1086, aux_1.acc_seg: 94.5452, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2622, aux_2.acc_seg: 96.0192, aux_3.loss_ce: 0.1200, aux_3.acc_seg: 94.2552, loss: 0.7959
2023-05-03 10:27:01,512 - mmseg - INFO - Iter [1950/10000]	lr: 8.227e-02, eta: 2:09:02, time: 0.924, data_time: 0.198, memory: 14777, decode.loss_ce: 0.0886, decode.acc_seg: 95.6891, aux_0.loss_ce: 0.0912, aux_0.acc_seg: 95.5982, aux_1.loss_ce: 0.1074, aux_1.acc_seg: 94.7966, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2628, aux_2.acc_seg: 96.0147, aux_3.loss_ce: 0.1180, aux_3.acc_seg: 94.5422, loss: 0.7924
2023-05-03 10:27:47,904 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-05-03 10:27:49,938 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:27:49,938 - mmseg - INFO - Iter [2000/10000]	lr: 8.181e-02, eta: 2:08:15, time: 0.969, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0906, decode.acc_seg: 95.6103, aux_0.loss_ce: 0.0941, aux_0.acc_seg: 95.4733, aux_1.loss_ce: 0.1100, aux_1.acc_seg: 94.7049, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 96.0329, aux_3.loss_ce: 0.1195, aux_3.acc_seg: 94.4992, loss: 0.8014
2023-05-03 10:27:54,972 - mmseg - INFO - per class results:
2023-05-03 10:27:54,973 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 84.64 | 91.34 |
|   Building  | 93.06 | 94.99 |
|     Car     | 91.91 |  93.3 |
| Column_Pole |  7.28 |  7.58 |
|    Fence    | 78.77 | 94.51 |
|  Pedestrian | 63.85 | 82.41 |
|     Road    | 97.05 | 97.85 |
|   Sidewalk  | 89.95 | 97.72 |
|  SignSymbol |  0.0  |  0.0  |
|     Sky     | 94.17 | 96.51 |
|     Tree    | 92.38 | 98.29 |
+-------------+-------+-------+
2023-05-03 10:27:54,973 - mmseg - INFO - Summary:
2023-05-03 10:27:54,973 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 95.98 | 72.1 | 77.68 |
+-------+------+-------+
2023-05-03 10:27:54,974 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:27:54,974 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9598, mIoU: 0.7210, mAcc: 0.7768, IoU.Bicyclist: 0.8464, IoU.Building: 0.9306, IoU.Car: 0.9191, IoU.Column_Pole: 0.0728, IoU.Fence: 0.7877, IoU.Pedestrian: 0.6385, IoU.Road: 0.9705, IoU.Sidewalk: 0.8995, IoU.SignSymbol: 0.0000, IoU.Sky: 0.9417, IoU.Tree: 0.9238, Acc.Bicyclist: 0.9134, Acc.Building: 0.9499, Acc.Car: 0.9330, Acc.Column_Pole: 0.0758, Acc.Fence: 0.9451, Acc.Pedestrian: 0.8241, Acc.Road: 0.9785, Acc.Sidewalk: 0.9772, Acc.SignSymbol: 0.0000, Acc.Sky: 0.9651, Acc.Tree: 0.9829
2023-05-03 10:28:45,411 - mmseg - INFO - Iter [2050/10000]	lr: 8.135e-02, eta: 2:07:56, time: 1.109, data_time: 0.377, memory: 14777, decode.loss_ce: 0.0895, decode.acc_seg: 95.5897, aux_0.loss_ce: 0.0936, aux_0.acc_seg: 95.4367, aux_1.loss_ce: 0.1088, aux_1.acc_seg: 94.6602, aux_2.loss_ce: 0.1229, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 96.0526, aux_3.loss_ce: 0.1188, aux_3.acc_seg: 94.3893, loss: 0.7957
2023-05-03 10:29:31,960 - mmseg - INFO - Iter [2100/10000]	lr: 8.089e-02, eta: 2:07:01, time: 0.931, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0860, decode.acc_seg: 95.6787, aux_0.loss_ce: 0.0895, aux_0.acc_seg: 95.5454, aux_1.loss_ce: 0.1039, aux_1.acc_seg: 94.7849, aux_2.loss_ce: 0.1221, aux_2.loss_dice: 0.2606, aux_2.acc_seg: 96.0610, aux_3.loss_ce: 0.1153, aux_3.acc_seg: 94.4957, loss: 0.7773
2023-05-03 10:30:18,624 - mmseg - INFO - Iter [2150/10000]	lr: 8.043e-02, eta: 2:06:07, time: 0.933, data_time: 0.208, memory: 14777, decode.loss_ce: 0.0947, decode.acc_seg: 95.3496, aux_0.loss_ce: 0.0984, aux_0.acc_seg: 95.1835, aux_1.loss_ce: 0.1128, aux_1.acc_seg: 94.4485, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 96.0051, aux_3.loss_ce: 0.1225, aux_3.acc_seg: 94.2260, loss: 0.8154
2023-05-03 10:31:03,926 - mmseg - INFO - Iter [2200/10000]	lr: 7.997e-02, eta: 2:05:09, time: 0.906, data_time: 0.190, memory: 14777, decode.loss_ce: 0.1005, decode.acc_seg: 95.2947, aux_0.loss_ce: 0.1050, aux_0.acc_seg: 95.1430, aux_1.loss_ce: 0.1169, aux_1.acc_seg: 94.4929, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 96.0366, aux_3.loss_ce: 0.1251, aux_3.acc_seg: 94.2854, loss: 0.8371
2023-05-03 10:31:54,202 - mmseg - INFO - Iter [2250/10000]	lr: 7.951e-02, eta: 2:04:28, time: 1.005, data_time: 0.277, memory: 14777, decode.loss_ce: 0.1046, decode.acc_seg: 95.1045, aux_0.loss_ce: 0.1082, aux_0.acc_seg: 94.9691, aux_1.loss_ce: 0.1235, aux_1.acc_seg: 94.1977, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2639, aux_2.acc_seg: 96.0503, aux_3.loss_ce: 0.1295, aux_3.acc_seg: 94.0527, loss: 0.8540
2023-05-03 10:32:40,830 - mmseg - INFO - Iter [2300/10000]	lr: 7.905e-02, eta: 2:03:34, time: 0.933, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0927, decode.acc_seg: 95.4406, aux_0.loss_ce: 0.0955, aux_0.acc_seg: 95.3539, aux_1.loss_ce: 0.1104, aux_1.acc_seg: 94.5730, aux_2.loss_ce: 0.1225, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 96.0636, aux_3.loss_ce: 0.1210, aux_3.acc_seg: 94.3068, loss: 0.8031
2023-05-03 10:33:27,139 - mmseg - INFO - Iter [2350/10000]	lr: 7.859e-02, eta: 2:02:40, time: 0.926, data_time: 0.199, memory: 14777, decode.loss_ce: 0.1056, decode.acc_seg: 94.8709, aux_0.loss_ce: 0.1086, aux_0.acc_seg: 94.7945, aux_1.loss_ce: 0.1217, aux_1.acc_seg: 94.0882, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2641, aux_2.acc_seg: 96.0425, aux_3.loss_ce: 0.1313, aux_3.acc_seg: 93.8485, loss: 0.8561
2023-05-03 10:34:16,992 - mmseg - INFO - Iter [2400/10000]	lr: 7.812e-02, eta: 2:01:58, time: 0.997, data_time: 0.271, memory: 14777, decode.loss_ce: 0.0906, decode.acc_seg: 95.6089, aux_0.loss_ce: 0.0937, aux_0.acc_seg: 95.5146, aux_1.loss_ce: 0.1083, aux_1.acc_seg: 94.7790, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2642, aux_2.acc_seg: 95.9971, aux_3.loss_ce: 0.1206, aux_3.acc_seg: 94.4632, loss: 0.8026
2023-05-03 10:35:03,951 - mmseg - INFO - Iter [2450/10000]	lr: 7.766e-02, eta: 2:01:06, time: 0.939, data_time: 0.211, memory: 14777, decode.loss_ce: 0.0851, decode.acc_seg: 95.7733, aux_0.loss_ce: 0.0886, aux_0.acc_seg: 95.6643, aux_1.loss_ce: 0.1030, aux_1.acc_seg: 94.9105, aux_2.loss_ce: 0.1228, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 96.0678, aux_3.loss_ce: 0.1161, aux_3.acc_seg: 94.4995, loss: 0.7770
2023-05-03 10:35:50,827 - mmseg - INFO - Iter [2500/10000]	lr: 7.720e-02, eta: 2:00:14, time: 0.937, data_time: 0.209, memory: 14777, decode.loss_ce: 0.0856, decode.acc_seg: 95.6534, aux_0.loss_ce: 0.0886, aux_0.acc_seg: 95.5460, aux_1.loss_ce: 0.1032, aux_1.acc_seg: 94.7779, aux_2.loss_ce: 0.1218, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 96.0924, aux_3.loss_ce: 0.1149, aux_3.acc_seg: 94.4422, loss: 0.7748
2023-05-03 10:36:37,859 - mmseg - INFO - Iter [2550/10000]	lr: 7.674e-02, eta: 1:59:23, time: 0.941, data_time: 0.209, memory: 14777, decode.loss_ce: 0.1011, decode.acc_seg: 95.2335, aux_0.loss_ce: 0.1040, aux_0.acc_seg: 95.1066, aux_1.loss_ce: 0.1201, aux_1.acc_seg: 94.3451, aux_2.loss_ce: 0.1242, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 95.9750, aux_3.loss_ce: 0.1260, aux_3.acc_seg: 94.1707, loss: 0.8363
2023-05-03 10:37:28,377 - mmseg - INFO - Iter [2600/10000]	lr: 7.627e-02, eta: 1:58:42, time: 1.010, data_time: 0.278, memory: 14777, decode.loss_ce: 0.0894, decode.acc_seg: 95.6188, aux_0.loss_ce: 0.0920, aux_0.acc_seg: 95.5440, aux_1.loss_ce: 0.1067, aux_1.acc_seg: 94.7817, aux_2.loss_ce: 0.1229, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 96.0279, aux_3.loss_ce: 0.1169, aux_3.acc_seg: 94.5279, loss: 0.7893
2023-05-03 10:38:14,776 - mmseg - INFO - Iter [2650/10000]	lr: 7.581e-02, eta: 1:57:49, time: 0.928, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0864, decode.acc_seg: 95.7771, aux_0.loss_ce: 0.0892, aux_0.acc_seg: 95.6794, aux_1.loss_ce: 0.1038, aux_1.acc_seg: 94.9394, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 96.0135, aux_3.loss_ce: 0.1163, aux_3.acc_seg: 94.5921, loss: 0.7801
2023-05-03 10:39:01,715 - mmseg - INFO - Iter [2700/10000]	lr: 7.534e-02, eta: 1:56:58, time: 0.939, data_time: 0.207, memory: 14777, decode.loss_ce: 0.0861, decode.acc_seg: 95.6858, aux_0.loss_ce: 0.0889, aux_0.acc_seg: 95.5698, aux_1.loss_ce: 0.1031, aux_1.acc_seg: 94.8285, aux_2.loss_ce: 0.1225, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 96.0521, aux_3.loss_ce: 0.1156, aux_3.acc_seg: 94.5319, loss: 0.7769
2023-05-03 10:39:48,146 - mmseg - INFO - Iter [2750/10000]	lr: 7.488e-02, eta: 1:56:05, time: 0.929, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0806, decode.acc_seg: 95.8530, aux_0.loss_ce: 0.0839, aux_0.acc_seg: 95.7339, aux_1.loss_ce: 0.0980, aux_1.acc_seg: 94.9706, aux_2.loss_ce: 0.1213, aux_2.loss_dice: 0.2587, aux_2.acc_seg: 96.0664, aux_3.loss_ce: 0.1111, aux_3.acc_seg: 94.5964, loss: 0.7537
2023-05-03 10:40:38,598 - mmseg - INFO - Iter [2800/10000]	lr: 7.441e-02, eta: 1:55:23, time: 1.009, data_time: 0.281, memory: 14777, decode.loss_ce: 0.0784, decode.acc_seg: 96.0253, aux_0.loss_ce: 0.0817, aux_0.acc_seg: 95.9056, aux_1.loss_ce: 0.0956, aux_1.acc_seg: 95.1771, aux_2.loss_ce: 0.1215, aux_2.loss_dice: 0.2589, aux_2.acc_seg: 96.0569, aux_3.loss_ce: 0.1091, aux_3.acc_seg: 94.7622, loss: 0.7453
2023-05-03 10:41:24,871 - mmseg - INFO - Iter [2850/10000]	lr: 7.395e-02, eta: 1:54:31, time: 0.925, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0797, decode.acc_seg: 96.0251, aux_0.loss_ce: 0.0825, aux_0.acc_seg: 95.9349, aux_1.loss_ce: 0.0968, aux_1.acc_seg: 95.1860, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2602, aux_2.acc_seg: 95.9647, aux_3.loss_ce: 0.1124, aux_3.acc_seg: 94.7082, loss: 0.7550
2023-05-03 10:42:11,383 - mmseg - INFO - Iter [2900/10000]	lr: 7.348e-02, eta: 1:53:39, time: 0.930, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0786, decode.acc_seg: 95.9909, aux_0.loss_ce: 0.0810, aux_0.acc_seg: 95.9028, aux_1.loss_ce: 0.0949, aux_1.acc_seg: 95.1498, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 96.0302, aux_3.loss_ce: 0.1078, aux_3.acc_seg: 94.7747, loss: 0.7440
2023-05-03 10:43:01,453 - mmseg - INFO - Iter [2950/10000]	lr: 7.302e-02, eta: 1:52:56, time: 1.001, data_time: 0.274, memory: 14777, decode.loss_ce: 0.0782, decode.acc_seg: 96.1069, aux_0.loss_ce: 0.0806, aux_0.acc_seg: 96.0188, aux_1.loss_ce: 0.0941, aux_1.acc_seg: 95.3136, aux_2.loss_ce: 0.1207, aux_2.loss_dice: 0.2576, aux_2.acc_seg: 96.0839, aux_3.loss_ce: 0.1081, aux_3.acc_seg: 94.8450, loss: 0.7392
2023-05-03 10:43:47,920 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-05-03 10:43:49,882 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:43:49,882 - mmseg - INFO - Iter [3000/10000]	lr: 7.255e-02, eta: 1:52:09, time: 0.969, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0805, decode.acc_seg: 95.9732, aux_0.loss_ce: 0.0831, aux_0.acc_seg: 95.8843, aux_1.loss_ce: 0.0976, aux_1.acc_seg: 95.1260, aux_2.loss_ce: 0.1233, aux_2.loss_dice: 0.2612, aux_2.acc_seg: 96.0175, aux_3.loss_ce: 0.1125, aux_3.acc_seg: 94.6936, loss: 0.7583
2023-05-03 10:43:55,885 - mmseg - INFO - per class results:
2023-05-03 10:43:55,886 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.04 | 92.19 |
|   Building  | 92.52 | 94.56 |
|     Car     | 92.92 | 94.59 |
| Column_Pole | 20.33 | 23.97 |
|    Fence    | 78.66 | 95.61 |
|  Pedestrian | 63.56 | 76.64 |
|     Road    | 97.43 | 98.41 |
|   Sidewalk  | 91.08 |  97.0 |
|  SignSymbol |  0.16 |  0.16 |
|     Sky     | 94.34 | 97.13 |
|     Tree    | 92.46 | 97.84 |
+-------------+-------+-------+
2023-05-03 10:43:55,886 - mmseg - INFO - Summary:
2023-05-03 10:43:55,886 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.08 | 73.59 | 78.92 |
+-------+-------+-------+
2023-05-03 10:43:55,887 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:43:55,887 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9608, mIoU: 0.7359, mAcc: 0.7892, IoU.Bicyclist: 0.8604, IoU.Building: 0.9252, IoU.Car: 0.9292, IoU.Column_Pole: 0.2033, IoU.Fence: 0.7866, IoU.Pedestrian: 0.6356, IoU.Road: 0.9743, IoU.Sidewalk: 0.9108, IoU.SignSymbol: 0.0016, IoU.Sky: 0.9434, IoU.Tree: 0.9246, Acc.Bicyclist: 0.9219, Acc.Building: 0.9456, Acc.Car: 0.9459, Acc.Column_Pole: 0.2397, Acc.Fence: 0.9561, Acc.Pedestrian: 0.7664, Acc.Road: 0.9841, Acc.Sidewalk: 0.9700, Acc.SignSymbol: 0.0016, Acc.Sky: 0.9713, Acc.Tree: 0.9784
2023-05-03 10:44:41,711 - mmseg - INFO - Iter [3050/10000]	lr: 7.208e-02, eta: 1:51:29, time: 1.036, data_time: 0.315, memory: 14777, decode.loss_ce: 0.0788, decode.acc_seg: 95.9979, aux_0.loss_ce: 0.0811, aux_0.acc_seg: 95.9333, aux_1.loss_ce: 0.0946, aux_1.acc_seg: 95.2090, aux_2.loss_ce: 0.1188, aux_2.loss_dice: 0.2569, aux_2.acc_seg: 96.1635, aux_3.loss_ce: 0.1089, aux_3.acc_seg: 94.7590, loss: 0.7391
2023-05-03 10:45:27,877 - mmseg - INFO - Iter [3100/10000]	lr: 7.162e-02, eta: 1:50:37, time: 0.923, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0852, decode.acc_seg: 95.7017, aux_0.loss_ce: 0.0876, aux_0.acc_seg: 95.6177, aux_1.loss_ce: 0.1014, aux_1.acc_seg: 94.8632, aux_2.loss_ce: 0.1213, aux_2.loss_dice: 0.2580, aux_2.acc_seg: 96.0701, aux_3.loss_ce: 0.1136, aux_3.acc_seg: 94.5071, loss: 0.7670
2023-05-03 10:46:17,677 - mmseg - INFO - Iter [3150/10000]	lr: 7.115e-02, eta: 1:49:52, time: 0.996, data_time: 0.272, memory: 14777, decode.loss_ce: 0.0773, decode.acc_seg: 96.0671, aux_0.loss_ce: 0.0798, aux_0.acc_seg: 95.9821, aux_1.loss_ce: 0.0936, aux_1.acc_seg: 95.2540, aux_2.loss_ce: 0.1207, aux_2.loss_dice: 0.2571, aux_2.acc_seg: 96.0555, aux_3.loss_ce: 0.1067, aux_3.acc_seg: 94.8439, loss: 0.7352
2023-05-03 10:47:04,006 - mmseg - INFO - Iter [3200/10000]	lr: 7.068e-02, eta: 1:49:00, time: 0.927, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0766, decode.acc_seg: 96.1239, aux_0.loss_ce: 0.0790, aux_0.acc_seg: 96.0427, aux_1.loss_ce: 0.0936, aux_1.acc_seg: 95.2763, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2584, aux_2.acc_seg: 96.0091, aux_3.loss_ce: 0.1078, aux_3.acc_seg: 94.8331, loss: 0.7376
2023-05-03 10:47:49,763 - mmseg - INFO - Iter [3250/10000]	lr: 7.022e-02, eta: 1:48:07, time: 0.915, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0754, decode.acc_seg: 96.0837, aux_0.loss_ce: 0.0779, aux_0.acc_seg: 95.9988, aux_1.loss_ce: 0.0911, aux_1.acc_seg: 95.2830, aux_2.loss_ce: 0.1214, aux_2.loss_dice: 0.2580, aux_2.acc_seg: 96.0463, aux_3.loss_ce: 0.1051, aux_3.acc_seg: 94.8482, loss: 0.7288
2023-05-03 10:48:35,884 - mmseg - INFO - Iter [3300/10000]	lr: 6.975e-02, eta: 1:47:15, time: 0.922, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0764, decode.acc_seg: 96.1165, aux_0.loss_ce: 0.0788, aux_0.acc_seg: 96.0347, aux_1.loss_ce: 0.0926, aux_1.acc_seg: 95.3004, aux_2.loss_ce: 0.1208, aux_2.loss_dice: 0.2572, aux_2.acc_seg: 96.0673, aux_3.loss_ce: 0.1069, aux_3.acc_seg: 94.8315, loss: 0.7328
2023-05-03 10:49:25,667 - mmseg - INFO - Iter [3350/10000]	lr: 6.928e-02, eta: 1:46:31, time: 0.996, data_time: 0.272, memory: 14777, decode.loss_ce: 0.0761, decode.acc_seg: 96.1011, aux_0.loss_ce: 0.0784, aux_0.acc_seg: 96.0259, aux_1.loss_ce: 0.0916, aux_1.acc_seg: 95.3091, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2559, aux_2.acc_seg: 96.0388, aux_3.loss_ce: 0.1051, aux_3.acc_seg: 94.9108, loss: 0.7273
2023-05-03 10:50:12,099 - mmseg - INFO - Iter [3400/10000]	lr: 6.881e-02, eta: 1:45:40, time: 0.929, data_time: 0.207, memory: 14777, decode.loss_ce: 0.0756, decode.acc_seg: 96.1070, aux_0.loss_ce: 0.0783, aux_0.acc_seg: 96.0098, aux_1.loss_ce: 0.0921, aux_1.acc_seg: 95.2741, aux_2.loss_ce: 0.1198, aux_2.loss_dice: 0.2572, aux_2.acc_seg: 96.1190, aux_3.loss_ce: 0.1061, aux_3.acc_seg: 94.8513, loss: 0.7290
2023-05-03 10:50:58,201 - mmseg - INFO - Iter [3450/10000]	lr: 6.834e-02, eta: 1:44:48, time: 0.922, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0732, decode.acc_seg: 96.1703, aux_0.loss_ce: 0.0757, aux_0.acc_seg: 96.0796, aux_1.loss_ce: 0.0892, aux_1.acc_seg: 95.3472, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2551, aux_2.acc_seg: 96.0983, aux_3.loss_ce: 0.1030, aux_3.acc_seg: 94.8959, loss: 0.7154
2023-05-03 10:51:48,017 - mmseg - INFO - Iter [3500/10000]	lr: 6.787e-02, eta: 1:44:03, time: 0.996, data_time: 0.275, memory: 14777, decode.loss_ce: 0.0758, decode.acc_seg: 96.1421, aux_0.loss_ce: 0.0778, aux_0.acc_seg: 96.0872, aux_1.loss_ce: 0.0921, aux_1.acc_seg: 95.3251, aux_2.loss_ce: 0.1236, aux_2.loss_dice: 0.2590, aux_2.acc_seg: 95.9367, aux_3.loss_ce: 0.1064, aux_3.acc_seg: 94.8648, loss: 0.7348
2023-05-03 10:52:34,305 - mmseg - INFO - Iter [3550/10000]	lr: 6.740e-02, eta: 1:43:12, time: 0.926, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0781, decode.acc_seg: 96.0731, aux_0.loss_ce: 0.0803, aux_0.acc_seg: 96.0014, aux_1.loss_ce: 0.0933, aux_1.acc_seg: 95.3102, aux_2.loss_ce: 0.1214, aux_2.loss_dice: 0.2579, aux_2.acc_seg: 96.0414, aux_3.loss_ce: 0.1077, aux_3.acc_seg: 94.8448, loss: 0.7387
2023-05-03 10:53:20,590 - mmseg - INFO - Iter [3600/10000]	lr: 6.693e-02, eta: 1:42:21, time: 0.926, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0730, decode.acc_seg: 96.2533, aux_0.loss_ce: 0.0750, aux_0.acc_seg: 96.1824, aux_1.loss_ce: 0.0890, aux_1.acc_seg: 95.4483, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2553, aux_2.acc_seg: 96.0698, aux_3.loss_ce: 0.1031, aux_3.acc_seg: 94.9729, loss: 0.7153
2023-05-03 10:54:06,337 - mmseg - INFO - Iter [3650/10000]	lr: 6.646e-02, eta: 1:41:29, time: 0.915, data_time: 0.197, memory: 14777, decode.loss_ce: 0.0734, decode.acc_seg: 96.2827, aux_0.loss_ce: 0.0758, aux_0.acc_seg: 96.2060, aux_1.loss_ce: 0.0894, aux_1.acc_seg: 95.4900, aux_2.loss_ce: 0.1198, aux_2.loss_dice: 0.2559, aux_2.acc_seg: 96.0580, aux_3.loss_ce: 0.1048, aux_3.acc_seg: 94.9551, loss: 0.7192
2023-05-03 10:54:55,713 - mmseg - INFO - Iter [3700/10000]	lr: 6.599e-02, eta: 1:40:44, time: 0.988, data_time: 0.270, memory: 14777, decode.loss_ce: 0.0727, decode.acc_seg: 96.2734, aux_0.loss_ce: 0.0748, aux_0.acc_seg: 96.2069, aux_1.loss_ce: 0.0882, aux_1.acc_seg: 95.5160, aux_2.loss_ce: 0.1201, aux_2.loss_dice: 0.2566, aux_2.acc_seg: 96.0923, aux_3.loss_ce: 0.1027, aux_3.acc_seg: 95.0269, loss: 0.7152
2023-05-03 10:55:41,717 - mmseg - INFO - Iter [3750/10000]	lr: 6.552e-02, eta: 1:39:52, time: 0.920, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0752, decode.acc_seg: 96.2070, aux_0.loss_ce: 0.0770, aux_0.acc_seg: 96.1622, aux_1.loss_ce: 0.0911, aux_1.acc_seg: 95.4270, aux_2.loss_ce: 0.1224, aux_2.loss_dice: 0.2576, aux_2.acc_seg: 95.9924, aux_3.loss_ce: 0.1045, aux_3.acc_seg: 95.0004, loss: 0.7278
2023-05-03 10:56:27,745 - mmseg - INFO - Iter [3800/10000]	lr: 6.505e-02, eta: 1:39:01, time: 0.921, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0728, decode.acc_seg: 96.2952, aux_0.loss_ce: 0.0748, aux_0.acc_seg: 96.2384, aux_1.loss_ce: 0.0888, aux_1.acc_seg: 95.4994, aux_2.loss_ce: 0.1217, aux_2.loss_dice: 0.2563, aux_2.acc_seg: 95.9860, aux_3.loss_ce: 0.1044, aux_3.acc_seg: 94.9796, loss: 0.7187
2023-05-03 10:57:13,664 - mmseg - INFO - Iter [3850/10000]	lr: 6.457e-02, eta: 1:38:10, time: 0.918, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0748, decode.acc_seg: 96.1675, aux_0.loss_ce: 0.0768, aux_0.acc_seg: 96.1138, aux_1.loss_ce: 0.0904, aux_1.acc_seg: 95.4017, aux_2.loss_ce: 0.1213, aux_2.loss_dice: 0.2565, aux_2.acc_seg: 96.0179, aux_3.loss_ce: 0.1045, aux_3.acc_seg: 94.9585, loss: 0.7243
2023-05-03 10:58:03,793 - mmseg - INFO - Iter [3900/10000]	lr: 6.410e-02, eta: 1:37:26, time: 1.003, data_time: 0.280, memory: 14777, decode.loss_ce: 0.0736, decode.acc_seg: 96.2653, aux_0.loss_ce: 0.0757, aux_0.acc_seg: 96.2069, aux_1.loss_ce: 0.0885, aux_1.acc_seg: 95.5276, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2570, aux_2.acc_seg: 96.0508, aux_3.loss_ce: 0.1025, aux_3.acc_seg: 95.0807, loss: 0.7177
2023-05-03 10:58:50,282 - mmseg - INFO - Iter [3950/10000]	lr: 6.363e-02, eta: 1:36:36, time: 0.930, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0737, decode.acc_seg: 96.1938, aux_0.loss_ce: 0.0754, aux_0.acc_seg: 96.1499, aux_1.loss_ce: 0.0884, aux_1.acc_seg: 95.4564, aux_2.loss_ce: 0.1194, aux_2.loss_dice: 0.2545, aux_2.acc_seg: 96.0897, aux_3.loss_ce: 0.1021, aux_3.acc_seg: 94.9983, loss: 0.7135
2023-05-03 10:59:36,417 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-05-03 10:59:38,365 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:59:38,365 - mmseg - INFO - Iter [4000/10000]	lr: 6.315e-02, eta: 1:35:48, time: 0.962, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0729, decode.acc_seg: 96.3019, aux_0.loss_ce: 0.0743, aux_0.acc_seg: 96.2841, aux_1.loss_ce: 0.0879, aux_1.acc_seg: 95.5826, aux_2.loss_ce: 0.1197, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 96.0831, aux_3.loss_ce: 0.1006, aux_3.acc_seg: 95.1642, loss: 0.7113
2023-05-03 10:59:43,634 - mmseg - INFO - per class results:
2023-05-03 10:59:43,635 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.79 | 95.05 |
|   Building  | 93.37 | 95.76 |
|     Car     | 92.66 | 93.92 |
| Column_Pole |  18.9 | 21.66 |
|    Fence    | 81.24 | 88.35 |
|  Pedestrian | 68.66 | 83.79 |
|     Road    | 97.65 | 98.48 |
|   Sidewalk  | 92.29 | 96.98 |
|  SignSymbol |  1.45 |  1.45 |
|     Sky     | 94.33 | 96.81 |
|     Tree    | 92.02 | 98.53 |
+-------------+-------+-------+
2023-05-03 10:59:43,635 - mmseg - INFO - Summary:
2023-05-03 10:59:43,635 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.36 | 74.49 | 79.16 |
+-------+-------+-------+
2023-05-03 10:59:43,636 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 10:59:43,636 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9636, mIoU: 0.7449, mAcc: 0.7916, IoU.Bicyclist: 0.8679, IoU.Building: 0.9337, IoU.Car: 0.9266, IoU.Column_Pole: 0.1890, IoU.Fence: 0.8124, IoU.Pedestrian: 0.6866, IoU.Road: 0.9765, IoU.Sidewalk: 0.9229, IoU.SignSymbol: 0.0145, IoU.Sky: 0.9433, IoU.Tree: 0.9202, Acc.Bicyclist: 0.9505, Acc.Building: 0.9576, Acc.Car: 0.9392, Acc.Column_Pole: 0.2166, Acc.Fence: 0.8835, Acc.Pedestrian: 0.8379, Acc.Road: 0.9848, Acc.Sidewalk: 0.9698, Acc.SignSymbol: 0.0145, Acc.Sky: 0.9681, Acc.Tree: 0.9853
2023-05-03 11:00:33,156 - mmseg - INFO - Iter [4050/10000]	lr: 6.268e-02, eta: 1:35:10, time: 1.095, data_time: 0.379, memory: 14777, decode.loss_ce: 0.0739, decode.acc_seg: 96.2486, aux_0.loss_ce: 0.0757, aux_0.acc_seg: 96.2063, aux_1.loss_ce: 0.0894, aux_1.acc_seg: 95.4793, aux_2.loss_ce: 0.1206, aux_2.loss_dice: 0.2563, aux_2.acc_seg: 96.0471, aux_3.loss_ce: 0.1034, aux_3.acc_seg: 95.0271, loss: 0.7192
2023-05-03 11:01:19,362 - mmseg - INFO - Iter [4100/10000]	lr: 6.221e-02, eta: 1:34:20, time: 0.924, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0724, decode.acc_seg: 96.2664, aux_0.loss_ce: 0.0742, aux_0.acc_seg: 96.2234, aux_1.loss_ce: 0.0873, aux_1.acc_seg: 95.5135, aux_2.loss_ce: 0.1204, aux_2.loss_dice: 0.2555, aux_2.acc_seg: 96.0018, aux_3.loss_ce: 0.1010, aux_3.acc_seg: 95.0496, loss: 0.7109
2023-05-03 11:02:05,676 - mmseg - INFO - Iter [4150/10000]	lr: 6.173e-02, eta: 1:33:29, time: 0.926, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0696, decode.acc_seg: 96.4341, aux_0.loss_ce: 0.0720, aux_0.acc_seg: 96.3706, aux_1.loss_ce: 0.0852, aux_1.acc_seg: 95.6377, aux_2.loss_ce: 0.1202, aux_2.loss_dice: 0.2550, aux_2.acc_seg: 96.0373, aux_3.loss_ce: 0.0997, aux_3.acc_seg: 95.1691, loss: 0.7016
2023-05-03 11:02:51,823 - mmseg - INFO - Iter [4200/10000]	lr: 6.126e-02, eta: 1:32:39, time: 0.923, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0714, decode.acc_seg: 96.2870, aux_0.loss_ce: 0.0731, aux_0.acc_seg: 96.2418, aux_1.loss_ce: 0.0863, aux_1.acc_seg: 95.5153, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2547, aux_2.acc_seg: 96.0356, aux_3.loss_ce: 0.1006, aux_3.acc_seg: 95.0332, loss: 0.7061
2023-05-03 11:03:41,724 - mmseg - INFO - Iter [4250/10000]	lr: 6.078e-02, eta: 1:31:54, time: 0.998, data_time: 0.275, memory: 14777, decode.loss_ce: 0.0696, decode.acc_seg: 96.4305, aux_0.loss_ce: 0.0714, aux_0.acc_seg: 96.3787, aux_1.loss_ce: 0.0847, aux_1.acc_seg: 95.6752, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2558, aux_2.acc_seg: 96.1317, aux_3.loss_ce: 0.0996, aux_3.acc_seg: 95.1510, loss: 0.6995
2023-05-03 11:04:28,416 - mmseg - INFO - Iter [4300/10000]	lr: 6.031e-02, eta: 1:31:04, time: 0.934, data_time: 0.210, memory: 14777, decode.loss_ce: 0.0711, decode.acc_seg: 96.2910, aux_0.loss_ce: 0.0734, aux_0.acc_seg: 96.2243, aux_1.loss_ce: 0.0863, aux_1.acc_seg: 95.5181, aux_2.loss_ce: 0.1187, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 96.1036, aux_3.loss_ce: 0.0992, aux_3.acc_seg: 95.1071, loss: 0.7031
2023-05-03 11:05:14,821 - mmseg - INFO - Iter [4350/10000]	lr: 5.983e-02, eta: 1:30:14, time: 0.928, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0682, decode.acc_seg: 96.4133, aux_0.loss_ce: 0.0702, aux_0.acc_seg: 96.3619, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.6538, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2536, aux_2.acc_seg: 96.0217, aux_3.loss_ce: 0.0977, aux_3.acc_seg: 95.1209, loss: 0.6920
2023-05-03 11:06:01,114 - mmseg - INFO - Iter [4400/10000]	lr: 5.935e-02, eta: 1:29:24, time: 0.926, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0724, decode.acc_seg: 96.2898, aux_0.loss_ce: 0.0741, aux_0.acc_seg: 96.2576, aux_1.loss_ce: 0.0870, aux_1.acc_seg: 95.5681, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 96.0255, aux_3.loss_ce: 0.1010, aux_3.acc_seg: 95.1244, loss: 0.7103
2023-05-03 11:06:50,357 - mmseg - INFO - Iter [4450/10000]	lr: 5.888e-02, eta: 1:28:38, time: 0.985, data_time: 0.268, memory: 14777, decode.loss_ce: 0.0747, decode.acc_seg: 96.1266, aux_0.loss_ce: 0.0760, aux_0.acc_seg: 96.0938, aux_1.loss_ce: 0.0896, aux_1.acc_seg: 95.3794, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2548, aux_2.acc_seg: 96.0862, aux_3.loss_ce: 0.1027, aux_3.acc_seg: 94.9291, loss: 0.7178
2023-05-03 11:07:36,531 - mmseg - INFO - Iter [4500/10000]	lr: 5.840e-02, eta: 1:27:48, time: 0.923, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0740, decode.acc_seg: 96.2119, aux_0.loss_ce: 0.0758, aux_0.acc_seg: 96.1746, aux_1.loss_ce: 0.0881, aux_1.acc_seg: 95.4982, aux_2.loss_ce: 0.1198, aux_2.loss_dice: 0.2567, aux_2.acc_seg: 96.1078, aux_3.loss_ce: 0.1016, aux_3.acc_seg: 95.0137, loss: 0.7159
2023-05-03 11:08:22,130 - mmseg - INFO - Iter [4550/10000]	lr: 5.792e-02, eta: 1:26:57, time: 0.912, data_time: 0.195, memory: 14777, decode.loss_ce: 0.0682, decode.acc_seg: 96.4857, aux_0.loss_ce: 0.0700, aux_0.acc_seg: 96.4476, aux_1.loss_ce: 0.0831, aux_1.acc_seg: 95.7524, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2543, aux_2.acc_seg: 96.0763, aux_3.loss_ce: 0.0976, aux_3.acc_seg: 95.2487, loss: 0.6918
2023-05-03 11:09:11,603 - mmseg - INFO - Iter [4600/10000]	lr: 5.744e-02, eta: 1:26:11, time: 0.989, data_time: 0.270, memory: 14777, decode.loss_ce: 0.0688, decode.acc_seg: 96.3994, aux_0.loss_ce: 0.0704, aux_0.acc_seg: 96.3776, aux_1.loss_ce: 0.0842, aux_1.acc_seg: 95.6451, aux_2.loss_ce: 0.1188, aux_2.loss_dice: 0.2547, aux_2.acc_seg: 96.0968, aux_3.loss_ce: 0.0991, aux_3.acc_seg: 95.1285, loss: 0.6960
2023-05-03 11:09:57,699 - mmseg - INFO - Iter [4650/10000]	lr: 5.696e-02, eta: 1:25:21, time: 0.922, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0691, decode.acc_seg: 96.4254, aux_0.loss_ce: 0.0708, aux_0.acc_seg: 96.3780, aux_1.loss_ce: 0.0836, aux_1.acc_seg: 95.7065, aux_2.loss_ce: 0.1187, aux_2.loss_dice: 0.2541, aux_2.acc_seg: 96.0947, aux_3.loss_ce: 0.0993, aux_3.acc_seg: 95.1262, loss: 0.6956
2023-05-03 11:10:43,724 - mmseg - INFO - Iter [4700/10000]	lr: 5.648e-02, eta: 1:24:31, time: 0.920, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0674, decode.acc_seg: 96.4388, aux_0.loss_ce: 0.0690, aux_0.acc_seg: 96.4040, aux_1.loss_ce: 0.0819, aux_1.acc_seg: 95.6973, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2535, aux_2.acc_seg: 95.9901, aux_3.loss_ce: 0.0976, aux_3.acc_seg: 95.1360, loss: 0.6894
2023-05-03 11:11:29,787 - mmseg - INFO - Iter [4750/10000]	lr: 5.600e-02, eta: 1:23:42, time: 0.921, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0711, decode.acc_seg: 96.3411, aux_0.loss_ce: 0.0727, aux_0.acc_seg: 96.3132, aux_1.loss_ce: 0.0856, aux_1.acc_seg: 95.6110, aux_2.loss_ce: 0.1202, aux_2.loss_dice: 0.2553, aux_2.acc_seg: 96.0089, aux_3.loss_ce: 0.0994, aux_3.acc_seg: 95.1826, loss: 0.7044
2023-05-03 11:12:19,138 - mmseg - INFO - Iter [4800/10000]	lr: 5.552e-02, eta: 1:22:55, time: 0.987, data_time: 0.268, memory: 14777, decode.loss_ce: 0.0680, decode.acc_seg: 96.4970, aux_0.loss_ce: 0.0694, aux_0.acc_seg: 96.4679, aux_1.loss_ce: 0.0830, aux_1.acc_seg: 95.7502, aux_2.loss_ce: 0.1188, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.0678, aux_3.loss_ce: 0.0987, aux_3.acc_seg: 95.2158, loss: 0.6911
2023-05-03 11:13:05,302 - mmseg - INFO - Iter [4850/10000]	lr: 5.504e-02, eta: 1:22:06, time: 0.923, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0687, decode.acc_seg: 96.4156, aux_0.loss_ce: 0.0703, aux_0.acc_seg: 96.3779, aux_1.loss_ce: 0.0829, aux_1.acc_seg: 95.6934, aux_2.loss_ce: 0.1181, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.0704, aux_3.loss_ce: 0.0970, aux_3.acc_seg: 95.1917, loss: 0.6901
2023-05-03 11:13:51,598 - mmseg - INFO - Iter [4900/10000]	lr: 5.456e-02, eta: 1:21:16, time: 0.926, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0695, decode.acc_seg: 96.3676, aux_0.loss_ce: 0.0713, aux_0.acc_seg: 96.3330, aux_1.loss_ce: 0.0838, aux_1.acc_seg: 95.6461, aux_2.loss_ce: 0.1197, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 96.0671, aux_3.loss_ce: 0.0994, aux_3.acc_seg: 95.0720, loss: 0.6991
2023-05-03 11:14:38,027 - mmseg - INFO - Iter [4950/10000]	lr: 5.408e-02, eta: 1:20:27, time: 0.929, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0732, decode.acc_seg: 96.2204, aux_0.loss_ce: 0.0751, aux_0.acc_seg: 96.1712, aux_1.loss_ce: 0.0875, aux_1.acc_seg: 95.4733, aux_2.loss_ce: 0.1198, aux_2.loss_dice: 0.2537, aux_2.acc_seg: 96.0285, aux_3.loss_ce: 0.1027, aux_3.acc_seg: 94.9248, loss: 0.7120
2023-05-03 11:15:27,643 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-05-03 11:15:29,543 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 11:15:29,543 - mmseg - INFO - Iter [5000/10000]	lr: 5.360e-02, eta: 1:19:43, time: 1.031, data_time: 0.272, memory: 14777, decode.loss_ce: 0.0693, decode.acc_seg: 96.4147, aux_0.loss_ce: 0.0709, aux_0.acc_seg: 96.3901, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.6945, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2542, aux_2.acc_seg: 96.0537, aux_3.loss_ce: 0.0983, aux_3.acc_seg: 95.1956, loss: 0.6955
2023-05-03 11:15:35,972 - mmseg - INFO - per class results:
2023-05-03 11:15:35,973 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.48 | 95.55 |
|   Building  | 93.84 | 95.54 |
|     Car     |  93.7 | 95.44 |
| Column_Pole | 34.63 |  47.6 |
|    Fence    | 81.39 | 90.02 |
|  Pedestrian | 67.46 | 87.56 |
|     Road    | 97.55 | 98.25 |
|   Sidewalk  |  92.0 | 97.36 |
|  SignSymbol |  0.78 |  0.79 |
|     Sky     | 94.27 | 96.36 |
|     Tree    | 92.67 |  98.3 |
+-------------+-------+-------+
2023-05-03 11:15:35,974 - mmseg - INFO - Summary:
2023-05-03 11:15:35,974 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.45 | 75.89 | 82.07 |
+-------+-------+-------+
2023-05-03 11:15:35,974 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 11:15:35,974 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9645, mIoU: 0.7589, mAcc: 0.8207, IoU.Bicyclist: 0.8648, IoU.Building: 0.9384, IoU.Car: 0.9370, IoU.Column_Pole: 0.3463, IoU.Fence: 0.8139, IoU.Pedestrian: 0.6746, IoU.Road: 0.9755, IoU.Sidewalk: 0.9200, IoU.SignSymbol: 0.0078, IoU.Sky: 0.9427, IoU.Tree: 0.9267, Acc.Bicyclist: 0.9555, Acc.Building: 0.9554, Acc.Car: 0.9544, Acc.Column_Pole: 0.4760, Acc.Fence: 0.9002, Acc.Pedestrian: 0.8756, Acc.Road: 0.9825, Acc.Sidewalk: 0.9736, Acc.SignSymbol: 0.0079, Acc.Sky: 0.9636, Acc.Tree: 0.9830
2023-05-03 11:16:22,332 - mmseg - INFO - Iter [5050/10000]	lr: 5.312e-02, eta: 1:19:00, time: 1.055, data_time: 0.332, memory: 14777, decode.loss_ce: 0.0652, decode.acc_seg: 96.5916, aux_0.loss_ce: 0.0671, aux_0.acc_seg: 96.5359, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 95.8200, aux_2.loss_ce: 0.1189, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 96.0372, aux_3.loss_ce: 0.0957, aux_3.acc_seg: 95.2750, loss: 0.6804
2023-05-03 11:17:08,342 - mmseg - INFO - Iter [5100/10000]	lr: 5.263e-02, eta: 1:18:10, time: 0.920, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0657, decode.acc_seg: 96.5533, aux_0.loss_ce: 0.0672, aux_0.acc_seg: 96.5309, aux_1.loss_ce: 0.0805, aux_1.acc_seg: 95.8067, aux_2.loss_ce: 0.1201, aux_2.loss_dice: 0.2537, aux_2.acc_seg: 95.9770, aux_3.loss_ce: 0.0962, aux_3.acc_seg: 95.2272, loss: 0.6833
2023-05-03 11:17:57,175 - mmseg - INFO - Iter [5150/10000]	lr: 5.215e-02, eta: 1:17:23, time: 0.977, data_time: 0.267, memory: 14777, decode.loss_ce: 0.0635, decode.acc_seg: 96.6289, aux_0.loss_ce: 0.0650, aux_0.acc_seg: 96.5979, aux_1.loss_ce: 0.0773, aux_1.acc_seg: 95.9356, aux_2.loss_ce: 0.1171, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 96.1240, aux_3.loss_ce: 0.0934, aux_3.acc_seg: 95.3462, loss: 0.6686
2023-05-03 11:18:42,853 - mmseg - INFO - Iter [5200/10000]	lr: 5.167e-02, eta: 1:16:33, time: 0.914, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0659, decode.acc_seg: 96.5621, aux_0.loss_ce: 0.0673, aux_0.acc_seg: 96.5405, aux_1.loss_ce: 0.0806, aux_1.acc_seg: 95.8347, aux_2.loss_ce: 0.1204, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 95.9749, aux_3.loss_ce: 0.0962, aux_3.acc_seg: 95.2653, loss: 0.6848
2023-05-03 11:19:27,787 - mmseg - INFO - Iter [5250/10000]	lr: 5.118e-02, eta: 1:15:43, time: 0.899, data_time: 0.191, memory: 14777, decode.loss_ce: 0.0662, decode.acc_seg: 96.5313, aux_0.loss_ce: 0.0679, aux_0.acc_seg: 96.5020, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 95.8358, aux_2.loss_ce: 0.1180, aux_2.loss_dice: 0.2526, aux_2.acc_seg: 96.0859, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.2799, loss: 0.6801
2023-05-03 11:20:13,153 - mmseg - INFO - Iter [5300/10000]	lr: 5.070e-02, eta: 1:14:53, time: 0.907, data_time: 0.196, memory: 14777, decode.loss_ce: 0.0665, decode.acc_seg: 96.4930, aux_0.loss_ce: 0.0681, aux_0.acc_seg: 96.4651, aux_1.loss_ce: 0.0812, aux_1.acc_seg: 95.7884, aux_2.loss_ce: 0.1188, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.0453, aux_3.loss_ce: 0.0968, aux_3.acc_seg: 95.2220, loss: 0.6843
2023-05-03 11:21:01,939 - mmseg - INFO - Iter [5350/10000]	lr: 5.021e-02, eta: 1:14:06, time: 0.976, data_time: 0.261, memory: 14777, decode.loss_ce: 0.0656, decode.acc_seg: 96.4936, aux_0.loss_ce: 0.0668, aux_0.acc_seg: 96.4663, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 95.7715, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 96.0744, aux_3.loss_ce: 0.0945, aux_3.acc_seg: 95.1951, loss: 0.6754
2023-05-03 11:21:48,244 - mmseg - INFO - Iter [5400/10000]	lr: 4.972e-02, eta: 1:13:17, time: 0.926, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0697, decode.acc_seg: 96.4408, aux_0.loss_ce: 0.0709, aux_0.acc_seg: 96.4296, aux_1.loss_ce: 0.0828, aux_1.acc_seg: 95.7656, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2548, aux_2.acc_seg: 96.0141, aux_3.loss_ce: 0.0983, aux_3.acc_seg: 95.1992, loss: 0.6967
2023-05-03 11:22:34,374 - mmseg - INFO - Iter [5450/10000]	lr: 4.924e-02, eta: 1:12:28, time: 0.923, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0698, decode.acc_seg: 96.4208, aux_0.loss_ce: 0.0710, aux_0.acc_seg: 96.4078, aux_1.loss_ce: 0.0833, aux_1.acc_seg: 95.7733, aux_2.loss_ce: 0.1209, aux_2.loss_dice: 0.2555, aux_2.acc_seg: 95.9944, aux_3.loss_ce: 0.0981, aux_3.acc_seg: 95.2471, loss: 0.6987
2023-05-03 11:23:19,962 - mmseg - INFO - Iter [5500/10000]	lr: 4.875e-02, eta: 1:11:38, time: 0.912, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0647, decode.acc_seg: 96.6372, aux_0.loss_ce: 0.0666, aux_0.acc_seg: 96.5944, aux_1.loss_ce: 0.0793, aux_1.acc_seg: 95.9141, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.2521, aux_2.acc_seg: 96.1104, aux_3.loss_ce: 0.0949, aux_3.acc_seg: 95.3653, loss: 0.6746
2023-05-03 11:24:09,197 - mmseg - INFO - Iter [5550/10000]	lr: 4.826e-02, eta: 1:10:52, time: 0.985, data_time: 0.269, memory: 14777, decode.loss_ce: 0.0650, decode.acc_seg: 96.5920, aux_0.loss_ce: 0.0666, aux_0.acc_seg: 96.5636, aux_1.loss_ce: 0.0779, aux_1.acc_seg: 95.9348, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2519, aux_2.acc_seg: 96.1898, aux_3.loss_ce: 0.0939, aux_3.acc_seg: 95.3396, loss: 0.6714
2023-05-03 11:24:54,485 - mmseg - INFO - Iter [5600/10000]	lr: 4.778e-02, eta: 1:10:02, time: 0.906, data_time: 0.194, memory: 14777, decode.loss_ce: 0.0651, decode.acc_seg: 96.5905, aux_0.loss_ce: 0.0663, aux_0.acc_seg: 96.5752, aux_1.loss_ce: 0.0794, aux_1.acc_seg: 95.8672, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2527, aux_2.acc_seg: 95.9938, aux_3.loss_ce: 0.0941, aux_3.acc_seg: 95.3262, loss: 0.6769
2023-05-03 11:25:40,950 - mmseg - INFO - Iter [5650/10000]	lr: 4.729e-02, eta: 1:09:13, time: 0.929, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0654, decode.acc_seg: 96.5692, aux_0.loss_ce: 0.0672, aux_0.acc_seg: 96.5348, aux_1.loss_ce: 0.0798, aux_1.acc_seg: 95.8524, aux_2.loss_ce: 0.1200, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 95.9956, aux_3.loss_ce: 0.0952, aux_3.acc_seg: 95.2925, loss: 0.6810
2023-05-03 11:26:30,634 - mmseg - INFO - Iter [5700/10000]	lr: 4.680e-02, eta: 1:08:27, time: 0.994, data_time: 0.270, memory: 14777, decode.loss_ce: 0.0643, decode.acc_seg: 96.6182, aux_0.loss_ce: 0.0659, aux_0.acc_seg: 96.5880, aux_1.loss_ce: 0.0785, aux_1.acc_seg: 95.9173, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2520, aux_2.acc_seg: 96.0415, aux_3.loss_ce: 0.0943, aux_3.acc_seg: 95.3497, loss: 0.6731
2023-05-03 11:27:17,113 - mmseg - INFO - Iter [5750/10000]	lr: 4.631e-02, eta: 1:07:38, time: 0.930, data_time: 0.208, memory: 14777, decode.loss_ce: 0.0688, decode.acc_seg: 96.3404, aux_0.loss_ce: 0.0699, aux_0.acc_seg: 96.3234, aux_1.loss_ce: 0.0827, aux_1.acc_seg: 95.6145, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.0617, aux_3.loss_ce: 0.0958, aux_3.acc_seg: 95.1651, loss: 0.6849
2023-05-03 11:28:03,155 - mmseg - INFO - Iter [5800/10000]	lr: 4.582e-02, eta: 1:06:49, time: 0.921, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0662, decode.acc_seg: 96.5594, aux_0.loss_ce: 0.0679, aux_0.acc_seg: 96.5258, aux_1.loss_ce: 0.0807, aux_1.acc_seg: 95.8393, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2541, aux_2.acc_seg: 95.9704, aux_3.loss_ce: 0.0968, aux_3.acc_seg: 95.2448, loss: 0.6862
2023-05-03 11:28:49,196 - mmseg - INFO - Iter [5850/10000]	lr: 4.533e-02, eta: 1:06:00, time: 0.921, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0639, decode.acc_seg: 96.6080, aux_0.loss_ce: 0.0653, aux_0.acc_seg: 96.5720, aux_1.loss_ce: 0.0774, aux_1.acc_seg: 95.9224, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 96.0793, aux_3.loss_ce: 0.0928, aux_3.acc_seg: 95.3526, loss: 0.6682
2023-05-03 11:29:38,662 - mmseg - INFO - Iter [5900/10000]	lr: 4.483e-02, eta: 1:05:14, time: 0.989, data_time: 0.269, memory: 14777, decode.loss_ce: 0.0630, decode.acc_seg: 96.6264, aux_0.loss_ce: 0.0642, aux_0.acc_seg: 96.5987, aux_1.loss_ce: 0.0764, aux_1.acc_seg: 95.9328, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.1458, aux_3.loss_ce: 0.0917, aux_3.acc_seg: 95.3628, loss: 0.6616
2023-05-03 11:30:24,571 - mmseg - INFO - Iter [5950/10000]	lr: 4.434e-02, eta: 1:04:25, time: 0.918, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0640, decode.acc_seg: 96.6718, aux_0.loss_ce: 0.0656, aux_0.acc_seg: 96.6401, aux_1.loss_ce: 0.0782, aux_1.acc_seg: 95.9715, aux_2.loss_ce: 0.1201, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 95.9903, aux_3.loss_ce: 0.0953, aux_3.acc_seg: 95.3307, loss: 0.6765
2023-05-03 11:31:10,414 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-05-03 11:31:12,324 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 11:31:12,324 - mmseg - INFO - Iter [6000/10000]	lr: 4.385e-02, eta: 1:03:37, time: 0.956, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0629, decode.acc_seg: 96.6435, aux_0.loss_ce: 0.0642, aux_0.acc_seg: 96.6202, aux_1.loss_ce: 0.0768, aux_1.acc_seg: 95.9262, aux_2.loss_ce: 0.1192, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 95.9875, aux_3.loss_ce: 0.0937, aux_3.acc_seg: 95.2779, loss: 0.6691
2023-05-03 11:31:17,799 - mmseg - INFO - per class results:
2023-05-03 11:31:17,800 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.38 | 93.98 |
|   Building  | 93.57 | 95.43 |
|     Car     | 92.85 |  94.3 |
| Column_Pole | 17.17 | 18.57 |
|    Fence    | 79.96 | 94.09 |
|  Pedestrian | 69.56 | 83.16 |
|     Road    |  97.5 | 98.25 |
|   Sidewalk  | 91.67 | 97.66 |
|  SignSymbol |  0.71 |  0.72 |
|     Sky     | 93.34 | 94.75 |
|     Tree    | 92.11 |  98.8 |
+-------------+-------+-------+
2023-05-03 11:31:17,800 - mmseg - INFO - Summary:
2023-05-03 11:31:17,801 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.25 | 74.08 | 79.06 |
+-------+-------+-------+
2023-05-03 11:31:17,801 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 11:31:17,801 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9625, mIoU: 0.7408, mAcc: 0.7906, IoU.Bicyclist: 0.8638, IoU.Building: 0.9357, IoU.Car: 0.9285, IoU.Column_Pole: 0.1717, IoU.Fence: 0.7996, IoU.Pedestrian: 0.6956, IoU.Road: 0.9750, IoU.Sidewalk: 0.9167, IoU.SignSymbol: 0.0071, IoU.Sky: 0.9334, IoU.Tree: 0.9211, Acc.Bicyclist: 0.9398, Acc.Building: 0.9543, Acc.Car: 0.9430, Acc.Column_Pole: 0.1857, Acc.Fence: 0.9409, Acc.Pedestrian: 0.8316, Acc.Road: 0.9825, Acc.Sidewalk: 0.9766, Acc.SignSymbol: 0.0072, Acc.Sky: 0.9475, Acc.Tree: 0.9880
2023-05-03 11:32:03,932 - mmseg - INFO - Iter [6050/10000]	lr: 4.336e-02, eta: 1:02:52, time: 1.032, data_time: 0.313, memory: 14777, decode.loss_ce: 0.0627, decode.acc_seg: 96.6426, aux_0.loss_ce: 0.0640, aux_0.acc_seg: 96.6266, aux_1.loss_ce: 0.0768, aux_1.acc_seg: 95.9302, aux_2.loss_ce: 0.1181, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0517, aux_3.loss_ce: 0.0916, aux_3.acc_seg: 95.3948, loss: 0.6642
2023-05-03 11:32:53,204 - mmseg - INFO - Iter [6100/10000]	lr: 4.286e-02, eta: 1:02:05, time: 0.985, data_time: 0.271, memory: 14777, decode.loss_ce: 0.0614, decode.acc_seg: 96.6929, aux_0.loss_ce: 0.0628, aux_0.acc_seg: 96.6566, aux_1.loss_ce: 0.0751, aux_1.acc_seg: 95.9907, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.1218, aux_3.loss_ce: 0.0910, aux_3.acc_seg: 95.3988, loss: 0.6570
2023-05-03 11:33:39,723 - mmseg - INFO - Iter [6150/10000]	lr: 4.237e-02, eta: 1:01:17, time: 0.930, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0610, decode.acc_seg: 96.7006, aux_0.loss_ce: 0.0625, aux_0.acc_seg: 96.6707, aux_1.loss_ce: 0.0752, aux_1.acc_seg: 95.9618, aux_2.loss_ce: 0.1174, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.0475, aux_3.loss_ce: 0.0921, aux_3.acc_seg: 95.3210, loss: 0.6583
2023-05-03 11:34:25,705 - mmseg - INFO - Iter [6200/10000]	lr: 4.187e-02, eta: 1:00:28, time: 0.920, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0607, decode.acc_seg: 96.7283, aux_0.loss_ce: 0.0623, aux_0.acc_seg: 96.6985, aux_1.loss_ce: 0.0749, aux_1.acc_seg: 95.9974, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.1630, aux_3.loss_ce: 0.0914, aux_3.acc_seg: 95.3594, loss: 0.6562
2023-05-03 11:35:15,642 - mmseg - INFO - Iter [6250/10000]	lr: 4.138e-02, eta: 0:59:41, time: 0.999, data_time: 0.281, memory: 14777, decode.loss_ce: 0.0626, decode.acc_seg: 96.6682, aux_0.loss_ce: 0.0642, aux_0.acc_seg: 96.6444, aux_1.loss_ce: 0.0772, aux_1.acc_seg: 95.9282, aux_2.loss_ce: 0.1189, aux_2.loss_dice: 0.2519, aux_2.acc_seg: 96.0183, aux_3.loss_ce: 0.0932, aux_3.acc_seg: 95.3442, loss: 0.6682
2023-05-03 11:36:01,643 - mmseg - INFO - Iter [6300/10000]	lr: 4.088e-02, eta: 0:58:52, time: 0.920, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0609, decode.acc_seg: 96.8137, aux_0.loss_ce: 0.0623, aux_0.acc_seg: 96.7863, aux_1.loss_ce: 0.0751, aux_1.acc_seg: 96.1020, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 96.0798, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.4783, loss: 0.6589
2023-05-03 11:36:47,522 - mmseg - INFO - Iter [6350/10000]	lr: 4.038e-02, eta: 0:58:04, time: 0.918, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0617, decode.acc_seg: 96.6792, aux_0.loss_ce: 0.0631, aux_0.acc_seg: 96.6512, aux_1.loss_ce: 0.0758, aux_1.acc_seg: 95.9459, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 95.9934, aux_3.loss_ce: 0.0924, aux_3.acc_seg: 95.3128, loss: 0.6622
2023-05-03 11:37:33,931 - mmseg - INFO - Iter [6400/10000]	lr: 3.988e-02, eta: 0:57:15, time: 0.928, data_time: 0.209, memory: 14777, decode.loss_ce: 0.0628, decode.acc_seg: 96.7441, aux_0.loss_ce: 0.0645, aux_0.acc_seg: 96.7139, aux_1.loss_ce: 0.0773, aux_1.acc_seg: 96.0391, aux_2.loss_ce: 0.1200, aux_2.loss_dice: 0.2537, aux_2.acc_seg: 95.9862, aux_3.loss_ce: 0.0944, aux_3.acc_seg: 95.4091, loss: 0.6726
2023-05-03 11:38:23,426 - mmseg - INFO - Iter [6450/10000]	lr: 3.938e-02, eta: 0:56:28, time: 0.990, data_time: 0.269, memory: 14777, decode.loss_ce: 0.0627, decode.acc_seg: 96.7129, aux_0.loss_ce: 0.0640, aux_0.acc_seg: 96.6859, aux_1.loss_ce: 0.0766, aux_1.acc_seg: 95.9915, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 96.0872, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.4154, loss: 0.6622
2023-05-03 11:39:09,744 - mmseg - INFO - Iter [6500/10000]	lr: 3.888e-02, eta: 0:55:40, time: 0.926, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0617, decode.acc_seg: 96.6723, aux_0.loss_ce: 0.0632, aux_0.acc_seg: 96.6505, aux_1.loss_ce: 0.0758, aux_1.acc_seg: 95.9615, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.0444, aux_3.loss_ce: 0.0919, aux_3.acc_seg: 95.3239, loss: 0.6603
2023-05-03 11:39:56,034 - mmseg - INFO - Iter [6550/10000]	lr: 3.838e-02, eta: 0:54:51, time: 0.926, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0619, decode.acc_seg: 96.7355, aux_0.loss_ce: 0.0636, aux_0.acc_seg: 96.7019, aux_1.loss_ce: 0.0759, aux_1.acc_seg: 96.0382, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 96.0618, aux_3.loss_ce: 0.0919, aux_3.acc_seg: 95.4309, loss: 0.6628
2023-05-03 11:40:41,727 - mmseg - INFO - Iter [6600/10000]	lr: 3.788e-02, eta: 0:54:03, time: 0.914, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0626, decode.acc_seg: 96.6320, aux_0.loss_ce: 0.0641, aux_0.acc_seg: 96.5986, aux_1.loss_ce: 0.0769, aux_1.acc_seg: 95.9023, aux_2.loss_ce: 0.1191, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 95.9721, aux_3.loss_ce: 0.0931, aux_3.acc_seg: 95.2964, loss: 0.6669
2023-05-03 11:41:31,160 - mmseg - INFO - Iter [6650/10000]	lr: 3.738e-02, eta: 0:53:16, time: 0.989, data_time: 0.271, memory: 14777, decode.loss_ce: 0.0605, decode.acc_seg: 96.7639, aux_0.loss_ce: 0.0619, aux_0.acc_seg: 96.7379, aux_1.loss_ce: 0.0739, aux_1.acc_seg: 96.0607, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.0792, aux_3.loss_ce: 0.0902, aux_3.acc_seg: 95.4514, loss: 0.6542
2023-05-03 11:42:16,889 - mmseg - INFO - Iter [6700/10000]	lr: 3.688e-02, eta: 0:52:27, time: 0.915, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0620, decode.acc_seg: 96.6958, aux_0.loss_ce: 0.0634, aux_0.acc_seg: 96.6780, aux_1.loss_ce: 0.0756, aux_1.acc_seg: 96.0137, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0567, aux_3.loss_ce: 0.0919, aux_3.acc_seg: 95.3994, loss: 0.6614
2023-05-03 11:43:02,319 - mmseg - INFO - Iter [6750/10000]	lr: 3.638e-02, eta: 0:51:38, time: 0.909, data_time: 0.193, memory: 14777, decode.loss_ce: 0.0613, decode.acc_seg: 96.7659, aux_0.loss_ce: 0.0624, aux_0.acc_seg: 96.7623, aux_1.loss_ce: 0.0748, aux_1.acc_seg: 96.0856, aux_2.loss_ce: 0.1181, aux_2.loss_dice: 0.2513, aux_2.acc_seg: 96.0435, aux_3.loss_ce: 0.0906, aux_3.acc_seg: 95.4940, loss: 0.6585
2023-05-03 11:43:51,430 - mmseg - INFO - Iter [6800/10000]	lr: 3.587e-02, eta: 0:50:51, time: 0.982, data_time: 0.268, memory: 14777, decode.loss_ce: 0.0616, decode.acc_seg: 96.7633, aux_0.loss_ce: 0.0628, aux_0.acc_seg: 96.7351, aux_1.loss_ce: 0.0756, aux_1.acc_seg: 96.0555, aux_2.loss_ce: 0.1213, aux_2.loss_dice: 0.2538, aux_2.acc_seg: 95.9335, aux_3.loss_ce: 0.0929, aux_3.acc_seg: 95.4010, loss: 0.6680
2023-05-03 11:44:37,268 - mmseg - INFO - Iter [6850/10000]	lr: 3.537e-02, eta: 0:50:03, time: 0.917, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0605, decode.acc_seg: 96.7690, aux_0.loss_ce: 0.0619, aux_0.acc_seg: 96.7387, aux_1.loss_ce: 0.0739, aux_1.acc_seg: 96.0724, aux_2.loss_ce: 0.1161, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.0976, aux_3.loss_ce: 0.0904, aux_3.acc_seg: 95.4466, loss: 0.6520
2023-05-03 11:45:23,281 - mmseg - INFO - Iter [6900/10000]	lr: 3.486e-02, eta: 0:49:14, time: 0.920, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0612, decode.acc_seg: 96.7256, aux_0.loss_ce: 0.0625, aux_0.acc_seg: 96.7102, aux_1.loss_ce: 0.0746, aux_1.acc_seg: 96.0462, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 96.1349, aux_3.loss_ce: 0.0898, aux_3.acc_seg: 95.4656, loss: 0.6560
2023-05-03 11:46:09,151 - mmseg - INFO - Iter [6950/10000]	lr: 3.436e-02, eta: 0:48:26, time: 0.917, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0625, decode.acc_seg: 96.7164, aux_0.loss_ce: 0.0636, aux_0.acc_seg: 96.7035, aux_1.loss_ce: 0.0759, aux_1.acc_seg: 96.0314, aux_2.loss_ce: 0.1181, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 96.0755, aux_3.loss_ce: 0.0914, aux_3.acc_seg: 95.4331, loss: 0.6641
2023-05-03 11:46:58,766 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-05-03 11:47:00,720 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 11:47:00,720 - mmseg - INFO - Iter [7000/10000]	lr: 3.385e-02, eta: 0:47:40, time: 1.032, data_time: 0.280, memory: 14777, decode.loss_ce: 0.0597, decode.acc_seg: 96.8294, aux_0.loss_ce: 0.0611, aux_0.acc_seg: 96.8107, aux_1.loss_ce: 0.0738, aux_1.acc_seg: 96.1275, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 95.9982, aux_3.loss_ce: 0.0902, aux_3.acc_seg: 95.4907, loss: 0.6525
2023-05-03 11:47:07,016 - mmseg - INFO - per class results:
2023-05-03 11:47:07,017 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.82 | 93.38 |
|   Building  | 93.79 | 95.75 |
|     Car     | 93.24 | 96.05 |
| Column_Pole | 21.14 | 23.56 |
|    Fence    |  82.4 | 95.24 |
|  Pedestrian | 70.31 | 86.44 |
|     Road    |  97.8 |  98.6 |
|   Sidewalk  | 92.73 | 96.91 |
|  SignSymbol |  0.58 |  0.58 |
|     Sky     | 94.45 | 97.12 |
|     Tree    | 92.67 | 97.99 |
+-------------+-------+-------+
2023-05-03 11:47:07,017 - mmseg - INFO - Summary:
2023-05-03 11:47:07,018 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.56 | 75.08 | 80.15 |
+-------+-------+-------+
2023-05-03 11:47:07,018 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 11:47:07,018 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9656, mIoU: 0.7508, mAcc: 0.8015, IoU.Bicyclist: 0.8682, IoU.Building: 0.9379, IoU.Car: 0.9324, IoU.Column_Pole: 0.2114, IoU.Fence: 0.8240, IoU.Pedestrian: 0.7031, IoU.Road: 0.9780, IoU.Sidewalk: 0.9273, IoU.SignSymbol: 0.0058, IoU.Sky: 0.9445, IoU.Tree: 0.9267, Acc.Bicyclist: 0.9338, Acc.Building: 0.9575, Acc.Car: 0.9605, Acc.Column_Pole: 0.2356, Acc.Fence: 0.9524, Acc.Pedestrian: 0.8644, Acc.Road: 0.9860, Acc.Sidewalk: 0.9691, Acc.SignSymbol: 0.0058, Acc.Sky: 0.9712, Acc.Tree: 0.9799
2023-05-03 11:47:52,607 - mmseg - INFO - Iter [7050/10000]	lr: 3.334e-02, eta: 0:46:54, time: 1.037, data_time: 0.324, memory: 14777, decode.loss_ce: 0.0594, decode.acc_seg: 96.8717, aux_0.loss_ce: 0.0605, aux_0.acc_seg: 96.8611, aux_1.loss_ce: 0.0734, aux_1.acc_seg: 96.1810, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 96.0203, aux_3.loss_ce: 0.0906, aux_3.acc_seg: 95.5078, loss: 0.6531
2023-05-03 11:48:38,408 - mmseg - INFO - Iter [7100/10000]	lr: 3.283e-02, eta: 0:46:06, time: 0.916, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0585, decode.acc_seg: 96.8978, aux_0.loss_ce: 0.0599, aux_0.acc_seg: 96.8706, aux_1.loss_ce: 0.0722, aux_1.acc_seg: 96.1882, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 96.0351, aux_3.loss_ce: 0.0896, aux_3.acc_seg: 95.5202, loss: 0.6489
2023-05-03 11:49:24,636 - mmseg - INFO - Iter [7150/10000]	lr: 3.232e-02, eta: 0:45:17, time: 0.925, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0611, decode.acc_seg: 96.7151, aux_0.loss_ce: 0.0624, aux_0.acc_seg: 96.7002, aux_1.loss_ce: 0.0747, aux_1.acc_seg: 96.0237, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2524, aux_2.acc_seg: 96.0507, aux_3.loss_ce: 0.0917, aux_3.acc_seg: 95.3777, loss: 0.6607
2023-05-03 11:50:14,333 - mmseg - INFO - Iter [7200/10000]	lr: 3.181e-02, eta: 0:44:30, time: 0.994, data_time: 0.276, memory: 14777, decode.loss_ce: 0.0588, decode.acc_seg: 96.8093, aux_0.loss_ce: 0.0604, aux_0.acc_seg: 96.7782, aux_1.loss_ce: 0.0728, aux_1.acc_seg: 96.1101, aux_2.loss_ce: 0.1165, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.0537, aux_3.loss_ce: 0.0896, aux_3.acc_seg: 95.4511, loss: 0.6480
2023-05-03 11:51:00,570 - mmseg - INFO - Iter [7250/10000]	lr: 3.130e-02, eta: 0:43:42, time: 0.925, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0605, decode.acc_seg: 96.8207, aux_0.loss_ce: 0.0619, aux_0.acc_seg: 96.8129, aux_1.loss_ce: 0.0745, aux_1.acc_seg: 96.1211, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 96.0298, aux_3.loss_ce: 0.0920, aux_3.acc_seg: 95.4488, loss: 0.6591
2023-05-03 11:51:46,620 - mmseg - INFO - Iter [7300/10000]	lr: 3.079e-02, eta: 0:42:54, time: 0.921, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0589, decode.acc_seg: 96.8435, aux_0.loss_ce: 0.0602, aux_0.acc_seg: 96.8292, aux_1.loss_ce: 0.0732, aux_1.acc_seg: 96.1147, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 95.9540, aux_3.loss_ce: 0.0907, aux_3.acc_seg: 95.4469, loss: 0.6524
2023-05-03 11:52:36,505 - mmseg - INFO - Iter [7350/10000]	lr: 3.027e-02, eta: 0:42:07, time: 0.998, data_time: 0.280, memory: 14777, decode.loss_ce: 0.0593, decode.acc_seg: 96.8993, aux_0.loss_ce: 0.0609, aux_0.acc_seg: 96.8691, aux_1.loss_ce: 0.0728, aux_1.acc_seg: 96.2292, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2526, aux_2.acc_seg: 96.1061, aux_3.loss_ce: 0.0907, aux_3.acc_seg: 95.5309, loss: 0.6538
2023-05-03 11:53:22,679 - mmseg - INFO - Iter [7400/10000]	lr: 2.976e-02, eta: 0:41:19, time: 0.923, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0600, decode.acc_seg: 96.8146, aux_0.loss_ce: 0.0613, aux_0.acc_seg: 96.7973, aux_1.loss_ce: 0.0737, aux_1.acc_seg: 96.1141, aux_2.loss_ce: 0.1183, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.0057, aux_3.loss_ce: 0.0912, aux_3.acc_seg: 95.4307, loss: 0.6549
2023-05-03 11:54:08,320 - mmseg - INFO - Iter [7450/10000]	lr: 2.924e-02, eta: 0:40:30, time: 0.913, data_time: 0.198, memory: 14777, decode.loss_ce: 0.0573, decode.acc_seg: 96.8964, aux_0.loss_ce: 0.0585, aux_0.acc_seg: 96.8783, aux_1.loss_ce: 0.0713, aux_1.acc_seg: 96.1606, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.0438, aux_3.loss_ce: 0.0884, aux_3.acc_seg: 95.4929, loss: 0.6426
2023-05-03 11:54:54,117 - mmseg - INFO - Iter [7500/10000]	lr: 2.873e-02, eta: 0:39:42, time: 0.916, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0601, decode.acc_seg: 96.8373, aux_0.loss_ce: 0.0615, aux_0.acc_seg: 96.8141, aux_1.loss_ce: 0.0739, aux_1.acc_seg: 96.1399, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 96.0630, aux_3.loss_ce: 0.0917, aux_3.acc_seg: 95.4607, loss: 0.6572
2023-05-03 11:55:43,703 - mmseg - INFO - Iter [7550/10000]	lr: 2.821e-02, eta: 0:38:55, time: 0.992, data_time: 0.276, memory: 14777, decode.loss_ce: 0.0589, decode.acc_seg: 96.8447, aux_0.loss_ce: 0.0606, aux_0.acc_seg: 96.8110, aux_1.loss_ce: 0.0732, aux_1.acc_seg: 96.1188, aux_2.loss_ce: 0.1172, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 96.0521, aux_3.loss_ce: 0.0911, aux_3.acc_seg: 95.4094, loss: 0.6509
2023-05-03 11:56:29,520 - mmseg - INFO - Iter [7600/10000]	lr: 2.769e-02, eta: 0:38:07, time: 0.916, data_time: 0.201, memory: 14777, decode.loss_ce: 0.0579, decode.acc_seg: 96.8002, aux_0.loss_ce: 0.0592, aux_0.acc_seg: 96.7852, aux_1.loss_ce: 0.0720, aux_1.acc_seg: 96.0670, aux_2.loss_ce: 0.1167, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.0523, aux_3.loss_ce: 0.0886, aux_3.acc_seg: 95.4197, loss: 0.6435
2023-05-03 11:57:15,858 - mmseg - INFO - Iter [7650/10000]	lr: 2.717e-02, eta: 0:37:19, time: 0.927, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0583, decode.acc_seg: 96.8454, aux_0.loss_ce: 0.0595, aux_0.acc_seg: 96.8261, aux_1.loss_ce: 0.0714, aux_1.acc_seg: 96.1718, aux_2.loss_ce: 0.1172, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 96.0294, aux_3.loss_ce: 0.0891, aux_3.acc_seg: 95.4572, loss: 0.6446
2023-05-03 11:58:01,571 - mmseg - INFO - Iter [7700/10000]	lr: 2.665e-02, eta: 0:36:31, time: 0.914, data_time: 0.200, memory: 14777, decode.loss_ce: 0.0589, decode.acc_seg: 96.9080, aux_0.loss_ce: 0.0601, aux_0.acc_seg: 96.9048, aux_1.loss_ce: 0.0727, aux_1.acc_seg: 96.2214, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 95.9947, aux_3.loss_ce: 0.0907, aux_3.acc_seg: 95.5270, loss: 0.6524
2023-05-03 11:58:51,824 - mmseg - INFO - Iter [7750/10000]	lr: 2.613e-02, eta: 0:35:44, time: 1.005, data_time: 0.283, memory: 14777, decode.loss_ce: 0.0570, decode.acc_seg: 96.9069, aux_0.loss_ce: 0.0583, aux_0.acc_seg: 96.8849, aux_1.loss_ce: 0.0706, aux_1.acc_seg: 96.2024, aux_2.loss_ce: 0.1180, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.0409, aux_3.loss_ce: 0.0885, aux_3.acc_seg: 95.4628, loss: 0.6428
2023-05-03 11:59:38,040 - mmseg - INFO - Iter [7800/10000]	lr: 2.561e-02, eta: 0:34:56, time: 0.924, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0577, decode.acc_seg: 96.8986, aux_0.loss_ce: 0.0591, aux_0.acc_seg: 96.8711, aux_1.loss_ce: 0.0718, aux_1.acc_seg: 96.1691, aux_2.loss_ce: 0.1180, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 95.9932, aux_3.loss_ce: 0.0899, aux_3.acc_seg: 95.4842, loss: 0.6459
2023-05-03 12:00:23,829 - mmseg - INFO - Iter [7850/10000]	lr: 2.508e-02, eta: 0:34:08, time: 0.916, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0551, decode.acc_seg: 96.9722, aux_0.loss_ce: 0.0566, aux_0.acc_seg: 96.9421, aux_1.loss_ce: 0.0686, aux_1.acc_seg: 96.2738, aux_2.loss_ce: 0.1148, aux_2.loss_dice: 0.2481, aux_2.acc_seg: 96.1197, aux_3.loss_ce: 0.0866, aux_3.acc_seg: 95.5622, loss: 0.6298
2023-05-03 12:01:13,830 - mmseg - INFO - Iter [7900/10000]	lr: 2.456e-02, eta: 0:33:21, time: 1.000, data_time: 0.280, memory: 14777, decode.loss_ce: 0.0569, decode.acc_seg: 96.9348, aux_0.loss_ce: 0.0581, aux_0.acc_seg: 96.9265, aux_1.loss_ce: 0.0705, aux_1.acc_seg: 96.2393, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.0569, aux_3.loss_ce: 0.0889, aux_3.acc_seg: 95.5167, loss: 0.6429
2023-05-03 12:01:59,617 - mmseg - INFO - Iter [7950/10000]	lr: 2.403e-02, eta: 0:32:32, time: 0.916, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0574, decode.acc_seg: 96.9280, aux_0.loss_ce: 0.0587, aux_0.acc_seg: 96.9136, aux_1.loss_ce: 0.0709, aux_1.acc_seg: 96.2323, aux_2.loss_ce: 0.1165, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 96.0759, aux_3.loss_ce: 0.0890, aux_3.acc_seg: 95.5523, loss: 0.6423
2023-05-03 12:02:46,128 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-05-03 12:02:48,627 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 12:02:48,627 - mmseg - INFO - Iter [8000/10000]	lr: 2.350e-02, eta: 0:31:45, time: 0.981, data_time: 0.209, memory: 14777, decode.loss_ce: 0.0570, decode.acc_seg: 96.9408, aux_0.loss_ce: 0.0586, aux_0.acc_seg: 96.9140, aux_1.loss_ce: 0.0702, aux_1.acc_seg: 96.2680, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.0882, aux_3.loss_ce: 0.0877, aux_3.acc_seg: 95.5815, loss: 0.6400
2023-05-03 12:02:53,827 - mmseg - INFO - per class results:
2023-05-03 12:02:53,828 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 87.16 | 92.85 |
|   Building  | 92.92 | 94.43 |
|     Car     | 93.32 | 94.94 |
| Column_Pole | 14.74 | 15.57 |
|    Fence    |  80.9 |  94.3 |
|  Pedestrian | 70.21 | 82.93 |
|     Road    |  97.6 | 98.37 |
|   Sidewalk  |  91.6 | 98.03 |
|  SignSymbol |  4.7  |  4.77 |
|     Sky     | 93.71 | 96.06 |
|     Tree    | 91.43 | 98.81 |
+-------------+-------+-------+
2023-05-03 12:02:53,828 - mmseg - INFO - Summary:
2023-05-03 12:02:53,828 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.17 | 74.39 | 79.19 |
+-------+-------+-------+
2023-05-03 12:02:53,830 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 12:02:53,830 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9617, mIoU: 0.7439, mAcc: 0.7919, IoU.Bicyclist: 0.8716, IoU.Building: 0.9292, IoU.Car: 0.9332, IoU.Column_Pole: 0.1474, IoU.Fence: 0.8090, IoU.Pedestrian: 0.7021, IoU.Road: 0.9760, IoU.Sidewalk: 0.9160, IoU.SignSymbol: 0.0470, IoU.Sky: 0.9371, IoU.Tree: 0.9143, Acc.Bicyclist: 0.9285, Acc.Building: 0.9443, Acc.Car: 0.9494, Acc.Column_Pole: 0.1557, Acc.Fence: 0.9430, Acc.Pedestrian: 0.8293, Acc.Road: 0.9837, Acc.Sidewalk: 0.9803, Acc.SignSymbol: 0.0477, Acc.Sky: 0.9606, Acc.Tree: 0.9881
2023-05-03 12:03:40,347 - mmseg - INFO - Iter [8050/10000]	lr: 2.297e-02, eta: 0:30:58, time: 1.034, data_time: 0.312, memory: 14777, decode.loss_ce: 0.0572, decode.acc_seg: 96.8919, aux_0.loss_ce: 0.0584, aux_0.acc_seg: 96.8749, aux_1.loss_ce: 0.0711, aux_1.acc_seg: 96.1768, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.0558, aux_3.loss_ce: 0.0884, aux_3.acc_seg: 95.5131, loss: 0.6414
2023-05-03 12:04:30,926 - mmseg - INFO - Iter [8100/10000]	lr: 2.244e-02, eta: 0:30:11, time: 1.012, data_time: 0.287, memory: 14777, decode.loss_ce: 0.0584, decode.acc_seg: 96.8706, aux_0.loss_ce: 0.0597, aux_0.acc_seg: 96.8523, aux_1.loss_ce: 0.0726, aux_1.acc_seg: 96.1510, aux_2.loss_ce: 0.1196, aux_2.loss_dice: 0.2519, aux_2.acc_seg: 95.9621, aux_3.loss_ce: 0.0902, aux_3.acc_seg: 95.4749, loss: 0.6524
2023-05-03 12:05:17,736 - mmseg - INFO - Iter [8150/10000]	lr: 2.191e-02, eta: 0:29:24, time: 0.936, data_time: 0.212, memory: 14777, decode.loss_ce: 0.0562, decode.acc_seg: 96.9729, aux_0.loss_ce: 0.0575, aux_0.acc_seg: 96.9549, aux_1.loss_ce: 0.0697, aux_1.acc_seg: 96.2969, aux_2.loss_ce: 0.1171, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0720, aux_3.loss_ce: 0.0878, aux_3.acc_seg: 95.5725, loss: 0.6392
2023-05-03 12:06:03,952 - mmseg - INFO - Iter [8200/10000]	lr: 2.138e-02, eta: 0:28:36, time: 0.924, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0563, decode.acc_seg: 96.9456, aux_0.loss_ce: 0.0575, aux_0.acc_seg: 96.9302, aux_1.loss_ce: 0.0696, aux_1.acc_seg: 96.2637, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.0731, aux_3.loss_ce: 0.0877, aux_3.acc_seg: 95.5329, loss: 0.6366
2023-05-03 12:06:50,022 - mmseg - INFO - Iter [8250/10000]	lr: 2.084e-02, eta: 0:27:48, time: 0.921, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0560, decode.acc_seg: 96.9700, aux_0.loss_ce: 0.0572, aux_0.acc_seg: 96.9530, aux_1.loss_ce: 0.0691, aux_1.acc_seg: 96.2879, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.1134, aux_3.loss_ce: 0.0872, aux_3.acc_seg: 95.5792, loss: 0.6340
2023-05-03 12:07:39,744 - mmseg - INFO - Iter [8300/10000]	lr: 2.031e-02, eta: 0:27:00, time: 0.994, data_time: 0.274, memory: 14777, decode.loss_ce: 0.0572, decode.acc_seg: 96.9666, aux_0.loss_ce: 0.0584, aux_0.acc_seg: 96.9489, aux_1.loss_ce: 0.0708, aux_1.acc_seg: 96.2672, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.0522, aux_3.loss_ce: 0.0892, aux_3.acc_seg: 95.5455, loss: 0.6431
2023-05-03 12:08:25,959 - mmseg - INFO - Iter [8350/10000]	lr: 1.977e-02, eta: 0:26:12, time: 0.924, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0571, decode.acc_seg: 96.9031, aux_0.loss_ce: 0.0585, aux_0.acc_seg: 96.8797, aux_1.loss_ce: 0.0709, aux_1.acc_seg: 96.1984, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 96.0457, aux_3.loss_ce: 0.0891, aux_3.acc_seg: 95.4945, loss: 0.6405
2023-05-03 12:09:11,726 - mmseg - INFO - Iter [8400/10000]	lr: 1.923e-02, eta: 0:25:24, time: 0.915, data_time: 0.197, memory: 14777, decode.loss_ce: 0.0554, decode.acc_seg: 97.0199, aux_0.loss_ce: 0.0565, aux_0.acc_seg: 97.0067, aux_1.loss_ce: 0.0690, aux_1.acc_seg: 96.3205, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.0977, aux_3.loss_ce: 0.0874, aux_3.acc_seg: 95.5796, loss: 0.6341
2023-05-03 12:10:01,232 - mmseg - INFO - Iter [8450/10000]	lr: 1.869e-02, eta: 0:24:37, time: 0.990, data_time: 0.272, memory: 14777, decode.loss_ce: 0.0537, decode.acc_seg: 97.0342, aux_0.loss_ce: 0.0551, aux_0.acc_seg: 97.0046, aux_1.loss_ce: 0.0672, aux_1.acc_seg: 96.3327, aux_2.loss_ce: 0.1142, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.1057, aux_3.loss_ce: 0.0851, aux_3.acc_seg: 95.5967, loss: 0.6221
2023-05-03 12:10:47,196 - mmseg - INFO - Iter [8500/10000]	lr: 1.815e-02, eta: 0:23:49, time: 0.919, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0547, decode.acc_seg: 96.9671, aux_0.loss_ce: 0.0560, aux_0.acc_seg: 96.9386, aux_1.loss_ce: 0.0685, aux_1.acc_seg: 96.2584, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 96.0618, aux_3.loss_ce: 0.0860, aux_3.acc_seg: 95.5470, loss: 0.6275
2023-05-03 12:11:32,987 - mmseg - INFO - Iter [8550/10000]	lr: 1.760e-02, eta: 0:23:01, time: 0.916, data_time: 0.204, memory: 14777, decode.loss_ce: 0.0562, decode.acc_seg: 96.9673, aux_0.loss_ce: 0.0576, aux_0.acc_seg: 96.9398, aux_1.loss_ce: 0.0702, aux_1.acc_seg: 96.2537, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.0514, aux_3.loss_ce: 0.0884, aux_3.acc_seg: 95.5191, loss: 0.6399
2023-05-03 12:12:19,361 - mmseg - INFO - Iter [8600/10000]	lr: 1.705e-02, eta: 0:22:13, time: 0.927, data_time: 0.205, memory: 14777, decode.loss_ce: 0.0561, decode.acc_seg: 97.0142, aux_0.loss_ce: 0.0575, aux_0.acc_seg: 96.9851, aux_1.loss_ce: 0.0696, aux_1.acc_seg: 96.3321, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2507, aux_2.acc_seg: 95.9946, aux_3.loss_ce: 0.0878, aux_3.acc_seg: 95.6224, loss: 0.6400
2023-05-03 12:13:08,705 - mmseg - INFO - Iter [8650/10000]	lr: 1.650e-02, eta: 0:21:26, time: 0.987, data_time: 0.273, memory: 14777, decode.loss_ce: 0.0566, decode.acc_seg: 96.9867, aux_0.loss_ce: 0.0581, aux_0.acc_seg: 96.9610, aux_1.loss_ce: 0.0707, aux_1.acc_seg: 96.2673, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 95.9832, aux_3.loss_ce: 0.0886, aux_3.acc_seg: 95.5925, loss: 0.6421
2023-05-03 12:13:54,485 - mmseg - INFO - Iter [8700/10000]	lr: 1.595e-02, eta: 0:20:38, time: 0.916, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0556, decode.acc_seg: 96.9600, aux_0.loss_ce: 0.0570, aux_0.acc_seg: 96.9352, aux_1.loss_ce: 0.0692, aux_1.acc_seg: 96.2539, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.0171, aux_3.loss_ce: 0.0874, aux_3.acc_seg: 95.5238, loss: 0.6355
2023-05-03 12:14:40,786 - mmseg - INFO - Iter [8750/10000]	lr: 1.540e-02, eta: 0:19:50, time: 0.926, data_time: 0.210, memory: 14777, decode.loss_ce: 0.0536, decode.acc_seg: 97.0917, aux_0.loss_ce: 0.0549, aux_0.acc_seg: 97.0719, aux_1.loss_ce: 0.0670, aux_1.acc_seg: 96.4029, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 96.0797, aux_3.loss_ce: 0.0856, aux_3.acc_seg: 95.6566, loss: 0.6256
2023-05-03 12:15:26,387 - mmseg - INFO - Iter [8800/10000]	lr: 1.485e-02, eta: 0:19:02, time: 0.912, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0548, decode.acc_seg: 97.0293, aux_0.loss_ce: 0.0561, aux_0.acc_seg: 97.0021, aux_1.loss_ce: 0.0687, aux_1.acc_seg: 96.3163, aux_2.loss_ce: 0.1156, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.0807, aux_3.loss_ce: 0.0876, aux_3.acc_seg: 95.5484, loss: 0.6308
2023-05-03 12:16:15,508 - mmseg - INFO - Iter [8850/10000]	lr: 1.429e-02, eta: 0:18:15, time: 0.982, data_time: 0.273, memory: 14777, decode.loss_ce: 0.0534, decode.acc_seg: 97.0572, aux_0.loss_ce: 0.0549, aux_0.acc_seg: 97.0334, aux_1.loss_ce: 0.0671, aux_1.acc_seg: 96.3431, aux_2.loss_ce: 0.1146, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.1025, aux_3.loss_ce: 0.0860, aux_3.acc_seg: 95.5704, loss: 0.6230
2023-05-03 12:17:00,778 - mmseg - INFO - Iter [8900/10000]	lr: 1.373e-02, eta: 0:17:27, time: 0.905, data_time: 0.202, memory: 14777, decode.loss_ce: 0.0570, decode.acc_seg: 96.9687, aux_0.loss_ce: 0.0583, aux_0.acc_seg: 96.9633, aux_1.loss_ce: 0.0709, aux_1.acc_seg: 96.2660, aux_2.loss_ce: 0.1179, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 95.9801, aux_3.loss_ce: 0.0889, aux_3.acc_seg: 95.5667, loss: 0.6425
2023-05-03 12:17:46,421 - mmseg - INFO - Iter [8950/10000]	lr: 1.317e-02, eta: 0:16:39, time: 0.913, data_time: 0.199, memory: 14777, decode.loss_ce: 0.0547, decode.acc_seg: 97.0433, aux_0.loss_ce: 0.0562, aux_0.acc_seg: 97.0181, aux_1.loss_ce: 0.0690, aux_1.acc_seg: 96.3197, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 96.0181, aux_3.loss_ce: 0.0876, aux_3.acc_seg: 95.5941, loss: 0.6349
2023-05-03 12:18:34,719 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-05-03 12:18:36,185 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 12:18:36,185 - mmseg - INFO - Iter [9000/10000]	lr: 1.260e-02, eta: 0:15:52, time: 0.996, data_time: 0.259, memory: 14777, decode.loss_ce: 0.0546, decode.acc_seg: 97.0540, aux_0.loss_ce: 0.0559, aux_0.acc_seg: 97.0328, aux_1.loss_ce: 0.0687, aux_1.acc_seg: 96.3329, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 96.0048, aux_3.loss_ce: 0.0882, aux_3.acc_seg: 95.5622, loss: 0.6353
2023-05-03 12:18:41,195 - mmseg - INFO - per class results:
2023-05-03 12:18:41,197 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 87.48 | 95.06 |
|   Building  | 93.78 | 95.66 |
|     Car     | 93.82 | 96.28 |
| Column_Pole | 30.71 | 36.64 |
|    Fence    | 83.44 | 93.56 |
|  Pedestrian | 71.71 | 85.12 |
|     Road    | 97.83 | 98.73 |
|   Sidewalk  | 92.86 | 96.43 |
|  SignSymbol |  1.52 |  1.52 |
|     Sky     | 94.27 |  98.1 |
|     Tree    | 92.67 | 97.67 |
+-------------+-------+-------+
2023-05-03 12:18:41,197 - mmseg - INFO - Summary:
2023-05-03 12:18:41,197 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.63 | 76.37 | 81.34 |
+-------+-------+-------+
2023-05-03 12:18:41,197 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 12:18:41,198 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9663, mIoU: 0.7637, mAcc: 0.8134, IoU.Bicyclist: 0.8748, IoU.Building: 0.9378, IoU.Car: 0.9382, IoU.Column_Pole: 0.3071, IoU.Fence: 0.8344, IoU.Pedestrian: 0.7171, IoU.Road: 0.9783, IoU.Sidewalk: 0.9286, IoU.SignSymbol: 0.0152, IoU.Sky: 0.9427, IoU.Tree: 0.9267, Acc.Bicyclist: 0.9506, Acc.Building: 0.9566, Acc.Car: 0.9628, Acc.Column_Pole: 0.3664, Acc.Fence: 0.9356, Acc.Pedestrian: 0.8512, Acc.Road: 0.9873, Acc.Sidewalk: 0.9643, Acc.SignSymbol: 0.0152, Acc.Sky: 0.9810, Acc.Tree: 0.9767
2023-05-03 12:19:28,018 - mmseg - INFO - Iter [9050/10000]	lr: 1.203e-02, eta: 0:15:05, time: 1.036, data_time: 0.313, memory: 14777, decode.loss_ce: 0.0531, decode.acc_seg: 97.1022, aux_0.loss_ce: 0.0546, aux_0.acc_seg: 97.0752, aux_1.loss_ce: 0.0669, aux_1.acc_seg: 96.3821, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2476, aux_2.acc_seg: 96.0501, aux_3.loss_ce: 0.0857, aux_3.acc_seg: 95.6349, loss: 0.6237
2023-05-03 12:20:14,385 - mmseg - INFO - Iter [9100/10000]	lr: 1.146e-02, eta: 0:14:17, time: 0.927, data_time: 0.206, memory: 14777, decode.loss_ce: 0.0540, decode.acc_seg: 97.0678, aux_0.loss_ce: 0.0554, aux_0.acc_seg: 97.0506, aux_1.loss_ce: 0.0677, aux_1.acc_seg: 96.3557, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.0399, aux_3.loss_ce: 0.0867, aux_3.acc_seg: 95.6022, loss: 0.6298
2023-05-03 12:21:01,141 - mmseg - INFO - Iter [9150/10000]	lr: 1.089e-02, eta: 0:13:29, time: 0.935, data_time: 0.211, memory: 14777, decode.loss_ce: 0.0534, decode.acc_seg: 97.0941, aux_0.loss_ce: 0.0549, aux_0.acc_seg: 97.0698, aux_1.loss_ce: 0.0671, aux_1.acc_seg: 96.3815, aux_2.loss_ce: 0.1152, aux_2.loss_dice: 0.2468, aux_2.acc_seg: 96.0854, aux_3.loss_ce: 0.0853, aux_3.acc_seg: 95.6542, loss: 0.6228
2023-05-03 12:21:51,556 - mmseg - INFO - Iter [9200/10000]	lr: 1.031e-02, eta: 0:12:42, time: 1.008, data_time: 0.284, memory: 14777, decode.loss_ce: 0.0539, decode.acc_seg: 97.0844, aux_0.loss_ce: 0.0553, aux_0.acc_seg: 97.0492, aux_1.loss_ce: 0.0676, aux_1.acc_seg: 96.3821, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 96.0596, aux_3.loss_ce: 0.0867, aux_3.acc_seg: 95.6057, loss: 0.6282
2023-05-03 12:22:38,431 - mmseg - INFO - Iter [9250/10000]	lr: 9.730e-03, eta: 0:11:54, time: 0.937, data_time: 0.214, memory: 14777, decode.loss_ce: 0.0554, decode.acc_seg: 96.9574, aux_0.loss_ce: 0.0565, aux_0.acc_seg: 96.9407, aux_1.loss_ce: 0.0691, aux_1.acc_seg: 96.2374, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 95.9742, aux_3.loss_ce: 0.0886, aux_3.acc_seg: 95.4264, loss: 0.6378
2023-05-03 12:23:25,100 - mmseg - INFO - Iter [9300/10000]	lr: 9.145e-03, eta: 0:11:06, time: 0.933, data_time: 0.211, memory: 14777, decode.loss_ce: 0.0534, decode.acc_seg: 97.1457, aux_0.loss_ce: 0.0548, aux_0.acc_seg: 97.1136, aux_1.loss_ce: 0.0671, aux_1.acc_seg: 96.4409, aux_2.loss_ce: 0.1167, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 96.0746, aux_3.loss_ce: 0.0862, aux_3.acc_seg: 95.6969, loss: 0.6290
2023-05-03 12:24:11,494 - mmseg - INFO - Iter [9350/10000]	lr: 8.556e-03, eta: 0:10:19, time: 0.928, data_time: 0.208, memory: 14777, decode.loss_ce: 0.0564, decode.acc_seg: 97.0464, aux_0.loss_ce: 0.0578, aux_0.acc_seg: 97.0247, aux_1.loss_ce: 0.0705, aux_1.acc_seg: 96.3322, aux_2.loss_ce: 0.1192, aux_2.loss_dice: 0.2518, aux_2.acc_seg: 95.9904, aux_3.loss_ce: 0.0907, aux_3.acc_seg: 95.5462, loss: 0.6464
2023-05-03 12:25:00,870 - mmseg - INFO - Iter [9400/10000]	lr: 7.962e-03, eta: 0:09:31, time: 0.987, data_time: 0.273, memory: 14777, decode.loss_ce: 0.0542, decode.acc_seg: 97.1237, aux_0.loss_ce: 0.0555, aux_0.acc_seg: 97.1001, aux_1.loss_ce: 0.0683, aux_1.acc_seg: 96.4097, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.0323, aux_3.loss_ce: 0.0877, aux_3.acc_seg: 95.6404, loss: 0.6335
2023-05-03 12:25:47,680 - mmseg - INFO - Iter [9450/10000]	lr: 7.364e-03, eta: 0:08:43, time: 0.936, data_time: 0.214, memory: 14777, decode.loss_ce: 0.0534, decode.acc_seg: 97.1322, aux_0.loss_ce: 0.0550, aux_0.acc_seg: 97.1047, aux_1.loss_ce: 0.0670, aux_1.acc_seg: 96.4424, aux_2.loss_ce: 0.1157, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.1065, aux_3.loss_ce: 0.0865, aux_3.acc_seg: 95.6600, loss: 0.6267
2023-05-03 12:26:34,145 - mmseg - INFO - Iter [9500/10000]	lr: 6.759e-03, eta: 0:07:56, time: 0.929, data_time: 0.209, memory: 14777, decode.loss_ce: 0.0541, decode.acc_seg: 97.0657, aux_0.loss_ce: 0.0555, aux_0.acc_seg: 97.0420, aux_1.loss_ce: 0.0680, aux_1.acc_seg: 96.3399, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 95.9739, aux_3.loss_ce: 0.0876, aux_3.acc_seg: 95.5562, loss: 0.6340
2023-05-03 12:27:24,116 - mmseg - INFO - Iter [9550/10000]	lr: 6.149e-03, eta: 0:07:08, time: 0.999, data_time: 0.280, memory: 14777, decode.loss_ce: 0.0539, decode.acc_seg: 97.1212, aux_0.loss_ce: 0.0554, aux_0.acc_seg: 97.0937, aux_1.loss_ce: 0.0679, aux_1.acc_seg: 96.4206, aux_2.loss_ce: 0.1192, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 95.9748, aux_3.loss_ce: 0.0882, aux_3.acc_seg: 95.6224, loss: 0.6362
2023-05-03 12:28:10,417 - mmseg - INFO - Iter [9600/10000]	lr: 5.532e-03, eta: 0:06:21, time: 0.926, data_time: 0.207, memory: 14777, decode.loss_ce: 0.0530, decode.acc_seg: 97.1325, aux_0.loss_ce: 0.0548, aux_0.acc_seg: 97.0899, aux_1.loss_ce: 0.0672, aux_1.acc_seg: 96.4157, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 95.9805, aux_3.loss_ce: 0.0872, aux_3.acc_seg: 95.6183, loss: 0.6288
2023-05-03 12:28:56,360 - mmseg - INFO - Iter [9650/10000]	lr: 4.908e-03, eta: 0:05:33, time: 0.919, data_time: 0.203, memory: 14777, decode.loss_ce: 0.0519, decode.acc_seg: 97.1226, aux_0.loss_ce: 0.0533, aux_0.acc_seg: 97.0883, aux_1.loss_ce: 0.0656, aux_1.acc_seg: 96.4042, aux_2.loss_ce: 0.1147, aux_2.loss_dice: 0.2468, aux_2.acc_seg: 96.0994, aux_3.loss_ce: 0.0851, aux_3.acc_seg: 95.6077, loss: 0.6173
2023-05-03 12:29:42,801 - mmseg - INFO - Iter [9700/10000]	lr: 4.274e-03, eta: 0:04:45, time: 0.929, data_time: 0.211, memory: 14777, decode.loss_ce: 0.0519, decode.acc_seg: 97.1338, aux_0.loss_ce: 0.0531, aux_0.acc_seg: 97.1133, aux_1.loss_ce: 0.0653, aux_1.acc_seg: 96.4241, aux_2.loss_ce: 0.1147, aux_2.loss_dice: 0.2473, aux_2.acc_seg: 96.1322, aux_3.loss_ce: 0.0848, aux_3.acc_seg: 95.6129, loss: 0.6171
2023-05-03 12:30:32,273 - mmseg - INFO - Iter [9750/10000]	lr: 3.629e-03, eta: 0:03:58, time: 0.989, data_time: 0.274, memory: 14777, decode.loss_ce: 0.0523, decode.acc_seg: 97.1094, aux_0.loss_ce: 0.0538, aux_0.acc_seg: 97.0726, aux_1.loss_ce: 0.0663, aux_1.acc_seg: 96.3818, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2463, aux_2.acc_seg: 96.0134, aux_3.loss_ce: 0.0858, aux_3.acc_seg: 95.5714, loss: 0.6207
2023-05-03 12:31:19,177 - mmseg - INFO - Iter [9800/10000]	lr: 2.972e-03, eta: 0:03:10, time: 0.938, data_time: 0.212, memory: 14777, decode.loss_ce: 0.0502, decode.acc_seg: 97.2129, aux_0.loss_ce: 0.0518, aux_0.acc_seg: 97.1721, aux_1.loss_ce: 0.0639, aux_1.acc_seg: 96.5002, aux_2.loss_ce: 0.1127, aux_2.loss_dice: 0.2448, aux_2.acc_seg: 96.1560, aux_3.loss_ce: 0.0830, aux_3.acc_seg: 95.7220, loss: 0.6063
2023-05-03 12:32:05,755 - mmseg - INFO - Iter [9850/10000]	lr: 2.298e-03, eta: 0:02:22, time: 0.932, data_time: 0.210, memory: 14777, decode.loss_ce: 0.0531, decode.acc_seg: 97.1210, aux_0.loss_ce: 0.0543, aux_0.acc_seg: 97.1066, aux_1.loss_ce: 0.0673, aux_1.acc_seg: 96.4100, aux_2.loss_ce: 0.1175, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 95.9853, aux_3.loss_ce: 0.0876, aux_3.acc_seg: 95.5811, loss: 0.6291
2023-05-03 12:32:52,066 - mmseg - INFO - Iter [9900/10000]	lr: 1.600e-03, eta: 0:01:35, time: 0.926, data_time: 0.207, memory: 14777, decode.loss_ce: 0.0528, decode.acc_seg: 97.1491, aux_0.loss_ce: 0.0542, aux_0.acc_seg: 97.1258, aux_1.loss_ce: 0.0666, aux_1.acc_seg: 96.4501, aux_2.loss_ce: 0.1152, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.1234, aux_3.loss_ce: 0.0875, aux_3.acc_seg: 95.6077, loss: 0.6252
2023-05-03 12:33:42,154 - mmseg - INFO - Iter [9950/10000]	lr: 8.656e-04, eta: 0:00:47, time: 1.002, data_time: 0.284, memory: 14777, decode.loss_ce: 0.0541, decode.acc_seg: 97.1059, aux_0.loss_ce: 0.0555, aux_0.acc_seg: 97.0877, aux_1.loss_ce: 0.0678, aux_1.acc_seg: 96.4141, aux_2.loss_ce: 0.1157, aux_2.loss_dice: 0.2481, aux_2.acc_seg: 96.0906, aux_3.loss_ce: 0.0879, aux_3.acc_seg: 95.6113, loss: 0.6290
2023-05-03 12:34:28,364 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-05-03 12:34:30,363 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 12:34:30,363 - mmseg - INFO - Iter [10000/10000]	lr: 2.612e-05, eta: 0:00:00, time: 0.965, data_time: 0.209, memory: 14777, decode.loss_ce: 0.0533, decode.acc_seg: 97.1559, aux_0.loss_ce: 0.0547, aux_0.acc_seg: 97.1268, aux_1.loss_ce: 0.0674, aux_1.acc_seg: 96.4446, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 95.9970, aux_3.loss_ce: 0.0881, aux_3.acc_seg: 95.6287, loss: 0.6336
2023-05-03 12:34:36,828 - mmseg - INFO - per class results:
2023-05-03 12:34:36,830 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 87.48 | 94.61 |
|   Building  |  93.6 | 95.35 |
|     Car     |  93.7 | 95.82 |
| Column_Pole | 27.05 | 31.78 |
|    Fence    | 82.93 | 93.83 |
|  Pedestrian | 71.76 | 85.77 |
|     Road    | 97.73 | 98.55 |
|   Sidewalk  | 92.55 | 97.09 |
|  SignSymbol |  3.05 |  3.05 |
|     Sky     | 94.39 | 97.41 |
|     Tree    | 92.38 | 98.08 |
+-------------+-------+-------+
2023-05-03 12:34:36,830 - mmseg - INFO - Summary:
2023-05-03 12:34:36,830 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.53 | 76.06 | 81.03 |
+-------+-------+-------+
2023-05-03 12:34:36,831 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_contextlength16.py
2023-05-03 12:34:36,831 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9653, mIoU: 0.7606, mAcc: 0.8103, IoU.Bicyclist: 0.8748, IoU.Building: 0.9360, IoU.Car: 0.9370, IoU.Column_Pole: 0.2705, IoU.Fence: 0.8293, IoU.Pedestrian: 0.7176, IoU.Road: 0.9773, IoU.Sidewalk: 0.9255, IoU.SignSymbol: 0.0305, IoU.Sky: 0.9439, IoU.Tree: 0.9238, Acc.Bicyclist: 0.9461, Acc.Building: 0.9535, Acc.Car: 0.9582, Acc.Column_Pole: 0.3178, Acc.Fence: 0.9383, Acc.Pedestrian: 0.8577, Acc.Road: 0.9855, Acc.Sidewalk: 0.9709, Acc.SignSymbol: 0.0305, Acc.Sky: 0.9741, Acc.Tree: 0.9808
