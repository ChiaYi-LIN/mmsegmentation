2023-05-01 22:28:28,229 - mmseg - INFO - Multi-processing start method is `None`
2023-05-01 22:28:28,231 - mmseg - INFO - OpenCV num_threads is `96
2023-05-01 22:28:28,292 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+e7ed570
------------------------------------------------------------

2023-05-01 22:28:28,293 - mmseg - INFO - Distributed training: False
2023-05-01 22:28:29,147 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextPathNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1024, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4)),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=520000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=19,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=520000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=19,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=520000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ])
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CityscapesDataset'
data_root = 'data/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        img_scale=(2048, 1024),
        ratio_range=(0.125, 1.5),
        scale_step_size=0.125),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/train',
        ann_dir='gtFine/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize',
                img_scale=(2048, 1024),
                ratio_range=(0.125, 1.5),
                scale_step_size=0.125),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.05,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            {
                'backbone.backbone': dict(lr_mult=0.1),
                'backbone.text_encoder': dict(lr_mult=0.0, decay_mult=0.0),
                '.bn.': dict(decay_mult=0.0)
            })))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/stdc1_1x16_512x1024_scale0.5_160k_cityscapes'
gpu_ids = [0]
auto_resume = False

2023-05-01 22:28:29,147 - mmseg - INFO - Set random seed to 902698081, deterministic: False
2023-05-01 22:28:29,190 - mmseg - INFO - Loaded 2975 images
2023-05-01 22:28:30,337 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-05-01 22:28:30,423 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1024, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([19, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([19]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([19, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([19]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-05-01 22:28:30,427 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextPathNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-05-01 22:28:36,639 - mmseg - INFO - Loaded 500 images
2023-05-01 22:28:36,640 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1_1x16_512x1024_scale0.5_160k_cityscapes
2023-05-01 22:28:36,640 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-05-01 22:28:36,640 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-05-01 22:28:36,640 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1_1x16_512x1024_scale0.5_160k_cityscapes by HardDiskBackend.
2023-05-01 22:29:29,756 - mmseg - INFO - Iter [50/160000]	lr: 2.450e-04, eta: 1 day, 22:57:27, time: 1.057, data_time: 0.282, memory: 17140, decode.loss_ce: 1.9031, decode.acc_seg: 34.3085, aux_0.loss_ce: 2.2248, aux_0.acc_seg: 13.9671, aux_1.loss_ce: 2.1026, aux_1.acc_seg: 23.1394, aux_2.loss_ce: 0.5506, aux_2.loss_dice: 0.5056, aux_2.acc_seg: 78.9199, loss: 7.2866
2023-05-01 22:30:02,819 - mmseg - INFO - Iter [100/160000]	lr: 4.948e-04, eta: 1 day, 14:09:24, time: 0.661, data_time: 0.294, memory: 17140, decode.loss_ce: 1.2803, decode.acc_seg: 53.2493, aux_0.loss_ce: 1.3800, aux_0.acc_seg: 53.0692, aux_1.loss_ce: 1.4349, aux_1.acc_seg: 49.1388, aux_2.loss_ce: 0.2360, aux_2.loss_dice: 0.4798, aux_2.acc_seg: 96.8940, loss: 4.8109
2023-05-01 22:30:36,455 - mmseg - INFO - Iter [150/160000]	lr: 7.444e-04, eta: 1 day, 11:23:09, time: 0.673, data_time: 0.303, memory: 17140, decode.loss_ce: 0.9384, decode.acc_seg: 66.5470, aux_0.loss_ce: 0.9173, aux_0.acc_seg: 68.4035, aux_1.loss_ce: 0.9978, aux_1.acc_seg: 64.6938, aux_2.loss_ce: 0.1662, aux_2.loss_dice: 0.4769, aux_2.acc_seg: 96.9065, loss: 3.4967
2023-05-01 22:31:12,078 - mmseg - INFO - Iter [200/160000]	lr: 9.939e-04, eta: 1 day, 10:26:15, time: 0.712, data_time: 0.333, memory: 17140, decode.loss_ce: 0.7027, decode.acc_seg: 74.9770, aux_0.loss_ce: 0.7205, aux_0.acc_seg: 74.4189, aux_1.loss_ce: 0.7802, aux_1.acc_seg: 72.3976, aux_2.loss_ce: 0.1525, aux_2.loss_dice: 0.3908, aux_2.acc_seg: 96.9599, loss: 2.7467
2023-05-01 22:31:38,708 - mmseg - INFO - Iter [250/160000]	lr: 1.243e-03, eta: 1 day, 8:16:05, time: 0.533, data_time: 0.147, memory: 17140, decode.loss_ce: 0.5929, decode.acc_seg: 77.9693, aux_0.loss_ce: 0.6091, aux_0.acc_seg: 77.8780, aux_1.loss_ce: 0.6621, aux_1.acc_seg: 76.2159, aux_2.loss_ce: 0.1311, aux_2.loss_dice: 0.3343, aux_2.acc_seg: 97.0178, loss: 2.3296
2023-05-01 22:32:05,707 - mmseg - INFO - Iter [300/160000]	lr: 1.493e-03, eta: 1 day, 6:52:26, time: 0.540, data_time: 0.147, memory: 17140, decode.loss_ce: 0.5492, decode.acc_seg: 79.2289, aux_0.loss_ce: 0.5644, aux_0.acc_seg: 79.1887, aux_1.loss_ce: 0.6065, aux_1.acc_seg: 77.6501, aux_2.loss_ce: 0.1171, aux_2.loss_dice: 0.3147, aux_2.acc_seg: 97.0963, loss: 2.1520
2023-05-01 22:32:32,335 - mmseg - INFO - Iter [350/160000]	lr: 1.742e-03, eta: 1 day, 5:49:44, time: 0.533, data_time: 0.137, memory: 17140, decode.loss_ce: 0.5238, decode.acc_seg: 80.7309, aux_0.loss_ce: 0.5401, aux_0.acc_seg: 80.5704, aux_1.loss_ce: 0.5762, aux_1.acc_seg: 79.2276, aux_2.loss_ce: 0.1123, aux_2.loss_dice: 0.3072, aux_2.acc_seg: 97.0990, loss: 2.0596
2023-05-01 22:33:03,138 - mmseg - INFO - Iter [400/160000]	lr: 1.991e-03, eta: 1 day, 5:30:21, time: 0.616, data_time: 0.235, memory: 17140, decode.loss_ce: 0.4651, decode.acc_seg: 82.6980, aux_0.loss_ce: 0.4815, aux_0.acc_seg: 82.3325, aux_1.loss_ce: 0.5129, aux_1.acc_seg: 81.1251, aux_2.loss_ce: 0.1089, aux_2.loss_dice: 0.3028, aux_2.acc_seg: 97.1322, loss: 1.8711
2023-05-01 22:33:30,055 - mmseg - INFO - Iter [450/160000]	lr: 2.239e-03, eta: 1 day, 4:52:13, time: 0.538, data_time: 0.153, memory: 17140, decode.loss_ce: 0.4187, decode.acc_seg: 84.0196, aux_0.loss_ce: 0.4344, aux_0.acc_seg: 83.6519, aux_1.loss_ce: 0.4667, aux_1.acc_seg: 82.3511, aux_2.loss_ce: 0.1074, aux_2.loss_dice: 0.2971, aux_2.acc_seg: 97.2057, loss: 1.7243
2023-05-01 22:33:57,750 - mmseg - INFO - Iter [500/160000]	lr: 2.488e-03, eta: 1 day, 4:25:45, time: 0.554, data_time: 0.168, memory: 17140, decode.loss_ce: 0.4278, decode.acc_seg: 83.8639, aux_0.loss_ce: 0.4457, aux_0.acc_seg: 83.4402, aux_1.loss_ce: 0.4766, aux_1.acc_seg: 82.1947, aux_2.loss_ce: 0.1084, aux_2.loss_dice: 0.2976, aux_2.acc_seg: 97.1260, loss: 1.7561
2023-05-01 22:34:23,079 - mmseg - INFO - Iter [550/160000]	lr: 2.737e-03, eta: 1 day, 3:52:34, time: 0.507, data_time: 0.124, memory: 17140, decode.loss_ce: 0.3991, decode.acc_seg: 84.8005, aux_0.loss_ce: 0.4126, aux_0.acc_seg: 84.3558, aux_1.loss_ce: 0.4452, aux_1.acc_seg: 83.1308, aux_2.loss_ce: 0.1068, aux_2.loss_dice: 0.2923, aux_2.acc_seg: 97.1812, loss: 1.6560
2023-05-01 22:34:52,570 - mmseg - INFO - Iter [600/160000]	lr: 2.985e-03, eta: 1 day, 3:43:17, time: 0.590, data_time: 0.204, memory: 17140, decode.loss_ce: 0.3966, decode.acc_seg: 84.0481, aux_0.loss_ce: 0.4093, aux_0.acc_seg: 83.7127, aux_1.loss_ce: 0.4367, aux_1.acc_seg: 82.6160, aux_2.loss_ce: 0.1028, aux_2.loss_dice: 0.2859, aux_2.acc_seg: 97.2637, loss: 1.6313
2023-05-01 22:35:19,577 - mmseg - INFO - Iter [650/160000]	lr: 3.233e-03, eta: 1 day, 3:25:12, time: 0.540, data_time: 0.150, memory: 17140, decode.loss_ce: 0.3694, decode.acc_seg: 85.9633, aux_0.loss_ce: 0.3777, aux_0.acc_seg: 85.7716, aux_1.loss_ce: 0.4123, aux_1.acc_seg: 84.4976, aux_2.loss_ce: 0.1057, aux_2.loss_dice: 0.2882, aux_2.acc_seg: 97.1957, loss: 1.5533
2023-05-01 22:35:46,828 - mmseg - INFO - Iter [700/160000]	lr: 3.481e-03, eta: 1 day, 3:10:34, time: 0.545, data_time: 0.146, memory: 17140, decode.loss_ce: 0.3911, decode.acc_seg: 84.9194, aux_0.loss_ce: 0.4006, aux_0.acc_seg: 84.7143, aux_1.loss_ce: 0.4290, aux_1.acc_seg: 83.4782, aux_2.loss_ce: 0.1063, aux_2.loss_dice: 0.2879, aux_2.acc_seg: 97.1905, loss: 1.6148
2023-05-01 22:36:17,149 - mmseg - INFO - Iter [750/160000]	lr: 3.729e-03, eta: 1 day, 3:08:41, time: 0.606, data_time: 0.210, memory: 17140, decode.loss_ce: 0.3466, decode.acc_seg: 86.0752, aux_0.loss_ce: 0.3597, aux_0.acc_seg: 85.7091, aux_1.loss_ce: 0.3863, aux_1.acc_seg: 84.4972, aux_2.loss_ce: 0.1059, aux_2.loss_dice: 0.2830, aux_2.acc_seg: 97.1863, loss: 1.4814
2023-05-01 22:36:44,147 - mmseg - INFO - Iter [800/160000]	lr: 3.977e-03, eta: 1 day, 2:55:57, time: 0.540, data_time: 0.147, memory: 17140, decode.loss_ce: 0.3458, decode.acc_seg: 86.1904, aux_0.loss_ce: 0.3558, aux_0.acc_seg: 85.8729, aux_1.loss_ce: 0.3859, aux_1.acc_seg: 84.6027, aux_2.loss_ce: 0.1070, aux_2.loss_dice: 0.2845, aux_2.acc_seg: 97.1618, loss: 1.4790
2023-05-01 22:37:11,574 - mmseg - INFO - Iter [850/160000]	lr: 4.225e-03, eta: 1 day, 2:46:00, time: 0.549, data_time: 0.154, memory: 17140, decode.loss_ce: 0.3255, decode.acc_seg: 86.9746, aux_0.loss_ce: 0.3347, aux_0.acc_seg: 86.7156, aux_1.loss_ce: 0.3627, aux_1.acc_seg: 85.4655, aux_2.loss_ce: 0.1035, aux_2.loss_dice: 0.2804, aux_2.acc_seg: 97.2517, loss: 1.4068
2023-05-01 22:37:38,661 - mmseg - INFO - Iter [900/160000]	lr: 4.472e-03, eta: 1 day, 2:36:06, time: 0.542, data_time: 0.150, memory: 17140, decode.loss_ce: 0.3224, decode.acc_seg: 87.2822, aux_0.loss_ce: 0.3358, aux_0.acc_seg: 86.7827, aux_1.loss_ce: 0.3631, aux_1.acc_seg: 85.6433, aux_2.loss_ce: 0.1051, aux_2.loss_dice: 0.2812, aux_2.acc_seg: 97.2047, loss: 1.4075
2023-05-01 22:38:09,369 - mmseg - INFO - Iter [950/160000]	lr: 4.720e-03, eta: 1 day, 2:37:19, time: 0.614, data_time: 0.217, memory: 17140, decode.loss_ce: 0.3429, decode.acc_seg: 86.1169, aux_0.loss_ce: 0.3491, aux_0.acc_seg: 85.7288, aux_1.loss_ce: 0.3742, aux_1.acc_seg: 84.7416, aux_2.loss_ce: 0.1040, aux_2.loss_dice: 0.2770, aux_2.acc_seg: 97.2404, loss: 1.4472
2023-05-01 22:38:36,180 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 22:38:36,180 - mmseg - INFO - Iter [1000/160000]	lr: 4.967e-03, eta: 1 day, 2:28:01, time: 0.536, data_time: 0.140, memory: 17140, decode.loss_ce: 0.3346, decode.acc_seg: 86.7597, aux_0.loss_ce: 0.3404, aux_0.acc_seg: 86.5924, aux_1.loss_ce: 0.3635, aux_1.acc_seg: 85.5795, aux_2.loss_ce: 0.1051, aux_2.loss_dice: 0.2791, aux_2.acc_seg: 97.2174, loss: 1.4228
2023-05-01 22:39:03,590 - mmseg - INFO - Iter [1050/160000]	lr: 4.970e-03, eta: 1 day, 2:21:05, time: 0.548, data_time: 0.149, memory: 17140, decode.loss_ce: 0.3087, decode.acc_seg: 87.5923, aux_0.loss_ce: 0.3178, aux_0.acc_seg: 87.2841, aux_1.loss_ce: 0.3452, aux_1.acc_seg: 86.1334, aux_2.loss_ce: 0.1047, aux_2.loss_dice: 0.2777, aux_2.acc_seg: 97.2211, loss: 1.3542
2023-05-01 22:39:30,620 - mmseg - INFO - Iter [1100/160000]	lr: 4.969e-03, eta: 1 day, 2:13:49, time: 0.541, data_time: 0.155, memory: 17140, decode.loss_ce: 0.2758, decode.acc_seg: 88.5749, aux_0.loss_ce: 0.2838, aux_0.acc_seg: 88.2351, aux_1.loss_ce: 0.3115, aux_1.acc_seg: 86.9936, aux_2.loss_ce: 0.1033, aux_2.loss_dice: 0.2745, aux_2.acc_seg: 97.2631, loss: 1.2489
2023-05-01 22:40:03,088 - mmseg - INFO - Iter [1150/160000]	lr: 4.968e-03, eta: 1 day, 2:19:39, time: 0.649, data_time: 0.255, memory: 17140, decode.loss_ce: 0.2796, decode.acc_seg: 88.0155, aux_0.loss_ce: 0.2856, aux_0.acc_seg: 87.8441, aux_1.loss_ce: 0.3106, aux_1.acc_seg: 86.7121, aux_2.loss_ce: 0.1017, aux_2.loss_dice: 0.2695, aux_2.acc_seg: 97.2972, loss: 1.2470
2023-05-01 22:40:27,990 - mmseg - INFO - Iter [1200/160000]	lr: 4.966e-03, eta: 1 day, 2:08:17, time: 0.498, data_time: 0.103, memory: 17140, decode.loss_ce: 0.2979, decode.acc_seg: 87.9756, aux_0.loss_ce: 0.3056, aux_0.acc_seg: 87.6032, aux_1.loss_ce: 0.3271, aux_1.acc_seg: 86.5733, aux_2.loss_ce: 0.1013, aux_2.loss_dice: 0.2722, aux_2.acc_seg: 97.3106, loss: 1.3042
2023-05-01 22:40:53,802 - mmseg - INFO - Iter [1250/160000]	lr: 4.965e-03, eta: 1 day, 1:59:42, time: 0.516, data_time: 0.122, memory: 17140, decode.loss_ce: 0.3000, decode.acc_seg: 87.8935, aux_0.loss_ce: 0.3101, aux_0.acc_seg: 87.5362, aux_1.loss_ce: 0.3338, aux_1.acc_seg: 86.5331, aux_2.loss_ce: 0.1048, aux_2.loss_dice: 0.2754, aux_2.acc_seg: 97.2256, loss: 1.3241
2023-05-01 22:41:24,431 - mmseg - INFO - Iter [1300/160000]	lr: 4.963e-03, eta: 1 day, 2:01:34, time: 0.613, data_time: 0.217, memory: 17140, decode.loss_ce: 0.2844, decode.acc_seg: 88.3649, aux_0.loss_ce: 0.2925, aux_0.acc_seg: 88.1790, aux_1.loss_ce: 0.3226, aux_1.acc_seg: 86.8404, aux_2.loss_ce: 0.1042, aux_2.loss_dice: 0.2722, aux_2.acc_seg: 97.2105, loss: 1.2759
2023-05-01 22:41:50,964 - mmseg - INFO - Iter [1350/160000]	lr: 4.962e-03, eta: 1 day, 1:55:13, time: 0.531, data_time: 0.136, memory: 17140, decode.loss_ce: 0.2866, decode.acc_seg: 88.3053, aux_0.loss_ce: 0.2941, aux_0.acc_seg: 88.0311, aux_1.loss_ce: 0.3183, aux_1.acc_seg: 86.8783, aux_2.loss_ce: 0.1026, aux_2.loss_dice: 0.2712, aux_2.acc_seg: 97.2643, loss: 1.2729
2023-05-01 22:42:18,365 - mmseg - INFO - Iter [1400/160000]	lr: 4.961e-03, eta: 1 day, 1:50:56, time: 0.548, data_time: 0.153, memory: 17140, decode.loss_ce: 0.2716, decode.acc_seg: 88.8029, aux_0.loss_ce: 0.2788, aux_0.acc_seg: 88.5036, aux_1.loss_ce: 0.3046, aux_1.acc_seg: 87.2957, aux_2.loss_ce: 0.1008, aux_2.loss_dice: 0.2681, aux_2.acc_seg: 97.2759, loss: 1.2239
2023-05-01 22:42:45,777 - mmseg - INFO - Iter [1450/160000]	lr: 4.959e-03, eta: 1 day, 1:46:56, time: 0.548, data_time: 0.157, memory: 17140, decode.loss_ce: 0.2738, decode.acc_seg: 88.5914, aux_0.loss_ce: 0.2806, aux_0.acc_seg: 88.2753, aux_1.loss_ce: 0.3055, aux_1.acc_seg: 87.2835, aux_2.loss_ce: 0.1013, aux_2.loss_dice: 0.2683, aux_2.acc_seg: 97.2857, loss: 1.2295
2023-05-01 22:43:16,028 - mmseg - INFO - Iter [1500/160000]	lr: 4.958e-03, eta: 1 day, 1:48:11, time: 0.605, data_time: 0.215, memory: 17140, decode.loss_ce: 0.2756, decode.acc_seg: 88.6401, aux_0.loss_ce: 0.2825, aux_0.acc_seg: 88.3815, aux_1.loss_ce: 0.3065, aux_1.acc_seg: 87.3342, aux_2.loss_ce: 0.1052, aux_2.loss_dice: 0.2726, aux_2.acc_seg: 97.1949, loss: 1.2424
2023-05-01 22:43:42,340 - mmseg - INFO - Iter [1550/160000]	lr: 4.956e-03, eta: 1 day, 1:42:36, time: 0.526, data_time: 0.134, memory: 17140, decode.loss_ce: 0.2659, decode.acc_seg: 88.9228, aux_0.loss_ce: 0.2727, aux_0.acc_seg: 88.6877, aux_1.loss_ce: 0.2977, aux_1.acc_seg: 87.3924, aux_2.loss_ce: 0.1032, aux_2.loss_dice: 0.2681, aux_2.acc_seg: 97.2319, loss: 1.2077
2023-05-01 22:44:08,797 - mmseg - INFO - Iter [1600/160000]	lr: 4.955e-03, eta: 1 day, 1:37:35, time: 0.529, data_time: 0.135, memory: 17140, decode.loss_ce: 0.2625, decode.acc_seg: 89.1879, aux_0.loss_ce: 0.2692, aux_0.acc_seg: 88.8781, aux_1.loss_ce: 0.2943, aux_1.acc_seg: 87.8124, aux_2.loss_ce: 0.1009, aux_2.loss_dice: 0.2683, aux_2.acc_seg: 97.2850, loss: 1.1952
2023-05-01 22:44:35,122 - mmseg - INFO - Iter [1650/160000]	lr: 4.954e-03, eta: 1 day, 1:32:37, time: 0.526, data_time: 0.131, memory: 17140, decode.loss_ce: 0.2667, decode.acc_seg: 89.2389, aux_0.loss_ce: 0.2763, aux_0.acc_seg: 88.9274, aux_1.loss_ce: 0.3028, aux_1.acc_seg: 87.7335, aux_2.loss_ce: 0.1033, aux_2.loss_dice: 0.2702, aux_2.acc_seg: 97.2002, loss: 1.2192
2023-05-01 22:45:05,520 - mmseg - INFO - Iter [1700/160000]	lr: 4.952e-03, eta: 1 day, 1:34:14, time: 0.608, data_time: 0.211, memory: 17140, decode.loss_ce: 0.2553, decode.acc_seg: 89.7030, aux_0.loss_ce: 0.2626, aux_0.acc_seg: 89.4599, aux_1.loss_ce: 0.2871, aux_1.acc_seg: 88.3955, aux_2.loss_ce: 0.1026, aux_2.loss_dice: 0.2691, aux_2.acc_seg: 97.2325, loss: 1.1767
2023-05-01 22:45:32,306 - mmseg - INFO - Iter [1750/160000]	lr: 4.951e-03, eta: 1 day, 1:30:18, time: 0.536, data_time: 0.141, memory: 17140, decode.loss_ce: 0.2455, decode.acc_seg: 89.5803, aux_0.loss_ce: 0.2525, aux_0.acc_seg: 89.2943, aux_1.loss_ce: 0.2785, aux_1.acc_seg: 88.2110, aux_2.loss_ce: 0.1011, aux_2.loss_dice: 0.2655, aux_2.acc_seg: 97.2534, loss: 1.1431
2023-05-01 22:45:59,215 - mmseg - INFO - Iter [1800/160000]	lr: 4.949e-03, eta: 1 day, 1:26:44, time: 0.538, data_time: 0.143, memory: 17140, decode.loss_ce: 0.2462, decode.acc_seg: 89.6478, aux_0.loss_ce: 0.2572, aux_0.acc_seg: 89.3370, aux_1.loss_ce: 0.2808, aux_1.acc_seg: 88.1667, aux_2.loss_ce: 0.1035, aux_2.loss_dice: 0.2696, aux_2.acc_seg: 97.1748, loss: 1.1573
2023-05-01 22:46:24,195 - mmseg - INFO - Iter [1850/160000]	lr: 4.948e-03, eta: 1 day, 1:20:36, time: 0.500, data_time: 0.106, memory: 17140, decode.loss_ce: 0.2422, decode.acc_seg: 89.7669, aux_0.loss_ce: 0.2483, aux_0.acc_seg: 89.5852, aux_1.loss_ce: 0.2750, aux_1.acc_seg: 88.4378, aux_2.loss_ce: 0.1006, aux_2.loss_dice: 0.2664, aux_2.acc_seg: 97.2733, loss: 1.1324
2023-05-01 22:46:55,353 - mmseg - INFO - Iter [1900/160000]	lr: 4.947e-03, eta: 1 day, 1:23:19, time: 0.623, data_time: 0.227, memory: 17140, decode.loss_ce: 0.2400, decode.acc_seg: 90.1431, aux_0.loss_ce: 0.2487, aux_0.acc_seg: 89.8012, aux_1.loss_ce: 0.2729, aux_1.acc_seg: 88.6878, aux_2.loss_ce: 0.1012, aux_2.loss_dice: 0.2681, aux_2.acc_seg: 97.2364, loss: 1.1309
2023-05-01 22:47:21,777 - mmseg - INFO - Iter [1950/160000]	lr: 4.945e-03, eta: 1 day, 1:19:29, time: 0.528, data_time: 0.134, memory: 17140, decode.loss_ce: 0.2301, decode.acc_seg: 90.1397, aux_0.loss_ce: 0.2380, aux_0.acc_seg: 89.8459, aux_1.loss_ce: 0.2629, aux_1.acc_seg: 88.7190, aux_2.loss_ce: 0.1005, aux_2.loss_dice: 0.2652, aux_2.acc_seg: 97.2682, loss: 1.0967
2023-05-01 22:47:48,496 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 22:47:48,496 - mmseg - INFO - Iter [2000/160000]	lr: 4.944e-03, eta: 1 day, 1:16:13, time: 0.535, data_time: 0.138, memory: 17140, decode.loss_ce: 0.2456, decode.acc_seg: 89.7062, aux_0.loss_ce: 0.2471, aux_0.acc_seg: 89.6750, aux_1.loss_ce: 0.2769, aux_1.acc_seg: 88.2951, aux_2.loss_ce: 0.1004, aux_2.loss_dice: 0.2659, aux_2.acc_seg: 97.2686, loss: 1.1359
2023-05-01 22:48:19,475 - mmseg - INFO - Iter [2050/160000]	lr: 4.942e-03, eta: 1 day, 1:18:33, time: 0.620, data_time: 0.229, memory: 17140, decode.loss_ce: 0.2274, decode.acc_seg: 90.3430, aux_0.loss_ce: 0.2358, aux_0.acc_seg: 90.0391, aux_1.loss_ce: 0.2595, aux_1.acc_seg: 88.9524, aux_2.loss_ce: 0.0980, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 97.3419, loss: 1.0823
2023-05-01 22:48:45,843 - mmseg - INFO - Iter [2100/160000]	lr: 4.941e-03, eta: 1 day, 1:14:58, time: 0.527, data_time: 0.133, memory: 17140, decode.loss_ce: 0.2409, decode.acc_seg: 89.5485, aux_0.loss_ce: 0.2460, aux_0.acc_seg: 89.4136, aux_1.loss_ce: 0.2718, aux_1.acc_seg: 88.2325, aux_2.loss_ce: 0.0984, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 97.3176, loss: 1.1187
2023-05-01 22:49:12,726 - mmseg - INFO - Iter [2150/160000]	lr: 4.940e-03, eta: 1 day, 1:12:09, time: 0.538, data_time: 0.142, memory: 17140, decode.loss_ce: 0.2376, decode.acc_seg: 89.9922, aux_0.loss_ce: 0.2442, aux_0.acc_seg: 89.7476, aux_1.loss_ce: 0.2688, aux_1.acc_seg: 88.6562, aux_2.loss_ce: 0.0997, aux_2.loss_dice: 0.2650, aux_2.acc_seg: 97.2901, loss: 1.1153
2023-05-01 22:49:39,350 - mmseg - INFO - Iter [2200/160000]	lr: 4.938e-03, eta: 1 day, 1:09:09, time: 0.532, data_time: 0.138, memory: 17140, decode.loss_ce: 0.2300, decode.acc_seg: 90.2472, aux_0.loss_ce: 0.2360, aux_0.acc_seg: 90.0101, aux_1.loss_ce: 0.2621, aux_1.acc_seg: 88.9105, aux_2.loss_ce: 0.0989, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 97.3236, loss: 1.0891
2023-05-01 22:50:10,763 - mmseg - INFO - Iter [2250/160000]	lr: 4.937e-03, eta: 1 day, 1:11:51, time: 0.628, data_time: 0.233, memory: 17140, decode.loss_ce: 0.2175, decode.acc_seg: 90.6762, aux_0.loss_ce: 0.2269, aux_0.acc_seg: 90.3315, aux_1.loss_ce: 0.2516, aux_1.acc_seg: 89.2338, aux_2.loss_ce: 0.0995, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 97.2992, loss: 1.0581
2023-05-01 22:50:38,037 - mmseg - INFO - Iter [2300/160000]	lr: 4.935e-03, eta: 1 day, 1:09:41, time: 0.545, data_time: 0.144, memory: 17140, decode.loss_ce: 0.2381, decode.acc_seg: 90.2945, aux_0.loss_ce: 0.2470, aux_0.acc_seg: 90.0107, aux_1.loss_ce: 0.2711, aux_1.acc_seg: 88.9436, aux_2.loss_ce: 0.1021, aux_2.loss_dice: 0.2662, aux_2.acc_seg: 97.1988, loss: 1.1245
2023-05-01 22:51:05,332 - mmseg - INFO - Iter [2350/160000]	lr: 4.934e-03, eta: 1 day, 1:07:36, time: 0.546, data_time: 0.142, memory: 17140, decode.loss_ce: 0.2331, decode.acc_seg: 90.1422, aux_0.loss_ce: 0.2380, aux_0.acc_seg: 89.9008, aux_1.loss_ce: 0.2637, aux_1.acc_seg: 88.9138, aux_2.loss_ce: 0.0983, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 97.3419, loss: 1.0939
2023-05-01 22:51:31,657 - mmseg - INFO - Iter [2400/160000]	lr: 4.932e-03, eta: 1 day, 1:04:32, time: 0.526, data_time: 0.134, memory: 17140, decode.loss_ce: 0.2038, decode.acc_seg: 91.2279, aux_0.loss_ce: 0.2128, aux_0.acc_seg: 90.9050, aux_1.loss_ce: 0.2376, aux_1.acc_seg: 89.7465, aux_2.loss_ce: 0.0990, aux_2.loss_dice: 0.2600, aux_2.acc_seg: 97.2930, loss: 1.0133
2023-05-01 22:52:01,943 - mmseg - INFO - Iter [2450/160000]	lr: 4.931e-03, eta: 1 day, 1:05:50, time: 0.606, data_time: 0.215, memory: 17140, decode.loss_ce: 0.2223, decode.acc_seg: 90.5900, aux_0.loss_ce: 0.2295, aux_0.acc_seg: 90.3456, aux_1.loss_ce: 0.2550, aux_1.acc_seg: 89.1583, aux_2.loss_ce: 0.0975, aux_2.loss_dice: 0.2598, aux_2.acc_seg: 97.3366, loss: 1.0640
2023-05-01 22:52:27,159 - mmseg - INFO - Iter [2500/160000]	lr: 4.930e-03, eta: 1 day, 1:01:43, time: 0.504, data_time: 0.119, memory: 17140, decode.loss_ce: 0.2221, decode.acc_seg: 90.3219, aux_0.loss_ce: 0.2277, aux_0.acc_seg: 90.1540, aux_1.loss_ce: 0.2521, aux_1.acc_seg: 88.9495, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2576, aux_2.acc_seg: 97.3186, loss: 1.0564
2023-05-01 22:52:54,226 - mmseg - INFO - Iter [2550/160000]	lr: 4.928e-03, eta: 1 day, 0:59:39, time: 0.541, data_time: 0.152, memory: 17140, decode.loss_ce: 0.2242, decode.acc_seg: 90.3434, aux_0.loss_ce: 0.2317, aux_0.acc_seg: 90.0701, aux_1.loss_ce: 0.2574, aux_1.acc_seg: 88.9462, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2631, aux_2.acc_seg: 97.2566, loss: 1.0761
2023-05-01 22:53:25,284 - mmseg - INFO - Iter [2600/160000]	lr: 4.927e-03, eta: 1 day, 1:01:41, time: 0.621, data_time: 0.223, memory: 17140, decode.loss_ce: 0.2151, decode.acc_seg: 90.7681, aux_0.loss_ce: 0.2214, aux_0.acc_seg: 90.5634, aux_1.loss_ce: 0.2464, aux_1.acc_seg: 89.3694, aux_2.loss_ce: 0.0986, aux_2.loss_dice: 0.2608, aux_2.acc_seg: 97.3070, loss: 1.0423
2023-05-01 22:53:52,300 - mmseg - INFO - Iter [2650/160000]	lr: 4.925e-03, eta: 1 day, 0:59:37, time: 0.540, data_time: 0.142, memory: 17140, decode.loss_ce: 0.2135, decode.acc_seg: 90.9668, aux_0.loss_ce: 0.2214, aux_0.acc_seg: 90.6773, aux_1.loss_ce: 0.2454, aux_1.acc_seg: 89.5310, aux_2.loss_ce: 0.1008, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 97.2198, loss: 1.0430
2023-05-01 22:54:18,976 - mmseg - INFO - Iter [2700/160000]	lr: 4.924e-03, eta: 1 day, 0:57:17, time: 0.533, data_time: 0.142, memory: 17140, decode.loss_ce: 0.2022, decode.acc_seg: 91.2215, aux_0.loss_ce: 0.2106, aux_0.acc_seg: 90.9088, aux_1.loss_ce: 0.2344, aux_1.acc_seg: 89.7882, aux_2.loss_ce: 0.0983, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 97.3033, loss: 1.0058
2023-05-01 22:54:45,407 - mmseg - INFO - Iter [2750/160000]	lr: 4.923e-03, eta: 1 day, 0:54:47, time: 0.529, data_time: 0.138, memory: 17140, decode.loss_ce: 0.2259, decode.acc_seg: 90.4090, aux_0.loss_ce: 0.2311, aux_0.acc_seg: 90.2925, aux_1.loss_ce: 0.2563, aux_1.acc_seg: 89.1434, aux_2.loss_ce: 0.0985, aux_2.loss_dice: 0.2622, aux_2.acc_seg: 97.3171, loss: 1.0741
2023-05-01 22:55:15,084 - mmseg - INFO - Iter [2800/160000]	lr: 4.921e-03, eta: 1 day, 0:55:24, time: 0.594, data_time: 0.206, memory: 17140, decode.loss_ce: 0.2173, decode.acc_seg: 90.7653, aux_0.loss_ce: 0.2255, aux_0.acc_seg: 90.5208, aux_1.loss_ce: 0.2498, aux_1.acc_seg: 89.3984, aux_2.loss_ce: 0.0991, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 97.2590, loss: 1.0537
2023-05-01 22:55:41,265 - mmseg - INFO - Iter [2850/160000]	lr: 4.920e-03, eta: 1 day, 0:52:45, time: 0.524, data_time: 0.137, memory: 17140, decode.loss_ce: 0.2125, decode.acc_seg: 91.0769, aux_0.loss_ce: 0.2197, aux_0.acc_seg: 90.8064, aux_1.loss_ce: 0.2437, aux_1.acc_seg: 89.7454, aux_2.loss_ce: 0.0990, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 97.3029, loss: 1.0365
2023-05-01 22:56:08,596 - mmseg - INFO - Iter [2900/160000]	lr: 4.918e-03, eta: 1 day, 0:51:13, time: 0.547, data_time: 0.159, memory: 17140, decode.loss_ce: 0.2312, decode.acc_seg: 90.0653, aux_0.loss_ce: 0.2384, aux_0.acc_seg: 89.7759, aux_1.loss_ce: 0.2638, aux_1.acc_seg: 88.6407, aux_2.loss_ce: 0.0969, aux_2.loss_dice: 0.2576, aux_2.acc_seg: 97.3582, loss: 1.0878
2023-05-01 22:56:34,947 - mmseg - INFO - Iter [2950/160000]	lr: 4.917e-03, eta: 1 day, 0:48:52, time: 0.527, data_time: 0.126, memory: 17140, decode.loss_ce: 0.2180, decode.acc_seg: 90.8561, aux_0.loss_ce: 0.2269, aux_0.acc_seg: 90.5729, aux_1.loss_ce: 0.2508, aux_1.acc_seg: 89.5509, aux_2.loss_ce: 0.1005, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 97.2092, loss: 1.0587
2023-05-01 22:57:05,911 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 22:57:05,911 - mmseg - INFO - Iter [3000/160000]	lr: 4.916e-03, eta: 1 day, 0:50:35, time: 0.619, data_time: 0.226, memory: 17140, decode.loss_ce: 0.2153, decode.acc_seg: 90.9448, aux_0.loss_ce: 0.2237, aux_0.acc_seg: 90.6843, aux_1.loss_ce: 0.2466, aux_1.acc_seg: 89.5507, aux_2.loss_ce: 0.1010, aux_2.loss_dice: 0.2625, aux_2.acc_seg: 97.2170, loss: 1.0490
2023-05-01 22:57:34,053 - mmseg - INFO - Iter [3050/160000]	lr: 4.914e-03, eta: 1 day, 0:49:49, time: 0.563, data_time: 0.165, memory: 17140, decode.loss_ce: 0.2015, decode.acc_seg: 91.4030, aux_0.loss_ce: 0.2085, aux_0.acc_seg: 91.1688, aux_1.loss_ce: 0.2318, aux_1.acc_seg: 90.1228, aux_2.loss_ce: 0.0978, aux_2.loss_dice: 0.2584, aux_2.acc_seg: 97.3109, loss: 0.9980
2023-05-01 22:58:01,382 - mmseg - INFO - Iter [3100/160000]	lr: 4.913e-03, eta: 1 day, 0:48:23, time: 0.547, data_time: 0.149, memory: 17140, decode.loss_ce: 0.2111, decode.acc_seg: 91.1147, aux_0.loss_ce: 0.2181, aux_0.acc_seg: 90.8934, aux_1.loss_ce: 0.2430, aux_1.acc_seg: 89.7438, aux_2.loss_ce: 0.0983, aux_2.loss_dice: 0.2581, aux_2.acc_seg: 97.2798, loss: 1.0287
2023-05-01 22:58:30,903 - mmseg - INFO - Iter [3150/160000]	lr: 4.911e-03, eta: 1 day, 0:48:47, time: 0.590, data_time: 0.196, memory: 17140, decode.loss_ce: 0.2177, decode.acc_seg: 91.0072, aux_0.loss_ce: 0.2231, aux_0.acc_seg: 90.8120, aux_1.loss_ce: 0.2495, aux_1.acc_seg: 89.6746, aux_2.loss_ce: 0.1007, aux_2.loss_dice: 0.2632, aux_2.acc_seg: 97.2302, loss: 1.0543
2023-05-01 22:58:57,726 - mmseg - INFO - Iter [3200/160000]	lr: 4.910e-03, eta: 1 day, 0:46:57, time: 0.536, data_time: 0.142, memory: 17140, decode.loss_ce: 0.1978, decode.acc_seg: 91.4800, aux_0.loss_ce: 0.2055, aux_0.acc_seg: 91.2502, aux_1.loss_ce: 0.2312, aux_1.acc_seg: 90.0179, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2584, aux_2.acc_seg: 97.2454, loss: 0.9928
2023-05-01 22:59:25,682 - mmseg - INFO - Iter [3250/160000]	lr: 4.909e-03, eta: 1 day, 0:46:05, time: 0.559, data_time: 0.173, memory: 17140, decode.loss_ce: 0.2034, decode.acc_seg: 91.1655, aux_0.loss_ce: 0.2103, aux_0.acc_seg: 90.9268, aux_1.loss_ce: 0.2340, aux_1.acc_seg: 89.8477, aux_2.loss_ce: 0.0957, aux_2.loss_dice: 0.2588, aux_2.acc_seg: 97.3713, loss: 1.0023
2023-05-01 22:59:52,702 - mmseg - INFO - Iter [3300/160000]	lr: 4.907e-03, eta: 1 day, 0:44:29, time: 0.540, data_time: 0.144, memory: 17140, decode.loss_ce: 0.2269, decode.acc_seg: 90.4787, aux_0.loss_ce: 0.2328, aux_0.acc_seg: 90.2856, aux_1.loss_ce: 0.2555, aux_1.acc_seg: 89.2315, aux_2.loss_ce: 0.0986, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 97.3243, loss: 1.0732
2023-05-01 23:00:24,572 - mmseg - INFO - Iter [3350/160000]	lr: 4.906e-03, eta: 1 day, 0:46:40, time: 0.637, data_time: 0.250, memory: 17140, decode.loss_ce: 0.2048, decode.acc_seg: 91.1173, aux_0.loss_ce: 0.2123, aux_0.acc_seg: 90.8606, aux_1.loss_ce: 0.2369, aux_1.acc_seg: 89.7745, aux_2.loss_ce: 0.0990, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 97.2764, loss: 1.0133
2023-05-01 23:00:52,292 - mmseg - INFO - Iter [3400/160000]	lr: 4.904e-03, eta: 1 day, 0:45:39, time: 0.555, data_time: 0.154, memory: 17140, decode.loss_ce: 0.1959, decode.acc_seg: 91.6679, aux_0.loss_ce: 0.2034, aux_0.acc_seg: 91.4116, aux_1.loss_ce: 0.2288, aux_1.acc_seg: 90.2680, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2595, aux_2.acc_seg: 97.3353, loss: 0.9844
2023-05-01 23:01:19,860 - mmseg - INFO - Iter [3450/160000]	lr: 4.903e-03, eta: 1 day, 0:44:30, time: 0.551, data_time: 0.151, memory: 17140, decode.loss_ce: 0.2072, decode.acc_seg: 91.0842, aux_0.loss_ce: 0.2143, aux_0.acc_seg: 90.7964, aux_1.loss_ce: 0.2386, aux_1.acc_seg: 89.6831, aux_2.loss_ce: 0.0990, aux_2.loss_dice: 0.2579, aux_2.acc_seg: 97.2509, loss: 1.0170
2023-05-01 23:01:47,780 - mmseg - INFO - Iter [3500/160000]	lr: 4.902e-03, eta: 1 day, 0:43:38, time: 0.558, data_time: 0.158, memory: 17140, decode.loss_ce: 0.2255, decode.acc_seg: 90.2985, aux_0.loss_ce: 0.2324, aux_0.acc_seg: 90.1901, aux_1.loss_ce: 0.2552, aux_1.acc_seg: 89.0665, aux_2.loss_ce: 0.1020, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 97.1961, loss: 1.0783
2023-05-01 23:02:19,976 - mmseg - INFO - Iter [3550/160000]	lr: 4.900e-03, eta: 1 day, 0:45:56, time: 0.645, data_time: 0.252, memory: 17140, decode.loss_ce: 0.2077, decode.acc_seg: 90.9538, aux_0.loss_ce: 0.2134, aux_0.acc_seg: 90.8097, aux_1.loss_ce: 0.2380, aux_1.acc_seg: 89.6026, aux_2.loss_ce: 0.0987, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 97.2753, loss: 1.0174
2023-05-01 23:02:47,529 - mmseg - INFO - Iter [3600/160000]	lr: 4.899e-03, eta: 1 day, 0:44:46, time: 0.550, data_time: 0.152, memory: 17140, decode.loss_ce: 0.2045, decode.acc_seg: 91.2908, aux_0.loss_ce: 0.2100, aux_0.acc_seg: 91.0423, aux_1.loss_ce: 0.2328, aux_1.acc_seg: 89.9906, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 97.3593, loss: 0.9992
2023-05-01 23:03:15,065 - mmseg - INFO - Iter [3650/160000]	lr: 4.897e-03, eta: 1 day, 0:43:37, time: 0.551, data_time: 0.151, memory: 17140, decode.loss_ce: 0.2157, decode.acc_seg: 90.8110, aux_0.loss_ce: 0.2241, aux_0.acc_seg: 90.5805, aux_1.loss_ce: 0.2479, aux_1.acc_seg: 89.4827, aux_2.loss_ce: 0.0990, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 97.2416, loss: 1.0461
2023-05-01 23:03:42,745 - mmseg - INFO - Iter [3700/160000]	lr: 4.896e-03, eta: 1 day, 0:42:35, time: 0.554, data_time: 0.153, memory: 17140, decode.loss_ce: 0.1906, decode.acc_seg: 91.9182, aux_0.loss_ce: 0.1974, aux_0.acc_seg: 91.7522, aux_1.loss_ce: 0.2234, aux_1.acc_seg: 90.5364, aux_2.loss_ce: 0.1001, aux_2.loss_dice: 0.2602, aux_2.acc_seg: 97.1647, loss: 0.9717
2023-05-01 23:04:14,124 - mmseg - INFO - Iter [3750/160000]	lr: 4.894e-03, eta: 1 day, 0:44:08, time: 0.628, data_time: 0.228, memory: 17140, decode.loss_ce: 0.1873, decode.acc_seg: 91.4743, aux_0.loss_ce: 0.1941, aux_0.acc_seg: 91.2674, aux_1.loss_ce: 0.2166, aux_1.acc_seg: 90.1291, aux_2.loss_ce: 0.0954, aux_2.loss_dice: 0.2533, aux_2.acc_seg: 97.3299, loss: 0.9467
2023-05-01 23:04:41,172 - mmseg - INFO - Iter [3800/160000]	lr: 4.893e-03, eta: 1 day, 0:42:40, time: 0.541, data_time: 0.143, memory: 17140, decode.loss_ce: 0.1874, decode.acc_seg: 91.7937, aux_0.loss_ce: 0.1949, aux_0.acc_seg: 91.5222, aux_1.loss_ce: 0.2193, aux_1.acc_seg: 90.4281, aux_2.loss_ce: 0.0972, aux_2.loss_dice: 0.2557, aux_2.acc_seg: 97.2873, loss: 0.9544
2023-05-01 23:05:08,588 - mmseg - INFO - Iter [3850/160000]	lr: 4.892e-03, eta: 1 day, 0:41:29, time: 0.548, data_time: 0.150, memory: 17140, decode.loss_ce: 0.1883, decode.acc_seg: 91.7095, aux_0.loss_ce: 0.1948, aux_0.acc_seg: 91.4841, aux_1.loss_ce: 0.2197, aux_1.acc_seg: 90.3314, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 97.3417, loss: 0.9532
2023-05-01 23:05:39,891 - mmseg - INFO - Iter [3900/160000]	lr: 4.890e-03, eta: 1 day, 0:42:54, time: 0.626, data_time: 0.239, memory: 17140, decode.loss_ce: 0.1996, decode.acc_seg: 91.4765, aux_0.loss_ce: 0.2053, aux_0.acc_seg: 91.3307, aux_1.loss_ce: 0.2300, aux_1.acc_seg: 90.1196, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 97.2939, loss: 0.9868
2023-05-01 23:06:07,586 - mmseg - INFO - Iter [3950/160000]	lr: 4.889e-03, eta: 1 day, 0:41:54, time: 0.554, data_time: 0.167, memory: 17140, decode.loss_ce: 0.1947, decode.acc_seg: 91.6199, aux_0.loss_ce: 0.2010, aux_0.acc_seg: 91.3289, aux_1.loss_ce: 0.2266, aux_1.acc_seg: 90.1710, aux_2.loss_ce: 0.0972, aux_2.loss_dice: 0.2569, aux_2.acc_seg: 97.2786, loss: 0.9765
2023-05-01 23:06:35,221 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 23:06:35,222 - mmseg - INFO - Iter [4000/160000]	lr: 4.887e-03, eta: 1 day, 0:40:52, time: 0.553, data_time: 0.161, memory: 17140, decode.loss_ce: 0.1925, decode.acc_seg: 91.7110, aux_0.loss_ce: 0.1989, aux_0.acc_seg: 91.5698, aux_1.loss_ce: 0.2235, aux_1.acc_seg: 90.3627, aux_2.loss_ce: 0.0983, aux_2.loss_dice: 0.2569, aux_2.acc_seg: 97.2468, loss: 0.9702
2023-05-01 23:07:02,836 - mmseg - INFO - Iter [4050/160000]	lr: 4.886e-03, eta: 1 day, 0:39:50, time: 0.552, data_time: 0.156, memory: 17140, decode.loss_ce: 0.2006, decode.acc_seg: 91.5514, aux_0.loss_ce: 0.2091, aux_0.acc_seg: 91.3210, aux_1.loss_ce: 0.2324, aux_1.acc_seg: 90.1913, aux_2.loss_ce: 0.0987, aux_2.loss_dice: 0.2577, aux_2.acc_seg: 97.2295, loss: 0.9984
2023-05-01 23:07:33,654 - mmseg - INFO - Iter [4100/160000]	lr: 4.885e-03, eta: 1 day, 0:40:51, time: 0.616, data_time: 0.231, memory: 17140, decode.loss_ce: 0.1910, decode.acc_seg: 91.6150, aux_0.loss_ce: 0.1986, aux_0.acc_seg: 91.3501, aux_1.loss_ce: 0.2235, aux_1.acc_seg: 90.2009, aux_2.loss_ce: 0.0971, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 97.2782, loss: 0.9633
2023-05-01 23:08:00,803 - mmseg - INFO - Iter [4150/160000]	lr: 4.883e-03, eta: 1 day, 0:39:32, time: 0.543, data_time: 0.162, memory: 17140, decode.loss_ce: 0.1909, decode.acc_seg: 91.6512, aux_0.loss_ce: 0.1958, aux_0.acc_seg: 91.4997, aux_1.loss_ce: 0.2196, aux_1.acc_seg: 90.3572, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 97.3464, loss: 0.9532
2023-05-01 23:08:27,806 - mmseg - INFO - Iter [4200/160000]	lr: 4.882e-03, eta: 1 day, 0:38:08, time: 0.540, data_time: 0.156, memory: 17140, decode.loss_ce: 0.2044, decode.acc_seg: 91.1790, aux_0.loss_ce: 0.2106, aux_0.acc_seg: 91.0223, aux_1.loss_ce: 0.2352, aux_1.acc_seg: 89.8604, aux_2.loss_ce: 0.0974, aux_2.loss_dice: 0.2595, aux_2.acc_seg: 97.2682, loss: 1.0071
2023-05-01 23:08:54,655 - mmseg - INFO - Iter [4250/160000]	lr: 4.880e-03, eta: 1 day, 0:36:41, time: 0.537, data_time: 0.148, memory: 17140, decode.loss_ce: 0.1919, decode.acc_seg: 91.7174, aux_0.loss_ce: 0.1987, aux_0.acc_seg: 91.5065, aux_1.loss_ce: 0.2234, aux_1.acc_seg: 90.3436, aux_2.loss_ce: 0.0977, aux_2.loss_dice: 0.2572, aux_2.acc_seg: 97.2806, loss: 0.9689
2023-05-01 23:09:25,937 - mmseg - INFO - Iter [4300/160000]	lr: 4.879e-03, eta: 1 day, 0:37:55, time: 0.626, data_time: 0.232, memory: 17140, decode.loss_ce: 0.1843, decode.acc_seg: 91.9032, aux_0.loss_ce: 0.1919, aux_0.acc_seg: 91.6428, aux_1.loss_ce: 0.2169, aux_1.acc_seg: 90.5146, aux_2.loss_ce: 0.0974, aux_2.loss_dice: 0.2559, aux_2.acc_seg: 97.2767, loss: 0.9464
2023-05-01 23:09:52,899 - mmseg - INFO - Iter [4350/160000]	lr: 4.878e-03, eta: 1 day, 0:36:32, time: 0.539, data_time: 0.142, memory: 17140, decode.loss_ce: 0.1838, decode.acc_seg: 92.0197, aux_0.loss_ce: 0.1910, aux_0.acc_seg: 91.7859, aux_1.loss_ce: 0.2148, aux_1.acc_seg: 90.6660, aux_2.loss_ce: 0.0972, aux_2.loss_dice: 0.2562, aux_2.acc_seg: 97.2505, loss: 0.9430
2023-05-01 23:10:19,506 - mmseg - INFO - Iter [4400/160000]	lr: 4.876e-03, eta: 1 day, 0:34:58, time: 0.532, data_time: 0.130, memory: 17140, decode.loss_ce: 0.1936, decode.acc_seg: 91.2679, aux_0.loss_ce: 0.1982, aux_0.acc_seg: 91.1292, aux_1.loss_ce: 0.2206, aux_1.acc_seg: 90.0612, aux_2.loss_ce: 0.0944, aux_2.loss_dice: 0.2528, aux_2.acc_seg: 97.3723, loss: 0.9596
2023-05-01 23:10:49,654 - mmseg - INFO - Iter [4450/160000]	lr: 4.875e-03, eta: 1 day, 0:35:30, time: 0.603, data_time: 0.205, memory: 17140, decode.loss_ce: 0.2333, decode.acc_seg: 90.1952, aux_0.loss_ce: 0.2417, aux_0.acc_seg: 89.9509, aux_1.loss_ce: 0.2641, aux_1.acc_seg: 88.8985, aux_2.loss_ce: 0.1022, aux_2.loss_dice: 0.2624, aux_2.acc_seg: 97.1612, loss: 1.1036
2023-05-01 23:11:16,167 - mmseg - INFO - Iter [4500/160000]	lr: 4.873e-03, eta: 1 day, 0:33:54, time: 0.530, data_time: 0.137, memory: 17140, decode.loss_ce: 0.2250, decode.acc_seg: 90.5733, aux_0.loss_ce: 0.2275, aux_0.acc_seg: 90.4946, aux_1.loss_ce: 0.2525, aux_1.acc_seg: 89.3404, aux_2.loss_ce: 0.0986, aux_2.loss_dice: 0.2592, aux_2.acc_seg: 97.3066, loss: 1.0628
2023-05-01 23:11:43,252 - mmseg - INFO - Iter [4550/160000]	lr: 4.872e-03, eta: 1 day, 0:32:40, time: 0.542, data_time: 0.150, memory: 17140, decode.loss_ce: 0.2105, decode.acc_seg: 91.2703, aux_0.loss_ce: 0.2160, aux_0.acc_seg: 91.1317, aux_1.loss_ce: 0.2436, aux_1.acc_seg: 89.8998, aux_2.loss_ce: 0.0977, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 97.2918, loss: 1.0282
2023-05-01 23:12:10,741 - mmseg - INFO - Iter [4600/160000]	lr: 4.870e-03, eta: 1 day, 0:31:40, time: 0.550, data_time: 0.152, memory: 17140, decode.loss_ce: 0.2014, decode.acc_seg: 91.4910, aux_0.loss_ce: 0.2077, aux_0.acc_seg: 91.3197, aux_1.loss_ce: 0.2328, aux_1.acc_seg: 90.1502, aux_2.loss_ce: 0.0979, aux_2.loss_dice: 0.2569, aux_2.acc_seg: 97.2691, loss: 0.9967
2023-05-01 23:12:41,768 - mmseg - INFO - Iter [4650/160000]	lr: 4.869e-03, eta: 1 day, 0:32:39, time: 0.620, data_time: 0.219, memory: 17140, decode.loss_ce: 0.2053, decode.acc_seg: 91.2274, aux_0.loss_ce: 0.2091, aux_0.acc_seg: 91.1217, aux_1.loss_ce: 0.2325, aux_1.acc_seg: 90.0160, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 97.2854, loss: 0.9988
2023-05-01 23:13:08,130 - mmseg - INFO - Iter [4700/160000]	lr: 4.868e-03, eta: 1 day, 0:31:01, time: 0.527, data_time: 0.141, memory: 17140, decode.loss_ce: 0.2001, decode.acc_seg: 91.5754, aux_0.loss_ce: 0.2040, aux_0.acc_seg: 91.4737, aux_1.loss_ce: 0.2280, aux_1.acc_seg: 90.3454, aux_2.loss_ce: 0.0986, aux_2.loss_dice: 0.2578, aux_2.acc_seg: 97.2732, loss: 0.9885
2023-05-01 23:13:34,620 - mmseg - INFO - Iter [4750/160000]	lr: 4.866e-03, eta: 1 day, 0:29:30, time: 0.530, data_time: 0.143, memory: 17140, decode.loss_ce: 0.1985, decode.acc_seg: 91.4730, aux_0.loss_ce: 0.2043, aux_0.acc_seg: 91.3400, aux_1.loss_ce: 0.2269, aux_1.acc_seg: 90.2075, aux_2.loss_ce: 0.0974, aux_2.loss_dice: 0.2551, aux_2.acc_seg: 97.2825, loss: 0.9821
2023-05-01 23:14:01,168 - mmseg - INFO - Iter [4800/160000]	lr: 4.865e-03, eta: 1 day, 0:28:02, time: 0.531, data_time: 0.141, memory: 17140, decode.loss_ce: 0.1955, decode.acc_seg: 91.6475, aux_0.loss_ce: 0.2012, aux_0.acc_seg: 91.4970, aux_1.loss_ce: 0.2235, aux_1.acc_seg: 90.4221, aux_2.loss_ce: 0.0963, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 97.3221, loss: 0.9714
2023-05-01 23:14:32,553 - mmseg - INFO - Iter [4850/160000]	lr: 4.863e-03, eta: 1 day, 0:29:10, time: 0.628, data_time: 0.236, memory: 17140, decode.loss_ce: 0.1876, decode.acc_seg: 92.0387, aux_0.loss_ce: 0.1935, aux_0.acc_seg: 91.8266, aux_1.loss_ce: 0.2187, aux_1.acc_seg: 90.6963, aux_2.loss_ce: 0.1008, aux_2.loss_dice: 0.2588, aux_2.acc_seg: 97.1690, loss: 0.9594
2023-05-01 23:14:59,421 - mmseg - INFO - Iter [4900/160000]	lr: 4.862e-03, eta: 1 day, 0:27:53, time: 0.537, data_time: 0.136, memory: 17140, decode.loss_ce: 0.1813, decode.acc_seg: 92.0052, aux_0.loss_ce: 0.1880, aux_0.acc_seg: 91.7556, aux_1.loss_ce: 0.2113, aux_1.acc_seg: 90.6617, aux_2.loss_ce: 0.0952, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 97.3250, loss: 0.9275
2023-05-01 23:15:26,592 - mmseg - INFO - Iter [4950/160000]	lr: 4.861e-03, eta: 1 day, 0:26:46, time: 0.543, data_time: 0.146, memory: 17140, decode.loss_ce: 0.1934, decode.acc_seg: 91.6957, aux_0.loss_ce: 0.1969, aux_0.acc_seg: 91.5996, aux_1.loss_ce: 0.2224, aux_1.acc_seg: 90.5418, aux_2.loss_ce: 0.0940, aux_2.loss_dice: 0.2521, aux_2.acc_seg: 97.3688, loss: 0.9589
2023-05-01 23:15:57,809 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 23:15:57,810 - mmseg - INFO - Iter [5000/160000]	lr: 4.859e-03, eta: 1 day, 0:27:45, time: 0.624, data_time: 0.228, memory: 17140, decode.loss_ce: 0.1786, decode.acc_seg: 92.3634, aux_0.loss_ce: 0.1848, aux_0.acc_seg: 92.1886, aux_1.loss_ce: 0.2090, aux_1.acc_seg: 91.0238, aux_2.loss_ce: 0.0958, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 97.3137, loss: 0.9226
2023-05-01 23:16:24,197 - mmseg - INFO - Iter [5050/160000]	lr: 4.858e-03, eta: 1 day, 0:26:15, time: 0.528, data_time: 0.134, memory: 17140, decode.loss_ce: 0.1912, decode.acc_seg: 91.7536, aux_0.loss_ce: 0.1960, aux_0.acc_seg: 91.6096, aux_1.loss_ce: 0.2188, aux_1.acc_seg: 90.5211, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2526, aux_2.acc_seg: 97.3218, loss: 0.9545
2023-05-01 23:16:50,654 - mmseg - INFO - Iter [5100/160000]	lr: 4.856e-03, eta: 1 day, 0:24:48, time: 0.529, data_time: 0.137, memory: 17140, decode.loss_ce: 0.1848, decode.acc_seg: 92.0391, aux_0.loss_ce: 0.1891, aux_0.acc_seg: 91.9063, aux_1.loss_ce: 0.2135, aux_1.acc_seg: 90.7368, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 97.2756, loss: 0.9357
2023-05-01 23:17:17,948 - mmseg - INFO - Iter [5150/160000]	lr: 4.855e-03, eta: 1 day, 0:23:47, time: 0.546, data_time: 0.154, memory: 17140, decode.loss_ce: 0.1840, decode.acc_seg: 92.1221, aux_0.loss_ce: 0.1899, aux_0.acc_seg: 91.9161, aux_1.loss_ce: 0.2143, aux_1.acc_seg: 90.7932, aux_2.loss_ce: 0.0972, aux_2.loss_dice: 0.2564, aux_2.acc_seg: 97.2901, loss: 0.9417
2023-05-01 23:17:49,179 - mmseg - INFO - Iter [5200/160000]	lr: 4.854e-03, eta: 1 day, 0:24:44, time: 0.625, data_time: 0.233, memory: 17140, decode.loss_ce: 0.1909, decode.acc_seg: 92.0351, aux_0.loss_ce: 0.1970, aux_0.acc_seg: 91.8698, aux_1.loss_ce: 0.2214, aux_1.acc_seg: 90.6847, aux_2.loss_ce: 0.0999, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 97.2187, loss: 0.9688
2023-05-01 23:18:16,363 - mmseg - INFO - Iter [5250/160000]	lr: 4.852e-03, eta: 1 day, 0:23:41, time: 0.544, data_time: 0.144, memory: 17140, decode.loss_ce: 0.1865, decode.acc_seg: 91.9537, aux_0.loss_ce: 0.1913, aux_0.acc_seg: 91.8133, aux_1.loss_ce: 0.2169, aux_1.acc_seg: 90.6104, aux_2.loss_ce: 0.0952, aux_2.loss_dice: 0.2518, aux_2.acc_seg: 97.3197, loss: 0.9416
2023-05-01 23:18:43,180 - mmseg - INFO - Iter [5300/160000]	lr: 4.851e-03, eta: 1 day, 0:22:27, time: 0.536, data_time: 0.148, memory: 17140, decode.loss_ce: 0.1849, decode.acc_seg: 92.0486, aux_0.loss_ce: 0.1902, aux_0.acc_seg: 91.8655, aux_1.loss_ce: 0.2169, aux_1.acc_seg: 90.6338, aux_2.loss_ce: 0.0985, aux_2.loss_dice: 0.2540, aux_2.acc_seg: 97.1957, loss: 0.9445
2023-05-01 23:19:10,461 - mmseg - INFO - Iter [5350/160000]	lr: 4.849e-03, eta: 1 day, 0:21:27, time: 0.546, data_time: 0.136, memory: 17140, decode.loss_ce: 0.2022, decode.acc_seg: 91.6726, aux_0.loss_ce: 0.2061, aux_0.acc_seg: 91.5722, aux_1.loss_ce: 0.2288, aux_1.acc_seg: 90.4483, aux_2.loss_ce: 0.0968, aux_2.loss_dice: 0.2555, aux_2.acc_seg: 97.2723, loss: 0.9894
2023-05-01 23:19:41,324 - mmseg - INFO - Iter [5400/160000]	lr: 4.848e-03, eta: 1 day, 0:22:11, time: 0.617, data_time: 0.225, memory: 17140, decode.loss_ce: 0.2013, decode.acc_seg: 91.5264, aux_0.loss_ce: 0.2054, aux_0.acc_seg: 91.3977, aux_1.loss_ce: 0.2281, aux_1.acc_seg: 90.3538, aux_2.loss_ce: 0.0971, aux_2.loss_dice: 0.2563, aux_2.acc_seg: 97.2793, loss: 0.9882
2023-05-01 23:20:08,041 - mmseg - INFO - Iter [5450/160000]	lr: 4.847e-03, eta: 1 day, 0:20:55, time: 0.534, data_time: 0.143, memory: 17140, decode.loss_ce: 0.1875, decode.acc_seg: 91.8251, aux_0.loss_ce: 0.1947, aux_0.acc_seg: 91.5619, aux_1.loss_ce: 0.2166, aux_1.acc_seg: 90.4673, aux_2.loss_ce: 0.0968, aux_2.loss_dice: 0.2532, aux_2.acc_seg: 97.2440, loss: 0.9488
2023-05-01 23:20:34,806 - mmseg - INFO - Iter [5500/160000]	lr: 4.845e-03, eta: 1 day, 0:19:42, time: 0.535, data_time: 0.144, memory: 17140, decode.loss_ce: 0.1822, decode.acc_seg: 92.0856, aux_0.loss_ce: 0.1869, aux_0.acc_seg: 91.9495, aux_1.loss_ce: 0.2107, aux_1.acc_seg: 90.7883, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2520, aux_2.acc_seg: 97.3479, loss: 0.9267
2023-05-01 23:21:01,757 - mmseg - INFO - Iter [5550/160000]	lr: 4.844e-03, eta: 1 day, 0:18:35, time: 0.539, data_time: 0.145, memory: 17140, decode.loss_ce: 0.1937, decode.acc_seg: 91.7974, aux_0.loss_ce: 0.2005, aux_0.acc_seg: 91.6477, aux_1.loss_ce: 0.2250, aux_1.acc_seg: 90.5184, aux_2.loss_ce: 0.0977, aux_2.loss_dice: 0.2555, aux_2.acc_seg: 97.2474, loss: 0.9725
2023-05-01 23:21:32,943 - mmseg - INFO - Iter [5600/160000]	lr: 4.842e-03, eta: 1 day, 0:19:25, time: 0.624, data_time: 0.221, memory: 17140, decode.loss_ce: 0.1865, decode.acc_seg: 91.9873, aux_0.loss_ce: 0.1897, aux_0.acc_seg: 91.9243, aux_1.loss_ce: 0.2141, aux_1.acc_seg: 90.8011, aux_2.loss_ce: 0.0952, aux_2.loss_dice: 0.2530, aux_2.acc_seg: 97.3345, loss: 0.9386
2023-05-01 23:21:59,305 - mmseg - INFO - Iter [5650/160000]	lr: 4.841e-03, eta: 1 day, 0:18:02, time: 0.527, data_time: 0.131, memory: 17140, decode.loss_ce: 0.1768, decode.acc_seg: 92.0585, aux_0.loss_ce: 0.1828, aux_0.acc_seg: 91.8866, aux_1.loss_ce: 0.2065, aux_1.acc_seg: 90.7063, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 97.2798, loss: 0.9101
2023-05-01 23:22:25,020 - mmseg - INFO - Iter [5700/160000]	lr: 4.839e-03, eta: 1 day, 0:16:23, time: 0.514, data_time: 0.123, memory: 17140, decode.loss_ce: 0.1704, decode.acc_seg: 92.7535, aux_0.loss_ce: 0.1754, aux_0.acc_seg: 92.5963, aux_1.loss_ce: 0.1994, aux_1.acc_seg: 91.5033, aux_2.loss_ce: 0.0954, aux_2.loss_dice: 0.2540, aux_2.acc_seg: 97.2875, loss: 0.8946
2023-05-01 23:22:54,921 - mmseg - INFO - Iter [5750/160000]	lr: 4.838e-03, eta: 1 day, 0:16:37, time: 0.598, data_time: 0.204, memory: 17140, decode.loss_ce: 0.1930, decode.acc_seg: 92.0406, aux_0.loss_ce: 0.1972, aux_0.acc_seg: 91.8632, aux_1.loss_ce: 0.2209, aux_1.acc_seg: 90.8006, aux_2.loss_ce: 0.0962, aux_2.loss_dice: 0.2552, aux_2.acc_seg: 97.2971, loss: 0.9625
2023-05-01 23:23:22,279 - mmseg - INFO - Iter [5800/160000]	lr: 4.837e-03, eta: 1 day, 0:15:43, time: 0.547, data_time: 0.155, memory: 17140, decode.loss_ce: 0.1859, decode.acc_seg: 91.8749, aux_0.loss_ce: 0.1902, aux_0.acc_seg: 91.7913, aux_1.loss_ce: 0.2133, aux_1.acc_seg: 90.6213, aux_2.loss_ce: 0.0974, aux_2.loss_dice: 0.2537, aux_2.acc_seg: 97.2291, loss: 0.9405
2023-05-01 23:23:49,013 - mmseg - INFO - Iter [5850/160000]	lr: 4.835e-03, eta: 1 day, 0:14:33, time: 0.535, data_time: 0.138, memory: 17140, decode.loss_ce: 0.1894, decode.acc_seg: 92.0755, aux_0.loss_ce: 0.1963, aux_0.acc_seg: 91.8776, aux_1.loss_ce: 0.2188, aux_1.acc_seg: 90.8607, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 97.2533, loss: 0.9568
2023-05-01 23:24:16,291 - mmseg - INFO - Iter [5900/160000]	lr: 4.834e-03, eta: 1 day, 0:13:38, time: 0.546, data_time: 0.151, memory: 17140, decode.loss_ce: 0.1905, decode.acc_seg: 91.9666, aux_0.loss_ce: 0.1953, aux_0.acc_seg: 91.7801, aux_1.loss_ce: 0.2173, aux_1.acc_seg: 90.7930, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2537, aux_2.acc_seg: 97.3124, loss: 0.9528
2023-05-01 23:24:47,139 - mmseg - INFO - Iter [5950/160000]	lr: 4.832e-03, eta: 1 day, 0:14:15, time: 0.617, data_time: 0.228, memory: 17140, decode.loss_ce: 0.1778, decode.acc_seg: 92.3243, aux_0.loss_ce: 0.1843, aux_0.acc_seg: 92.1025, aux_1.loss_ce: 0.2074, aux_1.acc_seg: 90.9883, aux_2.loss_ce: 0.0966, aux_2.loss_dice: 0.2536, aux_2.acc_seg: 97.2349, loss: 0.9197
2023-05-01 23:25:13,970 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 23:25:13,971 - mmseg - INFO - Iter [6000/160000]	lr: 4.831e-03, eta: 1 day, 0:13:09, time: 0.537, data_time: 0.142, memory: 17140, decode.loss_ce: 0.1652, decode.acc_seg: 92.7630, aux_0.loss_ce: 0.1704, aux_0.acc_seg: 92.5813, aux_1.loss_ce: 0.1941, aux_1.acc_seg: 91.4911, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 97.2826, loss: 0.8756
2023-05-01 23:25:40,845 - mmseg - INFO - Iter [6050/160000]	lr: 4.830e-03, eta: 1 day, 0:12:04, time: 0.537, data_time: 0.139, memory: 17140, decode.loss_ce: 0.1829, decode.acc_seg: 91.9953, aux_0.loss_ce: 0.1889, aux_0.acc_seg: 91.8713, aux_1.loss_ce: 0.2124, aux_1.acc_seg: 90.7005, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 97.3041, loss: 0.9297
2023-05-01 23:26:08,369 - mmseg - INFO - Iter [6100/160000]	lr: 4.828e-03, eta: 1 day, 0:11:16, time: 0.550, data_time: 0.151, memory: 17140, decode.loss_ce: 0.1754, decode.acc_seg: 92.3602, aux_0.loss_ce: 0.1825, aux_0.acc_seg: 92.1498, aux_1.loss_ce: 0.2054, aux_1.acc_seg: 91.0239, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 97.2633, loss: 0.9101
2023-05-01 23:26:39,147 - mmseg - INFO - Iter [6150/160000]	lr: 4.827e-03, eta: 1 day, 0:11:50, time: 0.616, data_time: 0.222, memory: 17140, decode.loss_ce: 0.1807, decode.acc_seg: 92.1826, aux_0.loss_ce: 0.1866, aux_0.acc_seg: 92.0276, aux_1.loss_ce: 0.2093, aux_1.acc_seg: 90.8948, aux_2.loss_ce: 0.0957, aux_2.loss_dice: 0.2521, aux_2.acc_seg: 97.2835, loss: 0.9243
2023-05-01 23:27:06,000 - mmseg - INFO - Iter [6200/160000]	lr: 4.825e-03, eta: 1 day, 0:10:46, time: 0.537, data_time: 0.145, memory: 17140, decode.loss_ce: 0.1774, decode.acc_seg: 92.3952, aux_0.loss_ce: 0.1827, aux_0.acc_seg: 92.2626, aux_1.loss_ce: 0.2059, aux_1.acc_seg: 91.2052, aux_2.loss_ce: 0.0972, aux_2.loss_dice: 0.2539, aux_2.acc_seg: 97.2342, loss: 0.9171
2023-05-01 23:27:32,741 - mmseg - INFO - Iter [6250/160000]	lr: 4.824e-03, eta: 1 day, 0:09:39, time: 0.535, data_time: 0.150, memory: 17140, decode.loss_ce: 0.1761, decode.acc_seg: 92.4545, aux_0.loss_ce: 0.1813, aux_0.acc_seg: 92.3430, aux_1.loss_ce: 0.2056, aux_1.acc_seg: 91.2564, aux_2.loss_ce: 0.0957, aux_2.loss_dice: 0.2527, aux_2.acc_seg: 97.2992, loss: 0.9115
2023-05-01 23:28:03,269 - mmseg - INFO - Iter [6300/160000]	lr: 4.823e-03, eta: 1 day, 0:10:05, time: 0.611, data_time: 0.215, memory: 17140, decode.loss_ce: 0.1678, decode.acc_seg: 92.8357, aux_0.loss_ce: 0.1719, aux_0.acc_seg: 92.7534, aux_1.loss_ce: 0.1967, aux_1.acc_seg: 91.5896, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 97.2962, loss: 0.8867
2023-05-01 23:28:29,507 - mmseg - INFO - Iter [6350/160000]	lr: 4.821e-03, eta: 1 day, 0:08:47, time: 0.525, data_time: 0.132, memory: 17140, decode.loss_ce: 0.1854, decode.acc_seg: 92.2202, aux_0.loss_ce: 0.1899, aux_0.acc_seg: 92.1374, aux_1.loss_ce: 0.2167, aux_1.acc_seg: 90.9438, aux_2.loss_ce: 0.0981, aux_2.loss_dice: 0.2557, aux_2.acc_seg: 97.1818, loss: 0.9458
2023-05-01 23:28:55,783 - mmseg - INFO - Iter [6400/160000]	lr: 4.820e-03, eta: 1 day, 0:07:31, time: 0.526, data_time: 0.139, memory: 17140, decode.loss_ce: 0.1772, decode.acc_seg: 92.3298, aux_0.loss_ce: 0.1817, aux_0.acc_seg: 92.2096, aux_1.loss_ce: 0.2049, aux_1.acc_seg: 91.0903, aux_2.loss_ce: 0.0955, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 97.3020, loss: 0.9108
2023-05-01 23:29:22,685 - mmseg - INFO - Iter [6450/160000]	lr: 4.818e-03, eta: 1 day, 0:06:30, time: 0.538, data_time: 0.148, memory: 17140, decode.loss_ce: 0.1789, decode.acc_seg: 92.4628, aux_0.loss_ce: 0.1841, aux_0.acc_seg: 92.3480, aux_1.loss_ce: 0.2062, aux_1.acc_seg: 91.2477, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2529, aux_2.acc_seg: 97.2709, loss: 0.9181
2023-05-01 23:29:53,762 - mmseg - INFO - Iter [6500/160000]	lr: 4.817e-03, eta: 1 day, 0:07:08, time: 0.622, data_time: 0.230, memory: 17140, decode.loss_ce: 0.1760, decode.acc_seg: 92.2354, aux_0.loss_ce: 0.1798, aux_0.acc_seg: 92.1488, aux_1.loss_ce: 0.2018, aux_1.acc_seg: 91.0486, aux_2.loss_ce: 0.0950, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 97.2992, loss: 0.9030
2023-05-01 23:30:20,527 - mmseg - INFO - Iter [6550/160000]	lr: 4.815e-03, eta: 1 day, 0:06:04, time: 0.535, data_time: 0.149, memory: 17140, decode.loss_ce: 0.1821, decode.acc_seg: 92.3349, aux_0.loss_ce: 0.1872, aux_0.acc_seg: 92.2129, aux_1.loss_ce: 0.2091, aux_1.acc_seg: 91.1221, aux_2.loss_ce: 0.0965, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 97.2654, loss: 0.9266
2023-05-01 23:30:48,203 - mmseg - INFO - Iter [6600/160000]	lr: 4.814e-03, eta: 1 day, 0:05:22, time: 0.554, data_time: 0.151, memory: 17140, decode.loss_ce: 0.1772, decode.acc_seg: 92.4608, aux_0.loss_ce: 0.1815, aux_0.acc_seg: 92.3198, aux_1.loss_ce: 0.2083, aux_1.acc_seg: 91.1429, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2524, aux_2.acc_seg: 97.2923, loss: 0.9146
2023-05-01 23:31:14,501 - mmseg - INFO - Iter [6650/160000]	lr: 4.813e-03, eta: 1 day, 0:04:08, time: 0.526, data_time: 0.129, memory: 17140, decode.loss_ce: 0.1873, decode.acc_seg: 91.8585, aux_0.loss_ce: 0.1902, aux_0.acc_seg: 91.8364, aux_1.loss_ce: 0.2112, aux_1.acc_seg: 90.7094, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2528, aux_2.acc_seg: 97.2630, loss: 0.9375
2023-05-01 23:31:44,975 - mmseg - INFO - Iter [6700/160000]	lr: 4.811e-03, eta: 1 day, 0:04:30, time: 0.609, data_time: 0.215, memory: 17140, decode.loss_ce: 0.2008, decode.acc_seg: 91.4732, aux_0.loss_ce: 0.2008, aux_0.acc_seg: 91.4473, aux_1.loss_ce: 0.2238, aux_1.acc_seg: 90.3297, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 97.3076, loss: 0.9732
2023-05-01 23:32:12,297 - mmseg - INFO - Iter [6750/160000]	lr: 4.810e-03, eta: 1 day, 0:03:41, time: 0.547, data_time: 0.153, memory: 17140, decode.loss_ce: 0.1990, decode.acc_seg: 91.5586, aux_0.loss_ce: 0.2011, aux_0.acc_seg: 91.4762, aux_1.loss_ce: 0.2245, aux_1.acc_seg: 90.4007, aux_2.loss_ce: 0.0961, aux_2.loss_dice: 0.2530, aux_2.acc_seg: 97.3028, loss: 0.9736
2023-05-01 23:32:40,054 - mmseg - INFO - Iter [6800/160000]	lr: 4.808e-03, eta: 1 day, 0:03:01, time: 0.555, data_time: 0.163, memory: 17140, decode.loss_ce: 0.1977, decode.acc_seg: 91.7178, aux_0.loss_ce: 0.1969, aux_0.acc_seg: 91.7620, aux_1.loss_ce: 0.2220, aux_1.acc_seg: 90.5748, aux_2.loss_ce: 0.0975, aux_2.loss_dice: 0.2545, aux_2.acc_seg: 97.2302, loss: 0.9686
2023-05-01 23:33:11,102 - mmseg - INFO - Iter [6850/160000]	lr: 4.807e-03, eta: 1 day, 0:03:36, time: 0.621, data_time: 0.227, memory: 17140, decode.loss_ce: 0.1754, decode.acc_seg: 92.3926, aux_0.loss_ce: 0.1790, aux_0.acc_seg: 92.2932, aux_1.loss_ce: 0.2037, aux_1.acc_seg: 91.1848, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 97.3030, loss: 0.9047
2023-05-01 23:33:37,222 - mmseg - INFO - Iter [6900/160000]	lr: 4.806e-03, eta: 1 day, 0:02:19, time: 0.522, data_time: 0.128, memory: 17140, decode.loss_ce: 0.1726, decode.acc_seg: 92.4965, aux_0.loss_ce: 0.1759, aux_0.acc_seg: 92.4192, aux_1.loss_ce: 0.1972, aux_1.acc_seg: 91.4247, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 97.3091, loss: 0.8900
2023-05-01 23:34:03,578 - mmseg - INFO - Iter [6950/160000]	lr: 4.804e-03, eta: 1 day, 0:01:09, time: 0.527, data_time: 0.140, memory: 17140, decode.loss_ce: 0.1799, decode.acc_seg: 92.2301, aux_0.loss_ce: 0.1850, aux_0.acc_seg: 92.0705, aux_1.loss_ce: 0.2073, aux_1.acc_seg: 90.9885, aux_2.loss_ce: 0.0947, aux_2.loss_dice: 0.2507, aux_2.acc_seg: 97.3172, loss: 0.9176
2023-05-01 23:34:29,049 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 23:34:29,050 - mmseg - INFO - Iter [7000/160000]	lr: 4.803e-03, eta: 23:59:40, time: 0.509, data_time: 0.115, memory: 17140, decode.loss_ce: 0.1770, decode.acc_seg: 92.3965, aux_0.loss_ce: 0.1811, aux_0.acc_seg: 92.3159, aux_1.loss_ce: 0.2043, aux_1.acc_seg: 91.2243, aux_2.loss_ce: 0.0942, aux_2.loss_dice: 0.2521, aux_2.acc_seg: 97.3505, loss: 0.9086
2023-05-01 23:34:58,971 - mmseg - INFO - Iter [7050/160000]	lr: 4.801e-03, eta: 23:59:49, time: 0.598, data_time: 0.204, memory: 17140, decode.loss_ce: 0.1812, decode.acc_seg: 92.2566, aux_0.loss_ce: 0.1851, aux_0.acc_seg: 92.1723, aux_1.loss_ce: 0.2071, aux_1.acc_seg: 91.1535, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2528, aux_2.acc_seg: 97.2884, loss: 0.9219
2023-05-01 23:35:26,819 - mmseg - INFO - Iter [7100/160000]	lr: 4.800e-03, eta: 23:59:12, time: 0.557, data_time: 0.157, memory: 17140, decode.loss_ce: 0.1721, decode.acc_seg: 92.7939, aux_0.loss_ce: 0.1764, aux_0.acc_seg: 92.6756, aux_1.loss_ce: 0.1985, aux_1.acc_seg: 91.6137, aux_2.loss_ce: 0.0977, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 97.2234, loss: 0.8982
2023-05-01 23:35:52,979 - mmseg - INFO - Iter [7150/160000]	lr: 4.799e-03, eta: 23:57:59, time: 0.523, data_time: 0.126, memory: 17140, decode.loss_ce: 0.1553, decode.acc_seg: 92.9782, aux_0.loss_ce: 0.1611, aux_0.acc_seg: 92.8111, aux_1.loss_ce: 0.1830, aux_1.acc_seg: 91.6906, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 97.2835, loss: 0.8402
2023-05-01 23:36:20,494 - mmseg - INFO - Iter [7200/160000]	lr: 4.797e-03, eta: 23:57:16, time: 0.550, data_time: 0.147, memory: 17140, decode.loss_ce: 0.1696, decode.acc_seg: 92.6257, aux_0.loss_ce: 0.1730, aux_0.acc_seg: 92.5455, aux_1.loss_ce: 0.1949, aux_1.acc_seg: 91.4597, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 97.3410, loss: 0.8822
2023-05-01 23:36:51,551 - mmseg - INFO - Iter [7250/160000]	lr: 4.796e-03, eta: 23:57:48, time: 0.621, data_time: 0.224, memory: 17140, decode.loss_ce: 0.2081, decode.acc_seg: 91.0605, aux_0.loss_ce: 0.2124, aux_0.acc_seg: 90.9489, aux_1.loss_ce: 0.2300, aux_1.acc_seg: 90.0619, aux_2.loss_ce: 0.0962, aux_2.loss_dice: 0.2536, aux_2.acc_seg: 97.3464, loss: 1.0002
2023-05-01 23:37:18,793 - mmseg - INFO - Iter [7300/160000]	lr: 4.794e-03, eta: 23:56:58, time: 0.545, data_time: 0.144, memory: 17140, decode.loss_ce: 0.2072, decode.acc_seg: 91.0933, aux_0.loss_ce: 0.2086, aux_0.acc_seg: 91.1536, aux_1.loss_ce: 0.2313, aux_1.acc_seg: 90.1101, aux_2.loss_ce: 0.1000, aux_2.loss_dice: 0.2587, aux_2.acc_seg: 97.2207, loss: 1.0058
2023-05-01 23:37:45,817 - mmseg - INFO - Iter [7350/160000]	lr: 4.793e-03, eta: 23:56:05, time: 0.540, data_time: 0.153, memory: 17140, decode.loss_ce: 0.1929, decode.acc_seg: 91.4943, aux_0.loss_ce: 0.1963, aux_0.acc_seg: 91.4314, aux_1.loss_ce: 0.2153, aux_1.acc_seg: 90.4103, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 97.3335, loss: 0.9490
2023-05-01 23:38:12,506 - mmseg - INFO - Iter [7400/160000]	lr: 4.791e-03, eta: 23:55:05, time: 0.534, data_time: 0.145, memory: 17140, decode.loss_ce: 0.1962, decode.acc_seg: 91.6844, aux_0.loss_ce: 0.2016, aux_0.acc_seg: 91.5117, aux_1.loss_ce: 0.2215, aux_1.acc_seg: 90.5034, aux_2.loss_ce: 0.0988, aux_2.loss_dice: 0.2572, aux_2.acc_seg: 97.2176, loss: 0.9753
2023-05-01 23:38:44,863 - mmseg - INFO - Iter [7450/160000]	lr: 4.790e-03, eta: 23:56:02, time: 0.647, data_time: 0.248, memory: 17140, decode.loss_ce: 0.1855, decode.acc_seg: 92.0171, aux_0.loss_ce: 0.1876, aux_0.acc_seg: 91.9930, aux_1.loss_ce: 0.2099, aux_1.acc_seg: 90.9431, aux_2.loss_ce: 0.0962, aux_2.loss_dice: 0.2541, aux_2.acc_seg: 97.2928, loss: 0.9333
2023-05-01 23:39:11,863 - mmseg - INFO - Iter [7500/160000]	lr: 4.789e-03, eta: 23:55:08, time: 0.540, data_time: 0.146, memory: 17140, decode.loss_ce: 0.1710, decode.acc_seg: 92.5090, aux_0.loss_ce: 0.1757, aux_0.acc_seg: 92.3695, aux_1.loss_ce: 0.1971, aux_1.acc_seg: 91.4003, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 97.3144, loss: 0.8897
2023-05-01 23:39:38,760 - mmseg - INFO - Iter [7550/160000]	lr: 4.787e-03, eta: 23:54:13, time: 0.538, data_time: 0.140, memory: 17140, decode.loss_ce: 0.1697, decode.acc_seg: 92.5961, aux_0.loss_ce: 0.1736, aux_0.acc_seg: 92.5112, aux_1.loss_ce: 0.1961, aux_1.acc_seg: 91.4267, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 97.2740, loss: 0.8855
2023-05-01 23:40:09,535 - mmseg - INFO - Iter [7600/160000]	lr: 4.786e-03, eta: 23:54:36, time: 0.616, data_time: 0.215, memory: 17140, decode.loss_ce: 0.1724, decode.acc_seg: 92.6721, aux_0.loss_ce: 0.1786, aux_0.acc_seg: 92.5083, aux_1.loss_ce: 0.2006, aux_1.acc_seg: 91.4331, aux_2.loss_ce: 0.0981, aux_2.loss_dice: 0.2539, aux_2.acc_seg: 97.1886, loss: 0.9036
2023-05-01 23:40:36,389 - mmseg - INFO - Iter [7650/160000]	lr: 4.784e-03, eta: 23:53:40, time: 0.537, data_time: 0.143, memory: 17140, decode.loss_ce: 0.1687, decode.acc_seg: 92.8619, aux_0.loss_ce: 0.1729, aux_0.acc_seg: 92.7843, aux_1.loss_ce: 0.1966, aux_1.acc_seg: 91.7038, aux_2.loss_ce: 0.0973, aux_2.loss_dice: 0.2537, aux_2.acc_seg: 97.2609, loss: 0.8892
2023-05-01 23:41:03,196 - mmseg - INFO - Iter [7700/160000]	lr: 4.783e-03, eta: 23:52:44, time: 0.536, data_time: 0.140, memory: 17140, decode.loss_ce: 0.1723, decode.acc_seg: 92.4611, aux_0.loss_ce: 0.1762, aux_0.acc_seg: 92.3213, aux_1.loss_ce: 0.1977, aux_1.acc_seg: 91.2932, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 97.2917, loss: 0.8923
2023-05-01 23:41:30,222 - mmseg - INFO - Iter [7750/160000]	lr: 4.782e-03, eta: 23:51:52, time: 0.540, data_time: 0.150, memory: 17140, decode.loss_ce: 0.1635, decode.acc_seg: 92.8744, aux_0.loss_ce: 0.1685, aux_0.acc_seg: 92.7802, aux_1.loss_ce: 0.1898, aux_1.acc_seg: 91.7423, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 97.2707, loss: 0.8684
2023-05-01 23:42:00,478 - mmseg - INFO - Iter [7800/160000]	lr: 4.780e-03, eta: 23:52:04, time: 0.605, data_time: 0.220, memory: 17140, decode.loss_ce: 0.1816, decode.acc_seg: 92.2974, aux_0.loss_ce: 0.1834, aux_0.acc_seg: 92.2522, aux_1.loss_ce: 0.2041, aux_1.acc_seg: 91.3325, aux_2.loss_ce: 0.0940, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 97.3096, loss: 0.9127
2023-05-01 23:42:27,394 - mmseg - INFO - Iter [7850/160000]	lr: 4.779e-03, eta: 23:51:10, time: 0.538, data_time: 0.157, memory: 17140, decode.loss_ce: 0.1784, decode.acc_seg: 92.3947, aux_0.loss_ce: 0.1806, aux_0.acc_seg: 92.3292, aux_1.loss_ce: 0.2023, aux_1.acc_seg: 91.2805, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 97.2399, loss: 0.9096
2023-05-01 23:42:54,538 - mmseg - INFO - Iter [7900/160000]	lr: 4.777e-03, eta: 23:50:21, time: 0.543, data_time: 0.161, memory: 17140, decode.loss_ce: 0.1720, decode.acc_seg: 92.4170, aux_0.loss_ce: 0.1748, aux_0.acc_seg: 92.3281, aux_1.loss_ce: 0.1967, aux_1.acc_seg: 91.2759, aux_2.loss_ce: 0.0946, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 97.3082, loss: 0.8885
2023-05-01 23:43:22,419 - mmseg - INFO - Iter [7950/160000]	lr: 4.776e-03, eta: 23:49:47, time: 0.558, data_time: 0.169, memory: 17140, decode.loss_ce: 0.1690, decode.acc_seg: 92.5876, aux_0.loss_ce: 0.1741, aux_0.acc_seg: 92.4442, aux_1.loss_ce: 0.1975, aux_1.acc_seg: 91.3217, aux_2.loss_ce: 0.0950, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 97.2846, loss: 0.8849
2023-05-01 23:43:53,012 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 23:43:53,013 - mmseg - INFO - Iter [8000/160000]	lr: 4.775e-03, eta: 23:50:04, time: 0.612, data_time: 0.223, memory: 17140, decode.loss_ce: 0.1703, decode.acc_seg: 92.7704, aux_0.loss_ce: 0.1749, aux_0.acc_seg: 92.6454, aux_1.loss_ce: 0.1960, aux_1.acc_seg: 91.6418, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 97.2922, loss: 0.8887
2023-05-01 23:44:19,694 - mmseg - INFO - Iter [8050/160000]	lr: 4.773e-03, eta: 23:49:06, time: 0.534, data_time: 0.145, memory: 17140, decode.loss_ce: 0.1752, decode.acc_seg: 92.2663, aux_0.loss_ce: 0.1795, aux_0.acc_seg: 92.1544, aux_1.loss_ce: 0.2011, aux_1.acc_seg: 91.1302, aux_2.loss_ce: 0.0958, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 97.2424, loss: 0.9027
2023-05-01 23:44:46,901 - mmseg - INFO - Iter [8100/160000]	lr: 4.772e-03, eta: 23:48:19, time: 0.544, data_time: 0.150, memory: 17140, decode.loss_ce: 0.1674, decode.acc_seg: 92.6229, aux_0.loss_ce: 0.1711, aux_0.acc_seg: 92.5699, aux_1.loss_ce: 0.1925, aux_1.acc_seg: 91.5250, aux_2.loss_ce: 0.0946, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 97.2866, loss: 0.8748
2023-05-01 23:45:17,641 - mmseg - INFO - Iter [8150/160000]	lr: 4.770e-03, eta: 23:48:38, time: 0.615, data_time: 0.218, memory: 17140, decode.loss_ce: 0.1929, decode.acc_seg: 91.9349, aux_0.loss_ce: 0.1951, aux_0.acc_seg: 91.8968, aux_1.loss_ce: 0.2181, aux_1.acc_seg: 90.8675, aux_2.loss_ce: 0.0965, aux_2.loss_dice: 0.2535, aux_2.acc_seg: 97.2513, loss: 0.9560
2023-05-01 23:45:45,028 - mmseg - INFO - Iter [8200/160000]	lr: 4.769e-03, eta: 23:47:54, time: 0.548, data_time: 0.153, memory: 17140, decode.loss_ce: 0.1935, decode.acc_seg: 91.9116, aux_0.loss_ce: 0.1966, aux_0.acc_seg: 91.8164, aux_1.loss_ce: 0.2184, aux_1.acc_seg: 90.7867, aux_2.loss_ce: 0.0961, aux_2.loss_dice: 0.2532, aux_2.acc_seg: 97.2987, loss: 0.9578
2023-05-01 23:46:11,507 - mmseg - INFO - Iter [8250/160000]	lr: 4.767e-03, eta: 23:46:54, time: 0.530, data_time: 0.135, memory: 17140, decode.loss_ce: 0.1712, decode.acc_seg: 92.5496, aux_0.loss_ce: 0.1752, aux_0.acc_seg: 92.4427, aux_1.loss_ce: 0.1966, aux_1.acc_seg: 91.3977, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 97.2572, loss: 0.8869
2023-05-01 23:46:37,092 - mmseg - INFO - Iter [8300/160000]	lr: 4.766e-03, eta: 23:45:38, time: 0.512, data_time: 0.110, memory: 17140, decode.loss_ce: 0.1747, decode.acc_seg: 92.3136, aux_0.loss_ce: 0.1775, aux_0.acc_seg: 92.2425, aux_1.loss_ce: 0.2004, aux_1.acc_seg: 91.1470, aux_2.loss_ce: 0.0942, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 97.3022, loss: 0.8956
2023-05-01 23:47:07,322 - mmseg - INFO - Iter [8350/160000]	lr: 4.765e-03, eta: 23:45:47, time: 0.605, data_time: 0.218, memory: 17140, decode.loss_ce: 0.1690, decode.acc_seg: 92.6037, aux_0.loss_ce: 0.1736, aux_0.acc_seg: 92.4624, aux_1.loss_ce: 0.1941, aux_1.acc_seg: 91.4904, aux_2.loss_ce: 0.0961, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 97.2449, loss: 0.8832
2023-05-01 23:47:34,414 - mmseg - INFO - Iter [8400/160000]	lr: 4.763e-03, eta: 23:44:58, time: 0.542, data_time: 0.144, memory: 17140, decode.loss_ce: 0.1761, decode.acc_seg: 92.6870, aux_0.loss_ce: 0.1795, aux_0.acc_seg: 92.5831, aux_1.loss_ce: 0.2011, aux_1.acc_seg: 91.5774, aux_2.loss_ce: 0.0955, aux_2.loss_dice: 0.2526, aux_2.acc_seg: 97.2498, loss: 0.9048
2023-05-01 23:48:00,645 - mmseg - INFO - Iter [8450/160000]	lr: 4.762e-03, eta: 23:43:55, time: 0.525, data_time: 0.135, memory: 17140, decode.loss_ce: 0.1897, decode.acc_seg: 92.0175, aux_0.loss_ce: 0.1943, aux_0.acc_seg: 91.9032, aux_1.loss_ce: 0.2131, aux_1.acc_seg: 90.8960, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 97.3233, loss: 0.9394
2023-05-01 23:48:27,750 - mmseg - INFO - Iter [8500/160000]	lr: 4.760e-03, eta: 23:43:07, time: 0.542, data_time: 0.160, memory: 17140, decode.loss_ce: 0.1719, decode.acc_seg: 92.7801, aux_0.loss_ce: 0.1757, aux_0.acc_seg: 92.6560, aux_1.loss_ce: 0.1982, aux_1.acc_seg: 91.5957, aux_2.loss_ce: 0.0950, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 97.2827, loss: 0.8918
2023-05-01 23:48:58,512 - mmseg - INFO - Iter [8550/160000]	lr: 4.759e-03, eta: 23:43:25, time: 0.615, data_time: 0.220, memory: 17140, decode.loss_ce: 0.1792, decode.acc_seg: 92.5058, aux_0.loss_ce: 0.1832, aux_0.acc_seg: 92.3895, aux_1.loss_ce: 0.2073, aux_1.acc_seg: 91.3355, aux_2.loss_ce: 0.0964, aux_2.loss_dice: 0.2524, aux_2.acc_seg: 97.2168, loss: 0.9185
2023-05-01 23:49:25,152 - mmseg - INFO - Iter [8600/160000]	lr: 4.758e-03, eta: 23:42:29, time: 0.533, data_time: 0.127, memory: 17140, decode.loss_ce: 0.1789, decode.acc_seg: 92.3628, aux_0.loss_ce: 0.1811, aux_0.acc_seg: 92.3741, aux_1.loss_ce: 0.2030, aux_1.acc_seg: 91.3132, aux_2.loss_ce: 0.0955, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 97.2462, loss: 0.9078
2023-05-01 23:49:52,026 - mmseg - INFO - Iter [8650/160000]	lr: 4.756e-03, eta: 23:41:38, time: 0.537, data_time: 0.135, memory: 17140, decode.loss_ce: 0.1639, decode.acc_seg: 92.8106, aux_0.loss_ce: 0.1681, aux_0.acc_seg: 92.6837, aux_1.loss_ce: 0.1913, aux_1.acc_seg: 91.6254, aux_2.loss_ce: 0.0947, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 97.2625, loss: 0.8678
2023-05-01 23:50:22,665 - mmseg - INFO - Iter [8700/160000]	lr: 4.755e-03, eta: 23:41:53, time: 0.613, data_time: 0.215, memory: 17140, decode.loss_ce: 0.1596, decode.acc_seg: 93.0348, aux_0.loss_ce: 0.1629, aux_0.acc_seg: 92.9542, aux_1.loss_ce: 0.1844, aux_1.acc_seg: 91.9426, aux_2.loss_ce: 0.0944, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 97.2870, loss: 0.8506
2023-05-01 23:50:49,356 - mmseg - INFO - Iter [8750/160000]	lr: 4.753e-03, eta: 23:40:59, time: 0.534, data_time: 0.145, memory: 17140, decode.loss_ce: 0.1626, decode.acc_seg: 92.9907, aux_0.loss_ce: 0.1671, aux_0.acc_seg: 92.9077, aux_1.loss_ce: 0.1887, aux_1.acc_seg: 91.9251, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 97.3099, loss: 0.8634
2023-05-01 23:51:16,173 - mmseg - INFO - Iter [8800/160000]	lr: 4.752e-03, eta: 23:40:07, time: 0.536, data_time: 0.146, memory: 17140, decode.loss_ce: 0.1645, decode.acc_seg: 92.6948, aux_0.loss_ce: 0.1683, aux_0.acc_seg: 92.5683, aux_1.loss_ce: 0.1913, aux_1.acc_seg: 91.4588, aux_2.loss_ce: 0.0940, aux_2.loss_dice: 0.2458, aux_2.acc_seg: 97.2806, loss: 0.8638
2023-05-01 23:51:43,592 - mmseg - INFO - Iter [8850/160000]	lr: 4.750e-03, eta: 23:39:26, time: 0.548, data_time: 0.156, memory: 17140, decode.loss_ce: 0.1638, decode.acc_seg: 92.7929, aux_0.loss_ce: 0.1680, aux_0.acc_seg: 92.7002, aux_1.loss_ce: 0.1891, aux_1.acc_seg: 91.6652, aux_2.loss_ce: 0.0967, aux_2.loss_dice: 0.2528, aux_2.acc_seg: 97.2102, loss: 0.8705
2023-05-01 23:52:14,428 - mmseg - INFO - Iter [8900/160000]	lr: 4.749e-03, eta: 23:39:43, time: 0.617, data_time: 0.226, memory: 17140, decode.loss_ce: 0.1679, decode.acc_seg: 92.7397, aux_0.loss_ce: 0.1711, aux_0.acc_seg: 92.6904, aux_1.loss_ce: 0.1928, aux_1.acc_seg: 91.5936, aux_2.loss_ce: 0.0950, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 97.2797, loss: 0.8773
2023-05-01 23:52:40,443 - mmseg - INFO - Iter [8950/160000]	lr: 4.748e-03, eta: 23:38:38, time: 0.520, data_time: 0.125, memory: 17140, decode.loss_ce: 0.1602, decode.acc_seg: 92.9419, aux_0.loss_ce: 0.1648, aux_0.acc_seg: 92.8121, aux_1.loss_ce: 0.1862, aux_1.acc_seg: 91.7851, aux_2.loss_ce: 0.0935, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 97.3211, loss: 0.8525
2023-05-01 23:53:06,840 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-01 23:53:06,840 - mmseg - INFO - Iter [9000/160000]	lr: 4.746e-03, eta: 23:37:40, time: 0.528, data_time: 0.131, memory: 17140, decode.loss_ce: 0.1913, decode.acc_seg: 91.8983, aux_0.loss_ce: 0.1948, aux_0.acc_seg: 91.7859, aux_1.loss_ce: 0.2137, aux_1.acc_seg: 90.8184, aux_2.loss_ce: 0.0931, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 97.3518, loss: 0.9420
2023-05-01 23:53:33,501 - mmseg - INFO - Iter [9050/160000]	lr: 4.745e-03, eta: 23:36:47, time: 0.533, data_time: 0.133, memory: 17140, decode.loss_ce: 0.1945, decode.acc_seg: 91.6631, aux_0.loss_ce: 0.1952, aux_0.acc_seg: 91.6438, aux_1.loss_ce: 0.2128, aux_1.acc_seg: 90.8281, aux_2.loss_ce: 0.0954, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 97.2711, loss: 0.9491
2023-05-01 23:54:03,643 - mmseg - INFO - Iter [9100/160000]	lr: 4.743e-03, eta: 23:36:51, time: 0.603, data_time: 0.213, memory: 17140, decode.loss_ce: 0.1738, decode.acc_seg: 92.4672, aux_0.loss_ce: 0.1755, aux_0.acc_seg: 92.4475, aux_1.loss_ce: 0.1969, aux_1.acc_seg: 91.3642, aux_2.loss_ce: 0.0926, aux_2.loss_dice: 0.2446, aux_2.acc_seg: 97.3540, loss: 0.8834
2023-05-01 23:54:29,971 - mmseg - INFO - Iter [9150/160000]	lr: 4.742e-03, eta: 23:35:53, time: 0.527, data_time: 0.137, memory: 17140, decode.loss_ce: 0.1730, decode.acc_seg: 92.6811, aux_0.loss_ce: 0.1779, aux_0.acc_seg: 92.6015, aux_1.loss_ce: 0.1981, aux_1.acc_seg: 91.6061, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2507, aux_2.acc_seg: 97.2930, loss: 0.8946
2023-05-01 23:54:56,616 - mmseg - INFO - Iter [9200/160000]	lr: 4.741e-03, eta: 23:35:00, time: 0.533, data_time: 0.141, memory: 17140, decode.loss_ce: 0.1883, decode.acc_seg: 91.9738, aux_0.loss_ce: 0.1908, aux_0.acc_seg: 91.9196, aux_1.loss_ce: 0.2120, aux_1.acc_seg: 90.8746, aux_2.loss_ce: 0.0963, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 97.2464, loss: 0.9397
2023-05-01 23:55:23,636 - mmseg - INFO - Iter [9250/160000]	lr: 4.739e-03, eta: 23:34:13, time: 0.540, data_time: 0.142, memory: 17140, decode.loss_ce: 0.1732, decode.acc_seg: 92.3697, aux_0.loss_ce: 0.1749, aux_0.acc_seg: 92.3348, aux_1.loss_ce: 0.1965, aux_1.acc_seg: 91.2973, aux_2.loss_ce: 0.0924, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 97.3625, loss: 0.8844
2023-05-01 23:55:53,913 - mmseg - INFO - Iter [9300/160000]	lr: 4.738e-03, eta: 23:34:20, time: 0.606, data_time: 0.214, memory: 17140, decode.loss_ce: 0.1665, decode.acc_seg: 92.6728, aux_0.loss_ce: 0.1713, aux_0.acc_seg: 92.5895, aux_1.loss_ce: 0.1931, aux_1.acc_seg: 91.5332, aux_2.loss_ce: 0.0940, aux_2.loss_dice: 0.2476, aux_2.acc_seg: 97.2657, loss: 0.8725
2023-05-01 23:56:21,261 - mmseg - INFO - Iter [9350/160000]	lr: 4.736e-03, eta: 23:33:39, time: 0.547, data_time: 0.152, memory: 17140, decode.loss_ce: 0.1752, decode.acc_seg: 92.5824, aux_0.loss_ce: 0.1784, aux_0.acc_seg: 92.5051, aux_1.loss_ce: 0.1997, aux_1.acc_seg: 91.4744, aux_2.loss_ce: 0.0963, aux_2.loss_dice: 0.2524, aux_2.acc_seg: 97.2450, loss: 0.9020
2023-05-01 23:56:50,317 - mmseg - INFO - Iter [9400/160000]	lr: 4.735e-03, eta: 23:33:25, time: 0.581, data_time: 0.183, memory: 17140, decode.loss_ce: 0.1652, decode.acc_seg: 92.7382, aux_0.loss_ce: 0.1685, aux_0.acc_seg: 92.6803, aux_1.loss_ce: 0.1907, aux_1.acc_seg: 91.6106, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 97.2705, loss: 0.8705
2023-05-01 23:57:20,725 - mmseg - INFO - Iter [9450/160000]	lr: 4.733e-03, eta: 23:33:33, time: 0.608, data_time: 0.212, memory: 17140, decode.loss_ce: 0.1661, decode.acc_seg: 92.7130, aux_0.loss_ce: 0.1689, aux_0.acc_seg: 92.6887, aux_1.loss_ce: 0.1893, aux_1.acc_seg: 91.7009, aux_2.loss_ce: 0.0943, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 97.3291, loss: 0.8694
2023-05-01 23:57:48,315 - mmseg - INFO - Iter [9500/160000]	lr: 4.732e-03, eta: 23:32:55, time: 0.552, data_time: 0.164, memory: 17140, decode.loss_ce: 0.1577, decode.acc_seg: 93.1124, aux_0.loss_ce: 0.1621, aux_0.acc_seg: 93.0133, aux_1.loss_ce: 0.1845, aux_1.acc_seg: 91.9502, aux_2.loss_ce: 0.0967, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 97.2032, loss: 0.8519
2023-05-01 23:58:15,186 - mmseg - INFO - Iter [9550/160000]	lr: 4.731e-03, eta: 23:32:07, time: 0.537, data_time: 0.151, memory: 17140, decode.loss_ce: 0.1759, decode.acc_seg: 92.4697, aux_0.loss_ce: 0.1809, aux_0.acc_seg: 92.3438, aux_1.loss_ce: 0.2009, aux_1.acc_seg: 91.3839, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 97.2753, loss: 0.9045
2023-05-01 23:58:42,307 - mmseg - INFO - Iter [9600/160000]	lr: 4.729e-03, eta: 23:31:22, time: 0.542, data_time: 0.144, memory: 17140, decode.loss_ce: 0.1732, decode.acc_seg: 92.3470, aux_0.loss_ce: 0.1765, aux_0.acc_seg: 92.3021, aux_1.loss_ce: 0.1991, aux_1.acc_seg: 91.1936, aux_2.loss_ce: 0.0931, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 97.3486, loss: 0.8901
2023-05-01 23:59:13,070 - mmseg - INFO - Iter [9650/160000]	lr: 4.728e-03, eta: 23:31:35, time: 0.615, data_time: 0.223, memory: 17140, decode.loss_ce: 0.1623, decode.acc_seg: 93.0674, aux_0.loss_ce: 0.1657, aux_0.acc_seg: 93.0022, aux_1.loss_ce: 0.1865, aux_1.acc_seg: 92.0181, aux_2.loss_ce: 0.0932, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 97.3472, loss: 0.8579
2023-05-01 23:59:39,571 - mmseg - INFO - Iter [9700/160000]	lr: 4.726e-03, eta: 23:30:41, time: 0.530, data_time: 0.139, memory: 17140, decode.loss_ce: 0.1884, decode.acc_seg: 91.9771, aux_0.loss_ce: 0.1909, aux_0.acc_seg: 91.9314, aux_1.loss_ce: 0.2106, aux_1.acc_seg: 90.9231, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 97.2734, loss: 0.9344
2023-05-02 00:00:07,009 - mmseg - INFO - Iter [9750/160000]	lr: 4.725e-03, eta: 23:30:02, time: 0.549, data_time: 0.145, memory: 17140, decode.loss_ce: 0.1943, decode.acc_seg: 91.8163, aux_0.loss_ce: 0.1967, aux_0.acc_seg: 91.7435, aux_1.loss_ce: 0.2189, aux_1.acc_seg: 90.6977, aux_2.loss_ce: 0.0978, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 97.1911, loss: 0.9599
2023-05-02 00:00:33,568 - mmseg - INFO - Iter [9800/160000]	lr: 4.724e-03, eta: 23:29:09, time: 0.531, data_time: 0.127, memory: 17140, decode.loss_ce: 0.1668, decode.acc_seg: 92.5369, aux_0.loss_ce: 0.1707, aux_0.acc_seg: 92.4437, aux_1.loss_ce: 0.1914, aux_1.acc_seg: 91.4572, aux_2.loss_ce: 0.0921, aux_2.loss_dice: 0.2445, aux_2.acc_seg: 97.3027, loss: 0.8654
2023-05-02 00:01:04,678 - mmseg - INFO - Iter [9850/160000]	lr: 4.722e-03, eta: 23:29:26, time: 0.622, data_time: 0.235, memory: 17140, decode.loss_ce: 0.1770, decode.acc_seg: 92.4355, aux_0.loss_ce: 0.1801, aux_0.acc_seg: 92.3680, aux_1.loss_ce: 0.2014, aux_1.acc_seg: 91.3437, aux_2.loss_ce: 0.0967, aux_2.loss_dice: 0.2521, aux_2.acc_seg: 97.2114, loss: 0.9073
2023-05-02 00:01:30,802 - mmseg - INFO - Iter [9900/160000]	lr: 4.721e-03, eta: 23:28:27, time: 0.522, data_time: 0.132, memory: 17140, decode.loss_ce: 0.1737, decode.acc_seg: 92.5146, aux_0.loss_ce: 0.1756, aux_0.acc_seg: 92.4909, aux_1.loss_ce: 0.1965, aux_1.acc_seg: 91.4847, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 97.3062, loss: 0.8878
2023-05-02 00:01:58,002 - mmseg - INFO - Iter [9950/160000]	lr: 4.719e-03, eta: 23:27:44, time: 0.544, data_time: 0.159, memory: 17140, decode.loss_ce: 0.1690, decode.acc_seg: 92.6985, aux_0.loss_ce: 0.1719, aux_0.acc_seg: 92.6430, aux_1.loss_ce: 0.1918, aux_1.acc_seg: 91.6283, aux_2.loss_ce: 0.0924, aux_2.loss_dice: 0.2472, aux_2.acc_seg: 97.3685, loss: 0.8724
2023-05-02 00:02:28,899 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-02 00:02:28,900 - mmseg - INFO - Iter [10000/160000]	lr: 4.718e-03, eta: 23:27:58, time: 0.618, data_time: 0.225, memory: 17140, decode.loss_ce: 0.1587, decode.acc_seg: 93.0689, aux_0.loss_ce: 0.1623, aux_0.acc_seg: 92.9663, aux_1.loss_ce: 0.1828, aux_1.acc_seg: 92.0168, aux_2.loss_ce: 0.0913, aux_2.loss_dice: 0.2454, aux_2.acc_seg: 97.3634, loss: 0.8406
2023-05-02 00:02:55,486 - mmseg - INFO - Iter [10050/160000]	lr: 4.717e-03, eta: 23:27:06, time: 0.532, data_time: 0.142, memory: 17140, decode.loss_ce: 0.1543, decode.acc_seg: 93.1754, aux_0.loss_ce: 0.1598, aux_0.acc_seg: 93.0896, aux_1.loss_ce: 0.1811, aux_1.acc_seg: 91.9891, aux_2.loss_ce: 0.0957, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 97.2218, loss: 0.8391
2023-05-02 00:03:22,690 - mmseg - INFO - Iter [10100/160000]	lr: 4.715e-03, eta: 23:26:24, time: 0.544, data_time: 0.145, memory: 17140, decode.loss_ce: 0.1645, decode.acc_seg: 92.7605, aux_0.loss_ce: 0.1668, aux_0.acc_seg: 92.7091, aux_1.loss_ce: 0.1869, aux_1.acc_seg: 91.7275, aux_2.loss_ce: 0.0921, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 97.3562, loss: 0.8566
2023-05-02 00:03:49,370 - mmseg - INFO - Iter [10150/160000]	lr: 4.714e-03, eta: 23:25:34, time: 0.534, data_time: 0.144, memory: 17140, decode.loss_ce: 0.1591, decode.acc_seg: 92.9295, aux_0.loss_ce: 0.1626, aux_0.acc_seg: 92.8332, aux_1.loss_ce: 0.1850, aux_1.acc_seg: 91.7878, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 97.2943, loss: 0.8478
2023-05-02 00:04:20,351 - mmseg - INFO - Iter [10200/160000]	lr: 4.712e-03, eta: 23:25:47, time: 0.620, data_time: 0.228, memory: 17140, decode.loss_ce: 0.1510, decode.acc_seg: 93.2100, aux_0.loss_ce: 0.1555, aux_0.acc_seg: 93.0679, aux_1.loss_ce: 0.1760, aux_1.acc_seg: 92.0987, aux_2.loss_ce: 0.0935, aux_2.loss_dice: 0.2457, aux_2.acc_seg: 97.2792, loss: 0.8218
2023-05-02 00:04:45,515 - mmseg - INFO - Iter [10250/160000]	lr: 4.711e-03, eta: 23:24:36, time: 0.503, data_time: 0.119, memory: 17140, decode.loss_ce: 0.1644, decode.acc_seg: 93.0180, aux_0.loss_ce: 0.1664, aux_0.acc_seg: 92.9493, aux_1.loss_ce: 0.1881, aux_1.acc_seg: 91.9318, aux_2.loss_ce: 0.0950, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 97.2611, loss: 0.8640
2023-05-02 00:05:13,116 - mmseg - INFO - Iter [10300/160000]	lr: 4.709e-03, eta: 23:24:00, time: 0.552, data_time: 0.160, memory: 17140, decode.loss_ce: 0.1534, decode.acc_seg: 93.2981, aux_0.loss_ce: 0.1593, aux_0.acc_seg: 93.1527, aux_1.loss_ce: 0.1790, aux_1.acc_seg: 92.2140, aux_2.loss_ce: 0.0930, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 97.3051, loss: 0.8332
2023-05-02 00:05:40,250 - mmseg - INFO - Iter [10350/160000]	lr: 4.708e-03, eta: 23:23:17, time: 0.543, data_time: 0.149, memory: 17140, decode.loss_ce: 0.1644, decode.acc_seg: 92.9052, aux_0.loss_ce: 0.1679, aux_0.acc_seg: 92.8297, aux_1.loss_ce: 0.1865, aux_1.acc_seg: 91.8845, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 97.2619, loss: 0.8627
2023-05-02 00:06:10,343 - mmseg - INFO - Iter [10400/160000]	lr: 4.707e-03, eta: 23:23:17, time: 0.602, data_time: 0.208, memory: 17140, decode.loss_ce: 0.1645, decode.acc_seg: 92.5937, aux_0.loss_ce: 0.1677, aux_0.acc_seg: 92.5256, aux_1.loss_ce: 0.1890, aux_1.acc_seg: 91.5391, aux_2.loss_ce: 0.0923, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 97.3379, loss: 0.8599
2023-05-02 00:06:37,736 - mmseg - INFO - Iter [10450/160000]	lr: 4.705e-03, eta: 23:22:38, time: 0.548, data_time: 0.149, memory: 17140, decode.loss_ce: 0.1687, decode.acc_seg: 92.8609, aux_0.loss_ce: 0.1705, aux_0.acc_seg: 92.8069, aux_1.loss_ce: 0.1921, aux_1.acc_seg: 91.7916, aux_2.loss_ce: 0.0958, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 97.2260, loss: 0.8773
2023-05-02 00:07:04,451 - mmseg - INFO - Iter [10500/160000]	lr: 4.704e-03, eta: 23:21:50, time: 0.534, data_time: 0.142, memory: 17140, decode.loss_ce: 0.1656, decode.acc_seg: 92.7052, aux_0.loss_ce: 0.1699, aux_0.acc_seg: 92.6114, aux_1.loss_ce: 0.1892, aux_1.acc_seg: 91.6359, aux_2.loss_ce: 0.0932, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 97.3252, loss: 0.8667
2023-05-02 00:07:34,904 - mmseg - INFO - Iter [10550/160000]	lr: 4.702e-03, eta: 23:21:55, time: 0.609, data_time: 0.220, memory: 17140, decode.loss_ce: 0.1652, decode.acc_seg: 92.7522, aux_0.loss_ce: 0.1676, aux_0.acc_seg: 92.7256, aux_1.loss_ce: 0.1877, aux_1.acc_seg: 91.7552, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2466, aux_2.acc_seg: 97.2844, loss: 0.8610
2023-05-02 00:08:01,340 - mmseg - INFO - Iter [10600/160000]	lr: 4.701e-03, eta: 23:21:02, time: 0.529, data_time: 0.144, memory: 17140, decode.loss_ce: 0.1559, decode.acc_seg: 93.3154, aux_0.loss_ce: 0.1595, aux_0.acc_seg: 93.2566, aux_1.loss_ce: 0.1804, aux_1.acc_seg: 92.2734, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2507, aux_2.acc_seg: 97.2303, loss: 0.8421
2023-05-02 00:08:29,043 - mmseg - INFO - Iter [10650/160000]	lr: 4.700e-03, eta: 23:20:28, time: 0.554, data_time: 0.168, memory: 17140, decode.loss_ce: 0.1622, decode.acc_seg: 93.1469, aux_0.loss_ce: 0.1666, aux_0.acc_seg: 93.0494, aux_1.loss_ce: 0.1877, aux_1.acc_seg: 92.0268, aux_2.loss_ce: 0.0950, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 97.2738, loss: 0.8605
2023-05-02 00:08:55,358 - mmseg - INFO - Iter [10700/160000]	lr: 4.698e-03, eta: 23:19:35, time: 0.526, data_time: 0.129, memory: 17140, decode.loss_ce: 0.1585, decode.acc_seg: 93.0121, aux_0.loss_ce: 0.1615, aux_0.acc_seg: 92.9534, aux_1.loss_ce: 0.1833, aux_1.acc_seg: 91.9092, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 97.2676, loss: 0.8456
2023-05-02 00:09:26,303 - mmseg - INFO - Iter [10750/160000]	lr: 4.697e-03, eta: 23:19:46, time: 0.619, data_time: 0.222, memory: 17140, decode.loss_ce: 0.1588, decode.acc_seg: 93.0646, aux_0.loss_ce: 0.1634, aux_0.acc_seg: 92.9292, aux_1.loss_ce: 0.1836, aux_1.acc_seg: 91.9888, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 97.3126, loss: 0.8481
2023-05-02 00:09:53,603 - mmseg - INFO - Iter [10800/160000]	lr: 4.695e-03, eta: 23:19:06, time: 0.546, data_time: 0.151, memory: 17140, decode.loss_ce: 0.1681, decode.acc_seg: 92.6722, aux_0.loss_ce: 0.1720, aux_0.acc_seg: 92.5487, aux_1.loss_ce: 0.1930, aux_1.acc_seg: 91.5643, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 97.2808, loss: 0.8763
2023-05-02 00:10:19,557 - mmseg - INFO - Iter [10850/160000]	lr: 4.694e-03, eta: 23:18:08, time: 0.519, data_time: 0.131, memory: 17140, decode.loss_ce: 0.1714, decode.acc_seg: 92.5444, aux_0.loss_ce: 0.1724, aux_0.acc_seg: 92.5378, aux_1.loss_ce: 0.1940, aux_1.acc_seg: 91.5238, aux_2.loss_ce: 0.0930, aux_2.loss_dice: 0.2471, aux_2.acc_seg: 97.3457, loss: 0.8779
2023-05-02 00:10:45,712 - mmseg - INFO - Iter [10900/160000]	lr: 4.692e-03, eta: 23:17:13, time: 0.523, data_time: 0.132, memory: 17140, decode.loss_ce: 0.1698, decode.acc_seg: 92.7532, aux_0.loss_ce: 0.1739, aux_0.acc_seg: 92.6596, aux_1.loss_ce: 0.1951, aux_1.acc_seg: 91.7013, aux_2.loss_ce: 0.0968, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 97.2237, loss: 0.8879
2023-05-02 00:11:16,523 - mmseg - INFO - Iter [10950/160000]	lr: 4.691e-03, eta: 23:17:22, time: 0.616, data_time: 0.222, memory: 17140, decode.loss_ce: 0.1561, decode.acc_seg: 93.1329, aux_0.loss_ce: 0.1595, aux_0.acc_seg: 93.0522, aux_1.loss_ce: 0.1812, aux_1.acc_seg: 91.9850, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 97.2604, loss: 0.8390
2023-05-02 00:11:43,789 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-02 00:11:43,789 - mmseg - INFO - Iter [11000/160000]	lr: 4.690e-03, eta: 23:16:42, time: 0.545, data_time: 0.153, memory: 17140, decode.loss_ce: 0.1587, decode.acc_seg: 93.0500, aux_0.loss_ce: 0.1619, aux_0.acc_seg: 93.0019, aux_1.loss_ce: 0.1823, aux_1.acc_seg: 92.0704, aux_2.loss_ce: 0.0925, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 97.3787, loss: 0.8424
2023-05-02 00:12:10,704 - mmseg - INFO - Iter [11050/160000]	lr: 4.688e-03, eta: 23:15:57, time: 0.538, data_time: 0.156, memory: 17140, decode.loss_ce: 0.1703, decode.acc_seg: 92.5807, aux_0.loss_ce: 0.1724, aux_0.acc_seg: 92.5648, aux_1.loss_ce: 0.1920, aux_1.acc_seg: 91.5623, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 97.2791, loss: 0.8787
2023-05-02 00:12:37,077 - mmseg - INFO - Iter [11100/160000]	lr: 4.687e-03, eta: 23:15:06, time: 0.527, data_time: 0.137, memory: 17140, decode.loss_ce: 0.1717, decode.acc_seg: 92.5487, aux_0.loss_ce: 0.1747, aux_0.acc_seg: 92.4534, aux_1.loss_ce: 0.1939, aux_1.acc_seg: 91.4929, aux_2.loss_ce: 0.0954, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 97.2713, loss: 0.8858
2023-05-02 00:13:07,859 - mmseg - INFO - Iter [11150/160000]	lr: 4.685e-03, eta: 23:15:14, time: 0.616, data_time: 0.224, memory: 17140, decode.loss_ce: 0.1548, decode.acc_seg: 93.2331, aux_0.loss_ce: 0.1595, aux_0.acc_seg: 93.1228, aux_1.loss_ce: 0.1796, aux_1.acc_seg: 92.1403, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2463, aux_2.acc_seg: 97.2732, loss: 0.8340
2023-05-02 00:13:34,586 - mmseg - INFO - Iter [11200/160000]	lr: 4.684e-03, eta: 23:14:27, time: 0.535, data_time: 0.140, memory: 17140, decode.loss_ce: 0.1643, decode.acc_seg: 92.8746, aux_0.loss_ce: 0.1669, aux_0.acc_seg: 92.8290, aux_1.loss_ce: 0.1864, aux_1.acc_seg: 91.9040, aux_2.loss_ce: 0.0922, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 97.3284, loss: 0.8575
2023-05-02 00:14:01,745 - mmseg - INFO - Iter [11250/160000]	lr: 4.683e-03, eta: 23:13:46, time: 0.542, data_time: 0.149, memory: 17140, decode.loss_ce: 0.1577, decode.acc_seg: 93.1925, aux_0.loss_ce: 0.1602, aux_0.acc_seg: 93.1336, aux_1.loss_ce: 0.1820, aux_1.acc_seg: 92.1088, aux_2.loss_ce: 0.0944, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 97.2648, loss: 0.8427
2023-05-02 00:14:31,785 - mmseg - INFO - Iter [11300/160000]	lr: 4.681e-03, eta: 23:13:43, time: 0.601, data_time: 0.215, memory: 17140, decode.loss_ce: 0.1536, decode.acc_seg: 93.2879, aux_0.loss_ce: 0.1573, aux_0.acc_seg: 93.1882, aux_1.loss_ce: 0.1791, aux_1.acc_seg: 92.1476, aux_2.loss_ce: 0.0961, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 97.2113, loss: 0.8361
2023-05-02 00:14:57,445 - mmseg - INFO - Iter [11350/160000]	lr: 4.680e-03, eta: 23:12:43, time: 0.513, data_time: 0.120, memory: 17140, decode.loss_ce: 0.1531, decode.acc_seg: 93.2712, aux_0.loss_ce: 0.1567, aux_0.acc_seg: 93.2114, aux_1.loss_ce: 0.1782, aux_1.acc_seg: 92.1718, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2481, aux_2.acc_seg: 97.2887, loss: 0.8298
2023-05-02 00:15:22,025 - mmseg - INFO - Iter [11400/160000]	lr: 4.678e-03, eta: 23:11:29, time: 0.492, data_time: 0.099, memory: 17140, decode.loss_ce: 0.1588, decode.acc_seg: 93.1262, aux_0.loss_ce: 0.1619, aux_0.acc_seg: 93.0639, aux_1.loss_ce: 0.1820, aux_1.acc_seg: 92.0663, aux_2.loss_ce: 0.0942, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 97.3030, loss: 0.8453
2023-05-02 00:15:47,932 - mmseg - INFO - Iter [11450/160000]	lr: 4.677e-03, eta: 23:10:33, time: 0.518, data_time: 0.125, memory: 17140, decode.loss_ce: 0.1596, decode.acc_seg: 92.9064, aux_0.loss_ce: 0.1628, aux_0.acc_seg: 92.8127, aux_1.loss_ce: 0.1833, aux_1.acc_seg: 91.8034, aux_2.loss_ce: 0.0932, aux_2.loss_dice: 0.2459, aux_2.acc_seg: 97.2890, loss: 0.8449
2023-05-02 00:16:17,118 - mmseg - INFO - Iter [11500/160000]	lr: 4.675e-03, eta: 23:10:19, time: 0.584, data_time: 0.193, memory: 17140, decode.loss_ce: 0.1680, decode.acc_seg: 92.8560, aux_0.loss_ce: 0.1723, aux_0.acc_seg: 92.7458, aux_1.loss_ce: 0.1946, aux_1.acc_seg: 91.7019, aux_2.loss_ce: 0.0966, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 97.2069, loss: 0.8824
2023-05-02 00:16:43,844 - mmseg - INFO - Iter [11550/160000]	lr: 4.674e-03, eta: 23:09:33, time: 0.534, data_time: 0.138, memory: 17140, decode.loss_ce: 0.1515, decode.acc_seg: 93.3372, aux_0.loss_ce: 0.1549, aux_0.acc_seg: 93.2114, aux_1.loss_ce: 0.1764, aux_1.acc_seg: 92.2042, aux_2.loss_ce: 0.0944, aux_2.loss_dice: 0.2459, aux_2.acc_seg: 97.2459, loss: 0.8230
2023-05-02 00:17:10,675 - mmseg - INFO - Iter [11600/160000]	lr: 4.673e-03, eta: 23:08:49, time: 0.537, data_time: 0.136, memory: 17140, decode.loss_ce: 0.1557, decode.acc_seg: 93.3141, aux_0.loss_ce: 0.1597, aux_0.acc_seg: 93.1926, aux_1.loss_ce: 0.1802, aux_1.acc_seg: 92.2492, aux_2.loss_ce: 0.0940, aux_2.loss_dice: 0.2481, aux_2.acc_seg: 97.2944, loss: 0.8376
2023-05-02 00:17:37,149 - mmseg - INFO - Iter [11650/160000]	lr: 4.671e-03, eta: 23:08:01, time: 0.529, data_time: 0.126, memory: 17140, decode.loss_ce: 0.1641, decode.acc_seg: 92.8730, aux_0.loss_ce: 0.1671, aux_0.acc_seg: 92.7937, aux_1.loss_ce: 0.1857, aux_1.acc_seg: 91.8353, aux_2.loss_ce: 0.0943, aux_2.loss_dice: 0.2488, aux_2.acc_seg: 97.2652, loss: 0.8601
2023-05-02 00:18:07,860 - mmseg - INFO - Iter [11700/160000]	lr: 4.670e-03, eta: 23:08:06, time: 0.614, data_time: 0.229, memory: 17140, decode.loss_ce: 0.1847, decode.acc_seg: 92.2707, aux_0.loss_ce: 0.1872, aux_0.acc_seg: 92.2167, aux_1.loss_ce: 0.2052, aux_1.acc_seg: 91.2997, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 97.2424, loss: 0.9217
2023-05-02 00:18:33,947 - mmseg - INFO - Iter [11750/160000]	lr: 4.668e-03, eta: 23:07:13, time: 0.522, data_time: 0.130, memory: 17140, decode.loss_ce: 0.1636, decode.acc_seg: 92.7698, aux_0.loss_ce: 0.1661, aux_0.acc_seg: 92.7262, aux_1.loss_ce: 0.1860, aux_1.acc_seg: 91.7183, aux_2.loss_ce: 0.0928, aux_2.loss_dice: 0.2439, aux_2.acc_seg: 97.3122, loss: 0.8524
2023-05-02 00:19:00,428 - mmseg - INFO - Iter [11800/160000]	lr: 4.667e-03, eta: 23:06:25, time: 0.530, data_time: 0.136, memory: 17140, decode.loss_ce: 0.1618, decode.acc_seg: 92.9433, aux_0.loss_ce: 0.1653, aux_0.acc_seg: 92.8308, aux_1.loss_ce: 0.1840, aux_1.acc_seg: 91.9233, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2462, aux_2.acc_seg: 97.2710, loss: 0.8510
2023-05-02 00:19:30,486 - mmseg - INFO - Iter [11850/160000]	lr: 4.666e-03, eta: 23:06:22, time: 0.601, data_time: 0.210, memory: 17140, decode.loss_ce: 0.1617, decode.acc_seg: 92.7265, aux_0.loss_ce: 0.1645, aux_0.acc_seg: 92.6809, aux_1.loss_ce: 0.1844, aux_1.acc_seg: 91.7324, aux_2.loss_ce: 0.0928, aux_2.loss_dice: 0.2458, aux_2.acc_seg: 97.3099, loss: 0.8492
2023-05-02 00:19:56,693 - mmseg - INFO - Iter [11900/160000]	lr: 4.664e-03, eta: 23:05:30, time: 0.524, data_time: 0.131, memory: 17140, decode.loss_ce: 0.1482, decode.acc_seg: 93.5773, aux_0.loss_ce: 0.1511, aux_0.acc_seg: 93.4890, aux_1.loss_ce: 0.1702, aux_1.acc_seg: 92.6216, aux_2.loss_ce: 0.0917, aux_2.loss_dice: 0.2471, aux_2.acc_seg: 97.3476, loss: 0.8083
2023-05-02 00:20:23,765 - mmseg - INFO - Iter [11950/160000]	lr: 4.663e-03, eta: 23:04:50, time: 0.541, data_time: 0.148, memory: 17140, decode.loss_ce: 0.1573, decode.acc_seg: 92.9791, aux_0.loss_ce: 0.1599, aux_0.acc_seg: 92.8924, aux_1.loss_ce: 0.1795, aux_1.acc_seg: 91.8945, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 97.2983, loss: 0.8378
2023-05-02 00:20:47,508 - mmseg - INFO - Exp name: stdc1_1x16_512x1024_scale0.5_160k_cityscapes.py
2023-05-02 00:20:47,508 - mmseg - INFO - Iter [12000/160000]	lr: 4.661e-03, eta: 23:03:28, time: 0.474, data_time: 0.089, memory: 17140, decode.loss_ce: 0.1634, decode.acc_seg: 92.7946, aux_0.loss_ce: 0.1665, aux_0.acc_seg: 92.7552, aux_1.loss_ce: 0.1868, aux_1.acc_seg: 91.7612, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 97.2799, loss: 0.8568
2023-05-02 00:21:16,316 - mmseg - INFO - Iter [12050/160000]	lr: 4.660e-03, eta: 23:03:10, time: 0.577, data_time: 0.187, memory: 17140, decode.loss_ce: 0.1567, decode.acc_seg: 92.9723, aux_0.loss_ce: 0.1590, aux_0.acc_seg: 92.9528, aux_1.loss_ce: 0.1804, aux_1.acc_seg: 91.8391, aux_2.loss_ce: 0.0923, aux_2.loss_dice: 0.2454, aux_2.acc_seg: 97.3077, loss: 0.8338
2023-05-02 00:21:41,261 - mmseg - INFO - Iter [12100/160000]	lr: 4.658e-03, eta: 23:02:04, time: 0.499, data_time: 0.107, memory: 17140, decode.loss_ce: 0.1627, decode.acc_seg: 93.1026, aux_0.loss_ce: 0.1662, aux_0.acc_seg: 93.0357, aux_1.loss_ce: 0.1876, aux_1.acc_seg: 92.0394, aux_2.loss_ce: 0.0962, aux_2.loss_dice: 0.2510, aux_2.acc_seg: 97.2312, loss: 0.8637
2023-05-02 00:22:06,813 - mmseg - INFO - Iter [12150/160000]	lr: 4.657e-03, eta: 23:01:06, time: 0.511, data_time: 0.119, memory: 17140, decode.loss_ce: 0.1548, decode.acc_seg: 93.2485, aux_0.loss_ce: 0.1570, aux_0.acc_seg: 93.2271, aux_1.loss_ce: 0.1774, aux_1.acc_seg: 92.2014, aux_2.loss_ce: 0.0924, aux_2.loss_dice: 0.2456, aux_2.acc_seg: 97.3354, loss: 0.8272
2023-05-02 00:22:32,062 - mmseg - INFO - Iter [12200/160000]	lr: 4.656e-03, eta: 23:00:04, time: 0.505, data_time: 0.118, memory: 17140, decode.loss_ce: 0.1536, decode.acc_seg: 93.3570, aux_0.loss_ce: 0.1572, aux_0.acc_seg: 93.2577, aux_1.loss_ce: 0.1773, aux_1.acc_seg: 92.2801, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 97.2967, loss: 0.8292
2023-05-02 00:23:02,175 - mmseg - INFO - Iter [12250/160000]	lr: 4.654e-03, eta: 23:00:01, time: 0.602, data_time: 0.212, memory: 17140, decode.loss_ce: 0.1515, decode.acc_seg: 93.1603, aux_0.loss_ce: 0.1535, aux_0.acc_seg: 93.1532, aux_1.loss_ce: 0.1728, aux_1.acc_seg: 92.1970, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2458, aux_2.acc_seg: 97.2803, loss: 0.8173
2023-05-02 00:23:29,267 - mmseg - INFO - Iter [12300/160000]	lr: 4.653e-03, eta: 22:59:22, time: 0.542, data_time: 0.146, memory: 17140, decode.loss_ce: 0.2060, decode.acc_seg: 91.2572, aux_0.loss_ce: 0.2089, aux_0.acc_seg: 91.2123, aux_1.loss_ce: 0.2283, aux_1.acc_seg: 90.3093, aux_2.loss_ce: 0.0968, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 97.2555, loss: 0.9914
2023-05-02 00:23:56,668 - mmseg - INFO - Iter [12350/160000]	lr: 4.651e-03, eta: 22:58:47, time: 0.548, data_time: 0.151, memory: 17140, decode.loss_ce: 0.1737, decode.acc_seg: 92.4606, aux_0.loss_ce: 0.1756, aux_0.acc_seg: 92.4133, aux_1.loss_ce: 0.1953, aux_1.acc_seg: 91.4365, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 97.3009, loss: 0.8881
2023-05-02 00:24:27,335 - mmseg - INFO - Iter [12400/160000]	lr: 4.650e-03, eta: 22:58:50, time: 0.613, data_time: 0.220, memory: 17140, decode.loss_ce: 0.1605, decode.acc_seg: 92.9854, aux_0.loss_ce: 0.1633, aux_0.acc_seg: 92.9494, aux_1.loss_ce: 0.1836, aux_1.acc_seg: 91.9856, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 97.2615, loss: 0.8490
2023-05-02 00:24:53,505 - mmseg - INFO - Iter [12450/160000]	lr: 4.649e-03, eta: 22:58:00, time: 0.523, data_time: 0.139, memory: 17140, decode.loss_ce: 0.1560, decode.acc_seg: 93.1150, aux_0.loss_ce: 0.1597, aux_0.acc_seg: 93.0442, aux_1.loss_ce: 0.1795, aux_1.acc_seg: 92.0446, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 97.2881, loss: 0.8383
2023-05-02 00:25:20,614 - mmseg - INFO - Iter [12500/160000]	lr: 4.647e-03, eta: 22:57:21, time: 0.542, data_time: 0.148, memory: 17140, decode.loss_ce: 0.1565, decode.acc_seg: 93.1221, aux_0.loss_ce: 0.1588, aux_0.acc_seg: 93.0762, aux_1.loss_ce: 0.1798, aux_1.acc_seg: 92.0784, aux_2.loss_ce: 0.0931, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 97.2824, loss: 0.8351
2023-05-02 00:25:47,139 - mmseg - INFO - Iter [12550/160000]	lr: 4.646e-03, eta: 22:56:36, time: 0.530, data_time: 0.141, memory: 17140, decode.loss_ce: 0.1618, decode.acc_seg: 92.8352, aux_0.loss_ce: 0.1654, aux_0.acc_seg: 92.7748, aux_1.loss_ce: 0.1840, aux_1.acc_seg: 91.8619, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 97.3284, loss: 0.8523
2023-05-02 00:26:17,796 - mmseg - INFO - Iter [12600/160000]	lr: 4.644e-03, eta: 22:56:39, time: 0.613, data_time: 0.222, memory: 17140, decode.loss_ce: 0.1713, decode.acc_seg: 92.7334, aux_0.loss_ce: 0.1728, aux_0.acc_seg: 92.6994, aux_1.loss_ce: 0.1945, aux_1.acc_seg: 91.6627, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 97.2393, loss: 0.8844
2023-05-02 00:26:44,410 - mmseg - INFO - Iter [12650/160000]	lr: 4.643e-03, eta: 22:55:55, time: 0.532, data_time: 0.142, memory: 17140, decode.loss_ce: 0.1538, decode.acc_seg: 93.2642, aux_0.loss_ce: 0.1565, aux_0.acc_seg: 93.1743, aux_1.loss_ce: 0.1765, aux_1.acc_seg: 92.1874, aux_2.loss_ce: 0.0930, aux_2.loss_dice: 0.2452, aux_2.acc_seg: 97.2946, loss: 0.8250
2023-05-02 00:27:10,797 - mmseg - INFO - Iter [12700/160000]	lr: 4.641e-03, eta: 22:55:08, time: 0.528, data_time: 0.134, memory: 17140, decode.loss_ce: 0.1614, decode.acc_seg: 92.9496, aux_0.loss_ce: 0.1636, aux_0.acc_seg: 92.9114, aux_1.loss_ce: 0.1855, aux_1.acc_seg: 91.8719, aux_2.loss_ce: 0.0958, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 97.2494, loss: 0.8562
2023-05-02 00:27:38,608 - mmseg - INFO - Iter [12750/160000]	lr: 4.640e-03, eta: 22:54:37, time: 0.556, data_time: 0.169, memory: 17140, decode.loss_ce: 0.1502, decode.acc_seg: 93.3782, aux_0.loss_ce: 0.1545, aux_0.acc_seg: 93.2650, aux_1.loss_ce: 0.1747, aux_1.acc_seg: 92.2934, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2449, aux_2.acc_seg: 97.2521, loss: 0.8179
2023-05-02 00:28:08,543 - mmseg - INFO - Iter [12800/160000]	lr: 4.639e-03, eta: 22:54:32, time: 0.599, data_time: 0.208, memory: 17140, decode.loss_ce: 0.1583, decode.acc_seg: 92.9232, aux_0.loss_ce: 0.1619, aux_0.acc_seg: 92.8438, aux_1.loss_ce: 0.1788, aux_1.acc_seg: 92.0311, aux_2.loss_ce: 0.0927, aux_2.loss_dice: 0.2450, aux_2.acc_seg: 97.2937, loss: 0.8366
