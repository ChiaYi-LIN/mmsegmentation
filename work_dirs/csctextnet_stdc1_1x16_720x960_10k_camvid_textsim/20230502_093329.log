2023-05-02 09:33:29,029 - mmseg - INFO - Multi-processing start method is `None`
2023-05-02 09:33:29,033 - mmseg - INFO - OpenCV num_threads is `96
2023-05-02 09:33:29,131 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+e7ed570
------------------------------------------------------------

2023-05-02 09:33:29,132 - mmseg - INFO - Distributed training: False
2023-05-02 09:33:29,988 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1035, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=13,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='CSC',
        CLASSES=('Bicyclist', 'Building', 'Car', 'Column_Pole', 'Fence',
                 'Pedestrian', 'Road', 'Sidewalk', 'SignSymbol', 'Sky',
                 'Tree')),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=11,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=690000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='IdentityHead',
            in_channels=11,
            channels=1,
            num_classes=11,
            in_index=5,
            loss_decode=dict(
                type='Text2TextContrastiveLoss',
                loss_weight=0.4,
                text_embeddings='./pretrained/textfeat_camvid_11_RN50_1024.pth'
            ))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CamVidDataset'
data_root = 'data/CamVid/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (720, 960)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        img_scale=(960, 720),
        ratio_range=(0.5, 2.5),
        scale_step_size=0.25),
    dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(960, 720),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='train',
        ann_dir='train_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize',
                img_scale=(960, 720),
                ratio_range=(0.5, 2.5),
                scale_step_size=0.25),
            dict(type='RandomCrop', crop_size=(720, 960), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(720, 960), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CamVidDataset',
        data_root='data/CamVid/',
        img_dir='val',
        ann_dir='val_labelIds',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(960, 720),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.1,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            {
                'backbone.backbone': dict(lr_mult=0.1),
                'backbone.text_encoder': dict(lr_mult=0.0, decay_mult=0.0),
                'backbone.contexts': dict(decay_mult=0.0),
                '.bn.': dict(decay_mult=0.0)
            })))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=200,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_textsim'
gpu_ids = [0]
auto_resume = False

2023-05-02 09:33:29,988 - mmseg - INFO - Set random seed to 284269716, deterministic: False
2023-05-02 09:33:29,994 - mmseg - INFO - Loaded 367 images
2023-05-02 09:33:31,576 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-05-02 09:33:33,090 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.label_texts - torch.Size([11, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.contexts - torch.Size([11, 8, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.text_encoder.positional_embedding - torch.Size([13, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.text_projection - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.0.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.1.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.2.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.3.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.4.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.5.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.6.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.7.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.8.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.9.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.10.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.transformer.resblocks.11.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.token_embedding.weight - torch.Size([49408, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.text_encoder.ln_final.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1035, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1035, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([11, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-05-02 09:33:33,096 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1035, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1035, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 11, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (4): IdentityHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): Text2TextContrastiveLoss()
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-05-02 09:33:40,674 - mmseg - INFO - Loaded 101 images
2023-05-02 09:33:40,675 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_textsim
2023-05-02 09:33:40,675 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-05-02 09:33:40,675 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2023-05-02 09:33:40,675 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/csctextnet_stdc1_1x16_720x960_10k_camvid_textsim by HardDiskBackend.
2023-05-02 09:34:40,852 - mmseg - INFO - Iter [50/10000]	lr: 2.439e-02, eta: 3:18:31, time: 1.197, data_time: 0.245, memory: 14762, decode.loss_ce: 1.3361, decode.acc_seg: 50.2733, aux_0.loss_ce: 1.3138, aux_0.acc_seg: 45.0010, aux_1.loss_ce: 1.3576, aux_1.acc_seg: 41.5149, aux_2.loss_ce: 0.3415, aux_2.loss_dice: 0.4982, aux_2.acc_seg: 89.7363, aux_3.loss_ce: 1.0375, aux_3.acc_seg: 60.2483, aux_4.loss_t2t: 0.1013, loss: 5.9862
2023-05-02 09:35:26,224 - mmseg - INFO - Iter [100/10000]	lr: 4.906e-02, eta: 2:53:37, time: 0.907, data_time: 0.189, memory: 14762, decode.loss_ce: 0.4323, decode.acc_seg: 82.5573, aux_0.loss_ce: 0.4386, aux_0.acc_seg: 82.9640, aux_1.loss_ce: 0.4677, aux_1.acc_seg: 81.9405, aux_2.loss_ce: 0.1633, aux_2.loss_dice: 0.4359, aux_2.acc_seg: 95.7875, aux_3.loss_ce: 0.4742, aux_3.acc_seg: 83.0455, aux_4.loss_t2t: 0.0879, loss: 2.4999
2023-05-02 09:36:11,930 - mmseg - INFO - Iter [150/10000]	lr: 7.350e-02, eta: 2:45:11, time: 0.914, data_time: 0.192, memory: 14762, decode.loss_ce: 0.3180, decode.acc_seg: 87.0272, aux_0.loss_ce: 0.3226, aux_0.acc_seg: 86.9453, aux_1.loss_ce: 0.3467, aux_1.acc_seg: 86.0673, aux_2.loss_ce: 0.1458, aux_2.loss_dice: 0.3296, aux_2.acc_seg: 95.9145, aux_3.loss_ce: 0.3777, aux_3.acc_seg: 86.0518, aux_4.loss_t2t: 0.0666, loss: 1.9072
2023-05-02 09:37:00,932 - mmseg - INFO - Iter [200/10000]	lr: 9.772e-02, eta: 2:43:16, time: 0.980, data_time: 0.256, memory: 14762, decode.loss_ce: 0.2606, decode.acc_seg: 89.0701, aux_0.loss_ce: 0.2678, aux_0.acc_seg: 88.8505, aux_1.loss_ce: 0.2893, aux_1.acc_seg: 88.1649, aux_2.loss_ce: 0.1405, aux_2.loss_dice: 0.3076, aux_2.acc_seg: 95.9379, aux_3.loss_ce: 0.3167, aux_3.acc_seg: 88.3527, aux_4.loss_t2t: 0.0570, loss: 1.6396
2023-05-02 09:37:46,620 - mmseg - INFO - Iter [250/10000]	lr: 9.776e-02, eta: 2:39:39, time: 0.914, data_time: 0.191, memory: 14762, decode.loss_ce: 0.2474, decode.acc_seg: 89.7193, aux_0.loss_ce: 0.2567, aux_0.acc_seg: 89.4239, aux_1.loss_ce: 0.2765, aux_1.acc_seg: 88.7751, aux_2.loss_ce: 0.1383, aux_2.loss_dice: 0.2988, aux_2.acc_seg: 95.9494, aux_3.loss_ce: 0.2992, aux_3.acc_seg: 89.0402, aux_4.loss_t2t: 0.0502, loss: 1.5671
2023-05-02 09:38:32,465 - mmseg - INFO - Iter [300/10000]	lr: 9.730e-02, eta: 2:37:04, time: 0.917, data_time: 0.196, memory: 14762, decode.loss_ce: 0.2627, decode.acc_seg: 88.9583, aux_0.loss_ce: 0.2598, aux_0.acc_seg: 89.1359, aux_1.loss_ce: 0.2808, aux_1.acc_seg: 88.3597, aux_2.loss_ce: 0.1377, aux_2.loss_dice: 0.2998, aux_2.acc_seg: 96.0167, aux_3.loss_ce: 0.3120, aux_3.acc_seg: 88.2438, aux_4.loss_t2t: 0.0474, loss: 1.6003
2023-05-02 09:39:17,645 - mmseg - INFO - Iter [350/10000]	lr: 9.685e-02, eta: 2:34:41, time: 0.904, data_time: 0.188, memory: 14762, decode.loss_ce: 0.2306, decode.acc_seg: 90.0248, aux_0.loss_ce: 0.2383, aux_0.acc_seg: 89.7649, aux_1.loss_ce: 0.2589, aux_1.acc_seg: 89.0995, aux_2.loss_ce: 0.1354, aux_2.loss_dice: 0.2949, aux_2.acc_seg: 96.0889, aux_3.loss_ce: 0.2999, aux_3.acc_seg: 88.7511, aux_4.loss_t2t: 0.0454, loss: 1.5034
2023-05-02 09:40:06,600 - mmseg - INFO - Iter [400/10000]	lr: 9.640e-02, eta: 2:34:14, time: 0.979, data_time: 0.257, memory: 14762, decode.loss_ce: 0.1947, decode.acc_seg: 91.4539, aux_0.loss_ce: 0.1989, aux_0.acc_seg: 91.3295, aux_1.loss_ce: 0.2221, aux_1.acc_seg: 90.4824, aux_2.loss_ce: 0.1345, aux_2.loss_dice: 0.2892, aux_2.acc_seg: 96.0752, aux_3.loss_ce: 0.2556, aux_3.acc_seg: 90.4045, aux_4.loss_t2t: 0.0392, loss: 1.3342
2023-05-02 09:40:51,600 - mmseg - INFO - Iter [450/10000]	lr: 9.595e-02, eta: 2:32:18, time: 0.900, data_time: 0.183, memory: 14762, decode.loss_ce: 0.1702, decode.acc_seg: 92.3932, aux_0.loss_ce: 0.1790, aux_0.acc_seg: 92.0615, aux_1.loss_ce: 0.2034, aux_1.acc_seg: 91.1455, aux_2.loss_ce: 0.1344, aux_2.loss_dice: 0.2857, aux_2.acc_seg: 95.9783, aux_3.loss_ce: 0.2320, aux_3.acc_seg: 91.1573, aux_4.loss_t2t: 0.0379, loss: 1.2427
2023-05-02 09:41:36,962 - mmseg - INFO - Iter [500/10000]	lr: 9.550e-02, eta: 2:30:43, time: 0.907, data_time: 0.189, memory: 14762, decode.loss_ce: 0.1632, decode.acc_seg: 92.6478, aux_0.loss_ce: 0.1667, aux_0.acc_seg: 92.5305, aux_1.loss_ce: 0.1899, aux_1.acc_seg: 91.6335, aux_2.loss_ce: 0.1308, aux_2.loss_dice: 0.2828, aux_2.acc_seg: 96.0933, aux_3.loss_ce: 0.2237, aux_3.acc_seg: 91.4537, aux_4.loss_t2t: 0.0357, loss: 1.1928
2023-05-02 09:42:21,980 - mmseg - INFO - Iter [550/10000]	lr: 9.505e-02, eta: 2:29:11, time: 0.900, data_time: 0.184, memory: 14762, decode.loss_ce: 0.1493, decode.acc_seg: 93.1999, aux_0.loss_ce: 0.1560, aux_0.acc_seg: 92.8658, aux_1.loss_ce: 0.1787, aux_1.acc_seg: 91.9668, aux_2.loss_ce: 0.1302, aux_2.loss_dice: 0.2802, aux_2.acc_seg: 96.0707, aux_3.loss_ce: 0.2162, aux_3.acc_seg: 91.6707, aux_4.loss_t2t: 0.0348, loss: 1.1452
2023-05-02 09:43:11,057 - mmseg - INFO - Iter [600/10000]	lr: 9.459e-02, eta: 2:28:50, time: 0.982, data_time: 0.258, memory: 14762, decode.loss_ce: 0.1543, decode.acc_seg: 93.0497, aux_0.loss_ce: 0.1579, aux_0.acc_seg: 92.8673, aux_1.loss_ce: 0.1782, aux_1.acc_seg: 92.0068, aux_2.loss_ce: 0.1311, aux_2.loss_dice: 0.2785, aux_2.acc_seg: 96.0102, aux_3.loss_ce: 0.2113, aux_3.acc_seg: 91.8939, aux_4.loss_t2t: 0.0334, loss: 1.1446
2023-05-02 09:43:57,293 - mmseg - INFO - Iter [650/10000]	lr: 9.414e-02, eta: 2:27:45, time: 0.925, data_time: 0.196, memory: 14762, decode.loss_ce: 0.1382, decode.acc_seg: 93.5701, aux_0.loss_ce: 0.1430, aux_0.acc_seg: 93.3528, aux_1.loss_ce: 0.1629, aux_1.acc_seg: 92.5319, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2772, aux_2.acc_seg: 96.1296, aux_3.loss_ce: 0.1991, aux_3.acc_seg: 92.2613, aux_4.loss_t2t: 0.0320, loss: 1.0814
2023-05-02 09:44:42,985 - mmseg - INFO - Iter [700/10000]	lr: 9.369e-02, eta: 2:26:34, time: 0.914, data_time: 0.191, memory: 14762, decode.loss_ce: 0.1332, decode.acc_seg: 93.6936, aux_0.loss_ce: 0.1379, aux_0.acc_seg: 93.4958, aux_1.loss_ce: 0.1581, aux_1.acc_seg: 92.5969, aux_2.loss_ce: 0.1295, aux_2.loss_dice: 0.2756, aux_2.acc_seg: 96.0381, aux_3.loss_ce: 0.1958, aux_3.acc_seg: 92.2570, aux_4.loss_t2t: 0.0309, loss: 1.0610
2023-05-02 09:45:31,089 - mmseg - INFO - Iter [750/10000]	lr: 9.323e-02, eta: 2:25:57, time: 0.962, data_time: 0.247, memory: 14762, decode.loss_ce: 0.1289, decode.acc_seg: 94.0525, aux_0.loss_ce: 0.1335, aux_0.acc_seg: 93.8240, aux_1.loss_ce: 0.1531, aux_1.acc_seg: 93.0295, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2750, aux_2.acc_seg: 96.0840, aux_3.loss_ce: 0.1902, aux_3.acc_seg: 92.6372, aux_4.loss_t2t: 0.0308, loss: 1.0405
2023-05-02 09:46:16,866 - mmseg - INFO - Iter [800/10000]	lr: 9.278e-02, eta: 2:24:52, time: 0.916, data_time: 0.190, memory: 14762, decode.loss_ce: 0.1353, decode.acc_seg: 93.8718, aux_0.loss_ce: 0.1411, aux_0.acc_seg: 93.6423, aux_1.loss_ce: 0.1602, aux_1.acc_seg: 92.8364, aux_2.loss_ce: 0.1287, aux_2.loss_dice: 0.2752, aux_2.acc_seg: 96.0584, aux_3.loss_ce: 0.1961, aux_3.acc_seg: 92.4949, aux_4.loss_t2t: 0.0297, loss: 1.0663
2023-05-02 09:47:03,099 - mmseg - INFO - Iter [850/10000]	lr: 9.233e-02, eta: 2:23:54, time: 0.925, data_time: 0.199, memory: 14762, decode.loss_ce: 0.1276, decode.acc_seg: 94.1311, aux_0.loss_ce: 0.1329, aux_0.acc_seg: 93.8902, aux_1.loss_ce: 0.1527, aux_1.acc_seg: 93.0292, aux_2.loss_ce: 0.1289, aux_2.loss_dice: 0.2743, aux_2.acc_seg: 95.9977, aux_3.loss_ce: 0.1907, aux_3.acc_seg: 92.6462, aux_4.loss_t2t: 0.0302, loss: 1.0372
2023-05-02 09:47:49,047 - mmseg - INFO - Iter [900/10000]	lr: 9.187e-02, eta: 2:22:54, time: 0.919, data_time: 0.194, memory: 14762, decode.loss_ce: 0.1206, decode.acc_seg: 94.5023, aux_0.loss_ce: 0.1262, aux_0.acc_seg: 94.2831, aux_1.loss_ce: 0.1462, aux_1.acc_seg: 93.4484, aux_2.loss_ce: 0.1316, aux_2.loss_dice: 0.2755, aux_2.acc_seg: 95.9205, aux_3.loss_ce: 0.1860, aux_3.acc_seg: 92.9694, aux_4.loss_t2t: 0.0298, loss: 1.0159
2023-05-02 09:48:38,560 - mmseg - INFO - Iter [950/10000]	lr: 9.142e-02, eta: 2:22:30, time: 0.990, data_time: 0.266, memory: 14762, decode.loss_ce: 0.1165, decode.acc_seg: 94.4212, aux_0.loss_ce: 0.1223, aux_0.acc_seg: 94.1862, aux_1.loss_ce: 0.1425, aux_1.acc_seg: 93.2824, aux_2.loss_ce: 0.1286, aux_2.loss_dice: 0.2710, aux_2.acc_seg: 95.9806, aux_3.loss_ce: 0.1790, aux_3.acc_seg: 92.9926, aux_4.loss_t2t: 0.0281, loss: 0.9881
2023-05-02 09:49:23,956 - mmseg - INFO - Saving checkpoint at 1000 iterations
2023-05-02 09:49:27,723 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 09:49:27,723 - mmseg - INFO - Iter [1000/10000]	lr: 9.096e-02, eta: 2:22:00, time: 0.984, data_time: 0.189, memory: 14762, decode.loss_ce: 0.1185, decode.acc_seg: 94.5258, aux_0.loss_ce: 0.1220, aux_0.acc_seg: 94.3795, aux_1.loss_ce: 0.1429, aux_1.acc_seg: 93.4976, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2710, aux_2.acc_seg: 96.0760, aux_3.loss_ce: 0.1818, aux_3.acc_seg: 93.1137, aux_4.loss_t2t: 0.0282, loss: 0.9906
2023-05-02 09:49:34,940 - mmseg - INFO - per class results:
2023-05-02 09:49:34,942 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 75.69 | 93.29 |
|   Building  | 90.44 | 91.94 |
|     Car     | 91.32 | 96.18 |
| Column_Pole | 14.99 | 18.71 |
|    Fence    | 70.86 | 94.86 |
|  Pedestrian | 47.47 | 86.85 |
|     Road    | 96.41 | 96.88 |
|   Sidewalk  | 89.69 | 97.25 |
|  SignSymbol |  0.16 |  0.16 |
|     Sky     | 94.02 | 97.88 |
|     Tree    | 93.02 |  97.2 |
+-------------+-------+-------+
2023-05-02 09:49:34,942 - mmseg - INFO - Summary:
2023-05-02 09:49:34,942 - mmseg - INFO - 
+------+-------+------+
| aAcc |  mIoU | mAcc |
+------+-------+------+
| 95.0 | 69.46 | 79.2 |
+------+-------+------+
2023-05-02 09:49:34,943 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 09:49:34,943 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9500, mIoU: 0.6946, mAcc: 0.7920, IoU.Bicyclist: 0.7569, IoU.Building: 0.9044, IoU.Car: 0.9132, IoU.Column_Pole: 0.1499, IoU.Fence: 0.7086, IoU.Pedestrian: 0.4747, IoU.Road: 0.9641, IoU.Sidewalk: 0.8969, IoU.SignSymbol: 0.0016, IoU.Sky: 0.9402, IoU.Tree: 0.9302, Acc.Bicyclist: 0.9329, Acc.Building: 0.9194, Acc.Car: 0.9618, Acc.Column_Pole: 0.1871, Acc.Fence: 0.9486, Acc.Pedestrian: 0.8685, Acc.Road: 0.9688, Acc.Sidewalk: 0.9725, Acc.SignSymbol: 0.0016, Acc.Sky: 0.9788, Acc.Tree: 0.9720
2023-05-02 09:50:19,979 - mmseg - INFO - Iter [1050/10000]	lr: 9.051e-02, eta: 2:21:55, time: 1.044, data_time: 0.327, memory: 14762, decode.loss_ce: 0.1128, decode.acc_seg: 94.7092, aux_0.loss_ce: 0.1172, aux_0.acc_seg: 94.5231, aux_1.loss_ce: 0.1366, aux_1.acc_seg: 93.6634, aux_2.loss_ce: 0.1285, aux_2.loss_dice: 0.2695, aux_2.acc_seg: 95.9694, aux_3.loss_ce: 0.1734, aux_3.acc_seg: 93.3352, aux_4.loss_t2t: 0.0276, loss: 0.9656
2023-05-02 09:51:05,727 - mmseg - INFO - Iter [1100/10000]	lr: 9.005e-02, eta: 2:20:52, time: 0.915, data_time: 0.192, memory: 14762, decode.loss_ce: 0.1126, decode.acc_seg: 94.6906, aux_0.loss_ce: 0.1175, aux_0.acc_seg: 94.4871, aux_1.loss_ce: 0.1368, aux_1.acc_seg: 93.6569, aux_2.loss_ce: 0.1288, aux_2.loss_dice: 0.2701, aux_2.acc_seg: 95.9262, aux_3.loss_ce: 0.1741, aux_3.acc_seg: 93.2821, aux_4.loss_t2t: 0.0270, loss: 0.9668
2023-05-02 09:51:53,920 - mmseg - INFO - Iter [1150/10000]	lr: 8.960e-02, eta: 2:20:10, time: 0.964, data_time: 0.250, memory: 14762, decode.loss_ce: 0.1060, decode.acc_seg: 94.8866, aux_0.loss_ce: 0.1104, aux_0.acc_seg: 94.6909, aux_1.loss_ce: 0.1307, aux_1.acc_seg: 93.7827, aux_2.loss_ce: 0.1275, aux_2.loss_dice: 0.2684, aux_2.acc_seg: 95.9874, aux_3.loss_ce: 0.1704, aux_3.acc_seg: 93.3145, aux_4.loss_t2t: 0.0268, loss: 0.9401
2023-05-02 09:52:39,711 - mmseg - INFO - Iter [1200/10000]	lr: 8.914e-02, eta: 2:19:10, time: 0.916, data_time: 0.193, memory: 14762, decode.loss_ce: 0.1039, decode.acc_seg: 95.0480, aux_0.loss_ce: 0.1084, aux_0.acc_seg: 94.8678, aux_1.loss_ce: 0.1277, aux_1.acc_seg: 93.9915, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2664, aux_2.acc_seg: 96.1545, aux_3.loss_ce: 0.1649, aux_3.acc_seg: 93.5953, aux_4.loss_t2t: 0.0266, loss: 0.9218
2023-05-02 09:53:25,594 - mmseg - INFO - Iter [1250/10000]	lr: 8.869e-02, eta: 2:18:12, time: 0.918, data_time: 0.196, memory: 14762, decode.loss_ce: 0.1013, decode.acc_seg: 95.0997, aux_0.loss_ce: 0.1059, aux_0.acc_seg: 94.9149, aux_1.loss_ce: 0.1259, aux_1.acc_seg: 93.9985, aux_2.loss_ce: 0.1254, aux_2.loss_dice: 0.2669, aux_2.acc_seg: 96.0643, aux_3.loss_ce: 0.1640, aux_3.acc_seg: 93.5678, aux_4.loss_t2t: 0.0263, loss: 0.9157
2023-05-02 09:54:15,001 - mmseg - INFO - Iter [1300/10000]	lr: 8.823e-02, eta: 2:17:38, time: 0.988, data_time: 0.265, memory: 14762, decode.loss_ce: 0.1055, decode.acc_seg: 94.9559, aux_0.loss_ce: 0.1093, aux_0.acc_seg: 94.7854, aux_1.loss_ce: 0.1299, aux_1.acc_seg: 93.8825, aux_2.loss_ce: 0.1252, aux_2.loss_dice: 0.2651, aux_2.acc_seg: 96.0307, aux_3.loss_ce: 0.1655, aux_3.acc_seg: 93.5167, aux_4.loss_t2t: 0.0256, loss: 0.9261
2023-05-02 09:55:00,331 - mmseg - INFO - Iter [1350/10000]	lr: 8.777e-02, eta: 2:16:37, time: 0.907, data_time: 0.187, memory: 14762, decode.loss_ce: 0.1127, decode.acc_seg: 94.7096, aux_0.loss_ce: 0.1176, aux_0.acc_seg: 94.5146, aux_1.loss_ce: 0.1370, aux_1.acc_seg: 93.6226, aux_2.loss_ce: 0.1266, aux_2.loss_dice: 0.2680, aux_2.acc_seg: 96.0269, aux_3.loss_ce: 0.1730, aux_3.acc_seg: 93.3146, aux_4.loss_t2t: 0.0263, loss: 0.9612
2023-05-02 09:55:46,329 - mmseg - INFO - Iter [1400/10000]	lr: 8.732e-02, eta: 2:15:41, time: 0.920, data_time: 0.194, memory: 14762, decode.loss_ce: 0.1098, decode.acc_seg: 94.8307, aux_0.loss_ce: 0.1149, aux_0.acc_seg: 94.6069, aux_1.loss_ce: 0.1332, aux_1.acc_seg: 93.7839, aux_2.loss_ce: 0.1264, aux_2.loss_dice: 0.2678, aux_2.acc_seg: 96.0613, aux_3.loss_ce: 0.1699, aux_3.acc_seg: 93.4343, aux_4.loss_t2t: 0.0261, loss: 0.9481
2023-05-02 09:56:31,794 - mmseg - INFO - Iter [1450/10000]	lr: 8.686e-02, eta: 2:14:42, time: 0.909, data_time: 0.188, memory: 14762, decode.loss_ce: 0.1054, decode.acc_seg: 95.0159, aux_0.loss_ce: 0.1091, aux_0.acc_seg: 94.8677, aux_1.loss_ce: 0.1303, aux_1.acc_seg: 93.9175, aux_2.loss_ce: 0.1265, aux_2.loss_dice: 0.2684, aux_2.acc_seg: 96.0582, aux_3.loss_ce: 0.1683, aux_3.acc_seg: 93.5364, aux_4.loss_t2t: 0.0261, loss: 0.9341
2023-05-02 09:57:20,506 - mmseg - INFO - Iter [1500/10000]	lr: 8.640e-02, eta: 2:14:03, time: 0.974, data_time: 0.257, memory: 14762, decode.loss_ce: 0.1020, decode.acc_seg: 95.0809, aux_0.loss_ce: 0.1062, aux_0.acc_seg: 94.8794, aux_1.loss_ce: 0.1256, aux_1.acc_seg: 94.0046, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2653, aux_2.acc_seg: 96.0919, aux_3.loss_ce: 0.1611, aux_3.acc_seg: 93.6813, aux_4.loss_t2t: 0.0253, loss: 0.9101
2023-05-02 09:58:05,396 - mmseg - INFO - Iter [1550/10000]	lr: 8.594e-02, eta: 2:13:03, time: 0.898, data_time: 0.186, memory: 14762, decode.loss_ce: 0.1026, decode.acc_seg: 95.0331, aux_0.loss_ce: 0.1071, aux_0.acc_seg: 94.8470, aux_1.loss_ce: 0.1265, aux_1.acc_seg: 93.9784, aux_2.loss_ce: 0.1256, aux_2.loss_dice: 0.2660, aux_2.acc_seg: 96.0417, aux_3.loss_ce: 0.1656, aux_3.acc_seg: 93.5270, aux_4.loss_t2t: 0.0243, loss: 0.9176
2023-05-02 09:58:50,876 - mmseg - INFO - Iter [1600/10000]	lr: 8.549e-02, eta: 2:12:06, time: 0.910, data_time: 0.189, memory: 14762, decode.loss_ce: 0.1063, decode.acc_seg: 94.8399, aux_0.loss_ce: 0.1115, aux_0.acc_seg: 94.6487, aux_1.loss_ce: 0.1295, aux_1.acc_seg: 93.8225, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2651, aux_2.acc_seg: 96.0738, aux_3.loss_ce: 0.1645, aux_3.acc_seg: 93.5219, aux_4.loss_t2t: 0.0255, loss: 0.9272
2023-05-02 09:59:36,334 - mmseg - INFO - Iter [1650/10000]	lr: 8.503e-02, eta: 2:11:10, time: 0.909, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0946, decode.acc_seg: 95.3914, aux_0.loss_ce: 0.0988, aux_0.acc_seg: 95.2187, aux_1.loss_ce: 0.1181, aux_1.acc_seg: 94.3065, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2633, aux_2.acc_seg: 96.0754, aux_3.loss_ce: 0.1560, aux_3.acc_seg: 93.8409, aux_4.loss_t2t: 0.0247, loss: 0.8791
2023-05-02 10:00:25,423 - mmseg - INFO - Iter [1700/10000]	lr: 8.457e-02, eta: 2:10:33, time: 0.982, data_time: 0.263, memory: 14762, decode.loss_ce: 0.0949, decode.acc_seg: 95.3638, aux_0.loss_ce: 0.0982, aux_0.acc_seg: 95.2407, aux_1.loss_ce: 0.1169, aux_1.acc_seg: 94.3720, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2628, aux_2.acc_seg: 96.1434, aux_3.loss_ce: 0.1555, aux_3.acc_seg: 93.8689, aux_4.loss_t2t: 0.0246, loss: 0.8753
2023-05-02 10:01:10,937 - mmseg - INFO - Iter [1750/10000]	lr: 8.411e-02, eta: 2:09:38, time: 0.910, data_time: 0.192, memory: 14762, decode.loss_ce: 0.1012, decode.acc_seg: 95.1686, aux_0.loss_ce: 0.1046, aux_0.acc_seg: 95.0150, aux_1.loss_ce: 0.1227, aux_1.acc_seg: 94.1741, aux_2.loss_ce: 0.1262, aux_2.loss_dice: 0.2653, aux_2.acc_seg: 95.9835, aux_3.loss_ce: 0.1597, aux_3.acc_seg: 93.7606, aux_4.loss_t2t: 0.0244, loss: 0.9041
2023-05-02 10:01:56,123 - mmseg - INFO - Iter [1800/10000]	lr: 8.365e-02, eta: 2:08:42, time: 0.904, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0926, decode.acc_seg: 95.5575, aux_0.loss_ce: 0.0961, aux_0.acc_seg: 95.4372, aux_1.loss_ce: 0.1153, aux_1.acc_seg: 94.5266, aux_2.loss_ce: 0.1233, aux_2.loss_dice: 0.2626, aux_2.acc_seg: 96.0925, aux_3.loss_ce: 0.1530, aux_3.acc_seg: 94.0435, aux_4.loss_t2t: 0.0241, loss: 0.8670
2023-05-02 10:02:45,003 - mmseg - INFO - Iter [1850/10000]	lr: 8.319e-02, eta: 2:08:02, time: 0.978, data_time: 0.261, memory: 14762, decode.loss_ce: 0.1020, decode.acc_seg: 95.1112, aux_0.loss_ce: 0.1063, aux_0.acc_seg: 94.9374, aux_1.loss_ce: 0.1237, aux_1.acc_seg: 94.0931, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2644, aux_2.acc_seg: 96.0564, aux_3.loss_ce: 0.1587, aux_3.acc_seg: 93.6477, aux_4.loss_t2t: 0.0235, loss: 0.9032
2023-05-02 10:03:30,127 - mmseg - INFO - Iter [1900/10000]	lr: 8.273e-02, eta: 2:07:07, time: 0.902, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0954, decode.acc_seg: 95.3608, aux_0.loss_ce: 0.0992, aux_0.acc_seg: 95.2339, aux_1.loss_ce: 0.1175, aux_1.acc_seg: 94.3588, aux_2.loss_ce: 0.1244, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 96.0540, aux_3.loss_ce: 0.1554, aux_3.acc_seg: 93.8999, aux_4.loss_t2t: 0.0235, loss: 0.8784
2023-05-02 10:04:15,387 - mmseg - INFO - Iter [1950/10000]	lr: 8.227e-02, eta: 2:06:12, time: 0.905, data_time: 0.190, memory: 14762, decode.loss_ce: 0.1070, decode.acc_seg: 94.8225, aux_0.loss_ce: 0.1109, aux_0.acc_seg: 94.6564, aux_1.loss_ce: 0.1284, aux_1.acc_seg: 93.7908, aux_2.loss_ce: 0.1248, aux_2.loss_dice: 0.2636, aux_2.acc_seg: 96.0302, aux_3.loss_ce: 0.1642, aux_3.acc_seg: 93.3666, aux_4.loss_t2t: 0.0237, loss: 0.9225
2023-05-02 10:05:00,366 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-05-02 10:05:04,035 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:05:04,035 - mmseg - INFO - Iter [2000/10000]	lr: 8.181e-02, eta: 2:05:32, time: 0.974, data_time: 0.184, memory: 14762, decode.loss_ce: 0.0947, decode.acc_seg: 95.3644, aux_0.loss_ce: 0.0983, aux_0.acc_seg: 95.2303, aux_1.loss_ce: 0.1164, aux_1.acc_seg: 94.3668, aux_2.loss_ce: 0.1216, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 96.1789, aux_3.loss_ce: 0.1539, aux_3.acc_seg: 93.8894, aux_4.loss_t2t: 0.0236, loss: 0.8700
2023-05-02 10:05:08,110 - mmseg - INFO - per class results:
2023-05-02 10:05:08,111 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 84.28 | 92.74 |
|   Building  | 91.33 | 92.96 |
|     Car     | 91.29 | 96.25 |
| Column_Pole |  5.74 |  6.42 |
|    Fence    | 74.85 | 92.38 |
|  Pedestrian | 60.27 | 83.36 |
|     Road    | 97.22 | 97.88 |
|   Sidewalk  | 89.95 | 97.65 |
|  SignSymbol |  0.93 |  0.93 |
|     Sky     | 94.27 | 97.57 |
|     Tree    | 91.43 | 98.04 |
+-------------+-------+-------+
2023-05-02 10:05:08,111 - mmseg - INFO - Summary:
2023-05-02 10:05:08,111 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.52 | 71.05 | 77.84 |
+-------+-------+-------+
2023-05-02 10:05:08,112 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:05:08,112 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9552, mIoU: 0.7105, mAcc: 0.7784, IoU.Bicyclist: 0.8428, IoU.Building: 0.9133, IoU.Car: 0.9129, IoU.Column_Pole: 0.0574, IoU.Fence: 0.7485, IoU.Pedestrian: 0.6027, IoU.Road: 0.9722, IoU.Sidewalk: 0.8995, IoU.SignSymbol: 0.0093, IoU.Sky: 0.9427, IoU.Tree: 0.9143, Acc.Bicyclist: 0.9274, Acc.Building: 0.9296, Acc.Car: 0.9625, Acc.Column_Pole: 0.0642, Acc.Fence: 0.9238, Acc.Pedestrian: 0.8336, Acc.Road: 0.9788, Acc.Sidewalk: 0.9765, Acc.SignSymbol: 0.0093, Acc.Sky: 0.9757, Acc.Tree: 0.9804
2023-05-02 10:05:56,808 - mmseg - INFO - Iter [2050/10000]	lr: 8.135e-02, eta: 2:05:07, time: 1.055, data_time: 0.339, memory: 14762, decode.loss_ce: 0.0959, decode.acc_seg: 95.3791, aux_0.loss_ce: 0.0992, aux_0.acc_seg: 95.2649, aux_1.loss_ce: 0.1172, aux_1.acc_seg: 94.4246, aux_2.loss_ce: 0.1247, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 96.0503, aux_3.loss_ce: 0.1552, aux_3.acc_seg: 93.9344, aux_4.loss_t2t: 0.0233, loss: 0.8791
2023-05-02 10:06:41,514 - mmseg - INFO - Iter [2100/10000]	lr: 8.089e-02, eta: 2:04:10, time: 0.894, data_time: 0.183, memory: 14762, decode.loss_ce: 0.0866, decode.acc_seg: 95.5714, aux_0.loss_ce: 0.0896, aux_0.acc_seg: 95.4776, aux_1.loss_ce: 0.1075, aux_1.acc_seg: 94.5797, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2610, aux_2.acc_seg: 96.1022, aux_3.loss_ce: 0.1444, aux_3.acc_seg: 94.0953, aux_4.loss_t2t: 0.0231, loss: 0.8345
2023-05-02 10:07:26,684 - mmseg - INFO - Iter [2150/10000]	lr: 8.043e-02, eta: 2:03:15, time: 0.903, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0889, decode.acc_seg: 95.6120, aux_0.loss_ce: 0.0921, aux_0.acc_seg: 95.5110, aux_1.loss_ce: 0.1100, aux_1.acc_seg: 94.6338, aux_2.loss_ce: 0.1224, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 96.0739, aux_3.loss_ce: 0.1500, aux_3.acc_seg: 94.0577, aux_4.loss_t2t: 0.0228, loss: 0.8467
2023-05-02 10:08:11,087 - mmseg - INFO - Iter [2200/10000]	lr: 7.997e-02, eta: 2:02:19, time: 0.888, data_time: 0.182, memory: 14762, decode.loss_ce: 0.0906, decode.acc_seg: 95.5828, aux_0.loss_ce: 0.0937, aux_0.acc_seg: 95.4625, aux_1.loss_ce: 0.1119, aux_1.acc_seg: 94.5834, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2634, aux_2.acc_seg: 96.0611, aux_3.loss_ce: 0.1490, aux_3.acc_seg: 94.1289, aux_4.loss_t2t: 0.0231, loss: 0.8556
2023-05-02 10:08:58,276 - mmseg - INFO - Iter [2250/10000]	lr: 7.951e-02, eta: 2:01:32, time: 0.944, data_time: 0.245, memory: 14762, decode.loss_ce: 0.0927, decode.acc_seg: 95.4376, aux_0.loss_ce: 0.0957, aux_0.acc_seg: 95.3203, aux_1.loss_ce: 0.1137, aux_1.acc_seg: 94.4725, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2620, aux_2.acc_seg: 96.0887, aux_3.loss_ce: 0.1525, aux_3.acc_seg: 93.9515, aux_4.loss_t2t: 0.0226, loss: 0.8630
2023-05-02 10:09:42,121 - mmseg - INFO - Iter [2300/10000]	lr: 7.905e-02, eta: 2:00:34, time: 0.877, data_time: 0.175, memory: 14762, decode.loss_ce: 0.0919, decode.acc_seg: 95.4789, aux_0.loss_ce: 0.0949, aux_0.acc_seg: 95.3722, aux_1.loss_ce: 0.1128, aux_1.acc_seg: 94.5133, aux_2.loss_ce: 0.1238, aux_2.loss_dice: 0.2615, aux_2.acc_seg: 96.0472, aux_3.loss_ce: 0.1505, aux_3.acc_seg: 94.0569, aux_4.loss_t2t: 0.0228, loss: 0.8582
2023-05-02 10:10:26,908 - mmseg - INFO - Iter [2350/10000]	lr: 7.859e-02, eta: 1:59:40, time: 0.896, data_time: 0.186, memory: 14762, decode.loss_ce: 0.0902, decode.acc_seg: 95.6020, aux_0.loss_ce: 0.0925, aux_0.acc_seg: 95.5297, aux_1.loss_ce: 0.1110, aux_1.acc_seg: 94.6552, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 96.0629, aux_3.loss_ce: 0.1477, aux_3.acc_seg: 94.2372, aux_4.loss_t2t: 0.0229, loss: 0.8506
2023-05-02 10:11:15,832 - mmseg - INFO - Iter [2400/10000]	lr: 7.812e-02, eta: 1:59:00, time: 0.978, data_time: 0.263, memory: 14762, decode.loss_ce: 0.0838, decode.acc_seg: 95.8413, aux_0.loss_ce: 0.0868, aux_0.acc_seg: 95.7291, aux_1.loss_ce: 0.1040, aux_1.acc_seg: 94.8711, aux_2.loss_ce: 0.1215, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 96.1141, aux_3.loss_ce: 0.1417, aux_3.acc_seg: 94.3489, aux_4.loss_t2t: 0.0225, loss: 0.8194
2023-05-02 10:12:01,611 - mmseg - INFO - Iter [2450/10000]	lr: 7.766e-02, eta: 1:58:09, time: 0.916, data_time: 0.197, memory: 14762, decode.loss_ce: 0.0896, decode.acc_seg: 95.6101, aux_0.loss_ce: 0.0923, aux_0.acc_seg: 95.5159, aux_1.loss_ce: 0.1084, aux_1.acc_seg: 94.7164, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 96.0965, aux_3.loss_ce: 0.1461, aux_3.acc_seg: 94.1930, aux_4.loss_t2t: 0.0219, loss: 0.8411
2023-05-02 10:12:47,046 - mmseg - INFO - Iter [2500/10000]	lr: 7.720e-02, eta: 1:57:18, time: 0.909, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0915, decode.acc_seg: 95.5314, aux_0.loss_ce: 0.0943, aux_0.acc_seg: 95.4453, aux_1.loss_ce: 0.1118, aux_1.acc_seg: 94.6167, aux_2.loss_ce: 0.1230, aux_2.loss_dice: 0.2609, aux_2.acc_seg: 96.0465, aux_3.loss_ce: 0.1490, aux_3.acc_seg: 94.1164, aux_4.loss_t2t: 0.0225, loss: 0.8530
2023-05-02 10:13:32,437 - mmseg - INFO - Iter [2550/10000]	lr: 7.674e-02, eta: 1:56:26, time: 0.908, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0842, decode.acc_seg: 95.7663, aux_0.loss_ce: 0.0872, aux_0.acc_seg: 95.6658, aux_1.loss_ce: 0.1042, aux_1.acc_seg: 94.8432, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2577, aux_2.acc_seg: 96.1395, aux_3.loss_ce: 0.1408, aux_3.acc_seg: 94.3078, aux_4.loss_t2t: 0.0222, loss: 0.8166
2023-05-02 10:14:21,297 - mmseg - INFO - Iter [2600/10000]	lr: 7.627e-02, eta: 1:55:45, time: 0.977, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0856, decode.acc_seg: 95.6785, aux_0.loss_ce: 0.0887, aux_0.acc_seg: 95.5933, aux_1.loss_ce: 0.1055, aux_1.acc_seg: 94.7562, aux_2.loss_ce: 0.1220, aux_2.loss_dice: 0.2587, aux_2.acc_seg: 96.0723, aux_3.loss_ce: 0.1432, aux_3.acc_seg: 94.2380, aux_4.loss_t2t: 0.0221, loss: 0.8256
2023-05-02 10:15:06,846 - mmseg - INFO - Iter [2650/10000]	lr: 7.581e-02, eta: 1:54:54, time: 0.911, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0785, decode.acc_seg: 96.0424, aux_0.loss_ce: 0.0813, aux_0.acc_seg: 95.9408, aux_1.loss_ce: 0.0985, aux_1.acc_seg: 95.1025, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2556, aux_2.acc_seg: 96.1176, aux_3.loss_ce: 0.1357, aux_3.acc_seg: 94.5757, aux_4.loss_t2t: 0.0217, loss: 0.7911
2023-05-02 10:15:52,228 - mmseg - INFO - Iter [2700/10000]	lr: 7.534e-02, eta: 1:54:03, time: 0.908, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0827, decode.acc_seg: 95.9245, aux_0.loss_ce: 0.0855, aux_0.acc_seg: 95.8465, aux_1.loss_ce: 0.1036, aux_1.acc_seg: 94.9660, aux_2.loss_ce: 0.1246, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 95.9438, aux_3.loss_ce: 0.1414, aux_3.acc_seg: 94.4637, aux_4.loss_t2t: 0.0216, loss: 0.8198
2023-05-02 10:16:37,472 - mmseg - INFO - Iter [2750/10000]	lr: 7.488e-02, eta: 1:53:12, time: 0.905, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0843, decode.acc_seg: 95.8285, aux_0.loss_ce: 0.0868, aux_0.acc_seg: 95.7429, aux_1.loss_ce: 0.1041, aux_1.acc_seg: 94.9004, aux_2.loss_ce: 0.1228, aux_2.loss_dice: 0.2596, aux_2.acc_seg: 96.0391, aux_3.loss_ce: 0.1430, aux_3.acc_seg: 94.3340, aux_4.loss_t2t: 0.0214, loss: 0.8222
2023-05-02 10:17:26,291 - mmseg - INFO - Iter [2800/10000]	lr: 7.441e-02, eta: 1:52:30, time: 0.976, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0840, decode.acc_seg: 95.8040, aux_0.loss_ce: 0.0865, aux_0.acc_seg: 95.7291, aux_1.loss_ce: 0.1038, aux_1.acc_seg: 94.8471, aux_2.loss_ce: 0.1217, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 96.0930, aux_3.loss_ce: 0.1402, aux_3.acc_seg: 94.3761, aux_4.loss_t2t: 0.0215, loss: 0.8171
2023-05-02 10:18:11,385 - mmseg - INFO - Iter [2850/10000]	lr: 7.395e-02, eta: 1:51:39, time: 0.902, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0813, decode.acc_seg: 95.9084, aux_0.loss_ce: 0.0840, aux_0.acc_seg: 95.8222, aux_1.loss_ce: 0.1010, aux_1.acc_seg: 94.9739, aux_2.loss_ce: 0.1237, aux_2.loss_dice: 0.2605, aux_2.acc_seg: 96.0109, aux_3.loss_ce: 0.1408, aux_3.acc_seg: 94.3719, aux_4.loss_t2t: 0.0216, loss: 0.8128
2023-05-02 10:18:56,607 - mmseg - INFO - Iter [2900/10000]	lr: 7.348e-02, eta: 1:50:48, time: 0.904, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0812, decode.acc_seg: 96.0157, aux_0.loss_ce: 0.0838, aux_0.acc_seg: 95.9243, aux_1.loss_ce: 0.1007, aux_1.acc_seg: 95.1306, aux_2.loss_ce: 0.1206, aux_2.loss_dice: 0.2578, aux_2.acc_seg: 96.1069, aux_3.loss_ce: 0.1396, aux_3.acc_seg: 94.5593, aux_4.loss_t2t: 0.0218, loss: 0.8055
2023-05-02 10:19:45,895 - mmseg - INFO - Iter [2950/10000]	lr: 7.302e-02, eta: 1:50:07, time: 0.986, data_time: 0.268, memory: 14762, decode.loss_ce: 0.0775, decode.acc_seg: 96.0207, aux_0.loss_ce: 0.0806, aux_0.acc_seg: 95.9143, aux_1.loss_ce: 0.0971, aux_1.acc_seg: 95.0517, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2551, aux_2.acc_seg: 96.0857, aux_3.loss_ce: 0.1345, aux_3.acc_seg: 94.5188, aux_4.loss_t2t: 0.0208, loss: 0.7857
2023-05-02 10:20:31,086 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-05-02 10:20:34,803 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:20:34,803 - mmseg - INFO - Iter [3000/10000]	lr: 7.255e-02, eta: 1:49:25, time: 0.979, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0755, decode.acc_seg: 96.1712, aux_0.loss_ce: 0.0786, aux_0.acc_seg: 96.0665, aux_1.loss_ce: 0.0956, aux_1.acc_seg: 95.2097, aux_2.loss_ce: 0.1210, aux_2.loss_dice: 0.2567, aux_2.acc_seg: 96.0173, aux_3.loss_ce: 0.1340, aux_3.acc_seg: 94.6160, aux_4.loss_t2t: 0.0211, loss: 0.7824
2023-05-02 10:20:38,759 - mmseg - INFO - per class results:
2023-05-02 10:20:38,760 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 85.15 | 92.87 |
|   Building  | 90.85 | 92.28 |
|     Car     | 92.45 | 94.54 |
| Column_Pole | 28.85 | 42.02 |
|    Fence    | 78.36 | 91.12 |
|  Pedestrian | 59.94 | 85.69 |
|     Road    | 97.34 | 98.42 |
|   Sidewalk  | 90.61 |  97.1 |
|  SignSymbol |  2.35 |  2.35 |
|     Sky     | 94.34 |  97.5 |
|     Tree    | 90.57 | 97.72 |
+-------------+-------+-------+
2023-05-02 10:20:38,760 - mmseg - INFO - Summary:
2023-05-02 10:20:38,760 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.55 | 73.71 | 81.06 |
+-------+-------+-------+
2023-05-02 10:20:38,761 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:20:38,761 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9555, mIoU: 0.7371, mAcc: 0.8106, IoU.Bicyclist: 0.8515, IoU.Building: 0.9085, IoU.Car: 0.9245, IoU.Column_Pole: 0.2885, IoU.Fence: 0.7836, IoU.Pedestrian: 0.5994, IoU.Road: 0.9734, IoU.Sidewalk: 0.9061, IoU.SignSymbol: 0.0235, IoU.Sky: 0.9434, IoU.Tree: 0.9057, Acc.Bicyclist: 0.9287, Acc.Building: 0.9228, Acc.Car: 0.9454, Acc.Column_Pole: 0.4202, Acc.Fence: 0.9112, Acc.Pedestrian: 0.8569, Acc.Road: 0.9842, Acc.Sidewalk: 0.9710, Acc.SignSymbol: 0.0235, Acc.Sky: 0.9750, Acc.Tree: 0.9772
2023-05-02 10:21:23,253 - mmseg - INFO - Iter [3050/10000]	lr: 7.208e-02, eta: 1:48:42, time: 0.968, data_time: 0.265, memory: 14762, decode.loss_ce: 0.0839, decode.acc_seg: 95.8256, aux_0.loss_ce: 0.0852, aux_0.acc_seg: 95.7901, aux_1.loss_ce: 0.1024, aux_1.acc_seg: 94.9725, aux_2.loss_ce: 0.1221, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 96.0701, aux_3.loss_ce: 0.1395, aux_3.acc_seg: 94.4921, aux_4.loss_t2t: 0.0207, loss: 0.8129
2023-05-02 10:22:06,977 - mmseg - INFO - Iter [3100/10000]	lr: 7.162e-02, eta: 1:47:48, time: 0.874, data_time: 0.179, memory: 14762, decode.loss_ce: 0.0808, decode.acc_seg: 95.9615, aux_0.loss_ce: 0.0832, aux_0.acc_seg: 95.8850, aux_1.loss_ce: 0.0997, aux_1.acc_seg: 95.0749, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2595, aux_2.acc_seg: 96.0732, aux_3.loss_ce: 0.1377, aux_3.acc_seg: 94.4933, aux_4.loss_t2t: 0.0211, loss: 0.8043
2023-05-02 10:22:54,183 - mmseg - INFO - Iter [3150/10000]	lr: 7.115e-02, eta: 1:47:01, time: 0.944, data_time: 0.245, memory: 14762, decode.loss_ce: 0.0826, decode.acc_seg: 95.9232, aux_0.loss_ce: 0.0857, aux_0.acc_seg: 95.8273, aux_1.loss_ce: 0.1028, aux_1.acc_seg: 94.9825, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2587, aux_2.acc_seg: 96.0394, aux_3.loss_ce: 0.1398, aux_3.acc_seg: 94.4425, aux_4.loss_t2t: 0.0209, loss: 0.8123
2023-05-02 10:23:38,842 - mmseg - INFO - Iter [3200/10000]	lr: 7.068e-02, eta: 1:46:10, time: 0.893, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0810, decode.acc_seg: 95.9354, aux_0.loss_ce: 0.0833, aux_0.acc_seg: 95.8521, aux_1.loss_ce: 0.1008, aux_1.acc_seg: 94.9682, aux_2.loss_ce: 0.1223, aux_2.loss_dice: 0.2575, aux_2.acc_seg: 95.9952, aux_3.loss_ce: 0.1368, aux_3.acc_seg: 94.5124, aux_4.loss_t2t: 0.0212, loss: 0.8028
2023-05-02 10:24:23,901 - mmseg - INFO - Iter [3250/10000]	lr: 7.022e-02, eta: 1:45:19, time: 0.901, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0774, decode.acc_seg: 96.1277, aux_0.loss_ce: 0.0795, aux_0.acc_seg: 96.0639, aux_1.loss_ce: 0.0969, aux_1.acc_seg: 95.2073, aux_2.loss_ce: 0.1209, aux_2.loss_dice: 0.2568, aux_2.acc_seg: 96.0706, aux_3.loss_ce: 0.1339, aux_3.acc_seg: 94.7090, aux_4.loss_t2t: 0.0210, loss: 0.7864
2023-05-02 10:25:08,755 - mmseg - INFO - Iter [3300/10000]	lr: 6.975e-02, eta: 1:44:28, time: 0.897, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0783, decode.acc_seg: 96.0956, aux_0.loss_ce: 0.0809, aux_0.acc_seg: 96.0058, aux_1.loss_ce: 0.0977, aux_1.acc_seg: 95.1675, aux_2.loss_ce: 0.1222, aux_2.loss_dice: 0.2584, aux_2.acc_seg: 96.0177, aux_3.loss_ce: 0.1373, aux_3.acc_seg: 94.5489, aux_4.loss_t2t: 0.0208, loss: 0.7956
2023-05-02 10:25:56,813 - mmseg - INFO - Iter [3350/10000]	lr: 6.928e-02, eta: 1:43:44, time: 0.961, data_time: 0.252, memory: 14762, decode.loss_ce: 0.0766, decode.acc_seg: 96.0894, aux_0.loss_ce: 0.0792, aux_0.acc_seg: 96.0154, aux_1.loss_ce: 0.0962, aux_1.acc_seg: 95.1495, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2573, aux_2.acc_seg: 96.0285, aux_3.loss_ce: 0.1334, aux_3.acc_seg: 94.6353, aux_4.loss_t2t: 0.0204, loss: 0.7850
2023-05-02 10:26:41,342 - mmseg - INFO - Iter [3400/10000]	lr: 6.881e-02, eta: 1:42:53, time: 0.891, data_time: 0.185, memory: 14762, decode.loss_ce: 0.0773, decode.acc_seg: 96.0978, aux_0.loss_ce: 0.0795, aux_0.acc_seg: 96.0237, aux_1.loss_ce: 0.0960, aux_1.acc_seg: 95.1923, aux_2.loss_ce: 0.1222, aux_2.loss_dice: 0.2563, aux_2.acc_seg: 95.9651, aux_3.loss_ce: 0.1350, aux_3.acc_seg: 94.5942, aux_4.loss_t2t: 0.0205, loss: 0.7869
2023-05-02 10:27:26,256 - mmseg - INFO - Iter [3450/10000]	lr: 6.834e-02, eta: 1:42:03, time: 0.898, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0787, decode.acc_seg: 95.9865, aux_0.loss_ce: 0.0810, aux_0.acc_seg: 95.9105, aux_1.loss_ce: 0.0965, aux_1.acc_seg: 95.1231, aux_2.loss_ce: 0.1195, aux_2.loss_dice: 0.2550, aux_2.acc_seg: 96.0916, aux_3.loss_ce: 0.1329, aux_3.acc_seg: 94.5908, aux_4.loss_t2t: 0.0201, loss: 0.7836
2023-05-02 10:28:14,293 - mmseg - INFO - Iter [3500/10000]	lr: 6.787e-02, eta: 1:41:18, time: 0.961, data_time: 0.253, memory: 14762, decode.loss_ce: 0.0798, decode.acc_seg: 95.9466, aux_0.loss_ce: 0.0815, aux_0.acc_seg: 95.8957, aux_1.loss_ce: 0.0981, aux_1.acc_seg: 95.0679, aux_2.loss_ce: 0.1214, aux_2.loss_dice: 0.2561, aux_2.acc_seg: 96.0320, aux_3.loss_ce: 0.1352, aux_3.acc_seg: 94.5053, aux_4.loss_t2t: 0.0203, loss: 0.7924
2023-05-02 10:28:59,416 - mmseg - INFO - Iter [3550/10000]	lr: 6.740e-02, eta: 1:40:29, time: 0.902, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0804, decode.acc_seg: 95.9132, aux_0.loss_ce: 0.0827, aux_0.acc_seg: 95.8426, aux_1.loss_ce: 0.0988, aux_1.acc_seg: 95.0235, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2575, aux_2.acc_seg: 96.1192, aux_3.loss_ce: 0.1360, aux_3.acc_seg: 94.4904, aux_4.loss_t2t: 0.0204, loss: 0.7964
2023-05-02 10:29:44,579 - mmseg - INFO - Iter [3600/10000]	lr: 6.693e-02, eta: 1:39:39, time: 0.903, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0755, decode.acc_seg: 96.1157, aux_0.loss_ce: 0.0778, aux_0.acc_seg: 96.0694, aux_1.loss_ce: 0.0945, aux_1.acc_seg: 95.2234, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2557, aux_2.acc_seg: 95.9837, aux_3.loss_ce: 0.1315, aux_3.acc_seg: 94.6599, aux_4.loss_t2t: 0.0200, loss: 0.7770
2023-05-02 10:30:29,889 - mmseg - INFO - Iter [3650/10000]	lr: 6.646e-02, eta: 1:38:50, time: 0.906, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0773, decode.acc_seg: 96.1120, aux_0.loss_ce: 0.0800, aux_0.acc_seg: 96.0311, aux_1.loss_ce: 0.0957, aux_1.acc_seg: 95.2356, aux_2.loss_ce: 0.1198, aux_2.loss_dice: 0.2556, aux_2.acc_seg: 96.0880, aux_3.loss_ce: 0.1344, aux_3.acc_seg: 94.6229, aux_4.loss_t2t: 0.0205, loss: 0.7834
2023-05-02 10:31:18,791 - mmseg - INFO - Iter [3700/10000]	lr: 6.599e-02, eta: 1:38:07, time: 0.978, data_time: 0.265, memory: 14762, decode.loss_ce: 0.0749, decode.acc_seg: 96.2504, aux_0.loss_ce: 0.0774, aux_0.acc_seg: 96.1924, aux_1.loss_ce: 0.0930, aux_1.acc_seg: 95.4071, aux_2.loss_ce: 0.1204, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 96.0333, aux_3.loss_ce: 0.1295, aux_3.acc_seg: 94.8394, aux_4.loss_t2t: 0.0207, loss: 0.7719
2023-05-02 10:32:03,626 - mmseg - INFO - Iter [3750/10000]	lr: 6.552e-02, eta: 1:37:17, time: 0.897, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0732, decode.acc_seg: 96.2648, aux_0.loss_ce: 0.0757, aux_0.acc_seg: 96.1992, aux_1.loss_ce: 0.0921, aux_1.acc_seg: 95.3468, aux_2.loss_ce: 0.1210, aux_2.loss_dice: 0.2553, aux_2.acc_seg: 96.0147, aux_3.loss_ce: 0.1294, aux_3.acc_seg: 94.8031, aux_4.loss_t2t: 0.0200, loss: 0.7667
2023-05-02 10:32:48,036 - mmseg - INFO - Iter [3800/10000]	lr: 6.505e-02, eta: 1:36:27, time: 0.888, data_time: 0.181, memory: 14762, decode.loss_ce: 0.0734, decode.acc_seg: 96.2304, aux_0.loss_ce: 0.0753, aux_0.acc_seg: 96.1788, aux_1.loss_ce: 0.0911, aux_1.acc_seg: 95.3883, aux_2.loss_ce: 0.1196, aux_2.loss_dice: 0.2556, aux_2.acc_seg: 96.1114, aux_3.loss_ce: 0.1296, aux_3.acc_seg: 94.7456, aux_4.loss_t2t: 0.0199, loss: 0.7646
2023-05-02 10:33:32,352 - mmseg - INFO - Iter [3850/10000]	lr: 6.457e-02, eta: 1:35:36, time: 0.886, data_time: 0.180, memory: 14762, decode.loss_ce: 0.0764, decode.acc_seg: 96.0761, aux_0.loss_ce: 0.0788, aux_0.acc_seg: 96.0038, aux_1.loss_ce: 0.0945, aux_1.acc_seg: 95.2063, aux_2.loss_ce: 0.1203, aux_2.loss_dice: 0.2558, aux_2.acc_seg: 96.0605, aux_3.loss_ce: 0.1330, aux_3.acc_seg: 94.6020, aux_4.loss_t2t: 0.0201, loss: 0.7788
2023-05-02 10:34:19,545 - mmseg - INFO - Iter [3900/10000]	lr: 6.410e-02, eta: 1:34:50, time: 0.944, data_time: 0.242, memory: 14762, decode.loss_ce: 0.1318, decode.acc_seg: 94.0270, aux_0.loss_ce: 0.1306, aux_0.acc_seg: 94.1154, aux_1.loss_ce: 0.1486, aux_1.acc_seg: 93.2111, aux_2.loss_ce: 0.1261, aux_2.loss_dice: 0.2649, aux_2.acc_seg: 96.1151, aux_3.loss_ce: 0.1718, aux_3.acc_seg: 93.1643, aux_4.loss_t2t: 0.0219, loss: 0.9956
2023-05-02 10:35:04,406 - mmseg - INFO - Iter [3950/10000]	lr: 6.363e-02, eta: 1:34:01, time: 0.897, data_time: 0.189, memory: 14762, decode.loss_ce: 0.1253, decode.acc_seg: 94.2241, aux_0.loss_ce: 0.1266, aux_0.acc_seg: 94.2091, aux_1.loss_ce: 0.1431, aux_1.acc_seg: 93.3934, aux_2.loss_ce: 0.1253, aux_2.loss_dice: 0.2631, aux_2.acc_seg: 96.0399, aux_3.loss_ce: 0.1648, aux_3.acc_seg: 93.4413, aux_4.loss_t2t: 0.0221, loss: 0.9703
2023-05-02 10:35:49,273 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-05-02 10:35:52,980 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:35:52,980 - mmseg - INFO - Iter [4000/10000]	lr: 6.315e-02, eta: 1:33:17, time: 0.972, data_time: 0.185, memory: 14762, decode.loss_ce: 0.1047, decode.acc_seg: 94.9676, aux_0.loss_ce: 0.1061, aux_0.acc_seg: 94.9168, aux_1.loss_ce: 0.1234, aux_1.acc_seg: 94.0755, aux_2.loss_ce: 0.1235, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 96.0093, aux_3.loss_ce: 0.1527, aux_3.acc_seg: 93.8401, aux_4.loss_t2t: 0.0225, loss: 0.8924
2023-05-02 10:35:56,614 - mmseg - INFO - per class results:
2023-05-02 10:35:56,615 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.99 | 90.49 |
|   Building  | 92.08 | 94.53 |
|     Car     | 89.71 | 91.15 |
| Column_Pole |  6.29 |  6.6  |
|    Fence    | 72.74 | 98.53 |
|  Pedestrian | 48.34 | 51.84 |
|     Road    | 97.29 | 98.11 |
|   Sidewalk  |  91.0 | 96.99 |
|  SignSymbol |  0.01 |  0.01 |
|     Sky     | 94.45 | 97.73 |
|     Tree    | 92.11 | 97.32 |
+-------------+-------+-------+
2023-05-02 10:35:56,615 - mmseg - INFO - Summary:
2023-05-02 10:35:56,615 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.68 | 69.82 | 74.85 |
+-------+-------+-------+
2023-05-02 10:35:56,616 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:35:56,616 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9568, mIoU: 0.6982, mAcc: 0.7485, IoU.Bicyclist: 0.8399, IoU.Building: 0.9208, IoU.Car: 0.8971, IoU.Column_Pole: 0.0629, IoU.Fence: 0.7274, IoU.Pedestrian: 0.4834, IoU.Road: 0.9729, IoU.Sidewalk: 0.9100, IoU.SignSymbol: 0.0001, IoU.Sky: 0.9445, IoU.Tree: 0.9211, Acc.Bicyclist: 0.9049, Acc.Building: 0.9453, Acc.Car: 0.9115, Acc.Column_Pole: 0.0660, Acc.Fence: 0.9853, Acc.Pedestrian: 0.5184, Acc.Road: 0.9811, Acc.Sidewalk: 0.9699, Acc.SignSymbol: 0.0001, Acc.Sky: 0.9773, Acc.Tree: 0.9732
2023-05-02 10:36:45,255 - mmseg - INFO - Iter [4050/10000]	lr: 6.268e-02, eta: 1:32:39, time: 1.045, data_time: 0.331, memory: 14762, decode.loss_ce: 0.0890, decode.acc_seg: 95.6258, aux_0.loss_ce: 0.0907, aux_0.acc_seg: 95.5848, aux_1.loss_ce: 0.1073, aux_1.acc_seg: 94.7642, aux_2.loss_ce: 0.1220, aux_2.loss_dice: 0.2586, aux_2.acc_seg: 96.0789, aux_3.loss_ce: 0.1408, aux_3.acc_seg: 94.3875, aux_4.loss_t2t: 0.0218, loss: 0.8302
2023-05-02 10:37:30,236 - mmseg - INFO - Iter [4100/10000]	lr: 6.221e-02, eta: 1:31:50, time: 0.900, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0834, decode.acc_seg: 95.8744, aux_0.loss_ce: 0.0854, aux_0.acc_seg: 95.8144, aux_1.loss_ce: 0.1023, aux_1.acc_seg: 94.9794, aux_2.loss_ce: 0.1226, aux_2.loss_dice: 0.2582, aux_2.acc_seg: 96.0105, aux_3.loss_ce: 0.1373, aux_3.acc_seg: 94.5112, aux_4.loss_t2t: 0.0212, loss: 0.8103
2023-05-02 10:38:14,752 - mmseg - INFO - Iter [4150/10000]	lr: 6.173e-02, eta: 1:31:00, time: 0.890, data_time: 0.182, memory: 14762, decode.loss_ce: 0.0859, decode.acc_seg: 95.7427, aux_0.loss_ce: 0.0882, aux_0.acc_seg: 95.6723, aux_1.loss_ce: 0.1044, aux_1.acc_seg: 94.8504, aux_2.loss_ce: 0.1218, aux_2.loss_dice: 0.2588, aux_2.acc_seg: 96.0554, aux_3.loss_ce: 0.1396, aux_3.acc_seg: 94.4065, aux_4.loss_t2t: 0.0212, loss: 0.8199
2023-05-02 10:38:59,660 - mmseg - INFO - Iter [4200/10000]	lr: 6.126e-02, eta: 1:30:11, time: 0.898, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0808, decode.acc_seg: 96.0200, aux_0.loss_ce: 0.0825, aux_0.acc_seg: 95.9761, aux_1.loss_ce: 0.0994, aux_1.acc_seg: 95.1667, aux_2.loss_ce: 0.1240, aux_2.loss_dice: 0.2590, aux_2.acc_seg: 95.9532, aux_3.loss_ce: 0.1358, aux_3.acc_seg: 94.6726, aux_4.loss_t2t: 0.0212, loss: 0.8026
2023-05-02 10:39:46,916 - mmseg - INFO - Iter [4250/10000]	lr: 6.078e-02, eta: 1:29:25, time: 0.945, data_time: 0.247, memory: 14762, decode.loss_ce: 0.0747, decode.acc_seg: 96.1602, aux_0.loss_ce: 0.0771, aux_0.acc_seg: 96.0764, aux_1.loss_ce: 0.0936, aux_1.acc_seg: 95.2356, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 96.0897, aux_3.loss_ce: 0.1299, aux_3.acc_seg: 94.6981, aux_4.loss_t2t: 0.0203, loss: 0.7698
2023-05-02 10:40:31,600 - mmseg - INFO - Iter [4300/10000]	lr: 6.031e-02, eta: 1:28:36, time: 0.894, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0755, decode.acc_seg: 96.1200, aux_0.loss_ce: 0.0773, aux_0.acc_seg: 96.0714, aux_1.loss_ce: 0.0938, aux_1.acc_seg: 95.2526, aux_2.loss_ce: 0.1204, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 96.0099, aux_3.loss_ce: 0.1300, aux_3.acc_seg: 94.7129, aux_4.loss_t2t: 0.0200, loss: 0.7714
2023-05-02 10:41:16,526 - mmseg - INFO - Iter [4350/10000]	lr: 5.983e-02, eta: 1:27:47, time: 0.899, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0798, decode.acc_seg: 95.9914, aux_0.loss_ce: 0.0819, aux_0.acc_seg: 95.9443, aux_1.loss_ce: 0.0984, aux_1.acc_seg: 95.1242, aux_2.loss_ce: 0.1236, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 95.9708, aux_3.loss_ce: 0.1369, aux_3.acc_seg: 94.5270, aux_4.loss_t2t: 0.0205, loss: 0.8002
2023-05-02 10:42:01,501 - mmseg - INFO - Iter [4400/10000]	lr: 5.935e-02, eta: 1:26:58, time: 0.899, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0781, decode.acc_seg: 96.0800, aux_0.loss_ce: 0.0803, aux_0.acc_seg: 96.0403, aux_1.loss_ce: 0.0962, aux_1.acc_seg: 95.2417, aux_2.loss_ce: 0.1216, aux_2.loss_dice: 0.2569, aux_2.acc_seg: 96.0372, aux_3.loss_ce: 0.1334, aux_3.acc_seg: 94.6624, aux_4.loss_t2t: 0.0202, loss: 0.7866
2023-05-02 10:42:50,311 - mmseg - INFO - Iter [4450/10000]	lr: 5.888e-02, eta: 1:26:14, time: 0.976, data_time: 0.265, memory: 14762, decode.loss_ce: 0.0764, decode.acc_seg: 96.0070, aux_0.loss_ce: 0.0783, aux_0.acc_seg: 95.9656, aux_1.loss_ce: 0.0945, aux_1.acc_seg: 95.1210, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2538, aux_2.acc_seg: 96.0692, aux_3.loss_ce: 0.1302, aux_3.acc_seg: 94.5875, aux_4.loss_t2t: 0.0198, loss: 0.7723
2023-05-02 10:43:35,409 - mmseg - INFO - Iter [4500/10000]	lr: 5.840e-02, eta: 1:25:26, time: 0.902, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0756, decode.acc_seg: 96.0934, aux_0.loss_ce: 0.0773, aux_0.acc_seg: 96.0679, aux_1.loss_ce: 0.0934, aux_1.acc_seg: 95.2501, aux_2.loss_ce: 0.1212, aux_2.loss_dice: 0.2562, aux_2.acc_seg: 96.0320, aux_3.loss_ce: 0.1320, aux_3.acc_seg: 94.6520, aux_4.loss_t2t: 0.0195, loss: 0.7753
2023-05-02 10:44:20,701 - mmseg - INFO - Iter [4550/10000]	lr: 5.792e-02, eta: 1:24:38, time: 0.906, data_time: 0.194, memory: 14762, decode.loss_ce: 0.0751, decode.acc_seg: 96.2090, aux_0.loss_ce: 0.0772, aux_0.acc_seg: 96.1607, aux_1.loss_ce: 0.0923, aux_1.acc_seg: 95.3948, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 96.0388, aux_3.loss_ce: 0.1298, aux_3.acc_seg: 94.7854, aux_4.loss_t2t: 0.0202, loss: 0.7700
2023-05-02 10:45:09,460 - mmseg - INFO - Iter [4600/10000]	lr: 5.744e-02, eta: 1:23:54, time: 0.975, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0740, decode.acc_seg: 96.2103, aux_0.loss_ce: 0.0760, aux_0.acc_seg: 96.1551, aux_1.loss_ce: 0.0923, aux_1.acc_seg: 95.3454, aux_2.loss_ce: 0.1214, aux_2.loss_dice: 0.2562, aux_2.acc_seg: 96.0160, aux_3.loss_ce: 0.1302, aux_3.acc_seg: 94.7294, aux_4.loss_t2t: 0.0196, loss: 0.7697
2023-05-02 10:45:53,477 - mmseg - INFO - Iter [4650/10000]	lr: 5.696e-02, eta: 1:23:04, time: 0.880, data_time: 0.179, memory: 14762, decode.loss_ce: 0.0693, decode.acc_seg: 96.4147, aux_0.loss_ce: 0.0715, aux_0.acc_seg: 96.3631, aux_1.loss_ce: 0.0875, aux_1.acc_seg: 95.5330, aux_2.loss_ce: 0.1183, aux_2.loss_dice: 0.2537, aux_2.acc_seg: 96.1053, aux_3.loss_ce: 0.1246, aux_3.acc_seg: 94.9363, aux_4.loss_t2t: 0.0197, loss: 0.7446
2023-05-02 10:46:38,210 - mmseg - INFO - Iter [4700/10000]	lr: 5.648e-02, eta: 1:22:15, time: 0.895, data_time: 0.186, memory: 14762, decode.loss_ce: 0.0709, decode.acc_seg: 96.2963, aux_0.loss_ce: 0.0728, aux_0.acc_seg: 96.2426, aux_1.loss_ce: 0.0889, aux_1.acc_seg: 95.4211, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 96.1267, aux_3.loss_ce: 0.1263, aux_3.acc_seg: 94.8151, aux_4.loss_t2t: 0.0191, loss: 0.7499
2023-05-02 10:47:22,854 - mmseg - INFO - Iter [4750/10000]	lr: 5.600e-02, eta: 1:21:27, time: 0.893, data_time: 0.185, memory: 14762, decode.loss_ce: 0.0731, decode.acc_seg: 96.1794, aux_0.loss_ce: 0.0750, aux_0.acc_seg: 96.1451, aux_1.loss_ce: 0.0910, aux_1.acc_seg: 95.3100, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2533, aux_2.acc_seg: 96.0927, aux_3.loss_ce: 0.1285, aux_3.acc_seg: 94.7375, aux_4.loss_t2t: 0.0189, loss: 0.7582
2023-05-02 10:48:11,167 - mmseg - INFO - Iter [4800/10000]	lr: 5.552e-02, eta: 1:20:42, time: 0.966, data_time: 0.256, memory: 14762, decode.loss_ce: 0.0692, decode.acc_seg: 96.4098, aux_0.loss_ce: 0.0711, aux_0.acc_seg: 96.3717, aux_1.loss_ce: 0.0874, aux_1.acc_seg: 95.5358, aux_2.loss_ce: 0.1201, aux_2.loss_dice: 0.2551, aux_2.acc_seg: 96.0635, aux_3.loss_ce: 0.1245, aux_3.acc_seg: 94.9454, aux_4.loss_t2t: 0.0192, loss: 0.7465
2023-05-02 10:48:56,468 - mmseg - INFO - Iter [4850/10000]	lr: 5.504e-02, eta: 1:19:54, time: 0.906, data_time: 0.194, memory: 14762, decode.loss_ce: 0.0810, decode.acc_seg: 95.8614, aux_0.loss_ce: 0.0827, aux_0.acc_seg: 95.8376, aux_1.loss_ce: 0.0997, aux_1.acc_seg: 94.9949, aux_2.loss_ce: 0.1208, aux_2.loss_dice: 0.2561, aux_2.acc_seg: 96.0544, aux_3.loss_ce: 0.1344, aux_3.acc_seg: 94.5584, aux_4.loss_t2t: 0.0191, loss: 0.7940
2023-05-02 10:49:41,904 - mmseg - INFO - Iter [4900/10000]	lr: 5.456e-02, eta: 1:19:06, time: 0.909, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0751, decode.acc_seg: 96.2026, aux_0.loss_ce: 0.0768, aux_0.acc_seg: 96.1782, aux_1.loss_ce: 0.0931, aux_1.acc_seg: 95.3574, aux_2.loss_ce: 0.1202, aux_2.loss_dice: 0.2547, aux_2.acc_seg: 96.0467, aux_3.loss_ce: 0.1285, aux_3.acc_seg: 94.8483, aux_4.loss_t2t: 0.0197, loss: 0.7680
2023-05-02 10:50:26,765 - mmseg - INFO - Iter [4950/10000]	lr: 5.408e-02, eta: 1:18:18, time: 0.897, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0741, decode.acc_seg: 96.2273, aux_0.loss_ce: 0.0759, aux_0.acc_seg: 96.1929, aux_1.loss_ce: 0.0922, aux_1.acc_seg: 95.3645, aux_2.loss_ce: 0.1221, aux_2.loss_dice: 0.2564, aux_2.acc_seg: 95.9758, aux_3.loss_ce: 0.1308, aux_3.acc_seg: 94.7313, aux_4.loss_t2t: 0.0195, loss: 0.7710
2023-05-02 10:51:14,669 - mmseg - INFO - Saving checkpoint at 5000 iterations
2023-05-02 10:51:17,972 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:51:17,973 - mmseg - INFO - Iter [5000/10000]	lr: 5.360e-02, eta: 1:17:36, time: 1.025, data_time: 0.257, memory: 14762, decode.loss_ce: 0.0729, decode.acc_seg: 96.3017, aux_0.loss_ce: 0.0745, aux_0.acc_seg: 96.2664, aux_1.loss_ce: 0.0906, aux_1.acc_seg: 95.4505, aux_2.loss_ce: 0.1207, aux_2.loss_dice: 0.2556, aux_2.acc_seg: 96.0499, aux_3.loss_ce: 0.1271, aux_3.acc_seg: 94.9020, aux_4.loss_t2t: 0.0196, loss: 0.7610
2023-05-02 10:51:21,483 - mmseg - INFO - per class results:
2023-05-02 10:51:21,484 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.14 | 94.09 |
|   Building  | 93.39 | 95.39 |
|     Car     | 93.85 | 96.88 |
| Column_Pole | 17.49 | 19.39 |
|    Fence    | 80.02 | 96.81 |
|  Pedestrian | 63.11 | 82.28 |
|     Road    | 97.78 | 98.43 |
|   Sidewalk  | 92.46 | 97.12 |
|  SignSymbol |  0.31 |  0.31 |
|     Sky     | 94.55 | 97.79 |
|     Tree    | 92.83 |  97.2 |
+-------------+-------+-------+
2023-05-02 10:51:21,484 - mmseg - INFO - Summary:
2023-05-02 10:51:21,485 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 96.4 | 73.81 | 79.61 |
+------+-------+-------+
2023-05-02 10:51:21,485 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 10:51:21,485 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9640, mIoU: 0.7381, mAcc: 0.7961, IoU.Bicyclist: 0.8614, IoU.Building: 0.9339, IoU.Car: 0.9385, IoU.Column_Pole: 0.1749, IoU.Fence: 0.8002, IoU.Pedestrian: 0.6311, IoU.Road: 0.9778, IoU.Sidewalk: 0.9246, IoU.SignSymbol: 0.0031, IoU.Sky: 0.9455, IoU.Tree: 0.9283, Acc.Bicyclist: 0.9409, Acc.Building: 0.9539, Acc.Car: 0.9688, Acc.Column_Pole: 0.1939, Acc.Fence: 0.9681, Acc.Pedestrian: 0.8228, Acc.Road: 0.9843, Acc.Sidewalk: 0.9712, Acc.SignSymbol: 0.0031, Acc.Sky: 0.9779, Acc.Tree: 0.9720
2023-05-02 10:52:04,811 - mmseg - INFO - Iter [5050/10000]	lr: 5.312e-02, eta: 1:16:50, time: 0.936, data_time: 0.246, memory: 14762, decode.loss_ce: 0.0710, decode.acc_seg: 96.3067, aux_0.loss_ce: 0.0729, aux_0.acc_seg: 96.2625, aux_1.loss_ce: 0.0889, aux_1.acc_seg: 95.4429, aux_2.loss_ce: 0.1194, aux_2.loss_dice: 0.2542, aux_2.acc_seg: 96.0726, aux_3.loss_ce: 0.1268, aux_3.acc_seg: 94.7939, aux_4.loss_t2t: 0.0192, loss: 0.7524
2023-05-02 10:52:48,341 - mmseg - INFO - Iter [5100/10000]	lr: 5.263e-02, eta: 1:16:01, time: 0.871, data_time: 0.175, memory: 14762, decode.loss_ce: 0.0708, decode.acc_seg: 96.3363, aux_0.loss_ce: 0.0728, aux_0.acc_seg: 96.2871, aux_1.loss_ce: 0.0893, aux_1.acc_seg: 95.4325, aux_2.loss_ce: 0.1200, aux_2.loss_dice: 0.2549, aux_2.acc_seg: 96.0510, aux_3.loss_ce: 0.1269, aux_3.acc_seg: 94.8208, aux_4.loss_t2t: 0.0192, loss: 0.7539
2023-05-02 10:53:37,066 - mmseg - INFO - Iter [5150/10000]	lr: 5.215e-02, eta: 1:15:16, time: 0.974, data_time: 0.262, memory: 14762, decode.loss_ce: 0.0732, decode.acc_seg: 96.2830, aux_0.loss_ce: 0.0749, aux_0.acc_seg: 96.2490, aux_1.loss_ce: 0.0909, aux_1.acc_seg: 95.4465, aux_2.loss_ce: 0.1206, aux_2.loss_dice: 0.2561, aux_2.acc_seg: 96.0169, aux_3.loss_ce: 0.1288, aux_3.acc_seg: 94.8549, aux_4.loss_t2t: 0.0193, loss: 0.7638
2023-05-02 10:54:22,267 - mmseg - INFO - Iter [5200/10000]	lr: 5.167e-02, eta: 1:14:28, time: 0.904, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0690, decode.acc_seg: 96.4815, aux_0.loss_ce: 0.0708, aux_0.acc_seg: 96.4493, aux_1.loss_ce: 0.0868, aux_1.acc_seg: 95.6478, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 96.0454, aux_3.loss_ce: 0.1244, aux_3.acc_seg: 95.0412, aux_4.loss_t2t: 0.0191, loss: 0.7434
2023-05-02 10:55:07,176 - mmseg - INFO - Iter [5250/10000]	lr: 5.118e-02, eta: 1:13:40, time: 0.898, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0750, decode.acc_seg: 96.1493, aux_0.loss_ce: 0.0758, aux_0.acc_seg: 96.1591, aux_1.loss_ce: 0.0919, aux_1.acc_seg: 95.3402, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 96.0978, aux_3.loss_ce: 0.1275, aux_3.acc_seg: 94.7833, aux_4.loss_t2t: 0.0190, loss: 0.7606
2023-05-02 10:55:52,268 - mmseg - INFO - Iter [5300/10000]	lr: 5.070e-02, eta: 1:12:52, time: 0.902, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0849, decode.acc_seg: 95.8484, aux_0.loss_ce: 0.0849, aux_0.acc_seg: 95.8614, aux_1.loss_ce: 0.1002, aux_1.acc_seg: 95.0671, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2557, aux_2.acc_seg: 95.9899, aux_3.loss_ce: 0.1357, aux_3.acc_seg: 94.5070, aux_4.loss_t2t: 0.0194, loss: 0.8026
2023-05-02 10:56:40,975 - mmseg - INFO - Iter [5350/10000]	lr: 5.021e-02, eta: 1:12:08, time: 0.974, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0755, decode.acc_seg: 96.1499, aux_0.loss_ce: 0.0772, aux_0.acc_seg: 96.1163, aux_1.loss_ce: 0.0929, aux_1.acc_seg: 95.3288, aux_2.loss_ce: 0.1215, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 96.0012, aux_3.loss_ce: 0.1295, aux_3.acc_seg: 94.7752, aux_4.loss_t2t: 0.0195, loss: 0.7716
2023-05-02 10:57:26,060 - mmseg - INFO - Iter [5400/10000]	lr: 4.972e-02, eta: 1:11:20, time: 0.902, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0781, decode.acc_seg: 96.0952, aux_0.loss_ce: 0.0806, aux_0.acc_seg: 96.0300, aux_1.loss_ce: 0.0963, aux_1.acc_seg: 95.2686, aux_2.loss_ce: 0.1216, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 95.9896, aux_3.loss_ce: 0.1311, aux_3.acc_seg: 94.7441, aux_4.loss_t2t: 0.0193, loss: 0.7831
2023-05-02 10:58:09,993 - mmseg - INFO - Iter [5450/10000]	lr: 4.924e-02, eta: 1:10:31, time: 0.879, data_time: 0.181, memory: 14762, decode.loss_ce: 0.0737, decode.acc_seg: 96.2895, aux_0.loss_ce: 0.0756, aux_0.acc_seg: 96.2556, aux_1.loss_ce: 0.0910, aux_1.acc_seg: 95.4819, aux_2.loss_ce: 0.1208, aux_2.loss_dice: 0.2556, aux_2.acc_seg: 96.0269, aux_3.loss_ce: 0.1297, aux_3.acc_seg: 94.8080, aux_4.loss_t2t: 0.0195, loss: 0.7659
2023-05-02 10:58:55,255 - mmseg - INFO - Iter [5500/10000]	lr: 4.875e-02, eta: 1:09:44, time: 0.905, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0683, decode.acc_seg: 96.4571, aux_0.loss_ce: 0.0702, aux_0.acc_seg: 96.4325, aux_1.loss_ce: 0.0856, aux_1.acc_seg: 95.6287, aux_2.loss_ce: 0.1189, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 96.0841, aux_3.loss_ce: 0.1229, aux_3.acc_seg: 94.9924, aux_4.loss_t2t: 0.0190, loss: 0.7382
2023-05-02 10:59:43,858 - mmseg - INFO - Iter [5550/10000]	lr: 4.826e-02, eta: 1:08:59, time: 0.972, data_time: 0.259, memory: 14762, decode.loss_ce: 0.0694, decode.acc_seg: 96.3453, aux_0.loss_ce: 0.0709, aux_0.acc_seg: 96.3206, aux_1.loss_ce: 0.0864, aux_1.acc_seg: 95.5139, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2526, aux_2.acc_seg: 96.0480, aux_3.loss_ce: 0.1241, aux_3.acc_seg: 94.8598, aux_4.loss_t2t: 0.0188, loss: 0.7409
2023-05-02 11:00:29,245 - mmseg - INFO - Iter [5600/10000]	lr: 4.778e-02, eta: 1:08:12, time: 0.908, data_time: 0.195, memory: 14762, decode.loss_ce: 0.0707, decode.acc_seg: 96.3981, aux_0.loss_ce: 0.0724, aux_0.acc_seg: 96.3685, aux_1.loss_ce: 0.0885, aux_1.acc_seg: 95.5685, aux_2.loss_ce: 0.1210, aux_2.loss_dice: 0.2551, aux_2.acc_seg: 95.9818, aux_3.loss_ce: 0.1274, aux_3.acc_seg: 94.9011, aux_4.loss_t2t: 0.0187, loss: 0.7538
2023-05-02 11:01:14,701 - mmseg - INFO - Iter [5650/10000]	lr: 4.729e-02, eta: 1:07:24, time: 0.909, data_time: 0.198, memory: 14762, decode.loss_ce: 0.0652, decode.acc_seg: 96.6401, aux_0.loss_ce: 0.0671, aux_0.acc_seg: 96.6081, aux_1.loss_ce: 0.0828, aux_1.acc_seg: 95.8185, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 96.0880, aux_3.loss_ce: 0.1210, aux_3.acc_seg: 95.1678, aux_4.loss_t2t: 0.0189, loss: 0.7250
2023-05-02 11:02:03,244 - mmseg - INFO - Iter [5700/10000]	lr: 4.680e-02, eta: 1:06:39, time: 0.971, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0640, decode.acc_seg: 96.6049, aux_0.loss_ce: 0.0659, aux_0.acc_seg: 96.5539, aux_1.loss_ce: 0.0812, aux_1.acc_seg: 95.7534, aux_2.loss_ce: 0.1171, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 96.0862, aux_3.loss_ce: 0.1182, aux_3.acc_seg: 95.0912, aux_4.loss_t2t: 0.0183, loss: 0.7159
2023-05-02 11:02:48,341 - mmseg - INFO - Iter [5750/10000]	lr: 4.631e-02, eta: 1:05:52, time: 0.902, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0702, decode.acc_seg: 96.3133, aux_0.loss_ce: 0.0719, aux_0.acc_seg: 96.2854, aux_1.loss_ce: 0.0871, aux_1.acc_seg: 95.4783, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 96.0646, aux_3.loss_ce: 0.1245, aux_3.acc_seg: 94.8279, aux_4.loss_t2t: 0.0183, loss: 0.7420
2023-05-02 11:03:32,873 - mmseg - INFO - Iter [5800/10000]	lr: 4.582e-02, eta: 1:05:04, time: 0.891, data_time: 0.185, memory: 14762, decode.loss_ce: 0.0681, decode.acc_seg: 96.3848, aux_0.loss_ce: 0.0697, aux_0.acc_seg: 96.3613, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.5697, aux_2.loss_ce: 0.1191, aux_2.loss_dice: 0.2519, aux_2.acc_seg: 96.0146, aux_3.loss_ce: 0.1211, aux_3.acc_seg: 94.9420, aux_4.loss_t2t: 0.0181, loss: 0.7326
2023-05-02 11:04:16,930 - mmseg - INFO - Iter [5850/10000]	lr: 4.533e-02, eta: 1:04:16, time: 0.881, data_time: 0.181, memory: 14762, decode.loss_ce: 0.0674, decode.acc_seg: 96.5019, aux_0.loss_ce: 0.0691, aux_0.acc_seg: 96.4609, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.6719, aux_2.loss_ce: 0.1190, aux_2.loss_dice: 0.2527, aux_2.acc_seg: 96.0608, aux_3.loss_ce: 0.1236, aux_3.acc_seg: 94.9765, aux_4.loss_t2t: 0.0183, loss: 0.7347
2023-05-02 11:05:06,033 - mmseg - INFO - Iter [5900/10000]	lr: 4.483e-02, eta: 1:03:31, time: 0.982, data_time: 0.269, memory: 14762, decode.loss_ce: 0.0672, decode.acc_seg: 96.5115, aux_0.loss_ce: 0.0691, aux_0.acc_seg: 96.4714, aux_1.loss_ce: 0.0845, aux_1.acc_seg: 95.6788, aux_2.loss_ce: 0.1191, aux_2.loss_dice: 0.2533, aux_2.acc_seg: 96.0435, aux_3.loss_ce: 0.1232, aux_3.acc_seg: 94.9973, aux_4.loss_t2t: 0.0184, loss: 0.7348
2023-05-02 11:05:51,325 - mmseg - INFO - Iter [5950/10000]	lr: 4.434e-02, eta: 1:02:44, time: 0.906, data_time: 0.195, memory: 14762, decode.loss_ce: 0.0679, decode.acc_seg: 96.5029, aux_0.loss_ce: 0.0692, aux_0.acc_seg: 96.4773, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.6894, aux_2.loss_ce: 0.1200, aux_2.loss_dice: 0.2545, aux_2.acc_seg: 96.0356, aux_3.loss_ce: 0.1231, aux_3.acc_seg: 95.0162, aux_4.loss_t2t: 0.0186, loss: 0.7382
2023-05-02 11:06:36,336 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-05-02 11:06:38,416 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:06:38,416 - mmseg - INFO - Iter [6000/10000]	lr: 4.385e-02, eta: 1:01:58, time: 0.942, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0679, decode.acc_seg: 96.4591, aux_0.loss_ce: 0.0694, aux_0.acc_seg: 96.4239, aux_1.loss_ce: 0.0848, aux_1.acc_seg: 95.6370, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2524, aux_2.acc_seg: 96.0868, aux_3.loss_ce: 0.1228, aux_3.acc_seg: 94.9832, aux_4.loss_t2t: 0.0184, loss: 0.7339
2023-05-02 11:06:42,729 - mmseg - INFO - per class results:
2023-05-02 11:06:42,730 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 85.86 | 94.39 |
|   Building  | 92.85 | 94.85 |
|     Car     | 93.06 |  95.6 |
| Column_Pole | 21.76 | 24.53 |
|    Fence    | 81.72 | 93.53 |
|  Pedestrian |  66.9 |  83.2 |
|     Road    | 97.73 | 98.54 |
|   Sidewalk  | 92.54 | 96.74 |
|  SignSymbol |  3.34 |  3.34 |
|     Sky     | 94.33 |  97.0 |
|     Tree    | 91.55 | 98.13 |
+-------------+-------+-------+
2023-05-02 11:06:42,730 - mmseg - INFO - Summary:
2023-05-02 11:06:42,730 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 96.26 | 74.7 | 79.99 |
+-------+------+-------+
2023-05-02 11:06:42,731 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:06:42,731 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9626, mIoU: 0.7470, mAcc: 0.7999, IoU.Bicyclist: 0.8586, IoU.Building: 0.9285, IoU.Car: 0.9306, IoU.Column_Pole: 0.2176, IoU.Fence: 0.8172, IoU.Pedestrian: 0.6690, IoU.Road: 0.9773, IoU.Sidewalk: 0.9254, IoU.SignSymbol: 0.0334, IoU.Sky: 0.9433, IoU.Tree: 0.9155, Acc.Bicyclist: 0.9439, Acc.Building: 0.9485, Acc.Car: 0.9560, Acc.Column_Pole: 0.2453, Acc.Fence: 0.9353, Acc.Pedestrian: 0.8320, Acc.Road: 0.9854, Acc.Sidewalk: 0.9674, Acc.SignSymbol: 0.0334, Acc.Sky: 0.9700, Acc.Tree: 0.9813
2023-05-02 11:07:27,937 - mmseg - INFO - Iter [6050/10000]	lr: 4.336e-02, eta: 1:01:13, time: 0.990, data_time: 0.278, memory: 14762, decode.loss_ce: 0.0834, decode.acc_seg: 95.8322, aux_0.loss_ce: 0.0837, aux_0.acc_seg: 95.8424, aux_1.loss_ce: 0.0988, aux_1.acc_seg: 95.0561, aux_2.loss_ce: 0.1210, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 96.0667, aux_3.loss_ce: 0.1310, aux_3.acc_seg: 94.5960, aux_4.loss_t2t: 0.0186, loss: 0.7924
2023-05-02 11:08:16,419 - mmseg - INFO - Iter [6100/10000]	lr: 4.286e-02, eta: 1:00:28, time: 0.970, data_time: 0.262, memory: 14762, decode.loss_ce: 0.0704, decode.acc_seg: 96.3080, aux_0.loss_ce: 0.0724, aux_0.acc_seg: 96.2547, aux_1.loss_ce: 0.0885, aux_1.acc_seg: 95.4013, aux_2.loss_ce: 0.1189, aux_2.loss_dice: 0.2543, aux_2.acc_seg: 96.0871, aux_3.loss_ce: 0.1236, aux_3.acc_seg: 94.8728, aux_4.loss_t2t: 0.0185, loss: 0.7466
2023-05-02 11:09:01,487 - mmseg - INFO - Iter [6150/10000]	lr: 4.237e-02, eta: 0:59:41, time: 0.901, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0718, decode.acc_seg: 96.3481, aux_0.loss_ce: 0.0730, aux_0.acc_seg: 96.3237, aux_1.loss_ce: 0.0886, aux_1.acc_seg: 95.5377, aux_2.loss_ce: 0.1197, aux_2.loss_dice: 0.2551, aux_2.acc_seg: 96.0883, aux_3.loss_ce: 0.1264, aux_3.acc_seg: 94.8882, aux_4.loss_t2t: 0.0186, loss: 0.7531
2023-05-02 11:09:45,573 - mmseg - INFO - Iter [6200/10000]	lr: 4.187e-02, eta: 0:58:53, time: 0.882, data_time: 0.183, memory: 14762, decode.loss_ce: 0.0666, decode.acc_seg: 96.5007, aux_0.loss_ce: 0.0683, aux_0.acc_seg: 96.4772, aux_1.loss_ce: 0.0841, aux_1.acc_seg: 95.6569, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2527, aux_2.acc_seg: 96.0399, aux_3.loss_ce: 0.1215, aux_3.acc_seg: 95.0106, aux_4.loss_t2t: 0.0189, loss: 0.7315
2023-05-02 11:10:32,932 - mmseg - INFO - Iter [6250/10000]	lr: 4.138e-02, eta: 0:58:07, time: 0.947, data_time: 0.250, memory: 14762, decode.loss_ce: 0.0685, decode.acc_seg: 96.4194, aux_0.loss_ce: 0.0698, aux_0.acc_seg: 96.4070, aux_1.loss_ce: 0.0858, aux_1.acc_seg: 95.5792, aux_2.loss_ce: 0.1199, aux_2.loss_dice: 0.2533, aux_2.acc_seg: 96.0007, aux_3.loss_ce: 0.1247, aux_3.acc_seg: 94.8903, aux_4.loss_t2t: 0.0182, loss: 0.7403
2023-05-02 11:11:17,620 - mmseg - INFO - Iter [6300/10000]	lr: 4.088e-02, eta: 0:57:19, time: 0.894, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0670, decode.acc_seg: 96.5110, aux_0.loss_ce: 0.0687, aux_0.acc_seg: 96.4770, aux_1.loss_ce: 0.0837, aux_1.acc_seg: 95.6949, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2528, aux_2.acc_seg: 96.0134, aux_3.loss_ce: 0.1216, aux_3.acc_seg: 95.0260, aux_4.loss_t2t: 0.0185, loss: 0.7316
2023-05-02 11:12:02,287 - mmseg - INFO - Iter [6350/10000]	lr: 4.038e-02, eta: 0:56:32, time: 0.893, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0647, decode.acc_seg: 96.5397, aux_0.loss_ce: 0.0661, aux_0.acc_seg: 96.5273, aux_1.loss_ce: 0.0819, aux_1.acc_seg: 95.7067, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 96.0692, aux_3.loss_ce: 0.1193, aux_3.acc_seg: 95.0434, aux_4.loss_t2t: 0.0182, loss: 0.7180
2023-05-02 11:12:47,113 - mmseg - INFO - Iter [6400/10000]	lr: 3.988e-02, eta: 0:55:44, time: 0.897, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0642, decode.acc_seg: 96.6168, aux_0.loss_ce: 0.0658, aux_0.acc_seg: 96.5992, aux_1.loss_ce: 0.0813, aux_1.acc_seg: 95.8097, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 96.1045, aux_3.loss_ce: 0.1201, aux_3.acc_seg: 95.1080, aux_4.loss_t2t: 0.0182, loss: 0.7199
2023-05-02 11:13:35,341 - mmseg - INFO - Iter [6450/10000]	lr: 3.938e-02, eta: 0:54:59, time: 0.965, data_time: 0.256, memory: 14762, decode.loss_ce: 0.0622, decode.acc_seg: 96.6528, aux_0.loss_ce: 0.0635, aux_0.acc_seg: 96.6403, aux_1.loss_ce: 0.0789, aux_1.acc_seg: 95.8414, aux_2.loss_ce: 0.1167, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.0784, aux_3.loss_ce: 0.1153, aux_3.acc_seg: 95.2122, aux_4.loss_t2t: 0.0179, loss: 0.7041
2023-05-02 11:14:19,912 - mmseg - INFO - Iter [6500/10000]	lr: 3.888e-02, eta: 0:54:11, time: 0.891, data_time: 0.185, memory: 14762, decode.loss_ce: 0.0639, decode.acc_seg: 96.6745, aux_0.loss_ce: 0.0655, aux_0.acc_seg: 96.6620, aux_1.loss_ce: 0.0808, aux_1.acc_seg: 95.8840, aux_2.loss_ce: 0.1183, aux_2.loss_dice: 0.2534, aux_2.acc_seg: 96.0982, aux_3.loss_ce: 0.1196, aux_3.acc_seg: 95.1800, aux_4.loss_t2t: 0.0180, loss: 0.7195
2023-05-02 11:15:04,970 - mmseg - INFO - Iter [6550/10000]	lr: 3.838e-02, eta: 0:53:24, time: 0.901, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0664, decode.acc_seg: 96.5205, aux_0.loss_ce: 0.0679, aux_0.acc_seg: 96.5065, aux_1.loss_ce: 0.0835, aux_1.acc_seg: 95.7098, aux_2.loss_ce: 0.1200, aux_2.loss_dice: 0.2538, aux_2.acc_seg: 95.9906, aux_3.loss_ce: 0.1212, aux_3.acc_seg: 95.0825, aux_4.loss_t2t: 0.0183, loss: 0.7311
2023-05-02 11:15:49,039 - mmseg - INFO - Iter [6600/10000]	lr: 3.788e-02, eta: 0:52:36, time: 0.881, data_time: 0.181, memory: 14762, decode.loss_ce: 0.0636, decode.acc_seg: 96.6010, aux_0.loss_ce: 0.0650, aux_0.acc_seg: 96.6003, aux_1.loss_ce: 0.0804, aux_1.acc_seg: 95.7756, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 96.0101, aux_3.loss_ce: 0.1178, aux_3.acc_seg: 95.0932, aux_4.loss_t2t: 0.0178, loss: 0.7140
2023-05-02 11:16:37,531 - mmseg - INFO - Iter [6650/10000]	lr: 3.738e-02, eta: 0:51:51, time: 0.970, data_time: 0.263, memory: 14762, decode.loss_ce: 0.0678, decode.acc_seg: 96.4533, aux_0.loss_ce: 0.0691, aux_0.acc_seg: 96.4322, aux_1.loss_ce: 0.0846, aux_1.acc_seg: 95.6435, aux_2.loss_ce: 0.1192, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 95.9907, aux_3.loss_ce: 0.1224, aux_3.acc_seg: 94.9790, aux_4.loss_t2t: 0.0179, loss: 0.7332
2023-05-02 11:17:22,547 - mmseg - INFO - Iter [6700/10000]	lr: 3.688e-02, eta: 0:51:04, time: 0.900, data_time: 0.194, memory: 14762, decode.loss_ce: 0.0625, decode.acc_seg: 96.6522, aux_0.loss_ce: 0.0639, aux_0.acc_seg: 96.6274, aux_1.loss_ce: 0.0797, aux_1.acc_seg: 95.8176, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 96.0334, aux_3.loss_ce: 0.1173, aux_3.acc_seg: 95.1333, aux_4.loss_t2t: 0.0178, loss: 0.7107
2023-05-02 11:18:07,399 - mmseg - INFO - Iter [6750/10000]	lr: 3.638e-02, eta: 0:50:17, time: 0.897, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0632, decode.acc_seg: 96.6262, aux_0.loss_ce: 0.0646, aux_0.acc_seg: 96.6043, aux_1.loss_ce: 0.0797, aux_1.acc_seg: 95.8066, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 96.1357, aux_3.loss_ce: 0.1192, aux_3.acc_seg: 95.0480, aux_4.loss_t2t: 0.0177, loss: 0.7118
2023-05-02 11:18:55,946 - mmseg - INFO - Iter [6800/10000]	lr: 3.587e-02, eta: 0:49:31, time: 0.971, data_time: 0.259, memory: 14762, decode.loss_ce: 0.0623, decode.acc_seg: 96.7496, aux_0.loss_ce: 0.0639, aux_0.acc_seg: 96.7190, aux_1.loss_ce: 0.0789, aux_1.acc_seg: 95.9508, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2504, aux_2.acc_seg: 96.0209, aux_3.loss_ce: 0.1173, aux_3.acc_seg: 95.2362, aux_4.loss_t2t: 0.0179, loss: 0.7092
2023-05-02 11:19:41,247 - mmseg - INFO - Iter [6850/10000]	lr: 3.537e-02, eta: 0:48:44, time: 0.906, data_time: 0.194, memory: 14762, decode.loss_ce: 0.0633, decode.acc_seg: 96.6571, aux_0.loss_ce: 0.0646, aux_0.acc_seg: 96.6355, aux_1.loss_ce: 0.0801, aux_1.acc_seg: 95.8437, aux_2.loss_ce: 0.1181, aux_2.loss_dice: 0.2516, aux_2.acc_seg: 96.0466, aux_3.loss_ce: 0.1190, aux_3.acc_seg: 95.1121, aux_4.loss_t2t: 0.0177, loss: 0.7142
2023-05-02 11:20:26,275 - mmseg - INFO - Iter [6900/10000]	lr: 3.486e-02, eta: 0:47:57, time: 0.901, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0636, decode.acc_seg: 96.7328, aux_0.loss_ce: 0.0652, aux_0.acc_seg: 96.7109, aux_1.loss_ce: 0.0807, aux_1.acc_seg: 95.9205, aux_2.loss_ce: 0.1205, aux_2.loss_dice: 0.2536, aux_2.acc_seg: 95.9923, aux_3.loss_ce: 0.1209, aux_3.acc_seg: 95.1574, aux_4.loss_t2t: 0.0178, loss: 0.7224
2023-05-02 11:21:11,470 - mmseg - INFO - Iter [6950/10000]	lr: 3.436e-02, eta: 0:47:10, time: 0.904, data_time: 0.194, memory: 14762, decode.loss_ce: 0.0629, decode.acc_seg: 96.6831, aux_0.loss_ce: 0.0640, aux_0.acc_seg: 96.6756, aux_1.loss_ce: 0.0793, aux_1.acc_seg: 95.8816, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 96.0686, aux_3.loss_ce: 0.1169, aux_3.acc_seg: 95.1964, aux_4.loss_t2t: 0.0181, loss: 0.7122
2023-05-02 11:21:59,271 - mmseg - INFO - Saving checkpoint at 7000 iterations
2023-05-02 11:22:01,360 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:22:01,360 - mmseg - INFO - Iter [7000/10000]	lr: 3.385e-02, eta: 0:46:25, time: 0.998, data_time: 0.254, memory: 14762, decode.loss_ce: 0.0654, decode.acc_seg: 96.5744, aux_0.loss_ce: 0.0668, aux_0.acc_seg: 96.5535, aux_1.loss_ce: 0.0819, aux_1.acc_seg: 95.7724, aux_2.loss_ce: 0.1183, aux_2.loss_dice: 0.2514, aux_2.acc_seg: 96.0567, aux_3.loss_ce: 0.1199, aux_3.acc_seg: 95.0669, aux_4.loss_t2t: 0.0176, loss: 0.7213
2023-05-02 11:22:05,507 - mmseg - INFO - per class results:
2023-05-02 11:22:05,508 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 83.78 | 94.29 |
|   Building  | 92.92 |  95.4 |
|     Car     | 93.56 | 94.94 |
| Column_Pole | 33.15 | 47.23 |
|    Fence    | 79.19 | 89.46 |
|  Pedestrian | 65.83 | 83.44 |
|     Road    | 96.41 | 96.78 |
|   Sidewalk  | 89.39 | 97.05 |
|  SignSymbol |  0.26 |  0.26 |
|     Sky     | 94.26 | 96.67 |
|     Tree    | 91.95 | 97.92 |
+-------------+-------+-------+
2023-05-02 11:22:05,509 - mmseg - INFO - Summary:
2023-05-02 11:22:05,509 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.84 | 74.61 | 81.22 |
+-------+-------+-------+
2023-05-02 11:22:05,509 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:22:05,509 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9584, mIoU: 0.7461, mAcc: 0.8122, IoU.Bicyclist: 0.8378, IoU.Building: 0.9292, IoU.Car: 0.9356, IoU.Column_Pole: 0.3315, IoU.Fence: 0.7919, IoU.Pedestrian: 0.6583, IoU.Road: 0.9641, IoU.Sidewalk: 0.8939, IoU.SignSymbol: 0.0026, IoU.Sky: 0.9426, IoU.Tree: 0.9195, Acc.Bicyclist: 0.9429, Acc.Building: 0.9540, Acc.Car: 0.9494, Acc.Column_Pole: 0.4723, Acc.Fence: 0.8946, Acc.Pedestrian: 0.8344, Acc.Road: 0.9678, Acc.Sidewalk: 0.9705, Acc.SignSymbol: 0.0026, Acc.Sky: 0.9667, Acc.Tree: 0.9792
2023-05-02 11:22:50,448 - mmseg - INFO - Iter [7050/10000]	lr: 3.334e-02, eta: 0:45:40, time: 0.981, data_time: 0.275, memory: 14762, decode.loss_ce: 0.0619, decode.acc_seg: 96.6893, aux_0.loss_ce: 0.0634, aux_0.acc_seg: 96.6697, aux_1.loss_ce: 0.0785, aux_1.acc_seg: 95.8813, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 96.1118, aux_3.loss_ce: 0.1156, aux_3.acc_seg: 95.1739, aux_4.loss_t2t: 0.0175, loss: 0.7033
2023-05-02 11:23:35,007 - mmseg - INFO - Iter [7100/10000]	lr: 3.283e-02, eta: 0:44:53, time: 0.891, data_time: 0.185, memory: 14762, decode.loss_ce: 0.0638, decode.acc_seg: 96.6209, aux_0.loss_ce: 0.0654, aux_0.acc_seg: 96.5958, aux_1.loss_ce: 0.0797, aux_1.acc_seg: 95.8400, aux_2.loss_ce: 0.1165, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 96.1184, aux_3.loss_ce: 0.1182, aux_3.acc_seg: 95.1156, aux_4.loss_t2t: 0.0175, loss: 0.7112
2023-05-02 11:24:19,321 - mmseg - INFO - Iter [7150/10000]	lr: 3.232e-02, eta: 0:44:05, time: 0.886, data_time: 0.184, memory: 14762, decode.loss_ce: 0.0627, decode.acc_seg: 96.5935, aux_0.loss_ce: 0.0643, aux_0.acc_seg: 96.5619, aux_1.loss_ce: 0.0797, aux_1.acc_seg: 95.7527, aux_2.loss_ce: 0.1183, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 95.9803, aux_3.loss_ce: 0.1175, aux_3.acc_seg: 95.0428, aux_4.loss_t2t: 0.0174, loss: 0.7092
2023-05-02 11:25:07,675 - mmseg - INFO - Iter [7200/10000]	lr: 3.181e-02, eta: 0:43:20, time: 0.967, data_time: 0.258, memory: 14762, decode.loss_ce: 0.0668, decode.acc_seg: 96.5255, aux_0.loss_ce: 0.0678, aux_0.acc_seg: 96.5182, aux_1.loss_ce: 0.0827, aux_1.acc_seg: 95.7396, aux_2.loss_ce: 0.1180, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0590, aux_3.loss_ce: 0.1215, aux_3.acc_seg: 94.9920, aux_4.loss_t2t: 0.0175, loss: 0.7251
2023-05-02 11:25:52,794 - mmseg - INFO - Iter [7250/10000]	lr: 3.130e-02, eta: 0:42:33, time: 0.902, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0643, decode.acc_seg: 96.5732, aux_0.loss_ce: 0.0658, aux_0.acc_seg: 96.5468, aux_1.loss_ce: 0.0809, aux_1.acc_seg: 95.7533, aux_2.loss_ce: 0.1186, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0326, aux_3.loss_ce: 0.1185, aux_3.acc_seg: 95.0661, aux_4.loss_t2t: 0.0176, loss: 0.7167
2023-05-02 11:26:37,840 - mmseg - INFO - Iter [7300/10000]	lr: 3.079e-02, eta: 0:41:46, time: 0.901, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0618, decode.acc_seg: 96.7134, aux_0.loss_ce: 0.0630, aux_0.acc_seg: 96.7022, aux_1.loss_ce: 0.0788, aux_1.acc_seg: 95.8839, aux_2.loss_ce: 0.1172, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 96.0415, aux_3.loss_ce: 0.1173, aux_3.acc_seg: 95.1733, aux_4.loss_t2t: 0.0173, loss: 0.7046
2023-05-02 11:27:25,620 - mmseg - INFO - Iter [7350/10000]	lr: 3.027e-02, eta: 0:41:00, time: 0.956, data_time: 0.255, memory: 14762, decode.loss_ce: 0.0626, decode.acc_seg: 96.6895, aux_0.loss_ce: 0.0641, aux_0.acc_seg: 96.6688, aux_1.loss_ce: 0.0791, aux_1.acc_seg: 95.8777, aux_2.loss_ce: 0.1188, aux_2.loss_dice: 0.2520, aux_2.acc_seg: 96.0456, aux_3.loss_ce: 0.1177, aux_3.acc_seg: 95.1644, aux_4.loss_t2t: 0.0173, loss: 0.7116
2023-05-02 11:28:08,380 - mmseg - INFO - Iter [7400/10000]	lr: 2.976e-02, eta: 0:40:12, time: 0.855, data_time: 0.170, memory: 14762, decode.loss_ce: 0.0635, decode.acc_seg: 96.6777, aux_0.loss_ce: 0.0652, aux_0.acc_seg: 96.6497, aux_1.loss_ce: 0.0808, aux_1.acc_seg: 95.8285, aux_2.loss_ce: 0.1194, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 95.9931, aux_3.loss_ce: 0.1201, aux_3.acc_seg: 95.0709, aux_4.loss_t2t: 0.0177, loss: 0.7188
2023-05-02 11:28:52,604 - mmseg - INFO - Iter [7450/10000]	lr: 2.924e-02, eta: 0:39:25, time: 0.884, data_time: 0.181, memory: 14762, decode.loss_ce: 0.0608, decode.acc_seg: 96.7468, aux_0.loss_ce: 0.0619, aux_0.acc_seg: 96.7363, aux_1.loss_ce: 0.0770, aux_1.acc_seg: 95.9553, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.1197, aux_3.loss_ce: 0.1166, aux_3.acc_seg: 95.1583, aux_4.loss_t2t: 0.0174, loss: 0.6996
2023-05-02 11:29:37,092 - mmseg - INFO - Iter [7500/10000]	lr: 2.873e-02, eta: 0:38:38, time: 0.890, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0608, decode.acc_seg: 96.7664, aux_0.loss_ce: 0.0621, aux_0.acc_seg: 96.7454, aux_1.loss_ce: 0.0769, aux_1.acc_seg: 95.9876, aux_2.loss_ce: 0.1155, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.1158, aux_3.loss_ce: 0.1145, aux_3.acc_seg: 95.2724, aux_4.loss_t2t: 0.0175, loss: 0.6963
2023-05-02 11:30:26,053 - mmseg - INFO - Iter [7550/10000]	lr: 2.821e-02, eta: 0:37:53, time: 0.979, data_time: 0.270, memory: 14762, decode.loss_ce: 0.0599, decode.acc_seg: 96.7849, aux_0.loss_ce: 0.0613, aux_0.acc_seg: 96.7661, aux_1.loss_ce: 0.0763, aux_1.acc_seg: 95.9692, aux_2.loss_ce: 0.1165, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.1093, aux_3.loss_ce: 0.1156, aux_3.acc_seg: 95.2153, aux_4.loss_t2t: 0.0174, loss: 0.6965
2023-05-02 11:31:10,918 - mmseg - INFO - Iter [7600/10000]	lr: 2.769e-02, eta: 0:37:06, time: 0.897, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0628, decode.acc_seg: 96.6883, aux_0.loss_ce: 0.0642, aux_0.acc_seg: 96.6804, aux_1.loss_ce: 0.0791, aux_1.acc_seg: 95.9041, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2513, aux_2.acc_seg: 96.0821, aux_3.loss_ce: 0.1176, aux_3.acc_seg: 95.1626, aux_4.loss_t2t: 0.0174, loss: 0.7100
2023-05-02 11:31:55,974 - mmseg - INFO - Iter [7650/10000]	lr: 2.717e-02, eta: 0:36:19, time: 0.901, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0609, decode.acc_seg: 96.7818, aux_0.loss_ce: 0.0624, aux_0.acc_seg: 96.7577, aux_1.loss_ce: 0.0776, aux_1.acc_seg: 95.9726, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.0356, aux_3.loss_ce: 0.1163, aux_3.acc_seg: 95.2327, aux_4.loss_t2t: 0.0174, loss: 0.7031
2023-05-02 11:32:41,303 - mmseg - INFO - Iter [7700/10000]	lr: 2.665e-02, eta: 0:35:32, time: 0.907, data_time: 0.194, memory: 14762, decode.loss_ce: 0.0619, decode.acc_seg: 96.7206, aux_0.loss_ce: 0.0635, aux_0.acc_seg: 96.7045, aux_1.loss_ce: 0.0784, aux_1.acc_seg: 95.9275, aux_2.loss_ce: 0.1179, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.0511, aux_3.loss_ce: 0.1175, aux_3.acc_seg: 95.1615, aux_4.loss_t2t: 0.0174, loss: 0.7069
2023-05-02 11:33:29,900 - mmseg - INFO - Iter [7750/10000]	lr: 2.613e-02, eta: 0:34:47, time: 0.972, data_time: 0.260, memory: 14762, decode.loss_ce: 0.0611, decode.acc_seg: 96.7456, aux_0.loss_ce: 0.0625, aux_0.acc_seg: 96.7274, aux_1.loss_ce: 0.0777, aux_1.acc_seg: 95.9335, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 96.0761, aux_3.loss_ce: 0.1167, aux_3.acc_seg: 95.1835, aux_4.loss_t2t: 0.0171, loss: 0.7039
2023-05-02 11:34:14,273 - mmseg - INFO - Iter [7800/10000]	lr: 2.561e-02, eta: 0:34:00, time: 0.887, data_time: 0.182, memory: 14762, decode.loss_ce: 0.0620, decode.acc_seg: 96.7116, aux_0.loss_ce: 0.0636, aux_0.acc_seg: 96.6717, aux_1.loss_ce: 0.0793, aux_1.acc_seg: 95.8659, aux_2.loss_ce: 0.1184, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 95.9884, aux_3.loss_ce: 0.1183, aux_3.acc_seg: 95.1365, aux_4.loss_t2t: 0.0173, loss: 0.7093
2023-05-02 11:34:59,308 - mmseg - INFO - Iter [7850/10000]	lr: 2.508e-02, eta: 0:33:13, time: 0.901, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0644, decode.acc_seg: 96.6008, aux_0.loss_ce: 0.0654, aux_0.acc_seg: 96.5982, aux_1.loss_ce: 0.0812, aux_1.acc_seg: 95.7999, aux_2.loss_ce: 0.1202, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 95.9663, aux_3.loss_ce: 0.1210, aux_3.acc_seg: 95.0472, aux_4.loss_t2t: 0.0172, loss: 0.7217
2023-05-02 11:35:48,179 - mmseg - INFO - Iter [7900/10000]	lr: 2.456e-02, eta: 0:32:27, time: 0.977, data_time: 0.265, memory: 14762, decode.loss_ce: 0.0607, decode.acc_seg: 96.8106, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.7876, aux_1.loss_ce: 0.0778, aux_1.acc_seg: 95.9848, aux_2.loss_ce: 0.1200, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 95.9923, aux_3.loss_ce: 0.1177, aux_3.acc_seg: 95.2143, aux_4.loss_t2t: 0.0175, loss: 0.7090
2023-05-02 11:36:32,989 - mmseg - INFO - Iter [7950/10000]	lr: 2.403e-02, eta: 0:31:40, time: 0.896, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0599, decode.acc_seg: 96.8220, aux_0.loss_ce: 0.0613, aux_0.acc_seg: 96.7999, aux_1.loss_ce: 0.0768, aux_1.acc_seg: 96.0109, aux_2.loss_ce: 0.1177, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.0428, aux_3.loss_ce: 0.1167, aux_3.acc_seg: 95.2229, aux_4.loss_t2t: 0.0174, loss: 0.7004
2023-05-02 11:37:17,885 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-05-02 11:37:19,832 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:37:19,832 - mmseg - INFO - Iter [8000/10000]	lr: 2.350e-02, eta: 0:30:54, time: 0.937, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0607, decode.acc_seg: 96.7983, aux_0.loss_ce: 0.0623, aux_0.acc_seg: 96.7811, aux_1.loss_ce: 0.0771, aux_1.acc_seg: 96.0079, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0081, aux_3.loss_ce: 0.1167, aux_3.acc_seg: 95.2667, aux_4.loss_t2t: 0.0175, loss: 0.7033
2023-05-02 11:37:23,758 - mmseg - INFO - per class results:
2023-05-02 11:37:23,759 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.74 | 92.87 |
|   Building  | 93.82 | 95.75 |
|     Car     | 93.24 | 95.25 |
| Column_Pole | 29.32 | 35.29 |
|    Fence    | 82.84 | 93.08 |
|  Pedestrian | 68.12 | 82.81 |
|     Road    | 97.75 | 98.75 |
|   Sidewalk  | 92.63 | 96.92 |
|  SignSymbol |  0.22 |  0.22 |
|     Sky     | 94.43 | 97.01 |
|     Tree    | 92.52 | 98.04 |
+-------------+-------+-------+
2023-05-02 11:37:23,759 - mmseg - INFO - Summary:
2023-05-02 11:37:23,759 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 96.56 | 75.6 | 80.55 |
+-------+------+-------+
2023-05-02 11:37:23,760 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:37:23,760 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9656, mIoU: 0.7560, mAcc: 0.8055, IoU.Bicyclist: 0.8674, IoU.Building: 0.9382, IoU.Car: 0.9324, IoU.Column_Pole: 0.2932, IoU.Fence: 0.8284, IoU.Pedestrian: 0.6812, IoU.Road: 0.9775, IoU.Sidewalk: 0.9263, IoU.SignSymbol: 0.0022, IoU.Sky: 0.9443, IoU.Tree: 0.9252, Acc.Bicyclist: 0.9287, Acc.Building: 0.9575, Acc.Car: 0.9525, Acc.Column_Pole: 0.3529, Acc.Fence: 0.9308, Acc.Pedestrian: 0.8281, Acc.Road: 0.9875, Acc.Sidewalk: 0.9692, Acc.SignSymbol: 0.0022, Acc.Sky: 0.9701, Acc.Tree: 0.9804
2023-05-02 11:38:08,512 - mmseg - INFO - Iter [8050/10000]	lr: 2.297e-02, eta: 0:30:08, time: 0.973, data_time: 0.268, memory: 14762, decode.loss_ce: 0.0605, decode.acc_seg: 96.7277, aux_0.loss_ce: 0.0619, aux_0.acc_seg: 96.7001, aux_1.loss_ce: 0.0770, aux_1.acc_seg: 95.9030, aux_2.loss_ce: 0.1189, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 96.0017, aux_3.loss_ce: 0.1163, aux_3.acc_seg: 95.1204, aux_4.loss_t2t: 0.0172, loss: 0.7024
2023-05-02 11:38:56,826 - mmseg - INFO - Iter [8100/10000]	lr: 2.244e-02, eta: 0:29:22, time: 0.966, data_time: 0.260, memory: 14762, decode.loss_ce: 0.0605, decode.acc_seg: 96.7778, aux_0.loss_ce: 0.0622, aux_0.acc_seg: 96.7432, aux_1.loss_ce: 0.0767, aux_1.acc_seg: 95.9919, aux_2.loss_ce: 0.1165, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 96.1069, aux_3.loss_ce: 0.1160, aux_3.acc_seg: 95.1995, aux_4.loss_t2t: 0.0174, loss: 0.6992
2023-05-02 11:39:41,351 - mmseg - INFO - Iter [8150/10000]	lr: 2.191e-02, eta: 0:28:36, time: 0.890, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0593, decode.acc_seg: 96.8720, aux_0.loss_ce: 0.0607, aux_0.acc_seg: 96.8551, aux_1.loss_ce: 0.0762, aux_1.acc_seg: 96.0526, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 96.0079, aux_3.loss_ce: 0.1164, aux_3.acc_seg: 95.2569, aux_4.loss_t2t: 0.0172, loss: 0.6992
2023-05-02 11:40:26,022 - mmseg - INFO - Iter [8200/10000]	lr: 2.138e-02, eta: 0:27:49, time: 0.893, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0614, decode.acc_seg: 96.7733, aux_0.loss_ce: 0.0628, aux_0.acc_seg: 96.7484, aux_1.loss_ce: 0.0779, aux_1.acc_seg: 95.9841, aux_2.loss_ce: 0.1200, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 95.9623, aux_3.loss_ce: 0.1180, aux_3.acc_seg: 95.1905, aux_4.loss_t2t: 0.0172, loss: 0.7098
2023-05-02 11:41:10,737 - mmseg - INFO - Iter [8250/10000]	lr: 2.084e-02, eta: 0:27:02, time: 0.894, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0583, decode.acc_seg: 96.8520, aux_0.loss_ce: 0.0598, aux_0.acc_seg: 96.8237, aux_1.loss_ce: 0.0747, aux_1.acc_seg: 96.0423, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 96.0475, aux_3.loss_ce: 0.1134, aux_3.acc_seg: 95.2636, aux_4.loss_t2t: 0.0172, loss: 0.6894
2023-05-02 11:41:58,970 - mmseg - INFO - Iter [8300/10000]	lr: 2.031e-02, eta: 0:26:16, time: 0.965, data_time: 0.259, memory: 14762, decode.loss_ce: 0.0573, decode.acc_seg: 96.9728, aux_0.loss_ce: 0.0590, aux_0.acc_seg: 96.9381, aux_1.loss_ce: 0.0747, aux_1.acc_seg: 96.1452, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 96.0159, aux_3.loss_ce: 0.1146, aux_3.acc_seg: 95.3562, aux_4.loss_t2t: 0.0172, loss: 0.6902
2023-05-02 11:42:43,886 - mmseg - INFO - Iter [8350/10000]	lr: 1.977e-02, eta: 0:25:30, time: 0.898, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0591, decode.acc_seg: 96.8627, aux_0.loss_ce: 0.0608, aux_0.acc_seg: 96.8141, aux_1.loss_ce: 0.0756, aux_1.acc_seg: 96.0579, aux_2.loss_ce: 0.1172, aux_2.loss_dice: 0.2495, aux_2.acc_seg: 96.0305, aux_3.loss_ce: 0.1151, aux_3.acc_seg: 95.2960, aux_4.loss_t2t: 0.0171, loss: 0.6944
2023-05-02 11:43:28,816 - mmseg - INFO - Iter [8400/10000]	lr: 1.923e-02, eta: 0:24:43, time: 0.899, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0597, decode.acc_seg: 96.8670, aux_0.loss_ce: 0.0616, aux_0.acc_seg: 96.8369, aux_1.loss_ce: 0.0767, aux_1.acc_seg: 96.0578, aux_2.loss_ce: 0.1185, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 96.0083, aux_3.loss_ce: 0.1168, aux_3.acc_seg: 95.2669, aux_4.loss_t2t: 0.0173, loss: 0.7010
2023-05-02 11:44:17,098 - mmseg - INFO - Iter [8450/10000]	lr: 1.869e-02, eta: 0:23:57, time: 0.966, data_time: 0.260, memory: 14762, decode.loss_ce: 0.0582, decode.acc_seg: 96.8995, aux_0.loss_ce: 0.0597, aux_0.acc_seg: 96.8831, aux_1.loss_ce: 0.0746, aux_1.acc_seg: 96.0939, aux_2.loss_ce: 0.1166, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 96.0808, aux_3.loss_ce: 0.1142, aux_3.acc_seg: 95.3213, aux_4.loss_t2t: 0.0170, loss: 0.6897
2023-05-02 11:45:02,150 - mmseg - INFO - Iter [8500/10000]	lr: 1.815e-02, eta: 0:23:10, time: 0.901, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0614, decode.acc_seg: 96.8168, aux_0.loss_ce: 0.0632, aux_0.acc_seg: 96.7919, aux_1.loss_ce: 0.0786, aux_1.acc_seg: 96.0144, aux_2.loss_ce: 0.1219, aux_2.loss_dice: 0.2532, aux_2.acc_seg: 95.8834, aux_3.loss_ce: 0.1191, aux_3.acc_seg: 95.2163, aux_4.loss_t2t: 0.0174, loss: 0.7149
2023-05-02 11:45:47,347 - mmseg - INFO - Iter [8550/10000]	lr: 1.760e-02, eta: 0:22:24, time: 0.904, data_time: 0.197, memory: 14762, decode.loss_ce: 0.0581, decode.acc_seg: 96.9198, aux_0.loss_ce: 0.0597, aux_0.acc_seg: 96.8836, aux_1.loss_ce: 0.0748, aux_1.acc_seg: 96.1140, aux_2.loss_ce: 0.1160, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.0710, aux_3.loss_ce: 0.1144, aux_3.acc_seg: 95.3346, aux_4.loss_t2t: 0.0172, loss: 0.6886
2023-05-02 11:46:31,724 - mmseg - INFO - Iter [8600/10000]	lr: 1.705e-02, eta: 0:21:37, time: 0.888, data_time: 0.188, memory: 14762, decode.loss_ce: 0.0587, decode.acc_seg: 96.8991, aux_0.loss_ce: 0.0603, aux_0.acc_seg: 96.8729, aux_1.loss_ce: 0.0753, aux_1.acc_seg: 96.0953, aux_2.loss_ce: 0.1168, aux_2.loss_dice: 0.2494, aux_2.acc_seg: 96.0691, aux_3.loss_ce: 0.1157, aux_3.acc_seg: 95.2875, aux_4.loss_t2t: 0.0173, loss: 0.6935
2023-05-02 11:47:20,021 - mmseg - INFO - Iter [8650/10000]	lr: 1.650e-02, eta: 0:20:51, time: 0.966, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0568, decode.acc_seg: 96.9476, aux_0.loss_ce: 0.0585, aux_0.acc_seg: 96.9153, aux_1.loss_ce: 0.0735, aux_1.acc_seg: 96.1107, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.0926, aux_3.loss_ce: 0.1134, aux_3.acc_seg: 95.3130, aux_4.loss_t2t: 0.0172, loss: 0.6843
2023-05-02 11:48:04,508 - mmseg - INFO - Iter [8700/10000]	lr: 1.595e-02, eta: 0:20:04, time: 0.890, data_time: 0.186, memory: 14762, decode.loss_ce: 0.0570, decode.acc_seg: 96.9007, aux_0.loss_ce: 0.0587, aux_0.acc_seg: 96.8658, aux_1.loss_ce: 0.0734, aux_1.acc_seg: 96.0835, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.0815, aux_3.loss_ce: 0.1126, aux_3.acc_seg: 95.2742, aux_4.loss_t2t: 0.0170, loss: 0.6830
2023-05-02 11:48:49,044 - mmseg - INFO - Iter [8750/10000]	lr: 1.540e-02, eta: 0:19:18, time: 0.891, data_time: 0.186, memory: 14762, decode.loss_ce: 0.0564, decode.acc_seg: 96.9636, aux_0.loss_ce: 0.0581, aux_0.acc_seg: 96.9372, aux_1.loss_ce: 0.0732, aux_1.acc_seg: 96.1533, aux_2.loss_ce: 0.1176, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.0097, aux_3.loss_ce: 0.1132, aux_3.acc_seg: 95.3402, aux_4.loss_t2t: 0.0169, loss: 0.6843
2023-05-02 11:49:33,790 - mmseg - INFO - Iter [8800/10000]	lr: 1.485e-02, eta: 0:18:31, time: 0.895, data_time: 0.194, memory: 14762, decode.loss_ce: 0.0590, decode.acc_seg: 96.8458, aux_0.loss_ce: 0.0605, aux_0.acc_seg: 96.8178, aux_1.loss_ce: 0.0752, aux_1.acc_seg: 96.0382, aux_2.loss_ce: 0.1180, aux_2.loss_dice: 0.2511, aux_2.acc_seg: 96.0639, aux_3.loss_ce: 0.1159, aux_3.acc_seg: 95.2063, aux_4.loss_t2t: 0.0170, loss: 0.6967
2023-05-02 11:50:22,393 - mmseg - INFO - Iter [8850/10000]	lr: 1.429e-02, eta: 0:17:45, time: 0.972, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0564, decode.acc_seg: 96.9424, aux_0.loss_ce: 0.0580, aux_0.acc_seg: 96.9177, aux_1.loss_ce: 0.0724, aux_1.acc_seg: 96.1577, aux_2.loss_ce: 0.1150, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.1450, aux_3.loss_ce: 0.1125, aux_3.acc_seg: 95.3193, aux_4.loss_t2t: 0.0167, loss: 0.6794
2023-05-02 11:51:07,263 - mmseg - INFO - Iter [8900/10000]	lr: 1.373e-02, eta: 0:16:59, time: 0.897, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0580, decode.acc_seg: 96.9261, aux_0.loss_ce: 0.0593, aux_0.acc_seg: 96.9070, aux_1.loss_ce: 0.0742, aux_1.acc_seg: 96.1406, aux_2.loss_ce: 0.1166, aux_2.loss_dice: 0.2499, aux_2.acc_seg: 96.0796, aux_3.loss_ce: 0.1140, aux_3.acc_seg: 95.3487, aux_4.loss_t2t: 0.0169, loss: 0.6888
2023-05-02 11:51:51,785 - mmseg - INFO - Iter [8950/10000]	lr: 1.317e-02, eta: 0:16:12, time: 0.890, data_time: 0.185, memory: 14762, decode.loss_ce: 0.0583, decode.acc_seg: 96.8963, aux_0.loss_ce: 0.0599, aux_0.acc_seg: 96.8652, aux_1.loss_ce: 0.0750, aux_1.acc_seg: 96.0792, aux_2.loss_ce: 0.1192, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 95.9700, aux_3.loss_ce: 0.1166, aux_3.acc_seg: 95.1960, aux_4.loss_t2t: 0.0170, loss: 0.6969
2023-05-02 11:52:39,484 - mmseg - INFO - Saving checkpoint at 9000 iterations
2023-05-02 11:52:41,583 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:52:41,583 - mmseg - INFO - Iter [9000/10000]	lr: 1.260e-02, eta: 0:15:26, time: 0.997, data_time: 0.254, memory: 14762, decode.loss_ce: 0.0569, decode.acc_seg: 96.9716, aux_0.loss_ce: 0.0585, aux_0.acc_seg: 96.9403, aux_1.loss_ce: 0.0735, aux_1.acc_seg: 96.1625, aux_2.loss_ce: 0.1173, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.0346, aux_3.loss_ce: 0.1139, aux_3.acc_seg: 95.3370, aux_4.loss_t2t: 0.0168, loss: 0.6860
2023-05-02 11:52:45,858 - mmseg - INFO - per class results:
2023-05-02 11:52:45,860 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.65 |  94.6 |
|   Building  | 93.36 | 95.15 |
|     Car     | 93.96 | 95.95 |
| Column_Pole | 23.07 | 26.07 |
|    Fence    | 82.89 | 93.84 |
|  Pedestrian | 68.41 | 85.84 |
|     Road    | 97.86 | 98.83 |
|   Sidewalk  | 92.82 | 96.74 |
|  SignSymbol |  1.03 |  1.03 |
|     Sky     | 94.28 | 96.72 |
|     Tree    | 91.94 | 98.22 |
+-------------+-------+-------+
2023-05-02 11:52:45,860 - mmseg - INFO - Summary:
2023-05-02 11:52:45,860 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 96.45 | 75.12 | 80.27 |
+-------+-------+-------+
2023-05-02 11:52:45,860 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 11:52:45,861 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9645, mIoU: 0.7512, mAcc: 0.8027, IoU.Bicyclist: 0.8665, IoU.Building: 0.9336, IoU.Car: 0.9396, IoU.Column_Pole: 0.2307, IoU.Fence: 0.8289, IoU.Pedestrian: 0.6841, IoU.Road: 0.9786, IoU.Sidewalk: 0.9282, IoU.SignSymbol: 0.0103, IoU.Sky: 0.9428, IoU.Tree: 0.9194, Acc.Bicyclist: 0.9460, Acc.Building: 0.9515, Acc.Car: 0.9595, Acc.Column_Pole: 0.2607, Acc.Fence: 0.9384, Acc.Pedestrian: 0.8584, Acc.Road: 0.9883, Acc.Sidewalk: 0.9674, Acc.SignSymbol: 0.0103, Acc.Sky: 0.9672, Acc.Tree: 0.9822
2023-05-02 11:53:30,597 - mmseg - INFO - Iter [9050/10000]	lr: 1.203e-02, eta: 0:14:40, time: 0.980, data_time: 0.277, memory: 14762, decode.loss_ce: 0.0567, decode.acc_seg: 96.9407, aux_0.loss_ce: 0.0583, aux_0.acc_seg: 96.9140, aux_1.loss_ce: 0.0734, aux_1.acc_seg: 96.1200, aux_2.loss_ce: 0.1167, aux_2.loss_dice: 0.2484, aux_2.acc_seg: 96.0636, aux_3.loss_ce: 0.1138, aux_3.acc_seg: 95.2752, aux_4.loss_t2t: 0.0170, loss: 0.6843
2023-05-02 11:54:15,910 - mmseg - INFO - Iter [9100/10000]	lr: 1.146e-02, eta: 0:13:54, time: 0.906, data_time: 0.195, memory: 14762, decode.loss_ce: 0.0565, decode.acc_seg: 96.9689, aux_0.loss_ce: 0.0581, aux_0.acc_seg: 96.9357, aux_1.loss_ce: 0.0733, aux_1.acc_seg: 96.1590, aux_2.loss_ce: 0.1170, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 96.0497, aux_3.loss_ce: 0.1137, aux_3.acc_seg: 95.3168, aux_4.loss_t2t: 0.0169, loss: 0.6853
2023-05-02 11:55:00,790 - mmseg - INFO - Iter [9150/10000]	lr: 1.089e-02, eta: 0:13:07, time: 0.898, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0573, decode.acc_seg: 96.9290, aux_0.loss_ce: 0.0587, aux_0.acc_seg: 96.9066, aux_1.loss_ce: 0.0740, aux_1.acc_seg: 96.1163, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.0135, aux_3.loss_ce: 0.1150, aux_3.acc_seg: 95.2438, aux_4.loss_t2t: 0.0168, loss: 0.6889
2023-05-02 11:55:49,355 - mmseg - INFO - Iter [9200/10000]	lr: 1.031e-02, eta: 0:12:21, time: 0.971, data_time: 0.261, memory: 14762, decode.loss_ce: 0.0557, decode.acc_seg: 96.9825, aux_0.loss_ce: 0.0573, aux_0.acc_seg: 96.9470, aux_1.loss_ce: 0.0723, aux_1.acc_seg: 96.1446, aux_2.loss_ce: 0.1171, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.0299, aux_3.loss_ce: 0.1123, aux_3.acc_seg: 95.3212, aux_4.loss_t2t: 0.0167, loss: 0.6804
2023-05-02 11:56:33,716 - mmseg - INFO - Iter [9250/10000]	lr: 9.730e-03, eta: 0:11:35, time: 0.887, data_time: 0.184, memory: 14762, decode.loss_ce: 0.0585, decode.acc_seg: 96.9168, aux_0.loss_ce: 0.0600, aux_0.acc_seg: 96.8961, aux_1.loss_ce: 0.0753, aux_1.acc_seg: 96.1086, aux_2.loss_ce: 0.1193, aux_2.loss_dice: 0.2515, aux_2.acc_seg: 95.9856, aux_3.loss_ce: 0.1166, aux_3.acc_seg: 95.2642, aux_4.loss_t2t: 0.0169, loss: 0.6980
2023-05-02 11:57:17,810 - mmseg - INFO - Iter [9300/10000]	lr: 9.145e-03, eta: 0:10:48, time: 0.882, data_time: 0.187, memory: 14762, decode.loss_ce: 0.0569, decode.acc_seg: 96.9237, aux_0.loss_ce: 0.0583, aux_0.acc_seg: 96.8952, aux_1.loss_ce: 0.0734, aux_1.acc_seg: 96.1062, aux_2.loss_ce: 0.1167, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 96.0459, aux_3.loss_ce: 0.1140, aux_3.acc_seg: 95.2578, aux_4.loss_t2t: 0.0167, loss: 0.6847
2023-05-02 11:58:01,043 - mmseg - INFO - Iter [9350/10000]	lr: 8.556e-03, eta: 0:10:02, time: 0.865, data_time: 0.174, memory: 14762, decode.loss_ce: 0.0549, decode.acc_seg: 97.0485, aux_0.loss_ce: 0.0566, aux_0.acc_seg: 97.0112, aux_1.loss_ce: 0.0715, aux_1.acc_seg: 96.2346, aux_2.loss_ce: 0.1158, aux_2.loss_dice: 0.2465, aux_2.acc_seg: 96.0740, aux_3.loss_ce: 0.1120, aux_3.acc_seg: 95.3743, aux_4.loss_t2t: 0.0168, loss: 0.6740
2023-05-02 11:58:49,056 - mmseg - INFO - Iter [9400/10000]	lr: 7.962e-03, eta: 0:09:15, time: 0.960, data_time: 0.257, memory: 14762, decode.loss_ce: 0.0566, decode.acc_seg: 96.9922, aux_0.loss_ce: 0.0581, aux_0.acc_seg: 96.9667, aux_1.loss_ce: 0.0730, aux_1.acc_seg: 96.2013, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 96.0080, aux_3.loss_ce: 0.1147, aux_3.acc_seg: 95.3474, aux_4.loss_t2t: 0.0167, loss: 0.6865
2023-05-02 11:59:33,955 - mmseg - INFO - Iter [9450/10000]	lr: 7.364e-03, eta: 0:08:29, time: 0.898, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0567, decode.acc_seg: 96.9372, aux_0.loss_ce: 0.0582, aux_0.acc_seg: 96.9012, aux_1.loss_ce: 0.0735, aux_1.acc_seg: 96.1062, aux_2.loss_ce: 0.1179, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 95.9981, aux_3.loss_ce: 0.1149, aux_3.acc_seg: 95.2239, aux_4.loss_t2t: 0.0167, loss: 0.6869
2023-05-02 12:00:18,770 - mmseg - INFO - Iter [9500/10000]	lr: 6.759e-03, eta: 0:07:43, time: 0.896, data_time: 0.189, memory: 14762, decode.loss_ce: 0.0566, decode.acc_seg: 96.9342, aux_0.loss_ce: 0.0582, aux_0.acc_seg: 96.8993, aux_1.loss_ce: 0.0734, aux_1.acc_seg: 96.1052, aux_2.loss_ce: 0.1162, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 96.0582, aux_3.loss_ce: 0.1138, aux_3.acc_seg: 95.2616, aux_4.loss_t2t: 0.0167, loss: 0.6826
2023-05-02 12:01:07,653 - mmseg - INFO - Iter [9550/10000]	lr: 6.149e-03, eta: 0:06:56, time: 0.978, data_time: 0.267, memory: 14762, decode.loss_ce: 0.0562, decode.acc_seg: 97.0318, aux_0.loss_ce: 0.0577, aux_0.acc_seg: 97.0037, aux_1.loss_ce: 0.0729, aux_1.acc_seg: 96.2302, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 96.0808, aux_3.loss_ce: 0.1144, aux_3.acc_seg: 95.3728, aux_4.loss_t2t: 0.0168, loss: 0.6825
2023-05-02 12:01:53,069 - mmseg - INFO - Iter [9600/10000]	lr: 5.532e-03, eta: 0:06:10, time: 0.908, data_time: 0.196, memory: 14762, decode.loss_ce: 0.0554, decode.acc_seg: 96.9854, aux_0.loss_ce: 0.0571, aux_0.acc_seg: 96.9482, aux_1.loss_ce: 0.0720, aux_1.acc_seg: 96.1676, aux_2.loss_ce: 0.1167, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 96.0861, aux_3.loss_ce: 0.1128, aux_3.acc_seg: 95.3004, aux_4.loss_t2t: 0.0168, loss: 0.6800
2023-05-02 12:02:38,368 - mmseg - INFO - Iter [9650/10000]	lr: 4.908e-03, eta: 0:05:24, time: 0.906, data_time: 0.196, memory: 14762, decode.loss_ce: 0.0556, decode.acc_seg: 97.0091, aux_0.loss_ce: 0.0573, aux_0.acc_seg: 96.9763, aux_1.loss_ce: 0.0724, aux_1.acc_seg: 96.1996, aux_2.loss_ce: 0.1182, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 96.0160, aux_3.loss_ce: 0.1144, aux_3.acc_seg: 95.3138, aux_4.loss_t2t: 0.0168, loss: 0.6850
2023-05-02 12:03:23,382 - mmseg - INFO - Iter [9700/10000]	lr: 4.274e-03, eta: 0:04:37, time: 0.900, data_time: 0.193, memory: 14762, decode.loss_ce: 0.0557, decode.acc_seg: 96.9599, aux_0.loss_ce: 0.0571, aux_0.acc_seg: 96.9349, aux_1.loss_ce: 0.0722, aux_1.acc_seg: 96.1379, aux_2.loss_ce: 0.1166, aux_2.loss_dice: 0.2490, aux_2.acc_seg: 96.0615, aux_3.loss_ce: 0.1132, aux_3.acc_seg: 95.2833, aux_4.loss_t2t: 0.0166, loss: 0.6804
2023-05-02 12:04:10,022 - mmseg - INFO - Iter [9750/10000]	lr: 3.629e-03, eta: 0:03:51, time: 0.933, data_time: 0.243, memory: 14762, decode.loss_ce: 0.0543, decode.acc_seg: 97.0771, aux_0.loss_ce: 0.0560, aux_0.acc_seg: 97.0485, aux_1.loss_ce: 0.0709, aux_1.acc_seg: 96.2828, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 96.0456, aux_3.loss_ce: 0.1129, aux_3.acc_seg: 95.3902, aux_4.loss_t2t: 0.0167, loss: 0.6753
2023-05-02 12:04:54,875 - mmseg - INFO - Iter [9800/10000]	lr: 2.972e-03, eta: 0:03:05, time: 0.897, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0547, decode.acc_seg: 97.0383, aux_0.loss_ce: 0.0561, aux_0.acc_seg: 97.0143, aux_1.loss_ce: 0.0713, aux_1.acc_seg: 96.2153, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 96.0115, aux_3.loss_ce: 0.1128, aux_3.acc_seg: 95.3285, aux_4.loss_t2t: 0.0167, loss: 0.6770
2023-05-02 12:05:39,831 - mmseg - INFO - Iter [9850/10000]	lr: 2.298e-03, eta: 0:02:18, time: 0.899, data_time: 0.192, memory: 14762, decode.loss_ce: 0.0547, decode.acc_seg: 97.0452, aux_0.loss_ce: 0.0562, aux_0.acc_seg: 97.0135, aux_1.loss_ce: 0.0713, aux_1.acc_seg: 96.2223, aux_2.loss_ce: 0.1163, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 96.0261, aux_3.loss_ce: 0.1124, aux_3.acc_seg: 95.3508, aux_4.loss_t2t: 0.0167, loss: 0.6746
2023-05-02 12:06:24,563 - mmseg - INFO - Iter [9900/10000]	lr: 1.600e-03, eta: 0:01:32, time: 0.895, data_time: 0.190, memory: 14762, decode.loss_ce: 0.0557, decode.acc_seg: 97.0339, aux_0.loss_ce: 0.0573, aux_0.acc_seg: 96.9941, aux_1.loss_ce: 0.0726, aux_1.acc_seg: 96.2078, aux_2.loss_ce: 0.1178, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 96.0101, aux_3.loss_ce: 0.1146, aux_3.acc_seg: 95.3113, aux_4.loss_t2t: 0.0167, loss: 0.6836
2023-05-02 12:07:13,086 - mmseg - INFO - Iter [9950/10000]	lr: 8.656e-04, eta: 0:00:46, time: 0.970, data_time: 0.265, memory: 14762, decode.loss_ce: 0.0547, decode.acc_seg: 97.0541, aux_0.loss_ce: 0.0565, aux_0.acc_seg: 97.0148, aux_1.loss_ce: 0.0717, aux_1.acc_seg: 96.2204, aux_2.loss_ce: 0.1171, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 96.0229, aux_3.loss_ce: 0.1125, aux_3.acc_seg: 95.3888, aux_4.loss_t2t: 0.0168, loss: 0.6784
2023-05-02 12:07:57,861 - mmseg - INFO - Saving checkpoint at 10000 iterations
2023-05-02 12:07:59,840 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 12:07:59,841 - mmseg - INFO - Iter [10000/10000]	lr: 2.612e-05, eta: 0:00:00, time: 0.936, data_time: 0.191, memory: 14762, decode.loss_ce: 0.0538, decode.acc_seg: 97.0659, aux_0.loss_ce: 0.0554, aux_0.acc_seg: 97.0395, aux_1.loss_ce: 0.0705, aux_1.acc_seg: 96.2584, aux_2.loss_ce: 0.1164, aux_2.loss_dice: 0.2476, aux_2.acc_seg: 96.0533, aux_3.loss_ce: 0.1114, aux_3.acc_seg: 95.3953, aux_4.loss_t2t: 0.0167, loss: 0.6718
2023-05-02 12:08:03,834 - mmseg - INFO - per class results:
2023-05-02 12:08:03,835 - mmseg - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  Bicyclist  | 86.53 | 93.92 |
|   Building  | 93.53 | 95.36 |
|     Car     | 93.69 | 96.04 |
| Column_Pole | 25.71 | 29.58 |
|    Fence    | 82.59 | 93.94 |
|  Pedestrian | 69.55 | 84.03 |
|     Road    | 97.83 | 98.66 |
|   Sidewalk  | 92.84 | 97.04 |
|  SignSymbol |  0.45 |  0.45 |
|     Sky     | 94.38 | 97.26 |
|     Tree    |  92.2 | 98.03 |
+-------------+-------+-------+
2023-05-02 12:08:03,835 - mmseg - INFO - Summary:
2023-05-02 12:08:03,835 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 96.5 | 75.39 | 80.39 |
+------+-------+-------+
2023-05-02 12:08:03,835 - mmseg - INFO - Exp name: csctextnet_stdc1_1x16_720x960_10k_camvid_textsim.py
2023-05-02 12:08:03,836 - mmseg - INFO - Iter(val) [101]	aAcc: 0.9650, mIoU: 0.7539, mAcc: 0.8039, IoU.Bicyclist: 0.8653, IoU.Building: 0.9353, IoU.Car: 0.9369, IoU.Column_Pole: 0.2571, IoU.Fence: 0.8259, IoU.Pedestrian: 0.6955, IoU.Road: 0.9783, IoU.Sidewalk: 0.9284, IoU.SignSymbol: 0.0045, IoU.Sky: 0.9438, IoU.Tree: 0.9220, Acc.Bicyclist: 0.9392, Acc.Building: 0.9536, Acc.Car: 0.9604, Acc.Column_Pole: 0.2958, Acc.Fence: 0.9394, Acc.Pedestrian: 0.8403, Acc.Road: 0.9866, Acc.Sidewalk: 0.9704, Acc.SignSymbol: 0.0045, Acc.Sky: 0.9726, Acc.Tree: 0.9803
