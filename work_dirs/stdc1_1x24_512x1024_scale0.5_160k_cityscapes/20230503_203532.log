2023-05-03 20:35:32,126 - mmseg - INFO - Multi-processing start method is `None`
2023-05-03 20:35:32,128 - mmseg - INFO - OpenCV num_threads is `96
2023-05-03 20:35:32,245 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+e7ed570
------------------------------------------------------------

2023-05-03 20:35:32,246 - mmseg - INFO - Distributed training: False
2023-05-03 20:35:33,130 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextPathNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False,
            init_cfg=dict(
                type='Pretrained',
                checkpoint=
                'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
            )),
        last_in_channels=(1024, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4)),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=780000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=19,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=780000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=19,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=780000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ])
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CityscapesDataset'
data_root = 'data/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        img_scale=(2048, 1024),
        ratio_range=(0.125, 1.5),
        scale_step_size=0.125),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=24,
    workers_per_gpu=4,
    train=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/train',
        ann_dir='gtFine/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize',
                img_scale=(2048, 1024),
                ratio_range=(0.125, 1.5),
                scale_step_size=0.125),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.05,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            {
                'backbone.backbone': dict(lr_mult=0.1),
                'backbone.text_encoder': dict(lr_mult=0.0, decay_mult=0.0),
                '.bn.': dict(decay_mult=0.0)
            })))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU', pre_eval=True)
checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'
work_dir = './work_dirs/stdc1_1x24_512x1024_scale0.5_160k_cityscapes'
gpu_ids = [0]
auto_resume = False

2023-05-03 20:35:33,131 - mmseg - INFO - Set random seed to 142311418, deterministic: False
2023-05-03 20:35:33,175 - mmseg - INFO - Loaded 2975 images
2023-05-03 20:35:34,295 - mmseg - INFO - initialize STDCNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
2023-05-03 20:35:34,613 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.backbone.stages.0.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.0.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.conv.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.conv.weight - torch.Size([128, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.0.downsample.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.0.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.1.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.conv.weight - torch.Size([32, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.2.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.conv.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.weight - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.2.1.layers.3.bn.bias - torch.Size([32]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.conv.weight - torch.Size([256, 256, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.conv.weight - torch.Size([256, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.0.downsample.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.0.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.1.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.conv.weight - torch.Size([64, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.2.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.conv.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.weight - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.3.1.layers.3.bn.bias - torch.Size([64]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.conv.weight - torch.Size([512, 512, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.conv.weight - torch.Size([512, 1, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.0.downsample.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.weight - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.0.bn.bias - torch.Size([512]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.conv.weight - torch.Size([256, 512, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.weight - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.1.bn.bias - torch.Size([256]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.conv.weight - torch.Size([128, 256, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.2.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.conv.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.weight - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.backbone.stages.4.1.layers.3.bn.bias - torch.Size([128]): 
PretrainedInit: load from https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth 

backbone.arms.0.conv_layer.conv.weight - torch.Size([128, 1024, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.0.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.0.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.conv.weight - torch.Size([128, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.arms.1.conv_layer.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.conv_layer.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.arms.1.atten_conv_layer.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.convs.1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.convs.1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.conv.weight - torch.Size([128, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_avg.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_avg.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.ffm.conv0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.conv0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.ffm.attention.2.conv.weight - torch.Size([256, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([19, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([19]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([19, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([19]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.fusion_kernel - torch.Size([1, 3, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.weight - torch.Size([2, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.conv_seg.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.2.convs.0.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-05-03 20:35:34,616 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextPathNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/stdc/stdc1_20220308-5368626c.pth'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-05-03 20:35:40,648 - mmseg - INFO - Loaded 500 images
2023-05-03 20:35:40,649 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1_1x24_512x1024_scale0.5_160k_cityscapes
2023-05-03 20:35:40,650 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-05-03 20:35:40,650 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-05-03 20:35:40,650 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/stdc1_1x24_512x1024_scale0.5_160k_cityscapes by HardDiskBackend.
2023-05-03 20:36:40,907 - mmseg - INFO - Iter [50/160000]	lr: 2.450e-04, eta: 2 days, 5:03:15, time: 1.194, data_time: 0.436, memory: 19452, decode.loss_ce: 1.9287, decode.acc_seg: 31.6911, aux_0.loss_ce: 2.1293, aux_0.acc_seg: 17.8477, aux_1.loss_ce: 2.0663, aux_1.acc_seg: 19.7950, aux_2.loss_ce: 0.5069, aux_2.loss_dice: 0.4808, aux_2.acc_seg: 91.1031, loss: 7.1121
2023-05-03 20:37:30,551 - mmseg - INFO - Iter [100/160000]	lr: 4.948e-04, eta: 2 days, 0:34:07, time: 0.993, data_time: 0.470, memory: 19452, decode.loss_ce: 1.2606, decode.acc_seg: 53.4450, aux_0.loss_ce: 1.3864, aux_0.acc_seg: 50.7867, aux_1.loss_ce: 1.4347, aux_1.acc_seg: 46.8701, aux_2.loss_ce: 0.2419, aux_2.loss_dice: 0.4772, aux_2.acc_seg: 96.8965, loss: 4.8008
2023-05-03 20:38:18,790 - mmseg - INFO - Iter [150/160000]	lr: 7.444e-04, eta: 1 day, 22:38:54, time: 0.965, data_time: 0.417, memory: 19452, decode.loss_ce: 0.9435, decode.acc_seg: 66.0771, aux_0.loss_ce: 0.9374, aux_0.acc_seg: 68.1699, aux_1.loss_ce: 1.0095, aux_1.acc_seg: 64.4777, aux_2.loss_ce: 0.1718, aux_2.loss_dice: 0.4781, aux_2.acc_seg: 96.8890, loss: 3.5403
2023-05-03 20:38:59,721 - mmseg - INFO - Iter [200/160000]	lr: 9.939e-04, eta: 1 day, 20:03:34, time: 0.819, data_time: 0.252, memory: 19452, decode.loss_ce: 0.7089, decode.acc_seg: 74.8023, aux_0.loss_ce: 0.7202, aux_0.acc_seg: 74.9091, aux_1.loss_ce: 0.7747, aux_1.acc_seg: 72.2538, aux_2.loss_ce: 0.1630, aux_2.loss_dice: 0.3802, aux_2.acc_seg: 96.9662, loss: 2.7471
2023-05-03 20:39:44,302 - mmseg - INFO - Iter [250/160000]	lr: 1.243e-03, eta: 1 day, 19:08:58, time: 0.892, data_time: 0.337, memory: 19452, decode.loss_ce: 0.5888, decode.acc_seg: 78.2041, aux_0.loss_ce: 0.6052, aux_0.acc_seg: 78.3558, aux_1.loss_ce: 0.6539, aux_1.acc_seg: 76.4742, aux_2.loss_ce: 0.1308, aux_2.loss_dice: 0.3299, aux_2.acc_seg: 97.0574, loss: 2.3086
2023-05-03 20:40:24,726 - mmseg - INFO - Iter [300/160000]	lr: 1.493e-03, eta: 1 day, 17:55:27, time: 0.808, data_time: 0.260, memory: 19452, decode.loss_ce: 0.5208, decode.acc_seg: 80.6243, aux_0.loss_ce: 0.5379, aux_0.acc_seg: 80.7212, aux_1.loss_ce: 0.5782, aux_1.acc_seg: 78.8284, aux_2.loss_ce: 0.1169, aux_2.loss_dice: 0.3115, aux_2.acc_seg: 97.1529, loss: 2.0654
2023-05-03 20:41:07,207 - mmseg - INFO - Iter [350/160000]	lr: 1.742e-03, eta: 1 day, 17:18:22, time: 0.850, data_time: 0.283, memory: 19452, decode.loss_ce: 0.4792, decode.acc_seg: 82.5567, aux_0.loss_ce: 0.4954, aux_0.acc_seg: 82.3144, aux_1.loss_ce: 0.5351, aux_1.acc_seg: 80.6623, aux_2.loss_ce: 0.1138, aux_2.loss_dice: 0.3082, aux_2.acc_seg: 97.0675, loss: 1.9317
2023-05-03 20:41:54,711 - mmseg - INFO - Iter [400/160000]	lr: 1.991e-03, eta: 1 day, 17:23:48, time: 0.950, data_time: 0.391, memory: 19452, decode.loss_ce: 0.4404, decode.acc_seg: 83.6645, aux_0.loss_ce: 0.4573, aux_0.acc_seg: 83.2788, aux_1.loss_ce: 0.4916, aux_1.acc_seg: 81.8541, aux_2.loss_ce: 0.1089, aux_2.loss_dice: 0.3013, aux_2.acc_seg: 97.1382, loss: 1.7995
2023-05-03 20:42:38,931 - mmseg - INFO - Iter [450/160000]	lr: 2.239e-03, eta: 1 day, 17:08:25, time: 0.884, data_time: 0.316, memory: 19452, decode.loss_ce: 0.4006, decode.acc_seg: 84.7720, aux_0.loss_ce: 0.4206, aux_0.acc_seg: 84.1595, aux_1.loss_ce: 0.4538, aux_1.acc_seg: 82.8279, aux_2.loss_ce: 0.1071, aux_2.loss_dice: 0.2963, aux_2.acc_seg: 97.1704, loss: 1.6783
2023-05-03 20:43:28,587 - mmseg - INFO - Iter [500/160000]	lr: 2.488e-03, eta: 1 day, 17:24:53, time: 0.993, data_time: 0.431, memory: 19452, decode.loss_ce: 0.3727, decode.acc_seg: 85.5496, aux_0.loss_ce: 0.3888, aux_0.acc_seg: 85.0059, aux_1.loss_ce: 0.4203, aux_1.acc_seg: 83.8233, aux_2.loss_ce: 0.1069, aux_2.loss_dice: 0.2933, aux_2.acc_seg: 97.1550, loss: 1.5821
2023-05-03 20:44:13,893 - mmseg - INFO - Iter [550/160000]	lr: 2.737e-03, eta: 1 day, 17:17:11, time: 0.906, data_time: 0.345, memory: 19452, decode.loss_ce: 0.3713, decode.acc_seg: 85.6014, aux_0.loss_ce: 0.3802, aux_0.acc_seg: 85.3056, aux_1.loss_ce: 0.4143, aux_1.acc_seg: 83.9911, aux_2.loss_ce: 0.1053, aux_2.loss_dice: 0.2900, aux_2.acc_seg: 97.2083, loss: 1.5612
2023-05-03 20:44:58,595 - mmseg - INFO - Iter [600/160000]	lr: 2.985e-03, eta: 1 day, 17:07:58, time: 0.894, data_time: 0.330, memory: 19452, decode.loss_ce: 0.3699, decode.acc_seg: 85.7439, aux_0.loss_ce: 0.3801, aux_0.acc_seg: 85.4563, aux_1.loss_ce: 0.4143, aux_1.acc_seg: 84.1263, aux_2.loss_ce: 0.1075, aux_2.loss_dice: 0.2895, aux_2.acc_seg: 97.1338, loss: 1.5613
2023-05-03 20:45:47,051 - mmseg - INFO - Iter [650/160000]	lr: 3.233e-03, eta: 1 day, 17:15:23, time: 0.969, data_time: 0.404, memory: 19452, decode.loss_ce: 0.3381, decode.acc_seg: 86.5505, aux_0.loss_ce: 0.3469, aux_0.acc_seg: 86.3026, aux_1.loss_ce: 0.3803, aux_1.acc_seg: 84.8893, aux_2.loss_ce: 0.1051, aux_2.loss_dice: 0.2841, aux_2.acc_seg: 97.1803, loss: 1.4545
2023-05-03 20:46:31,280 - mmseg - INFO - Iter [700/160000]	lr: 3.481e-03, eta: 1 day, 17:05:36, time: 0.885, data_time: 0.309, memory: 19452, decode.loss_ce: 0.3202, decode.acc_seg: 87.4172, aux_0.loss_ce: 0.3310, aux_0.acc_seg: 87.0893, aux_1.loss_ce: 0.3618, aux_1.acc_seg: 85.8413, aux_2.loss_ce: 0.1052, aux_2.loss_dice: 0.2863, aux_2.acc_seg: 97.1871, loss: 1.4045
2023-05-03 20:47:20,643 - mmseg - INFO - Iter [750/160000]	lr: 3.729e-03, eta: 1 day, 17:15:12, time: 0.987, data_time: 0.424, memory: 19452, decode.loss_ce: 0.3044, decode.acc_seg: 87.5460, aux_0.loss_ce: 0.3134, aux_0.acc_seg: 87.1015, aux_1.loss_ce: 0.3449, aux_1.acc_seg: 85.8500, aux_2.loss_ce: 0.1019, aux_2.loss_dice: 0.2789, aux_2.acc_seg: 97.2899, loss: 1.3435
2023-05-03 20:48:05,474 - mmseg - INFO - Iter [800/160000]	lr: 3.977e-03, eta: 1 day, 17:08:28, time: 0.897, data_time: 0.333, memory: 19452, decode.loss_ce: 0.2952, decode.acc_seg: 87.9441, aux_0.loss_ce: 0.3041, aux_0.acc_seg: 87.6015, aux_1.loss_ce: 0.3331, aux_1.acc_seg: 86.4488, aux_2.loss_ce: 0.1026, aux_2.loss_dice: 0.2778, aux_2.acc_seg: 97.2776, loss: 1.3128
2023-05-03 20:48:50,213 - mmseg - INFO - Iter [850/160000]	lr: 4.225e-03, eta: 1 day, 17:02:08, time: 0.895, data_time: 0.325, memory: 19452, decode.loss_ce: 0.2805, decode.acc_seg: 88.4719, aux_0.loss_ce: 0.2898, aux_0.acc_seg: 88.1072, aux_1.loss_ce: 0.3184, aux_1.acc_seg: 86.8911, aux_2.loss_ce: 0.1023, aux_2.loss_dice: 0.2758, aux_2.acc_seg: 97.2515, loss: 1.2669
2023-05-03 20:49:39,443 - mmseg - INFO - Iter [900/160000]	lr: 4.472e-03, eta: 1 day, 17:09:40, time: 0.985, data_time: 0.416, memory: 19452, decode.loss_ce: 0.2848, decode.acc_seg: 88.0078, aux_0.loss_ce: 0.2950, aux_0.acc_seg: 87.6546, aux_1.loss_ce: 0.3227, aux_1.acc_seg: 86.4899, aux_2.loss_ce: 0.1030, aux_2.loss_dice: 0.2766, aux_2.acc_seg: 97.2199, loss: 1.2822
2023-05-03 20:50:24,327 - mmseg - INFO - Iter [950/160000]	lr: 4.720e-03, eta: 1 day, 17:04:11, time: 0.898, data_time: 0.328, memory: 19452, decode.loss_ce: 0.2922, decode.acc_seg: 87.9903, aux_0.loss_ce: 0.3003, aux_0.acc_seg: 87.7086, aux_1.loss_ce: 0.3272, aux_1.acc_seg: 86.5607, aux_2.loss_ce: 0.1026, aux_2.loss_dice: 0.2752, aux_2.acc_seg: 97.2568, loss: 1.2974
2023-05-03 20:51:14,028 - mmseg - INFO - Exp name: stdc1_1x24_512x1024_scale0.5_160k_cityscapes.py
2023-05-03 20:51:14,029 - mmseg - INFO - Iter [1000/160000]	lr: 4.967e-03, eta: 1 day, 17:11:57, time: 0.994, data_time: 0.412, memory: 19452, decode.loss_ce: 0.2811, decode.acc_seg: 88.4633, aux_0.loss_ce: 0.2902, aux_0.acc_seg: 88.1739, aux_1.loss_ce: 0.3168, aux_1.acc_seg: 86.9972, aux_2.loss_ce: 0.1037, aux_2.loss_dice: 0.2760, aux_2.acc_seg: 97.2246, loss: 1.2678
2023-05-03 20:51:58,742 - mmseg - INFO - Iter [1050/160000]	lr: 4.970e-03, eta: 1 day, 17:06:18, time: 0.894, data_time: 0.337, memory: 19452, decode.loss_ce: 0.2917, decode.acc_seg: 88.1872, aux_0.loss_ce: 0.2996, aux_0.acc_seg: 87.8970, aux_1.loss_ce: 0.3251, aux_1.acc_seg: 86.7639, aux_2.loss_ce: 0.1038, aux_2.loss_dice: 0.2759, aux_2.acc_seg: 97.2357, loss: 1.2961
2023-05-03 20:52:44,603 - mmseg - INFO - Iter [1100/160000]	lr: 4.969e-03, eta: 1 day, 17:03:52, time: 0.917, data_time: 0.346, memory: 19452, decode.loss_ce: 0.2823, decode.acc_seg: 88.3443, aux_0.loss_ce: 0.2895, aux_0.acc_seg: 88.1180, aux_1.loss_ce: 0.3160, aux_1.acc_seg: 86.9415, aux_2.loss_ce: 0.1050, aux_2.loss_dice: 0.2744, aux_2.acc_seg: 97.1892, loss: 1.2672
2023-05-03 20:53:35,381 - mmseg - INFO - Iter [1150/160000]	lr: 4.968e-03, eta: 1 day, 17:12:54, time: 1.016, data_time: 0.458, memory: 19452, decode.loss_ce: 0.2628, decode.acc_seg: 88.6251, aux_0.loss_ce: 0.2705, aux_0.acc_seg: 88.3331, aux_1.loss_ce: 0.2934, aux_1.acc_seg: 87.1981, aux_2.loss_ce: 0.1003, aux_2.loss_dice: 0.2657, aux_2.acc_seg: 97.3338, loss: 1.1929
2023-05-03 20:54:26,879 - mmseg - INFO - Iter [1200/160000]	lr: 4.966e-03, eta: 1 day, 17:22:42, time: 1.030, data_time: 0.472, memory: 19452, decode.loss_ce: 0.2734, decode.acc_seg: 88.8138, aux_0.loss_ce: 0.2814, aux_0.acc_seg: 88.5674, aux_1.loss_ce: 0.3092, aux_1.acc_seg: 87.3265, aux_2.loss_ce: 0.1032, aux_2.loss_dice: 0.2734, aux_2.acc_seg: 97.2566, loss: 1.2406
2023-05-03 20:55:19,936 - mmseg - INFO - Iter [1250/160000]	lr: 4.965e-03, eta: 1 day, 17:34:57, time: 1.061, data_time: 0.482, memory: 19452, decode.loss_ce: 0.2660, decode.acc_seg: 88.8833, aux_0.loss_ce: 0.2766, aux_0.acc_seg: 88.5244, aux_1.loss_ce: 0.3010, aux_1.acc_seg: 87.3313, aux_2.loss_ce: 0.1029, aux_2.loss_dice: 0.2706, aux_2.acc_seg: 97.2592, loss: 1.2171
2023-05-03 20:56:09,556 - mmseg - INFO - Iter [1300/160000]	lr: 4.963e-03, eta: 1 day, 17:39:10, time: 0.992, data_time: 0.421, memory: 19452, decode.loss_ce: 0.2587, decode.acc_seg: 89.2154, aux_0.loss_ce: 0.2657, aux_0.acc_seg: 88.9887, aux_1.loss_ce: 0.2909, aux_1.acc_seg: 87.8671, aux_2.loss_ce: 0.1013, aux_2.loss_dice: 0.2685, aux_2.acc_seg: 97.2765, loss: 1.1851
2023-05-03 20:56:58,236 - mmseg - INFO - Iter [1350/160000]	lr: 4.962e-03, eta: 1 day, 17:41:13, time: 0.974, data_time: 0.421, memory: 19452, decode.loss_ce: 0.2580, decode.acc_seg: 89.2617, aux_0.loss_ce: 0.2675, aux_0.acc_seg: 88.8838, aux_1.loss_ce: 0.2912, aux_1.acc_seg: 87.8488, aux_2.loss_ce: 0.1020, aux_2.loss_dice: 0.2694, aux_2.acc_seg: 97.2683, loss: 1.1880
2023-05-03 20:57:51,619 - mmseg - INFO - Iter [1400/160000]	lr: 4.961e-03, eta: 1 day, 17:51:55, time: 1.068, data_time: 0.500, memory: 19452, decode.loss_ce: 0.2519, decode.acc_seg: 89.1815, aux_0.loss_ce: 0.2589, aux_0.acc_seg: 88.9746, aux_1.loss_ce: 0.2823, aux_1.acc_seg: 87.8855, aux_2.loss_ce: 0.1015, aux_2.loss_dice: 0.2677, aux_2.acc_seg: 97.2775, loss: 1.1624
2023-05-03 20:58:39,553 - mmseg - INFO - Iter [1450/160000]	lr: 4.959e-03, eta: 1 day, 17:51:53, time: 0.959, data_time: 0.379, memory: 19452, decode.loss_ce: 0.2514, decode.acc_seg: 89.3148, aux_0.loss_ce: 0.2580, aux_0.acc_seg: 89.1276, aux_1.loss_ce: 0.2814, aux_1.acc_seg: 88.0075, aux_2.loss_ce: 0.1007, aux_2.loss_dice: 0.2672, aux_2.acc_seg: 97.3284, loss: 1.1587
2023-05-03 20:59:32,052 - mmseg - INFO - Iter [1500/160000]	lr: 4.958e-03, eta: 1 day, 17:59:51, time: 1.050, data_time: 0.487, memory: 19452, decode.loss_ce: 0.2401, decode.acc_seg: 89.8700, aux_0.loss_ce: 0.2497, aux_0.acc_seg: 89.5390, aux_1.loss_ce: 0.2735, aux_1.acc_seg: 88.4682, aux_2.loss_ce: 0.1006, aux_2.loss_dice: 0.2656, aux_2.acc_seg: 97.3065, loss: 1.1294
2023-05-03 21:00:23,155 - mmseg - INFO - Iter [1550/160000]	lr: 4.956e-03, eta: 1 day, 18:04:51, time: 1.022, data_time: 0.450, memory: 19452, decode.loss_ce: 0.2467, decode.acc_seg: 89.8578, aux_0.loss_ce: 0.2558, aux_0.acc_seg: 89.5949, aux_1.loss_ce: 0.2820, aux_1.acc_seg: 88.3635, aux_2.loss_ce: 0.1037, aux_2.loss_dice: 0.2707, aux_2.acc_seg: 97.2168, loss: 1.1588
2023-05-03 21:01:17,379 - mmseg - INFO - Iter [1600/160000]	lr: 4.955e-03, eta: 1 day, 18:14:39, time: 1.084, data_time: 0.503, memory: 19452, decode.loss_ce: 0.2349, decode.acc_seg: 90.1299, aux_0.loss_ce: 0.2427, aux_0.acc_seg: 89.8798, aux_1.loss_ce: 0.2690, aux_1.acc_seg: 88.7980, aux_2.loss_ce: 0.1023, aux_2.loss_dice: 0.2698, aux_2.acc_seg: 97.2527, loss: 1.1186
2023-05-03 21:02:05,721 - mmseg - INFO - Iter [1650/160000]	lr: 4.954e-03, eta: 1 day, 18:14:23, time: 0.967, data_time: 0.391, memory: 19452, decode.loss_ce: 0.2290, decode.acc_seg: 90.1136, aux_0.loss_ce: 0.2383, aux_0.acc_seg: 89.8157, aux_1.loss_ce: 0.2631, aux_1.acc_seg: 88.6672, aux_2.loss_ce: 0.0997, aux_2.loss_dice: 0.2649, aux_2.acc_seg: 97.3472, loss: 1.0950
2023-05-03 21:02:55,347 - mmseg - INFO - Iter [1700/160000]	lr: 4.952e-03, eta: 1 day, 18:16:05, time: 0.993, data_time: 0.426, memory: 19452, decode.loss_ce: 0.2220, decode.acc_seg: 90.4309, aux_0.loss_ce: 0.2299, aux_0.acc_seg: 90.1671, aux_1.loss_ce: 0.2552, aux_1.acc_seg: 89.0369, aux_2.loss_ce: 0.1020, aux_2.loss_dice: 0.2657, aux_2.acc_seg: 97.2313, loss: 1.0748
2023-05-03 21:03:49,932 - mmseg - INFO - Iter [1750/160000]	lr: 4.951e-03, eta: 1 day, 18:25:07, time: 1.092, data_time: 0.533, memory: 19452, decode.loss_ce: 0.2191, decode.acc_seg: 90.5789, aux_0.loss_ce: 0.2276, aux_0.acc_seg: 90.2721, aux_1.loss_ce: 0.2526, aux_1.acc_seg: 89.1453, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2642, aux_2.acc_seg: 97.3084, loss: 1.0634
2023-05-03 21:04:38,539 - mmseg - INFO - Iter [1800/160000]	lr: 4.949e-03, eta: 1 day, 18:24:50, time: 0.972, data_time: 0.414, memory: 19452, decode.loss_ce: 0.2133, decode.acc_seg: 90.8703, aux_0.loss_ce: 0.2210, aux_0.acc_seg: 90.5699, aux_1.loss_ce: 0.2446, aux_1.acc_seg: 89.4849, aux_2.loss_ce: 0.1000, aux_2.loss_dice: 0.2631, aux_2.acc_seg: 97.2970, loss: 1.0420
2023-05-03 21:05:32,980 - mmseg - INFO - Iter [1850/160000]	lr: 4.948e-03, eta: 1 day, 18:32:50, time: 1.089, data_time: 0.532, memory: 19452, decode.loss_ce: 0.2194, decode.acc_seg: 90.7348, aux_0.loss_ce: 0.2271, aux_0.acc_seg: 90.5017, aux_1.loss_ce: 0.2504, aux_1.acc_seg: 89.3891, aux_2.loss_ce: 0.0999, aux_2.loss_dice: 0.2627, aux_2.acc_seg: 97.3023, loss: 1.0595
2023-05-03 21:06:21,383 - mmseg - INFO - Iter [1900/160000]	lr: 4.947e-03, eta: 1 day, 18:32:00, time: 0.968, data_time: 0.403, memory: 19452, decode.loss_ce: 0.2259, decode.acc_seg: 90.4136, aux_0.loss_ce: 0.2334, aux_0.acc_seg: 90.1842, aux_1.loss_ce: 0.2591, aux_1.acc_seg: 89.0403, aux_2.loss_ce: 0.1004, aux_2.loss_dice: 0.2654, aux_2.acc_seg: 97.2751, loss: 1.0841
2023-05-03 21:07:13,346 - mmseg - INFO - Iter [1950/160000]	lr: 4.945e-03, eta: 1 day, 18:35:58, time: 1.039, data_time: 0.465, memory: 19452, decode.loss_ce: 0.2269, decode.acc_seg: 90.1887, aux_0.loss_ce: 0.2347, aux_0.acc_seg: 89.9034, aux_1.loss_ce: 0.2595, aux_1.acc_seg: 88.7631, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2632, aux_2.acc_seg: 97.3082, loss: 1.0841
2023-05-03 21:08:10,533 - mmseg - INFO - Exp name: stdc1_1x24_512x1024_scale0.5_160k_cityscapes.py
2023-05-03 21:08:10,534 - mmseg - INFO - Iter [2000/160000]	lr: 4.944e-03, eta: 1 day, 18:46:35, time: 1.144, data_time: 0.580, memory: 19452, decode.loss_ce: 0.2240, decode.acc_seg: 90.5574, aux_0.loss_ce: 0.2320, aux_0.acc_seg: 90.2932, aux_1.loss_ce: 0.2558, aux_1.acc_seg: 89.1713, aux_2.loss_ce: 0.1002, aux_2.loss_dice: 0.2635, aux_2.acc_seg: 97.2885, loss: 1.0755
2023-05-03 21:09:04,824 - mmseg - INFO - Iter [2050/160000]	lr: 4.942e-03, eta: 1 day, 18:52:54, time: 1.086, data_time: 0.500, memory: 19452, decode.loss_ce: 0.2082, decode.acc_seg: 91.0349, aux_0.loss_ce: 0.2158, aux_0.acc_seg: 90.7760, aux_1.loss_ce: 0.2415, aux_1.acc_seg: 89.5940, aux_2.loss_ce: 0.0993, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 97.3045, loss: 1.0270
2023-05-03 21:10:01,947 - mmseg - INFO - Iter [2100/160000]	lr: 4.941e-03, eta: 1 day, 19:02:26, time: 1.142, data_time: 0.581, memory: 19452, decode.loss_ce: 0.2057, decode.acc_seg: 91.2081, aux_0.loss_ce: 0.2125, aux_0.acc_seg: 90.9841, aux_1.loss_ce: 0.2362, aux_1.acc_seg: 89.8237, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2624, aux_2.acc_seg: 97.3025, loss: 1.0166
2023-05-03 21:10:52,387 - mmseg - INFO - Iter [2150/160000]	lr: 4.940e-03, eta: 1 day, 19:03:18, time: 1.009, data_time: 0.432, memory: 19452, decode.loss_ce: 0.2157, decode.acc_seg: 90.8536, aux_0.loss_ce: 0.2237, aux_0.acc_seg: 90.6185, aux_1.loss_ce: 0.2477, aux_1.acc_seg: 89.4869, aux_2.loss_ce: 0.1010, aux_2.loss_dice: 0.2646, aux_2.acc_seg: 97.2457, loss: 1.0527
2023-05-03 21:11:43,976 - mmseg - INFO - Iter [2200/160000]	lr: 4.938e-03, eta: 1 day, 19:05:27, time: 1.032, data_time: 0.463, memory: 19452, decode.loss_ce: 0.2006, decode.acc_seg: 91.6006, aux_0.loss_ce: 0.2084, aux_0.acc_seg: 91.3626, aux_1.loss_ce: 0.2338, aux_1.acc_seg: 90.2178, aux_2.loss_ce: 0.1004, aux_2.loss_dice: 0.2638, aux_2.acc_seg: 97.2598, loss: 1.0069
2023-05-03 21:12:34,473 - mmseg - INFO - Iter [2250/160000]	lr: 4.937e-03, eta: 1 day, 19:06:17, time: 1.011, data_time: 0.444, memory: 19452, decode.loss_ce: 0.2004, decode.acc_seg: 91.3252, aux_0.loss_ce: 0.2097, aux_0.acc_seg: 91.0110, aux_1.loss_ce: 0.2342, aux_1.acc_seg: 89.8706, aux_2.loss_ce: 0.0993, aux_2.loss_dice: 0.2616, aux_2.acc_seg: 97.2834, loss: 1.0053
2023-05-03 21:13:23,077 - mmseg - INFO - Iter [2300/160000]	lr: 4.935e-03, eta: 1 day, 19:04:44, time: 0.971, data_time: 0.403, memory: 19452, decode.loss_ce: 0.2063, decode.acc_seg: 91.2752, aux_0.loss_ce: 0.2149, aux_0.acc_seg: 90.9535, aux_1.loss_ce: 0.2384, aux_1.acc_seg: 89.8675, aux_2.loss_ce: 0.1000, aux_2.loss_dice: 0.2621, aux_2.acc_seg: 97.2624, loss: 1.0217
2023-05-03 21:14:19,175 - mmseg - INFO - Iter [2350/160000]	lr: 4.934e-03, eta: 1 day, 19:11:39, time: 1.122, data_time: 0.566, memory: 19452, decode.loss_ce: 0.2093, decode.acc_seg: 90.9998, aux_0.loss_ce: 0.2160, aux_0.acc_seg: 90.8423, aux_1.loss_ce: 0.2386, aux_1.acc_seg: 89.8024, aux_2.loss_ce: 0.0997, aux_2.loss_dice: 0.2630, aux_2.acc_seg: 97.2754, loss: 1.0267
2023-05-03 21:15:08,634 - mmseg - INFO - Iter [2400/160000]	lr: 4.932e-03, eta: 1 day, 19:10:59, time: 0.989, data_time: 0.418, memory: 19452, decode.loss_ce: 0.2084, decode.acc_seg: 91.2261, aux_0.loss_ce: 0.2152, aux_0.acc_seg: 90.9927, aux_1.loss_ce: 0.2401, aux_1.acc_seg: 89.8555, aux_2.loss_ce: 0.0983, aux_2.loss_dice: 0.2613, aux_2.acc_seg: 97.3345, loss: 1.0233
2023-05-03 21:15:59,533 - mmseg - INFO - Iter [2450/160000]	lr: 4.931e-03, eta: 1 day, 19:11:51, time: 1.018, data_time: 0.443, memory: 19452, decode.loss_ce: 0.2085, decode.acc_seg: 91.1343, aux_0.loss_ce: 0.2155, aux_0.acc_seg: 90.8599, aux_1.loss_ce: 0.2416, aux_1.acc_seg: 89.7283, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2618, aux_2.acc_seg: 97.2728, loss: 1.0271
2023-05-03 21:16:53,126 - mmseg - INFO - Iter [2500/160000]	lr: 4.930e-03, eta: 1 day, 19:15:29, time: 1.072, data_time: 0.503, memory: 19452, decode.loss_ce: 0.1971, decode.acc_seg: 91.5246, aux_0.loss_ce: 0.2039, aux_0.acc_seg: 91.3363, aux_1.loss_ce: 0.2290, aux_1.acc_seg: 90.1886, aux_2.loss_ce: 0.0976, aux_2.loss_dice: 0.2594, aux_2.acc_seg: 97.3435, loss: 0.9869
2023-05-03 21:17:41,873 - mmseg - INFO - Iter [2550/160000]	lr: 4.928e-03, eta: 1 day, 19:13:57, time: 0.975, data_time: 0.398, memory: 19452, decode.loss_ce: 0.2006, decode.acc_seg: 91.4912, aux_0.loss_ce: 0.2091, aux_0.acc_seg: 91.1816, aux_1.loss_ce: 0.2325, aux_1.acc_seg: 90.1004, aux_2.loss_ce: 0.1009, aux_2.loss_dice: 0.2629, aux_2.acc_seg: 97.2250, loss: 1.0060
2023-05-03 21:18:36,112 - mmseg - INFO - Iter [2600/160000]	lr: 4.927e-03, eta: 1 day, 19:17:59, time: 1.085, data_time: 0.537, memory: 19452, decode.loss_ce: 0.2016, decode.acc_seg: 91.4281, aux_0.loss_ce: 0.2091, aux_0.acc_seg: 91.1448, aux_1.loss_ce: 0.2336, aux_1.acc_seg: 90.0989, aux_2.loss_ce: 0.1005, aux_2.loss_dice: 0.2629, aux_2.acc_seg: 97.2475, loss: 1.0078
2023-05-03 21:19:25,667 - mmseg - INFO - Iter [2650/160000]	lr: 4.925e-03, eta: 1 day, 19:17:11, time: 0.991, data_time: 0.397, memory: 19452, decode.loss_ce: 0.1970, decode.acc_seg: 91.6025, aux_0.loss_ce: 0.2040, aux_0.acc_seg: 91.3544, aux_1.loss_ce: 0.2273, aux_1.acc_seg: 90.2863, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2619, aux_2.acc_seg: 97.2825, loss: 0.9900
2023-05-03 21:20:15,956 - mmseg - INFO - Iter [2700/160000]	lr: 4.924e-03, eta: 1 day, 19:17:07, time: 1.006, data_time: 0.421, memory: 19452, decode.loss_ce: 0.1989, decode.acc_seg: 91.5232, aux_0.loss_ce: 0.2068, aux_0.acc_seg: 91.2687, aux_1.loss_ce: 0.2315, aux_1.acc_seg: 90.1523, aux_2.loss_ce: 0.0994, aux_2.loss_dice: 0.2603, aux_2.acc_seg: 97.2694, loss: 0.9969
2023-05-03 21:21:09,755 - mmseg - INFO - Iter [2750/160000]	lr: 4.923e-03, eta: 1 day, 19:20:22, time: 1.076, data_time: 0.519, memory: 19452, decode.loss_ce: 0.2033, decode.acc_seg: 91.1219, aux_0.loss_ce: 0.2108, aux_0.acc_seg: 90.8724, aux_1.loss_ce: 0.2346, aux_1.acc_seg: 89.7426, aux_2.loss_ce: 0.0972, aux_2.loss_dice: 0.2590, aux_2.acc_seg: 97.3220, loss: 1.0049
2023-05-03 21:21:59,307 - mmseg - INFO - Iter [2800/160000]	lr: 4.921e-03, eta: 1 day, 19:19:28, time: 0.991, data_time: 0.427, memory: 19452, decode.loss_ce: 0.1930, decode.acc_seg: 91.7133, aux_0.loss_ce: 0.2008, aux_0.acc_seg: 91.4754, aux_1.loss_ce: 0.2240, aux_1.acc_seg: 90.3763, aux_2.loss_ce: 0.0962, aux_2.loss_dice: 0.2569, aux_2.acc_seg: 97.3693, loss: 0.9710
2023-05-03 21:22:54,961 - mmseg - INFO - Iter [2850/160000]	lr: 4.920e-03, eta: 1 day, 19:24:12, time: 1.113, data_time: 0.552, memory: 19452, decode.loss_ce: 0.1903, decode.acc_seg: 91.9212, aux_0.loss_ce: 0.1968, aux_0.acc_seg: 91.7000, aux_1.loss_ce: 0.2218, aux_1.acc_seg: 90.5424, aux_2.loss_ce: 0.0988, aux_2.loss_dice: 0.2607, aux_2.acc_seg: 97.2846, loss: 0.9684
2023-05-03 21:23:44,110 - mmseg - INFO - Iter [2900/160000]	lr: 4.918e-03, eta: 1 day, 19:22:52, time: 0.983, data_time: 0.412, memory: 19452, decode.loss_ce: 0.1915, decode.acc_seg: 91.5522, aux_0.loss_ce: 0.1992, aux_0.acc_seg: 91.3019, aux_1.loss_ce: 0.2220, aux_1.acc_seg: 90.1857, aux_2.loss_ce: 0.0975, aux_2.loss_dice: 0.2570, aux_2.acc_seg: 97.3221, loss: 0.9673
2023-05-03 21:24:32,209 - mmseg - INFO - Iter [2950/160000]	lr: 4.917e-03, eta: 1 day, 19:20:37, time: 0.962, data_time: 0.406, memory: 19452, decode.loss_ce: 0.1961, decode.acc_seg: 91.5171, aux_0.loss_ce: 0.2019, aux_0.acc_seg: 91.3570, aux_1.loss_ce: 0.2253, aux_1.acc_seg: 90.2323, aux_2.loss_ce: 0.0969, aux_2.loss_dice: 0.2574, aux_2.acc_seg: 97.3283, loss: 0.9777
2023-05-03 21:25:24,185 - mmseg - INFO - Exp name: stdc1_1x24_512x1024_scale0.5_160k_cityscapes.py
2023-05-03 21:25:24,185 - mmseg - INFO - Iter [3000/160000]	lr: 4.916e-03, eta: 1 day, 19:21:47, time: 1.040, data_time: 0.480, memory: 19452, decode.loss_ce: 0.1917, decode.acc_seg: 91.6395, aux_0.loss_ce: 0.1987, aux_0.acc_seg: 91.4422, aux_1.loss_ce: 0.2218, aux_1.acc_seg: 90.3177, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2574, aux_2.acc_seg: 97.3426, loss: 0.9665
2023-05-03 21:26:14,882 - mmseg - INFO - Iter [3050/160000]	lr: 4.914e-03, eta: 1 day, 19:21:48, time: 1.014, data_time: 0.450, memory: 19452, decode.loss_ce: 0.1839, decode.acc_seg: 91.9895, aux_0.loss_ce: 0.1915, aux_0.acc_seg: 91.7227, aux_1.loss_ce: 0.2151, aux_1.acc_seg: 90.6391, aux_2.loss_ce: 0.0975, aux_2.loss_dice: 0.2570, aux_2.acc_seg: 97.3089, loss: 0.9451
2023-05-03 21:27:08,260 - mmseg - INFO - Iter [3100/160000]	lr: 4.913e-03, eta: 1 day, 19:24:03, time: 1.067, data_time: 0.498, memory: 19452, decode.loss_ce: 0.1930, decode.acc_seg: 91.5402, aux_0.loss_ce: 0.2025, aux_0.acc_seg: 91.1766, aux_1.loss_ce: 0.2236, aux_1.acc_seg: 90.2056, aux_2.loss_ce: 0.0969, aux_2.loss_dice: 0.2562, aux_2.acc_seg: 97.3230, loss: 0.9721
2023-05-03 21:27:57,938 - mmseg - INFO - Iter [3150/160000]	lr: 4.911e-03, eta: 1 day, 19:23:07, time: 0.994, data_time: 0.424, memory: 19452, decode.loss_ce: 0.1830, decode.acc_seg: 92.0394, aux_0.loss_ce: 0.1915, aux_0.acc_seg: 91.7565, aux_1.loss_ce: 0.2154, aux_1.acc_seg: 90.6339, aux_2.loss_ce: 0.0985, aux_2.loss_dice: 0.2565, aux_2.acc_seg: 97.2768, loss: 0.9449
2023-05-03 21:28:54,653 - mmseg - INFO - Iter [3200/160000]	lr: 4.910e-03, eta: 1 day, 19:27:57, time: 1.134, data_time: 0.565, memory: 19452, decode.loss_ce: 0.1812, decode.acc_seg: 92.1335, aux_0.loss_ce: 0.1885, aux_0.acc_seg: 91.8821, aux_1.loss_ce: 0.2137, aux_1.acc_seg: 90.7222, aux_2.loss_ce: 0.0989, aux_2.loss_dice: 0.2597, aux_2.acc_seg: 97.2602, loss: 0.9419
2023-05-03 21:29:43,570 - mmseg - INFO - Iter [3250/160000]	lr: 4.909e-03, eta: 1 day, 19:26:20, time: 0.978, data_time: 0.384, memory: 19452, decode.loss_ce: 0.1914, decode.acc_seg: 91.9102, aux_0.loss_ce: 0.1987, aux_0.acc_seg: 91.6793, aux_1.loss_ce: 0.2220, aux_1.acc_seg: 90.6220, aux_2.loss_ce: 0.0980, aux_2.loss_dice: 0.2591, aux_2.acc_seg: 97.2899, loss: 0.9692
2023-05-03 21:30:34,465 - mmseg - INFO - Iter [3300/160000]	lr: 4.907e-03, eta: 1 day, 19:26:18, time: 1.018, data_time: 0.438, memory: 19452, decode.loss_ce: 0.1837, decode.acc_seg: 92.0451, aux_0.loss_ce: 0.1915, aux_0.acc_seg: 91.8106, aux_1.loss_ce: 0.2145, aux_1.acc_seg: 90.7133, aux_2.loss_ce: 0.0986, aux_2.loss_dice: 0.2589, aux_2.acc_seg: 97.2856, loss: 0.9471
2023-05-03 21:31:27,312 - mmseg - INFO - Iter [3350/160000]	lr: 4.906e-03, eta: 1 day, 19:27:46, time: 1.057, data_time: 0.491, memory: 19452, decode.loss_ce: 0.1770, decode.acc_seg: 92.1511, aux_0.loss_ce: 0.1843, aux_0.acc_seg: 91.8655, aux_1.loss_ce: 0.2077, aux_1.acc_seg: 90.7683, aux_2.loss_ce: 0.0969, aux_2.loss_dice: 0.2557, aux_2.acc_seg: 97.3184, loss: 0.9216
2023-05-03 21:32:16,877 - mmseg - INFO - Iter [3400/160000]	lr: 4.904e-03, eta: 1 day, 19:26:34, time: 0.990, data_time: 0.423, memory: 19452, decode.loss_ce: 0.1861, decode.acc_seg: 91.8343, aux_0.loss_ce: 0.1940, aux_0.acc_seg: 91.5500, aux_1.loss_ce: 0.2163, aux_1.acc_seg: 90.4928, aux_2.loss_ce: 0.0964, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 97.3390, loss: 0.9482
2023-05-03 21:33:10,425 - mmseg - INFO - Iter [3450/160000]	lr: 4.903e-03, eta: 1 day, 19:28:32, time: 1.073, data_time: 0.509, memory: 19452, decode.loss_ce: 0.1856, decode.acc_seg: 91.8442, aux_0.loss_ce: 0.1927, aux_0.acc_seg: 91.6470, aux_1.loss_ce: 0.2169, aux_1.acc_seg: 90.5224, aux_2.loss_ce: 0.0973, aux_2.loss_dice: 0.2548, aux_2.acc_seg: 97.2967, loss: 0.9473
2023-05-03 21:33:59,723 - mmseg - INFO - Iter [3500/160000]	lr: 4.902e-03, eta: 1 day, 19:27:12, time: 0.986, data_time: 0.426, memory: 19452, decode.loss_ce: 0.1796, decode.acc_seg: 92.2075, aux_0.loss_ce: 0.1874, aux_0.acc_seg: 91.9537, aux_1.loss_ce: 0.2082, aux_1.acc_seg: 90.9626, aux_2.loss_ce: 0.0971, aux_2.loss_dice: 0.2566, aux_2.acc_seg: 97.3161, loss: 0.9288
2023-05-03 21:34:49,451 - mmseg - INFO - Iter [3550/160000]	lr: 4.900e-03, eta: 1 day, 19:26:10, time: 0.995, data_time: 0.440, memory: 19452, decode.loss_ce: 0.1793, decode.acc_seg: 92.2107, aux_0.loss_ce: 0.1871, aux_0.acc_seg: 91.9891, aux_1.loss_ce: 0.2108, aux_1.acc_seg: 90.8765, aux_2.loss_ce: 0.0984, aux_2.loss_dice: 0.2567, aux_2.acc_seg: 97.2804, loss: 0.9324
2023-05-03 21:35:41,556 - mmseg - INFO - Iter [3600/160000]	lr: 4.899e-03, eta: 1 day, 19:26:53, time: 1.042, data_time: 0.483, memory: 19452, decode.loss_ce: 0.1838, decode.acc_seg: 91.9680, aux_0.loss_ce: 0.1902, aux_0.acc_seg: 91.7789, aux_1.loss_ce: 0.2122, aux_1.acc_seg: 90.7454, aux_2.loss_ce: 0.0966, aux_2.loss_dice: 0.2568, aux_2.acc_seg: 97.3068, loss: 0.9396
2023-05-03 21:36:29,965 - mmseg - INFO - Iter [3650/160000]	lr: 4.897e-03, eta: 1 day, 19:24:55, time: 0.968, data_time: 0.414, memory: 19452, decode.loss_ce: 0.1812, decode.acc_seg: 92.0434, aux_0.loss_ce: 0.1872, aux_0.acc_seg: 91.8339, aux_1.loss_ce: 0.2108, aux_1.acc_seg: 90.6999, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2542, aux_2.acc_seg: 97.3487, loss: 0.9291
2023-05-03 21:37:26,047 - mmseg - INFO - Iter [3700/160000]	lr: 4.896e-03, eta: 1 day, 19:28:23, time: 1.122, data_time: 0.573, memory: 19452, decode.loss_ce: 0.1742, decode.acc_seg: 92.4704, aux_0.loss_ce: 0.1825, aux_0.acc_seg: 92.2257, aux_1.loss_ce: 0.2058, aux_1.acc_seg: 91.1387, aux_2.loss_ce: 0.0958, aux_2.loss_dice: 0.2559, aux_2.acc_seg: 97.3553, loss: 0.9142
2023-05-03 21:38:19,343 - mmseg - INFO - Iter [3750/160000]	lr: 4.894e-03, eta: 1 day, 19:29:47, time: 1.066, data_time: 0.507, memory: 19452, decode.loss_ce: 0.1867, decode.acc_seg: 91.9920, aux_0.loss_ce: 0.1950, aux_0.acc_seg: 91.7401, aux_1.loss_ce: 0.2165, aux_1.acc_seg: 90.6566, aux_2.loss_ce: 0.0978, aux_2.loss_dice: 0.2564, aux_2.acc_seg: 97.2931, loss: 0.9523
2023-05-03 21:39:09,376 - mmseg - INFO - Iter [3800/160000]	lr: 4.893e-03, eta: 1 day, 19:28:54, time: 1.001, data_time: 0.433, memory: 19452, decode.loss_ce: 0.1766, decode.acc_seg: 92.3454, aux_0.loss_ce: 0.1829, aux_0.acc_seg: 92.1726, aux_1.loss_ce: 0.2060, aux_1.acc_seg: 91.0873, aux_2.loss_ce: 0.0965, aux_2.loss_dice: 0.2541, aux_2.acc_seg: 97.3190, loss: 0.9162
2023-05-03 21:40:05,577 - mmseg - INFO - Iter [3850/160000]	lr: 4.892e-03, eta: 1 day, 19:32:11, time: 1.124, data_time: 0.559, memory: 19452, decode.loss_ce: 0.1736, decode.acc_seg: 92.5236, aux_0.loss_ce: 0.1814, aux_0.acc_seg: 92.2663, aux_1.loss_ce: 0.2049, aux_1.acc_seg: 91.2013, aux_2.loss_ce: 0.0983, aux_2.loss_dice: 0.2574, aux_2.acc_seg: 97.2666, loss: 0.9155
2023-05-03 21:40:58,535 - mmseg - INFO - Iter [3900/160000]	lr: 4.890e-03, eta: 1 day, 19:33:11, time: 1.059, data_time: 0.499, memory: 19452, decode.loss_ce: 0.1777, decode.acc_seg: 92.2711, aux_0.loss_ce: 0.1837, aux_0.acc_seg: 92.1023, aux_1.loss_ce: 0.2091, aux_1.acc_seg: 90.9471, aux_2.loss_ce: 0.0989, aux_2.loss_dice: 0.2582, aux_2.acc_seg: 97.2441, loss: 0.9276
2023-05-03 21:41:53,155 - mmseg - INFO - Iter [3950/160000]	lr: 4.889e-03, eta: 1 day, 19:35:15, time: 1.092, data_time: 0.542, memory: 19452, decode.loss_ce: 0.1735, decode.acc_seg: 92.5822, aux_0.loss_ce: 0.1795, aux_0.acc_seg: 92.3627, aux_1.loss_ce: 0.2048, aux_1.acc_seg: 91.2403, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2546, aux_2.acc_seg: 97.3349, loss: 0.9083
2023-05-03 21:42:39,913 - mmseg - INFO - Exp name: stdc1_1x24_512x1024_scale0.5_160k_cityscapes.py
2023-05-03 21:42:39,914 - mmseg - INFO - Iter [4000/160000]	lr: 4.887e-03, eta: 1 day, 19:32:07, time: 0.935, data_time: 0.384, memory: 19452, decode.loss_ce: 0.1663, decode.acc_seg: 92.7128, aux_0.loss_ce: 0.1731, aux_0.acc_seg: 92.4770, aux_1.loss_ce: 0.1960, aux_1.acc_seg: 91.4215, aux_2.loss_ce: 0.0961, aux_2.loss_dice: 0.2538, aux_2.acc_seg: 97.3107, loss: 0.8853
2023-05-03 21:43:31,897 - mmseg - INFO - Iter [4050/160000]	lr: 4.886e-03, eta: 1 day, 19:32:25, time: 1.040, data_time: 0.482, memory: 19452, decode.loss_ce: 0.1809, decode.acc_seg: 92.1169, aux_0.loss_ce: 0.1869, aux_0.acc_seg: 91.9682, aux_1.loss_ce: 0.2100, aux_1.acc_seg: 90.8509, aux_2.loss_ce: 0.0976, aux_2.loss_dice: 0.2557, aux_2.acc_seg: 97.2508, loss: 0.9311
2023-05-03 21:44:27,368 - mmseg - INFO - Iter [4100/160000]	lr: 4.885e-03, eta: 1 day, 19:34:53, time: 1.109, data_time: 0.549, memory: 19452, decode.loss_ce: 0.1725, decode.acc_seg: 92.5015, aux_0.loss_ce: 0.1796, aux_0.acc_seg: 92.2951, aux_1.loss_ce: 0.2026, aux_1.acc_seg: 91.1923, aux_2.loss_ce: 0.0967, aux_2.loss_dice: 0.2543, aux_2.acc_seg: 97.2813, loss: 0.9056
2023-05-03 21:45:17,453 - mmseg - INFO - Iter [4150/160000]	lr: 4.883e-03, eta: 1 day, 19:33:54, time: 1.002, data_time: 0.436, memory: 19452, decode.loss_ce: 0.1817, decode.acc_seg: 92.3101, aux_0.loss_ce: 0.1880, aux_0.acc_seg: 92.1322, aux_1.loss_ce: 0.2112, aux_1.acc_seg: 91.0312, aux_2.loss_ce: 0.0981, aux_2.loss_dice: 0.2579, aux_2.acc_seg: 97.2847, loss: 0.9369
2023-05-03 21:46:12,813 - mmseg - INFO - Iter [4200/160000]	lr: 4.882e-03, eta: 1 day, 19:36:10, time: 1.107, data_time: 0.549, memory: 19452, decode.loss_ce: 0.1730, decode.acc_seg: 92.4824, aux_0.loss_ce: 0.1807, aux_0.acc_seg: 92.2408, aux_1.loss_ce: 0.2028, aux_1.acc_seg: 91.1659, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 97.2985, loss: 0.9048
2023-05-03 21:47:01,378 - mmseg - INFO - Iter [4250/160000]	lr: 4.880e-03, eta: 1 day, 19:34:14, time: 0.971, data_time: 0.408, memory: 19452, decode.loss_ce: 0.1817, decode.acc_seg: 92.1972, aux_0.loss_ce: 0.1882, aux_0.acc_seg: 91.9848, aux_1.loss_ce: 0.2117, aux_1.acc_seg: 90.8844, aux_2.loss_ce: 0.0979, aux_2.loss_dice: 0.2560, aux_2.acc_seg: 97.2810, loss: 0.9355
