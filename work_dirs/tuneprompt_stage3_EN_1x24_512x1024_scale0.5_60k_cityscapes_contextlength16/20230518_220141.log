2023-05-18 22:01:41,662 - mmseg - INFO - Multi-processing start method is `None`
2023-05-18 22:01:41,668 - mmseg - INFO - OpenCV num_threads is `96
2023-05-18 22:01:41,777 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1+cu113
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.30.0+e7ed570
------------------------------------------------------------

2023-05-18 22:01:41,778 - mmseg - INFO - Distributed training: False
2023-05-18 22:01:42,678 - mmseg - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=None,
    backbone=dict(
        type='STDCContextNet',
        backbone_cfg=dict(
            type='STDCNet',
            stdc_type='STDCNet1',
            in_channels=3,
            channels=(32, 64, 256, 512, 1024),
            bottleneck_type='cat',
            num_convs=4,
            norm_cfg=dict(type='BN', requires_grad=True),
            act_cfg=dict(type='ReLU'),
            with_final_conv=False),
        last_in_channels=(1043, 512),
        out_channels=128,
        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),
        textencoder_cfg=dict(
            type='CLIPTextContextEncoder',
            context_length=16,
            encoder_type='RN50',
            pretrained='./pretrained/RN50.pt'),
        context_mode='CSC',
        CLASSES=('road', 'sidewalk', 'building', 'wall', 'fence', 'pole',
                 'traffic light', 'traffic sign', 'vegetation', 'terrain',
                 'sky', 'person', 'rider', 'car', 'truck', 'bus', 'train',
                 'motorcycle', 'bicycle')),
    decode_head=dict(
        type='FCNHead',
        in_channels=256,
        channels=256,
        num_convs=1,
        num_classes=19,
        in_index=3,
        concat_input=False,
        dropout_ratio=0.1,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=True,
        sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=780000),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=19,
            in_index=2,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=780000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='FCNHead',
            in_channels=128,
            channels=64,
            num_convs=1,
            num_classes=19,
            in_index=1,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=False,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=780000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
        dict(
            type='STDCHead',
            in_channels=256,
            channels=64,
            num_convs=1,
            num_classes=2,
            boundary_threshold=0.1,
            in_index=0,
            norm_cfg=dict(type='BN', requires_grad=True),
            concat_input=False,
            align_corners=True,
            loss_decode=[
                dict(
                    type='CrossEntropyLoss',
                    loss_name='loss_ce',
                    use_sigmoid=True,
                    loss_weight=1.0),
                dict(type='DiceLoss', loss_name='loss_dice', loss_weight=1.0)
            ]),
        dict(
            type='VanillaHead',
            temperature=0.07,
            in_channels=19,
            channels=1,
            num_classes=19,
            in_index=4,
            sampler=dict(type='OHEMPixelSampler', thresh=0.7, min_kept=780000),
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'),
    init_cfg=dict(
        type='Pretrained',
        checkpoint=
        './work_dirs/tuneprompt_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16_fixbackbone/latest.pth'
    ))
dataset_type = 'CityscapesDataset'
data_root = 'data/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='Resize',
        img_scale=(2048, 1024),
        ratio_range=(0.125, 1.5),
        scale_step_size=0.125),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=24,
    workers_per_gpu=4,
    train=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/train',
        ann_dir='gtFine/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize',
                img_scale=(2048, 1024),
                ratio_range=(0.125, 1.5),
                scale_step_size=0.125),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='SGD',
    lr=0.1,
    momentum=0.9,
    weight_decay=0.0005,
    paramwise_cfg=dict(
        custom_keys=dict(
            {
                'backbone.backbone': dict(lr_mult=0.1),
                'backbone.text_encoder': dict(lr_mult=0.0, decay_mult=0.0),
                'backbone.contexts': dict(decay_mult=0.0),
                '.bn.': dict(decay_mult=0.0)
            })))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=0.9,
    min_lr=1e-06,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=1e-05)
runner = dict(type='IterBasedRunner', max_iters=60000)
checkpoint_config = dict(by_epoch=False, interval=1500)
evaluation = dict(
    interval=1500, metric='mIoU', pre_eval=True, save_best='mIoU')
checkpoint = './work_dirs/tuneprompt_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16_fixbackbone/latest.pth'
work_dir = './work_dirs/tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16'
gpu_ids = [0]
auto_resume = False

2023-05-18 22:01:42,679 - mmseg - INFO - Set random seed to 1604980074, deterministic: False
2023-05-18 22:01:42,754 - mmseg - INFO - Loaded 2975 images
2023-05-18 22:01:45,924 - mmseg - INFO - initialize EncoderDecoder with init_cfg {'type': 'Pretrained', 'checkpoint': './work_dirs/tuneprompt_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16_fixbackbone/latest.pth'}
2023-05-18 22:01:57,670 - mmseg - INFO - EncoderDecoder(
  (backbone): STDCContextNet(
    (backbone): STDCNet(
      (stages): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (3): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
        (4): Sequential(
          (0): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
            (downsample): ConvModule(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (skip): AvgPool2d(kernel_size=3, stride=2, padding=1)
          )
          (1): STDCModule(
            (layers): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (1): ConvModule(
                (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (2): ConvModule(
                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (3): ConvModule(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (text_encoder): CLIPTextContextEncoder(
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (drop_path): Identity()
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    init_cfg={'type': 'Pretrained', 'checkpoint': './pretrained/RN50.pt'}
    (arms): ModuleList(
      (0): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(1043, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
      (1): AttentionRefinementModule(
        (conv_layer): ConvModule(
          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (atten_conv_layer): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): ConvModule(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sigmoid()
        )
      )
    )
    (convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_avg): ConvModule(
      (conv): Conv2d(1043, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (ffm): FeatureFusionModule(
      (conv0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (attention): Sequential(
        (0): AdaptiveAvgPool2d(output_size=(1, 1))
        (1): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (3): Sigmoid()
      )
    )
  )
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=True
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (1): FCNHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (2): STDCHead(
      input_transform=None, ignore_index=255, align_corners=True
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss(avg_non_ignore=False)
        (1): DiceLoss()
      )
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (3): VanillaHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
      (conv_seg): None
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
init_cfg={'type': 'Pretrained', 'checkpoint': './work_dirs/tuneprompt_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16_fixbackbone/latest.pth'}
2023-05-18 22:01:57,763 - mmseg - INFO - Loaded 500 images
2023-05-18 22:01:57,763 - mmseg - INFO - Start running, host: linchiayi@cml9, work_dir: /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16
2023-05-18 22:01:57,763 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-05-18 22:01:57,764 - mmseg - INFO - workflow: [('train', 1)], max: 60000 iters
2023-05-18 22:01:57,764 - mmseg - INFO - Checkpoints will be saved to /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16 by HardDiskBackend.
2023-05-18 22:03:16,060 - mmseg - INFO - Iter [50/60000]	lr: 4.897e-03, eta: 1 day, 1:57:08, time: 1.558, data_time: 0.145, memory: 19944, decode.loss_ce: 0.0718, decode.acc_seg: 96.5255, aux_0.loss_ce: 0.0753, aux_0.acc_seg: 96.3896, aux_1.loss_ce: 0.0911, aux_1.acc_seg: 95.6180, aux_2.loss_ce: 0.0864, aux_2.loss_dice: 0.2293, aux_2.acc_seg: 97.3272, aux_3.loss_ce: 0.1252, aux_3.acc_seg: 94.2568, loss: 0.6789
2023-05-18 22:04:10,867 - mmseg - INFO - Iter [100/60000]	lr: 9.886e-03, eta: 22:05:04, time: 1.096, data_time: 0.061, memory: 19944, decode.loss_ce: 0.0749, decode.acc_seg: 96.3738, aux_0.loss_ce: 0.0783, aux_0.acc_seg: 96.2526, aux_1.loss_ce: 0.0944, aux_1.acc_seg: 95.4447, aux_2.loss_ce: 0.0872, aux_2.loss_dice: 0.2303, aux_2.acc_seg: 97.3092, aux_3.loss_ce: 0.1256, aux_3.acc_seg: 94.1915, loss: 0.6907
2023-05-18 22:05:11,785 - mmseg - INFO - Iter [150/60000]	lr: 1.487e-02, eta: 21:27:44, time: 1.218, data_time: 0.176, memory: 19944, decode.loss_ce: 0.0786, decode.acc_seg: 96.2606, aux_0.loss_ce: 0.0817, aux_0.acc_seg: 96.1516, aux_1.loss_ce: 0.0985, aux_1.acc_seg: 95.3439, aux_2.loss_ce: 0.0872, aux_2.loss_dice: 0.2322, aux_2.acc_seg: 97.3198, aux_3.loss_ce: 0.1273, aux_3.acc_seg: 94.1891, loss: 0.7055
2023-05-18 22:06:07,047 - mmseg - INFO - Iter [200/60000]	lr: 1.984e-02, eta: 20:40:23, time: 1.105, data_time: 0.063, memory: 19944, decode.loss_ce: 0.0866, decode.acc_seg: 95.9195, aux_0.loss_ce: 0.0891, aux_0.acc_seg: 95.8442, aux_1.loss_ce: 0.1058, aux_1.acc_seg: 95.0297, aux_2.loss_ce: 0.0894, aux_2.loss_dice: 0.2340, aux_2.acc_seg: 97.2738, aux_3.loss_ce: 0.1314, aux_3.acc_seg: 93.9998, loss: 0.7363
2023-05-18 22:07:07,912 - mmseg - INFO - Iter [250/60000]	lr: 2.481e-02, eta: 20:33:55, time: 1.217, data_time: 0.170, memory: 19944, decode.loss_ce: 0.1027, decode.acc_seg: 95.3033, aux_0.loss_ce: 0.1044, aux_0.acc_seg: 95.2747, aux_1.loss_ce: 0.1209, aux_1.acc_seg: 94.4431, aux_2.loss_ce: 0.0895, aux_2.loss_dice: 0.2357, aux_2.acc_seg: 97.2865, aux_3.loss_ce: 0.1425, aux_3.acc_seg: 93.5777, loss: 0.7956
2023-05-18 22:08:03,673 - mmseg - INFO - Iter [300/60000]	lr: 2.977e-02, eta: 20:12:20, time: 1.115, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1964, decode.acc_seg: 91.9725, aux_0.loss_ce: 0.1931, aux_0.acc_seg: 92.0268, aux_1.loss_ce: 0.2104, aux_1.acc_seg: 91.1840, aux_2.loss_ce: 0.0921, aux_2.loss_dice: 0.2427, aux_2.acc_seg: 97.3206, aux_3.loss_ce: 0.2033, aux_3.acc_seg: 91.2879, loss: 1.1379
2023-05-18 22:09:00,023 - mmseg - INFO - Iter [350/60000]	lr: 3.472e-02, eta: 19:58:20, time: 1.127, data_time: 0.060, memory: 19944, decode.loss_ce: 0.3390, decode.acc_seg: 86.9198, aux_0.loss_ce: 0.3341, aux_0.acc_seg: 87.1615, aux_1.loss_ce: 0.3577, aux_1.acc_seg: 86.1065, aux_2.loss_ce: 0.1018, aux_2.loss_dice: 0.2580, aux_2.acc_seg: 97.2279, aux_3.loss_ce: 0.3116, aux_3.acc_seg: 87.5135, loss: 1.7024
2023-05-18 22:10:01,740 - mmseg - INFO - Iter [400/60000]	lr: 3.966e-02, eta: 20:00:56, time: 1.234, data_time: 0.165, memory: 19944, decode.loss_ce: 0.3612, decode.acc_seg: 86.1085, aux_0.loss_ce: 0.3578, aux_0.acc_seg: 86.2584, aux_1.loss_ce: 0.3744, aux_1.acc_seg: 85.4806, aux_2.loss_ce: 0.1016, aux_2.loss_dice: 0.2604, aux_2.acc_seg: 97.2541, aux_3.loss_ce: 0.3387, aux_3.acc_seg: 86.5087, loss: 1.7941
2023-05-18 22:10:58,145 - mmseg - INFO - Iter [450/60000]	lr: 4.460e-02, eta: 19:51:00, time: 1.128, data_time: 0.060, memory: 19944, decode.loss_ce: 0.3288, decode.acc_seg: 87.2765, aux_0.loss_ce: 0.3273, aux_0.acc_seg: 87.3140, aux_1.loss_ce: 0.3445, aux_1.acc_seg: 86.4999, aux_2.loss_ce: 0.0999, aux_2.loss_dice: 0.2575, aux_2.acc_seg: 97.2928, aux_3.loss_ce: 0.3200, aux_3.acc_seg: 87.0780, loss: 1.6781
2023-05-18 22:11:59,551 - mmseg - INFO - Iter [500/60000]	lr: 4.953e-02, eta: 19:52:47, time: 1.228, data_time: 0.161, memory: 19944, decode.loss_ce: 0.2517, decode.acc_seg: 89.5915, aux_0.loss_ce: 0.2503, aux_0.acc_seg: 89.7054, aux_1.loss_ce: 0.2681, aux_1.acc_seg: 88.8171, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2525, aux_2.acc_seg: 97.2746, aux_3.loss_ce: 0.2531, aux_3.acc_seg: 89.2644, loss: 1.3727
2023-05-18 22:12:55,836 - mmseg - INFO - Iter [550/60000]	lr: 5.445e-02, eta: 19:44:50, time: 1.126, data_time: 0.060, memory: 19944, decode.loss_ce: 0.2560, decode.acc_seg: 89.5038, aux_0.loss_ce: 0.2555, aux_0.acc_seg: 89.5779, aux_1.loss_ce: 0.2749, aux_1.acc_seg: 88.7081, aux_2.loss_ce: 0.0974, aux_2.loss_dice: 0.2540, aux_2.acc_seg: 97.3031, aux_3.loss_ce: 0.2598, aux_3.acc_seg: 89.1911, loss: 1.3977
2023-05-18 22:13:52,471 - mmseg - INFO - Iter [600/60000]	lr: 5.936e-02, eta: 19:38:38, time: 1.133, data_time: 0.062, memory: 19944, decode.loss_ce: 0.2892, decode.acc_seg: 88.1903, aux_0.loss_ce: 0.2874, aux_0.acc_seg: 88.3155, aux_1.loss_ce: 0.3052, aux_1.acc_seg: 87.4488, aux_2.loss_ce: 0.0981, aux_2.loss_dice: 0.2554, aux_2.acc_seg: 97.3303, aux_3.loss_ce: 0.2901, aux_3.acc_seg: 87.8834, loss: 1.5253
2023-05-18 22:14:54,246 - mmseg - INFO - Iter [650/60000]	lr: 6.427e-02, eta: 19:41:04, time: 1.235, data_time: 0.168, memory: 19944, decode.loss_ce: 0.2911, decode.acc_seg: 88.2360, aux_0.loss_ce: 0.2916, aux_0.acc_seg: 88.3383, aux_1.loss_ce: 0.3070, aux_1.acc_seg: 87.5518, aux_2.loss_ce: 0.0976, aux_2.loss_dice: 0.2544, aux_2.acc_seg: 97.3212, aux_3.loss_ce: 0.2856, aux_3.acc_seg: 88.1993, loss: 1.5273
2023-05-18 22:15:50,694 - mmseg - INFO - Iter [700/60000]	lr: 6.917e-02, eta: 19:35:28, time: 1.129, data_time: 0.062, memory: 19944, decode.loss_ce: 0.3001, decode.acc_seg: 88.1463, aux_0.loss_ce: 0.3025, aux_0.acc_seg: 88.1553, aux_1.loss_ce: 0.3183, aux_1.acc_seg: 87.4068, aux_2.loss_ce: 0.0979, aux_2.loss_dice: 0.2566, aux_2.acc_seg: 97.3735, aux_3.loss_ce: 0.2965, aux_3.acc_seg: 87.9914, loss: 1.5719
2023-05-18 22:16:52,190 - mmseg - INFO - Iter [750/60000]	lr: 7.406e-02, eta: 19:37:09, time: 1.230, data_time: 0.162, memory: 19944, decode.loss_ce: 0.2759, decode.acc_seg: 88.8736, aux_0.loss_ce: 0.2746, aux_0.acc_seg: 88.8721, aux_1.loss_ce: 0.2925, aux_1.acc_seg: 88.0860, aux_2.loss_ce: 0.0977, aux_2.loss_dice: 0.2555, aux_2.acc_seg: 97.3375, aux_3.loss_ce: 0.2788, aux_3.acc_seg: 88.4024, loss: 1.4750
2023-05-18 22:17:48,559 - mmseg - INFO - Iter [800/60000]	lr: 7.894e-02, eta: 19:32:10, time: 1.127, data_time: 0.059, memory: 19944, decode.loss_ce: 0.2869, decode.acc_seg: 88.3408, aux_0.loss_ce: 0.2854, aux_0.acc_seg: 88.4196, aux_1.loss_ce: 0.3021, aux_1.acc_seg: 87.7059, aux_2.loss_ce: 0.0974, aux_2.loss_dice: 0.2545, aux_2.acc_seg: 97.3345, aux_3.loss_ce: 0.2878, aux_3.acc_seg: 88.0980, loss: 1.5140
2023-05-18 22:18:45,268 - mmseg - INFO - Iter [850/60000]	lr: 8.382e-02, eta: 19:28:03, time: 1.134, data_time: 0.065, memory: 19944, decode.loss_ce: 0.2939, decode.acc_seg: 88.2063, aux_0.loss_ce: 0.2933, aux_0.acc_seg: 88.2147, aux_1.loss_ce: 0.3110, aux_1.acc_seg: 87.4831, aux_2.loss_ce: 0.0990, aux_2.loss_dice: 0.2564, aux_2.acc_seg: 97.2883, aux_3.loss_ce: 0.2913, aux_3.acc_seg: 88.0095, loss: 1.5450
2023-05-18 22:19:46,614 - mmseg - INFO - Iter [900/60000]	lr: 8.869e-02, eta: 19:29:22, time: 1.227, data_time: 0.163, memory: 19944, decode.loss_ce: 0.3353, decode.acc_seg: 86.6744, aux_0.loss_ce: 0.3355, aux_0.acc_seg: 86.6338, aux_1.loss_ce: 0.3527, aux_1.acc_seg: 85.9029, aux_2.loss_ce: 0.1005, aux_2.loss_dice: 0.2611, aux_2.acc_seg: 97.3292, aux_3.loss_ce: 0.3332, aux_3.acc_seg: 86.5059, loss: 1.7185
2023-05-18 22:20:42,854 - mmseg - INFO - Iter [950/60000]	lr: 9.355e-02, eta: 19:25:09, time: 1.125, data_time: 0.055, memory: 19944, decode.loss_ce: 0.2867, decode.acc_seg: 88.2271, aux_0.loss_ce: 0.2848, aux_0.acc_seg: 88.3050, aux_1.loss_ce: 0.3025, aux_1.acc_seg: 87.4209, aux_2.loss_ce: 0.0979, aux_2.loss_dice: 0.2580, aux_2.acc_seg: 97.3656, aux_3.loss_ce: 0.2921, aux_3.acc_seg: 87.7944, loss: 1.5219
2023-05-18 22:21:44,576 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-18 22:21:44,577 - mmseg - INFO - Iter [1000/60000]	lr: 9.840e-02, eta: 19:26:39, time: 1.234, data_time: 0.166, memory: 19944, decode.loss_ce: 0.3043, decode.acc_seg: 87.6364, aux_0.loss_ce: 0.3040, aux_0.acc_seg: 87.6538, aux_1.loss_ce: 0.3208, aux_1.acc_seg: 86.9331, aux_2.loss_ce: 0.0986, aux_2.loss_dice: 0.2575, aux_2.acc_seg: 97.3360, aux_3.loss_ce: 0.3044, aux_3.acc_seg: 87.3766, loss: 1.5896
2023-05-18 22:22:40,672 - mmseg - INFO - Iter [1050/60000]	lr: 9.843e-02, eta: 19:22:38, time: 1.122, data_time: 0.059, memory: 19944, decode.loss_ce: 0.2646, decode.acc_seg: 89.0445, aux_0.loss_ce: 0.2638, aux_0.acc_seg: 89.1074, aux_1.loss_ce: 0.2795, aux_1.acc_seg: 88.3846, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2538, aux_2.acc_seg: 97.3569, aux_3.loss_ce: 0.2749, aux_3.acc_seg: 88.5006, loss: 1.4327
2023-05-18 22:23:36,926 - mmseg - INFO - Iter [1100/60000]	lr: 9.835e-02, eta: 19:19:03, time: 1.125, data_time: 0.057, memory: 19944, decode.loss_ce: 0.2506, decode.acc_seg: 89.5231, aux_0.loss_ce: 0.2520, aux_0.acc_seg: 89.5214, aux_1.loss_ce: 0.2703, aux_1.acc_seg: 88.7456, aux_2.loss_ce: 0.0974, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 97.3152, aux_3.loss_ce: 0.2649, aux_3.acc_seg: 88.8290, loss: 1.3883
2023-05-18 22:24:38,729 - mmseg - INFO - Iter [1150/60000]	lr: 9.827e-02, eta: 19:20:26, time: 1.236, data_time: 0.165, memory: 19944, decode.loss_ce: 0.2473, decode.acc_seg: 89.5626, aux_0.loss_ce: 0.2481, aux_0.acc_seg: 89.5638, aux_1.loss_ce: 0.2657, aux_1.acc_seg: 88.7403, aux_2.loss_ce: 0.0958, aux_2.loss_dice: 0.2516, aux_2.acc_seg: 97.3548, aux_3.loss_ce: 0.2609, aux_3.acc_seg: 88.9062, loss: 1.3692
2023-05-18 22:25:35,412 - mmseg - INFO - Iter [1200/60000]	lr: 9.820e-02, eta: 19:17:25, time: 1.134, data_time: 0.062, memory: 19944, decode.loss_ce: 0.2486, decode.acc_seg: 89.6232, aux_0.loss_ce: 0.2473, aux_0.acc_seg: 89.6962, aux_1.loss_ce: 0.2683, aux_1.acc_seg: 88.7582, aux_2.loss_ce: 0.0963, aux_2.loss_dice: 0.2531, aux_2.acc_seg: 97.3615, aux_3.loss_ce: 0.2593, aux_3.acc_seg: 89.1106, loss: 1.3729
2023-05-18 22:26:37,088 - mmseg - INFO - Iter [1250/60000]	lr: 9.812e-02, eta: 19:18:30, time: 1.234, data_time: 0.168, memory: 19944, decode.loss_ce: 0.2378, decode.acc_seg: 90.2151, aux_0.loss_ce: 0.2403, aux_0.acc_seg: 90.1592, aux_1.loss_ce: 0.2594, aux_1.acc_seg: 89.3468, aux_2.loss_ce: 0.0968, aux_2.loss_dice: 0.2512, aux_2.acc_seg: 97.2820, aux_3.loss_ce: 0.2449, aux_3.acc_seg: 89.6640, loss: 1.3305
2023-05-18 22:27:33,626 - mmseg - INFO - Iter [1300/60000]	lr: 9.805e-02, eta: 19:15:32, time: 1.131, data_time: 0.062, memory: 19944, decode.loss_ce: 0.2392, decode.acc_seg: 89.8351, aux_0.loss_ce: 0.2398, aux_0.acc_seg: 89.8893, aux_1.loss_ce: 0.2574, aux_1.acc_seg: 89.1105, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 97.3527, aux_3.loss_ce: 0.2514, aux_3.acc_seg: 89.2212, loss: 1.3323
2023-05-18 22:28:30,074 - mmseg - INFO - Iter [1350/60000]	lr: 9.797e-02, eta: 19:12:40, time: 1.129, data_time: 0.060, memory: 19944, decode.loss_ce: 0.2425, decode.acc_seg: 90.0832, aux_0.loss_ce: 0.2422, aux_0.acc_seg: 90.1563, aux_1.loss_ce: 0.2562, aux_1.acc_seg: 89.4905, aux_2.loss_ce: 0.0977, aux_2.loss_dice: 0.2540, aux_2.acc_seg: 97.2894, aux_3.loss_ce: 0.2533, aux_3.acc_seg: 89.4499, loss: 1.3459
2023-05-18 22:29:32,147 - mmseg - INFO - Iter [1400/60000]	lr: 9.790e-02, eta: 19:13:51, time: 1.241, data_time: 0.171, memory: 19944, decode.loss_ce: 0.2457, decode.acc_seg: 89.7216, aux_0.loss_ce: 0.2446, aux_0.acc_seg: 89.7496, aux_1.loss_ce: 0.2614, aux_1.acc_seg: 88.8985, aux_2.loss_ce: 0.0963, aux_2.loss_dice: 0.2520, aux_2.acc_seg: 97.3378, aux_3.loss_ce: 0.2548, aux_3.acc_seg: 89.1208, loss: 1.3548
2023-05-18 22:30:28,527 - mmseg - INFO - Iter [1450/60000]	lr: 9.782e-02, eta: 19:11:03, time: 1.128, data_time: 0.059, memory: 19944, decode.loss_ce: 0.2538, decode.acc_seg: 89.6099, aux_0.loss_ce: 0.2540, aux_0.acc_seg: 89.6297, aux_1.loss_ce: 0.2714, aux_1.acc_seg: 88.8438, aux_2.loss_ce: 0.0976, aux_2.loss_dice: 0.2530, aux_2.acc_seg: 97.2953, aux_3.loss_ce: 0.2630, aux_3.acc_seg: 88.9239, loss: 1.3928
2023-05-18 22:31:30,293 - mmseg - INFO - Saving checkpoint at 1500 iterations
2023-05-18 22:31:34,077 - mmseg - INFO - Iter [1500/60000]	lr: 9.775e-02, eta: 19:14:22, time: 1.312, data_time: 0.168, memory: 19944, decode.loss_ce: 0.2179, decode.acc_seg: 90.7494, aux_0.loss_ce: 0.2173, aux_0.acc_seg: 90.8006, aux_1.loss_ce: 0.2312, aux_1.acc_seg: 90.1769, aux_2.loss_ce: 0.0946, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 97.3508, aux_3.loss_ce: 0.2353, aux_3.acc_seg: 89.9466, loss: 1.2468
2023-05-18 22:32:08,546 - mmseg - INFO - per class results:
2023-05-18 22:32:08,548 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 95.46 | 96.33 |
|    sidewalk   | 70.83 | 85.92 |
|    building   | 85.22 | 94.98 |
|      wall     | 26.14 | 27.87 |
|     fence     | 41.72 | 50.79 |
|      pole     | 32.19 | 40.33 |
| traffic light | 29.83 | 31.99 |
|  traffic sign | 43.68 | 48.45 |
|   vegetation  | 86.13 | 94.48 |
|    terrain    | 50.72 | 59.46 |
|      sky      | 90.54 | 94.06 |
|     person    | 58.28 | 74.42 |
|     rider     | 32.29 | 38.27 |
|      car      | 82.32 |  96.3 |
|     truck     |  0.01 |  0.01 |
|      bus      | 44.14 | 58.42 |
|     train     |  0.23 |  0.23 |
|   motorcycle  | 27.63 | 32.33 |
|    bicycle    | 55.14 | 74.56 |
+---------------+-------+-------+
2023-05-18 22:32:08,548 - mmseg - INFO - Summary:
2023-05-18 22:32:08,548 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 91.46 | 50.13 | 57.85 |
+-------+-------+-------+
2023-05-18 22:32:09,936 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1500.pth.
2023-05-18 22:32:09,936 - mmseg - INFO - Best mIoU is 0.5013 at 1500 iter.
2023-05-18 22:32:09,936 - mmseg - INFO - Iter(val) [500]	aAcc: 0.9146, mIoU: 0.5013, mAcc: 0.5785, IoU.road: 0.9546, IoU.sidewalk: 0.7083, IoU.building: 0.8522, IoU.wall: 0.2614, IoU.fence: 0.4172, IoU.pole: 0.3219, IoU.traffic light: 0.2983, IoU.traffic sign: 0.4368, IoU.vegetation: 0.8613, IoU.terrain: 0.5072, IoU.sky: 0.9054, IoU.person: 0.5828, IoU.rider: 0.3229, IoU.car: 0.8232, IoU.truck: 0.0001, IoU.bus: 0.4414, IoU.train: 0.0023, IoU.motorcycle: 0.2763, IoU.bicycle: 0.5514, Acc.road: 0.9633, Acc.sidewalk: 0.8592, Acc.building: 0.9498, Acc.wall: 0.2787, Acc.fence: 0.5079, Acc.pole: 0.4033, Acc.traffic light: 0.3199, Acc.traffic sign: 0.4845, Acc.vegetation: 0.9448, Acc.terrain: 0.5946, Acc.sky: 0.9406, Acc.person: 0.7442, Acc.rider: 0.3827, Acc.car: 0.9630, Acc.truck: 0.0001, Acc.bus: 0.5842, Acc.train: 0.0023, Acc.motorcycle: 0.3233, Acc.bicycle: 0.7456
2023-05-18 22:33:06,049 - mmseg - INFO - Iter [1550/60000]	lr: 9.767e-02, eta: 19:33:57, time: 1.839, data_time: 0.777, memory: 19944, decode.loss_ce: 0.2028, decode.acc_seg: 91.2310, aux_0.loss_ce: 0.2031, aux_0.acc_seg: 91.3021, aux_1.loss_ce: 0.2215, aux_1.acc_seg: 90.4298, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2500, aux_2.acc_seg: 97.3053, aux_3.loss_ce: 0.2227, aux_3.acc_seg: 90.3054, loss: 1.1960
2023-05-18 22:34:07,527 - mmseg - INFO - Iter [1600/60000]	lr: 9.760e-02, eta: 19:33:42, time: 1.230, data_time: 0.164, memory: 19944, decode.loss_ce: 0.2102, decode.acc_seg: 91.1086, aux_0.loss_ce: 0.2124, aux_0.acc_seg: 91.0578, aux_1.loss_ce: 0.2272, aux_1.acc_seg: 90.3499, aux_2.loss_ce: 0.0957, aux_2.loss_dice: 0.2492, aux_2.acc_seg: 97.2767, aux_3.loss_ce: 0.2310, aux_3.acc_seg: 90.1930, loss: 1.2257
2023-05-18 22:35:03,860 - mmseg - INFO - Iter [1650/60000]	lr: 9.752e-02, eta: 19:30:21, time: 1.127, data_time: 0.060, memory: 19944, decode.loss_ce: 0.2138, decode.acc_seg: 90.8599, aux_0.loss_ce: 0.2135, aux_0.acc_seg: 90.9240, aux_1.loss_ce: 0.2305, aux_1.acc_seg: 90.1395, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 97.3754, aux_3.loss_ce: 0.2360, aux_3.acc_seg: 89.9290, loss: 1.2354
2023-05-18 22:36:00,502 - mmseg - INFO - Iter [1700/60000]	lr: 9.745e-02, eta: 19:27:20, time: 1.133, data_time: 0.061, memory: 19944, decode.loss_ce: 0.2152, decode.acc_seg: 91.0430, aux_0.loss_ce: 0.2141, aux_0.acc_seg: 91.1092, aux_1.loss_ce: 0.2303, aux_1.acc_seg: 90.3544, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 97.3194, aux_3.loss_ce: 0.2287, aux_3.acc_seg: 90.3339, loss: 1.2350
2023-05-18 22:37:01,961 - mmseg - INFO - Iter [1750/60000]	lr: 9.737e-02, eta: 19:27:06, time: 1.229, data_time: 0.161, memory: 19944, decode.loss_ce: 0.2045, decode.acc_seg: 91.3597, aux_0.loss_ce: 0.2050, aux_0.acc_seg: 91.3950, aux_1.loss_ce: 0.2212, aux_1.acc_seg: 90.6670, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2513, aux_2.acc_seg: 97.3193, aux_3.loss_ce: 0.2252, aux_3.acc_seg: 90.4456, loss: 1.2029
2023-05-18 22:37:58,655 - mmseg - INFO - Iter [1800/60000]	lr: 9.730e-02, eta: 19:24:15, time: 1.134, data_time: 0.064, memory: 19944, decode.loss_ce: 0.2073, decode.acc_seg: 91.1706, aux_0.loss_ce: 0.2079, aux_0.acc_seg: 91.1998, aux_1.loss_ce: 0.2229, aux_1.acc_seg: 90.4714, aux_2.loss_ce: 0.0966, aux_2.loss_dice: 0.2509, aux_2.acc_seg: 97.2945, aux_3.loss_ce: 0.2275, aux_3.acc_seg: 90.2448, loss: 1.2131
2023-05-18 22:39:00,311 - mmseg - INFO - Iter [1850/60000]	lr: 9.722e-02, eta: 19:24:07, time: 1.233, data_time: 0.163, memory: 19944, decode.loss_ce: 0.2046, decode.acc_seg: 91.3704, aux_0.loss_ce: 0.2047, aux_0.acc_seg: 91.4013, aux_1.loss_ce: 0.2197, aux_1.acc_seg: 90.6923, aux_2.loss_ce: 0.0926, aux_2.loss_dice: 0.2468, aux_2.acc_seg: 97.4049, aux_3.loss_ce: 0.2224, aux_3.acc_seg: 90.4493, loss: 1.1910
2023-05-18 22:39:56,474 - mmseg - INFO - Iter [1900/60000]	lr: 9.715e-02, eta: 19:21:08, time: 1.123, data_time: 0.057, memory: 19944, decode.loss_ce: 0.2132, decode.acc_seg: 91.2067, aux_0.loss_ce: 0.2127, aux_0.acc_seg: 91.2539, aux_1.loss_ce: 0.2308, aux_1.acc_seg: 90.4206, aux_2.loss_ce: 0.0952, aux_2.loss_dice: 0.2513, aux_2.acc_seg: 97.3354, aux_3.loss_ce: 0.2327, aux_3.acc_seg: 90.3132, loss: 1.2359
2023-05-18 22:40:52,541 - mmseg - INFO - Iter [1950/60000]	lr: 9.707e-02, eta: 19:18:12, time: 1.121, data_time: 0.057, memory: 19944, decode.loss_ce: 0.2108, decode.acc_seg: 91.1467, aux_0.loss_ce: 0.2112, aux_0.acc_seg: 91.1452, aux_1.loss_ce: 0.2280, aux_1.acc_seg: 90.4372, aux_2.loss_ce: 0.0979, aux_2.loss_dice: 0.2517, aux_2.acc_seg: 97.2331, aux_3.loss_ce: 0.2315, aux_3.acc_seg: 90.2321, loss: 1.2311
2023-05-18 22:41:54,017 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-18 22:41:54,017 - mmseg - INFO - Iter [2000/60000]	lr: 9.700e-02, eta: 19:17:59, time: 1.229, data_time: 0.164, memory: 19944, decode.loss_ce: 0.2103, decode.acc_seg: 91.4014, aux_0.loss_ce: 0.2102, aux_0.acc_seg: 91.4063, aux_1.loss_ce: 0.2270, aux_1.acc_seg: 90.6214, aux_2.loss_ce: 0.0952, aux_2.loss_dice: 0.2496, aux_2.acc_seg: 97.3149, aux_3.loss_ce: 0.2283, aux_3.acc_seg: 90.4599, loss: 1.2207
2023-05-18 22:42:50,422 - mmseg - INFO - Iter [2050/60000]	lr: 9.692e-02, eta: 19:15:21, time: 1.128, data_time: 0.061, memory: 19944, decode.loss_ce: 0.2369, decode.acc_seg: 90.1561, aux_0.loss_ce: 0.2359, aux_0.acc_seg: 90.2340, aux_1.loss_ce: 0.2539, aux_1.acc_seg: 89.3958, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 97.3386, aux_3.loss_ce: 0.2388, aux_3.acc_seg: 89.8454, loss: 1.3110
2023-05-18 22:43:51,786 - mmseg - INFO - Iter [2100/60000]	lr: 9.685e-02, eta: 19:15:04, time: 1.227, data_time: 0.163, memory: 19944, decode.loss_ce: 0.2024, decode.acc_seg: 91.6084, aux_0.loss_ce: 0.2033, aux_0.acc_seg: 91.5944, aux_1.loss_ce: 0.2183, aux_1.acc_seg: 90.8423, aux_2.loss_ce: 0.0932, aux_2.loss_dice: 0.2465, aux_2.acc_seg: 97.3530, aux_3.loss_ce: 0.2166, aux_3.acc_seg: 90.7620, loss: 1.1803
2023-05-18 22:44:47,967 - mmseg - INFO - Iter [2150/60000]	lr: 9.677e-02, eta: 19:12:25, time: 1.124, data_time: 0.060, memory: 19944, decode.loss_ce: 0.2012, decode.acc_seg: 91.5672, aux_0.loss_ce: 0.2021, aux_0.acc_seg: 91.5889, aux_1.loss_ce: 0.2167, aux_1.acc_seg: 90.8638, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2485, aux_2.acc_seg: 97.3536, aux_3.loss_ce: 0.2217, aux_3.acc_seg: 90.5683, loss: 1.1838
2023-05-18 22:45:44,343 - mmseg - INFO - Iter [2200/60000]	lr: 9.670e-02, eta: 19:09:56, time: 1.128, data_time: 0.061, memory: 19944, decode.loss_ce: 0.2227, decode.acc_seg: 90.8004, aux_0.loss_ce: 0.2240, aux_0.acc_seg: 90.7762, aux_1.loss_ce: 0.2402, aux_1.acc_seg: 90.0293, aux_2.loss_ce: 0.0963, aux_2.loss_dice: 0.2503, aux_2.acc_seg: 97.2990, aux_3.loss_ce: 0.2418, aux_3.acc_seg: 89.8343, loss: 1.2752
2023-05-18 22:46:45,545 - mmseg - INFO - Iter [2250/60000]	lr: 9.662e-02, eta: 19:09:36, time: 1.224, data_time: 0.160, memory: 19944, decode.loss_ce: 0.1930, decode.acc_seg: 91.6606, aux_0.loss_ce: 0.1923, aux_0.acc_seg: 91.7529, aux_1.loss_ce: 0.2090, aux_1.acc_seg: 90.9992, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 97.3410, aux_3.loss_ce: 0.2130, aux_3.acc_seg: 90.8254, loss: 1.1516
2023-05-18 22:47:41,762 - mmseg - INFO - Iter [2300/60000]	lr: 9.654e-02, eta: 19:07:08, time: 1.124, data_time: 0.060, memory: 19944, decode.loss_ce: 0.2236, decode.acc_seg: 90.9230, aux_0.loss_ce: 0.2237, aux_0.acc_seg: 90.9654, aux_1.loss_ce: 0.2399, aux_1.acc_seg: 90.2234, aux_2.loss_ce: 0.0968, aux_2.loss_dice: 0.2522, aux_2.acc_seg: 97.2713, aux_3.loss_ce: 0.2370, aux_3.acc_seg: 90.2285, loss: 1.2732
2023-05-18 22:48:43,387 - mmseg - INFO - Iter [2350/60000]	lr: 9.647e-02, eta: 19:06:57, time: 1.232, data_time: 0.167, memory: 19944, decode.loss_ce: 0.2117, decode.acc_seg: 91.1395, aux_0.loss_ce: 0.2125, aux_0.acc_seg: 91.1378, aux_1.loss_ce: 0.2281, aux_1.acc_seg: 90.4055, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2508, aux_2.acc_seg: 97.3357, aux_3.loss_ce: 0.2286, aux_3.acc_seg: 90.2843, loss: 1.2268
2023-05-18 22:49:40,291 - mmseg - INFO - Iter [2400/60000]	lr: 9.639e-02, eta: 19:04:50, time: 1.138, data_time: 0.065, memory: 19944, decode.loss_ce: 0.1941, decode.acc_seg: 91.7288, aux_0.loss_ce: 0.1961, aux_0.acc_seg: 91.7915, aux_1.loss_ce: 0.2114, aux_1.acc_seg: 91.0127, aux_2.loss_ce: 0.0969, aux_2.loss_dice: 0.2523, aux_2.acc_seg: 97.2704, aux_3.loss_ce: 0.2148, aux_3.acc_seg: 90.7692, loss: 1.1655
2023-05-18 22:50:36,777 - mmseg - INFO - Iter [2450/60000]	lr: 9.632e-02, eta: 19:02:37, time: 1.130, data_time: 0.062, memory: 19944, decode.loss_ce: 0.1927, decode.acc_seg: 91.7239, aux_0.loss_ce: 0.1939, aux_0.acc_seg: 91.6746, aux_1.loss_ce: 0.2089, aux_1.acc_seg: 90.9899, aux_2.loss_ce: 0.0957, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 97.2779, aux_3.loss_ce: 0.2128, aux_3.acc_seg: 90.8493, loss: 1.1530
2023-05-18 22:51:38,549 - mmseg - INFO - Iter [2500/60000]	lr: 9.624e-02, eta: 19:02:28, time: 1.235, data_time: 0.167, memory: 19944, decode.loss_ce: 0.1928, decode.acc_seg: 91.7447, aux_0.loss_ce: 0.1956, aux_0.acc_seg: 91.7445, aux_1.loss_ce: 0.2105, aux_1.acc_seg: 90.9942, aux_2.loss_ce: 0.0943, aux_2.loss_dice: 0.2470, aux_2.acc_seg: 97.2958, aux_3.loss_ce: 0.2148, aux_3.acc_seg: 90.7246, loss: 1.1550
2023-05-18 22:52:35,030 - mmseg - INFO - Iter [2550/60000]	lr: 9.617e-02, eta: 19:00:18, time: 1.130, data_time: 0.062, memory: 19944, decode.loss_ce: 0.2031, decode.acc_seg: 91.5299, aux_0.loss_ce: 0.2037, aux_0.acc_seg: 91.5021, aux_1.loss_ce: 0.2206, aux_1.acc_seg: 90.6792, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2471, aux_2.acc_seg: 97.3305, aux_3.loss_ce: 0.2199, aux_3.acc_seg: 90.6396, loss: 1.1888
2023-05-18 22:53:36,584 - mmseg - INFO - Iter [2600/60000]	lr: 9.609e-02, eta: 19:00:03, time: 1.231, data_time: 0.163, memory: 19944, decode.loss_ce: 0.1908, decode.acc_seg: 92.1435, aux_0.loss_ce: 0.1922, aux_0.acc_seg: 92.1451, aux_1.loss_ce: 0.2099, aux_1.acc_seg: 91.3557, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 97.2772, aux_3.loss_ce: 0.2120, aux_3.acc_seg: 91.1387, loss: 1.1502
2023-05-18 22:54:32,861 - mmseg - INFO - Iter [2650/60000]	lr: 9.602e-02, eta: 18:57:52, time: 1.126, data_time: 0.060, memory: 19944, decode.loss_ce: 0.2001, decode.acc_seg: 91.5042, aux_0.loss_ce: 0.2000, aux_0.acc_seg: 91.5607, aux_1.loss_ce: 0.2159, aux_1.acc_seg: 90.8559, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2497, aux_2.acc_seg: 97.3237, aux_3.loss_ce: 0.2212, aux_3.acc_seg: 90.5040, loss: 1.1817
2023-05-18 22:55:29,019 - mmseg - INFO - Iter [2700/60000]	lr: 9.594e-02, eta: 18:55:41, time: 1.123, data_time: 0.057, memory: 19944, decode.loss_ce: 0.1901, decode.acc_seg: 91.6217, aux_0.loss_ce: 0.1912, aux_0.acc_seg: 91.6281, aux_1.loss_ce: 0.2075, aux_1.acc_seg: 90.8879, aux_2.loss_ce: 0.0932, aux_2.loss_dice: 0.2454, aux_2.acc_seg: 97.3595, aux_3.loss_ce: 0.2117, aux_3.acc_seg: 90.6811, loss: 1.1391
2023-05-18 22:56:30,520 - mmseg - INFO - Iter [2750/60000]	lr: 9.587e-02, eta: 18:55:24, time: 1.230, data_time: 0.163, memory: 19944, decode.loss_ce: 0.1753, decode.acc_seg: 92.4003, aux_0.loss_ce: 0.1762, aux_0.acc_seg: 92.4463, aux_1.loss_ce: 0.1917, aux_1.acc_seg: 91.7374, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 97.2886, aux_3.loss_ce: 0.1993, aux_3.acc_seg: 91.3982, loss: 1.0848
2023-05-18 22:57:27,435 - mmseg - INFO - Iter [2800/60000]	lr: 9.579e-02, eta: 18:53:32, time: 1.138, data_time: 0.064, memory: 19944, decode.loss_ce: 0.2093, decode.acc_seg: 91.0790, aux_0.loss_ce: 0.2087, aux_0.acc_seg: 91.1459, aux_1.loss_ce: 0.2269, aux_1.acc_seg: 90.3509, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2491, aux_2.acc_seg: 97.2789, aux_3.loss_ce: 0.2239, aux_3.acc_seg: 90.4361, loss: 1.2139
2023-05-18 22:58:28,860 - mmseg - INFO - Iter [2850/60000]	lr: 9.572e-02, eta: 18:53:12, time: 1.228, data_time: 0.160, memory: 19944, decode.loss_ce: 0.1882, decode.acc_seg: 91.8613, aux_0.loss_ce: 0.1891, aux_0.acc_seg: 91.8542, aux_1.loss_ce: 0.2053, aux_1.acc_seg: 91.1270, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2472, aux_2.acc_seg: 97.3114, aux_3.loss_ce: 0.2113, aux_3.acc_seg: 90.8247, loss: 1.1360
2023-05-18 22:59:25,151 - mmseg - INFO - Iter [2900/60000]	lr: 9.564e-02, eta: 18:51:09, time: 1.126, data_time: 0.060, memory: 19944, decode.loss_ce: 0.1869, decode.acc_seg: 92.1078, aux_0.loss_ce: 0.1871, aux_0.acc_seg: 92.1443, aux_1.loss_ce: 0.2027, aux_1.acc_seg: 91.4951, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2506, aux_2.acc_seg: 97.2986, aux_3.loss_ce: 0.2053, aux_3.acc_seg: 91.3602, loss: 1.1276
2023-05-18 23:00:21,524 - mmseg - INFO - Iter [2950/60000]	lr: 9.557e-02, eta: 18:49:11, time: 1.127, data_time: 0.062, memory: 19944, decode.loss_ce: 0.2048, decode.acc_seg: 91.3744, aux_0.loss_ce: 0.2046, aux_0.acc_seg: 91.4708, aux_1.loss_ce: 0.2205, aux_1.acc_seg: 90.7335, aux_2.loss_ce: 0.0964, aux_2.loss_dice: 0.2501, aux_2.acc_seg: 97.2694, aux_3.loss_ce: 0.2222, aux_3.acc_seg: 90.6319, loss: 1.1986
2023-05-18 23:01:23,169 - mmseg - INFO - Saving checkpoint at 3000 iterations
2023-05-18 23:01:27,919 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-18 23:01:27,920 - mmseg - INFO - Iter [3000/60000]	lr: 9.549e-02, eta: 18:50:25, time: 1.329, data_time: 0.167, memory: 19944, decode.loss_ce: 0.1987, decode.acc_seg: 91.5275, aux_0.loss_ce: 0.1983, aux_0.acc_seg: 91.5324, aux_1.loss_ce: 0.2141, aux_1.acc_seg: 90.7636, aux_2.loss_ce: 0.0961, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 97.2658, aux_3.loss_ce: 0.2191, aux_3.acc_seg: 90.5698, loss: 1.1745
2023-05-18 23:02:12,313 - mmseg - INFO - per class results:
2023-05-18 23:02:12,315 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 96.61 | 98.71 |
|    sidewalk   | 74.51 | 85.15 |
|    building   | 86.56 | 94.95 |
|      wall     |  29.4 | 36.77 |
|     fence     | 45.73 | 57.25 |
|      pole     | 31.82 | 37.96 |
| traffic light | 42.51 | 54.76 |
|  traffic sign | 53.28 | 63.21 |
|   vegetation  | 86.63 | 93.47 |
|    terrain    | 51.68 | 59.27 |
|      sky      | 90.78 | 94.44 |
|     person    | 62.33 | 73.83 |
|     rider     | 43.01 | 56.21 |
|      car      | 88.89 | 94.69 |
|     truck     | 58.42 | 71.54 |
|      bus      | 61.22 | 76.19 |
|     train     |  21.4 | 25.93 |
|   motorcycle  | 37.69 | 44.38 |
|    bicycle    | 60.74 | 79.65 |
+---------------+-------+-------+
2023-05-18 23:02:12,315 - mmseg - INFO - Summary:
2023-05-18 23:02:12,315 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 92.65 | 59.12 | 68.34 |
+-------+-------+-------+
2023-05-18 23:02:12,354 - mmseg - INFO - The previous best checkpoint /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16/best_mIoU_iter_1500.pth was removed
2023-05-18 23:02:14,003 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_3000.pth.
2023-05-18 23:02:14,004 - mmseg - INFO - Best mIoU is 0.5912 at 3000 iter.
2023-05-18 23:02:14,004 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-18 23:02:14,004 - mmseg - INFO - Iter(val) [500]	aAcc: 0.9265, mIoU: 0.5912, mAcc: 0.6834, IoU.road: 0.9661, IoU.sidewalk: 0.7451, IoU.building: 0.8656, IoU.wall: 0.2940, IoU.fence: 0.4573, IoU.pole: 0.3182, IoU.traffic light: 0.4251, IoU.traffic sign: 0.5328, IoU.vegetation: 0.8663, IoU.terrain: 0.5168, IoU.sky: 0.9078, IoU.person: 0.6233, IoU.rider: 0.4301, IoU.car: 0.8889, IoU.truck: 0.5842, IoU.bus: 0.6122, IoU.train: 0.2140, IoU.motorcycle: 0.3769, IoU.bicycle: 0.6074, Acc.road: 0.9871, Acc.sidewalk: 0.8515, Acc.building: 0.9495, Acc.wall: 0.3677, Acc.fence: 0.5725, Acc.pole: 0.3796, Acc.traffic light: 0.5476, Acc.traffic sign: 0.6321, Acc.vegetation: 0.9347, Acc.terrain: 0.5927, Acc.sky: 0.9444, Acc.person: 0.7383, Acc.rider: 0.5621, Acc.car: 0.9469, Acc.truck: 0.7154, Acc.bus: 0.7619, Acc.train: 0.2593, Acc.motorcycle: 0.4438, Acc.bicycle: 0.7965
2023-05-18 23:03:10,995 - mmseg - INFO - Iter [3050/60000]	lr: 9.541e-02, eta: 19:02:59, time: 2.061, data_time: 0.988, memory: 19944, decode.loss_ce: 0.1863, decode.acc_seg: 92.1835, aux_0.loss_ce: 0.1854, aux_0.acc_seg: 92.2115, aux_1.loss_ce: 0.2014, aux_1.acc_seg: 91.4832, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 97.3401, aux_3.loss_ce: 0.2075, aux_3.acc_seg: 91.1233, loss: 1.1214
2023-05-18 23:04:12,725 - mmseg - INFO - Iter [3100/60000]	lr: 9.534e-02, eta: 19:02:27, time: 1.235, data_time: 0.168, memory: 19944, decode.loss_ce: 0.2194, decode.acc_seg: 91.0867, aux_0.loss_ce: 0.2173, aux_0.acc_seg: 91.2208, aux_1.loss_ce: 0.2335, aux_1.acc_seg: 90.4425, aux_2.loss_ce: 0.0967, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 97.2674, aux_3.loss_ce: 0.2281, aux_3.acc_seg: 90.4184, loss: 1.2452
2023-05-18 23:05:09,428 - mmseg - INFO - Iter [3150/60000]	lr: 9.526e-02, eta: 19:00:23, time: 1.134, data_time: 0.062, memory: 19944, decode.loss_ce: 0.1895, decode.acc_seg: 92.0573, aux_0.loss_ce: 0.1888, aux_0.acc_seg: 92.0959, aux_1.loss_ce: 0.2027, aux_1.acc_seg: 91.4347, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2474, aux_2.acc_seg: 97.3122, aux_3.loss_ce: 0.2072, aux_3.acc_seg: 91.2102, loss: 1.1295
2023-05-18 23:06:11,076 - mmseg - INFO - Iter [3200/60000]	lr: 9.519e-02, eta: 18:59:48, time: 1.233, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1924, decode.acc_seg: 91.7851, aux_0.loss_ce: 0.1928, aux_0.acc_seg: 91.8326, aux_1.loss_ce: 0.2068, aux_1.acc_seg: 91.1912, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 97.2829, aux_3.loss_ce: 0.2147, aux_3.acc_seg: 90.8457, loss: 1.1492
2023-05-18 23:07:07,685 - mmseg - INFO - Iter [3250/60000]	lr: 9.511e-02, eta: 18:57:45, time: 1.132, data_time: 0.064, memory: 19944, decode.loss_ce: 0.1927, decode.acc_seg: 91.7660, aux_0.loss_ce: 0.1922, aux_0.acc_seg: 91.8704, aux_1.loss_ce: 0.2078, aux_1.acc_seg: 91.1039, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 97.3031, aux_3.loss_ce: 0.2064, aux_3.acc_seg: 91.1019, loss: 1.1393
2023-05-18 23:08:04,058 - mmseg - INFO - Iter [3300/60000]	lr: 9.504e-02, eta: 18:55:40, time: 1.127, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1833, decode.acc_seg: 92.1967, aux_0.loss_ce: 0.1825, aux_0.acc_seg: 92.2723, aux_1.loss_ce: 0.2006, aux_1.acc_seg: 91.4675, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2471, aux_2.acc_seg: 97.3165, aux_3.loss_ce: 0.2026, aux_3.acc_seg: 91.2764, loss: 1.1102
2023-05-18 23:09:05,752 - mmseg - INFO - Iter [3350/60000]	lr: 9.496e-02, eta: 18:55:07, time: 1.234, data_time: 0.164, memory: 19944, decode.loss_ce: 0.1791, decode.acc_seg: 92.2011, aux_0.loss_ce: 0.1795, aux_0.acc_seg: 92.2521, aux_1.loss_ce: 0.1962, aux_1.acc_seg: 91.4459, aux_2.loss_ce: 0.0950, aux_2.loss_dice: 0.2465, aux_2.acc_seg: 97.2541, aux_3.loss_ce: 0.2020, aux_3.acc_seg: 91.2087, loss: 1.0984
2023-05-18 23:10:02,228 - mmseg - INFO - Iter [3400/60000]	lr: 9.489e-02, eta: 18:53:07, time: 1.130, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1818, decode.acc_seg: 92.3880, aux_0.loss_ce: 0.1816, aux_0.acc_seg: 92.4265, aux_1.loss_ce: 0.1961, aux_1.acc_seg: 91.7679, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2458, aux_2.acc_seg: 97.3080, aux_3.loss_ce: 0.2039, aux_3.acc_seg: 91.2347, loss: 1.1024
2023-05-18 23:11:04,055 - mmseg - INFO - Iter [3450/60000]	lr: 9.481e-02, eta: 18:52:36, time: 1.237, data_time: 0.169, memory: 19944, decode.loss_ce: 0.1816, decode.acc_seg: 92.2405, aux_0.loss_ce: 0.1815, aux_0.acc_seg: 92.2865, aux_1.loss_ce: 0.1982, aux_1.acc_seg: 91.5238, aux_2.loss_ce: 0.0957, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 97.2536, aux_3.loss_ce: 0.2024, aux_3.acc_seg: 91.3109, loss: 1.1081
2023-05-18 23:12:00,807 - mmseg - INFO - Iter [3500/60000]	lr: 9.474e-02, eta: 18:50:42, time: 1.135, data_time: 0.063, memory: 19944, decode.loss_ce: 0.1790, decode.acc_seg: 92.2732, aux_0.loss_ce: 0.1795, aux_0.acc_seg: 92.3145, aux_1.loss_ce: 0.1963, aux_1.acc_seg: 91.5090, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2468, aux_2.acc_seg: 97.2591, aux_3.loss_ce: 0.2046, aux_3.acc_seg: 91.1432, loss: 1.1013
2023-05-18 23:12:57,504 - mmseg - INFO - Iter [3550/60000]	lr: 9.466e-02, eta: 18:48:49, time: 1.134, data_time: 0.065, memory: 19944, decode.loss_ce: 0.1778, decode.acc_seg: 92.2104, aux_0.loss_ce: 0.1775, aux_0.acc_seg: 92.3203, aux_1.loss_ce: 0.1929, aux_1.acc_seg: 91.5840, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2451, aux_2.acc_seg: 97.2932, aux_3.loss_ce: 0.1999, aux_3.acc_seg: 91.2156, loss: 1.0872
2023-05-18 23:13:59,574 - mmseg - INFO - Iter [3600/60000]	lr: 9.458e-02, eta: 18:48:21, time: 1.241, data_time: 0.170, memory: 19944, decode.loss_ce: 0.1785, decode.acc_seg: 92.3433, aux_0.loss_ce: 0.1796, aux_0.acc_seg: 92.3414, aux_1.loss_ce: 0.1956, aux_1.acc_seg: 91.6210, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 97.3124, aux_3.loss_ce: 0.2031, aux_3.acc_seg: 91.1883, loss: 1.0968
2023-05-18 23:14:56,329 - mmseg - INFO - Iter [3650/60000]	lr: 9.451e-02, eta: 18:46:31, time: 1.135, data_time: 0.066, memory: 19944, decode.loss_ce: 0.1918, decode.acc_seg: 91.8508, aux_0.loss_ce: 0.1921, aux_0.acc_seg: 91.9405, aux_1.loss_ce: 0.2090, aux_1.acc_seg: 91.1144, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2477, aux_2.acc_seg: 97.3078, aux_3.loss_ce: 0.2085, aux_3.acc_seg: 91.0142, loss: 1.1440
2023-05-18 23:15:57,983 - mmseg - INFO - Iter [3700/60000]	lr: 9.443e-02, eta: 18:45:56, time: 1.233, data_time: 0.165, memory: 19944, decode.loss_ce: 0.1863, decode.acc_seg: 91.9542, aux_0.loss_ce: 0.1863, aux_0.acc_seg: 92.0009, aux_1.loss_ce: 0.2023, aux_1.acc_seg: 91.2316, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2463, aux_2.acc_seg: 97.3040, aux_3.loss_ce: 0.2033, aux_3.acc_seg: 91.1840, loss: 1.1185
2023-05-18 23:16:54,302 - mmseg - INFO - Iter [3750/60000]	lr: 9.436e-02, eta: 18:44:01, time: 1.126, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1796, decode.acc_seg: 92.3153, aux_0.loss_ce: 0.1797, aux_0.acc_seg: 92.3832, aux_1.loss_ce: 0.1951, aux_1.acc_seg: 91.6756, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2459, aux_2.acc_seg: 97.3038, aux_3.loss_ce: 0.2025, aux_3.acc_seg: 91.3112, loss: 1.0967
2023-05-18 23:17:50,955 - mmseg - INFO - Iter [3800/60000]	lr: 9.428e-02, eta: 18:42:13, time: 1.133, data_time: 0.065, memory: 19944, decode.loss_ce: 0.1703, decode.acc_seg: 92.6427, aux_0.loss_ce: 0.1707, aux_0.acc_seg: 92.6757, aux_1.loss_ce: 0.1862, aux_1.acc_seg: 91.9906, aux_2.loss_ce: 0.0929, aux_2.loss_dice: 0.2457, aux_2.acc_seg: 97.3190, aux_3.loss_ce: 0.1962, aux_3.acc_seg: 91.4729, loss: 1.0620
2023-05-18 23:18:52,848 - mmseg - INFO - Iter [3850/60000]	lr: 9.421e-02, eta: 18:41:42, time: 1.238, data_time: 0.170, memory: 19944, decode.loss_ce: 0.1903, decode.acc_seg: 91.9530, aux_0.loss_ce: 0.1898, aux_0.acc_seg: 92.0138, aux_1.loss_ce: 0.2043, aux_1.acc_seg: 91.3035, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 97.2692, aux_3.loss_ce: 0.2100, aux_3.acc_seg: 90.9876, loss: 1.1390
2023-05-18 23:19:49,149 - mmseg - INFO - Iter [3900/60000]	lr: 9.413e-02, eta: 18:39:49, time: 1.126, data_time: 0.060, memory: 19944, decode.loss_ce: 0.1885, decode.acc_seg: 91.9765, aux_0.loss_ce: 0.1888, aux_0.acc_seg: 92.0359, aux_1.loss_ce: 0.2033, aux_1.acc_seg: 91.3257, aux_2.loss_ce: 0.0934, aux_2.loss_dice: 0.2458, aux_2.acc_seg: 97.3130, aux_3.loss_ce: 0.2032, aux_3.acc_seg: 91.2171, loss: 1.1230
2023-05-18 23:20:51,395 - mmseg - INFO - Iter [3950/60000]	lr: 9.406e-02, eta: 18:39:23, time: 1.245, data_time: 0.174, memory: 19944, decode.loss_ce: 0.1681, decode.acc_seg: 92.8132, aux_0.loss_ce: 0.1679, aux_0.acc_seg: 92.8681, aux_1.loss_ce: 0.1854, aux_1.acc_seg: 92.0720, aux_2.loss_ce: 0.0956, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 97.2342, aux_3.loss_ce: 0.1941, aux_3.acc_seg: 91.6617, loss: 1.0593
2023-05-18 23:21:48,235 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-18 23:21:48,235 - mmseg - INFO - Iter [4000/60000]	lr: 9.398e-02, eta: 18:37:40, time: 1.137, data_time: 0.067, memory: 19944, decode.loss_ce: 0.1657, decode.acc_seg: 92.8219, aux_0.loss_ce: 0.1656, aux_0.acc_seg: 92.8993, aux_1.loss_ce: 0.1814, aux_1.acc_seg: 92.1311, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2464, aux_2.acc_seg: 97.3043, aux_3.loss_ce: 0.1905, aux_3.acc_seg: 91.7245, loss: 1.0435
2023-05-18 23:22:44,351 - mmseg - INFO - Iter [4050/60000]	lr: 9.391e-02, eta: 18:35:48, time: 1.122, data_time: 0.058, memory: 19944, decode.loss_ce: 0.1723, decode.acc_seg: 92.4576, aux_0.loss_ce: 0.1723, aux_0.acc_seg: 92.5200, aux_1.loss_ce: 0.1872, aux_1.acc_seg: 91.7876, aux_2.loss_ce: 0.0921, aux_2.loss_dice: 0.2430, aux_2.acc_seg: 97.3629, aux_3.loss_ce: 0.1951, aux_3.acc_seg: 91.4539, loss: 1.0620
2023-05-18 23:23:46,455 - mmseg - INFO - Iter [4100/60000]	lr: 9.383e-02, eta: 18:35:19, time: 1.242, data_time: 0.171, memory: 19944, decode.loss_ce: 0.1773, decode.acc_seg: 92.2957, aux_0.loss_ce: 0.1760, aux_0.acc_seg: 92.3944, aux_1.loss_ce: 0.1918, aux_1.acc_seg: 91.6044, aux_2.loss_ce: 0.0928, aux_2.loss_dice: 0.2446, aux_2.acc_seg: 97.3239, aux_3.loss_ce: 0.1972, aux_3.acc_seg: 91.3828, loss: 1.0798
2023-05-18 23:24:42,625 - mmseg - INFO - Iter [4150/60000]	lr: 9.375e-02, eta: 18:33:30, time: 1.123, data_time: 0.059, memory: 19944, decode.loss_ce: 0.1718, decode.acc_seg: 92.5503, aux_0.loss_ce: 0.1729, aux_0.acc_seg: 92.5891, aux_1.loss_ce: 0.1870, aux_1.acc_seg: 91.9027, aux_2.loss_ce: 0.0929, aux_2.loss_dice: 0.2438, aux_2.acc_seg: 97.3488, aux_3.loss_ce: 0.1948, aux_3.acc_seg: 91.4608, loss: 1.0632
2023-05-18 23:25:44,667 - mmseg - INFO - Iter [4200/60000]	lr: 9.368e-02, eta: 18:33:00, time: 1.241, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1692, decode.acc_seg: 92.7853, aux_0.loss_ce: 0.1701, aux_0.acc_seg: 92.8326, aux_1.loss_ce: 0.1856, aux_1.acc_seg: 92.0636, aux_2.loss_ce: 0.0945, aux_2.loss_dice: 0.2487, aux_2.acc_seg: 97.3076, aux_3.loss_ce: 0.1945, aux_3.acc_seg: 91.6229, loss: 1.0626
2023-05-18 23:26:41,283 - mmseg - INFO - Iter [4250/60000]	lr: 9.360e-02, eta: 18:31:18, time: 1.132, data_time: 0.063, memory: 19944, decode.loss_ce: 0.1767, decode.acc_seg: 92.5748, aux_0.loss_ce: 0.1775, aux_0.acc_seg: 92.6304, aux_1.loss_ce: 0.1936, aux_1.acc_seg: 91.8501, aux_2.loss_ce: 0.0948, aux_2.loss_dice: 0.2468, aux_2.acc_seg: 97.2922, aux_3.loss_ce: 0.1970, aux_3.acc_seg: 91.5996, loss: 1.0864
2023-05-18 23:27:37,937 - mmseg - INFO - Iter [4300/60000]	lr: 9.353e-02, eta: 18:29:37, time: 1.133, data_time: 0.062, memory: 19944, decode.loss_ce: 0.1732, decode.acc_seg: 92.5801, aux_0.loss_ce: 0.1728, aux_0.acc_seg: 92.6397, aux_1.loss_ce: 0.1887, aux_1.acc_seg: 91.8925, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2456, aux_2.acc_seg: 97.3117, aux_3.loss_ce: 0.1948, aux_3.acc_seg: 91.5329, loss: 1.0689
2023-05-18 23:28:39,570 - mmseg - INFO - Iter [4350/60000]	lr: 9.345e-02, eta: 18:29:01, time: 1.233, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1680, decode.acc_seg: 92.5984, aux_0.loss_ce: 0.1684, aux_0.acc_seg: 92.6231, aux_1.loss_ce: 0.1823, aux_1.acc_seg: 91.9355, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2436, aux_2.acc_seg: 97.2958, aux_3.loss_ce: 0.1903, aux_3.acc_seg: 91.6084, loss: 1.0461
2023-05-18 23:29:35,835 - mmseg - INFO - Iter [4400/60000]	lr: 9.338e-02, eta: 18:27:17, time: 1.125, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1791, decode.acc_seg: 92.2343, aux_0.loss_ce: 0.1793, aux_0.acc_seg: 92.3174, aux_1.loss_ce: 0.1951, aux_1.acc_seg: 91.5139, aux_2.loss_ce: 0.0916, aux_2.loss_dice: 0.2460, aux_2.acc_seg: 97.4044, aux_3.loss_ce: 0.1975, aux_3.acc_seg: 91.3637, loss: 1.0885
2023-05-18 23:30:37,382 - mmseg - INFO - Iter [4450/60000]	lr: 9.330e-02, eta: 18:26:40, time: 1.231, data_time: 0.164, memory: 19944, decode.loss_ce: 0.1729, decode.acc_seg: 92.5725, aux_0.loss_ce: 0.1725, aux_0.acc_seg: 92.6497, aux_1.loss_ce: 0.1875, aux_1.acc_seg: 91.8868, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2446, aux_2.acc_seg: 97.3343, aux_3.loss_ce: 0.1940, aux_3.acc_seg: 91.5408, loss: 1.0647
2023-05-18 23:31:33,894 - mmseg - INFO - Saving checkpoint at 4500 iterations
2023-05-18 23:31:38,879 - mmseg - INFO - Iter [4500/60000]	lr: 9.323e-02, eta: 18:26:02, time: 1.231, data_time: 0.063, memory: 19944, decode.loss_ce: 0.1658, decode.acc_seg: 92.7650, aux_0.loss_ce: 0.1651, aux_0.acc_seg: 92.8434, aux_1.loss_ce: 0.1790, aux_1.acc_seg: 92.1163, aux_2.loss_ce: 0.0920, aux_2.loss_dice: 0.2426, aux_2.acc_seg: 97.3455, aux_3.loss_ce: 0.1863, aux_3.acc_seg: 91.7885, loss: 1.0308
2023-05-18 23:32:19,873 - mmseg - INFO - per class results:
2023-05-18 23:32:19,874 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     |  96.8 | 98.26 |
|    sidewalk   | 75.57 | 87.66 |
|    building   | 87.49 | 92.89 |
|      wall     | 45.57 | 68.99 |
|     fence     | 45.06 | 62.32 |
|      pole     | 39.89 | 54.43 |
| traffic light | 43.69 | 64.91 |
|  traffic sign | 57.46 | 63.98 |
|   vegetation  | 88.35 | 94.97 |
|    terrain    | 55.87 | 67.12 |
|      sky      | 90.85 | 96.89 |
|     person    | 65.31 | 78.02 |
|     rider     | 43.59 | 57.39 |
|      car      | 89.51 | 94.24 |
|     truck     | 49.27 | 55.87 |
|      bus      | 60.61 | 85.13 |
|     train     |  30.0 | 37.99 |
|   motorcycle  |  0.5  |  0.5  |
|    bicycle    | 60.37 | 74.03 |
+---------------+-------+-------+
2023-05-18 23:32:19,875 - mmseg - INFO - Summary:
2023-05-18 23:32:19,875 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.07 | 59.25 | 70.29 |
+-------+-------+-------+
2023-05-18 23:32:19,959 - mmseg - INFO - The previous best checkpoint /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16/best_mIoU_iter_3000.pth was removed
2023-05-18 23:32:21,272 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_4500.pth.
2023-05-18 23:32:21,273 - mmseg - INFO - Best mIoU is 0.5925 at 4500 iter.
2023-05-18 23:32:21,273 - mmseg - INFO - Iter(val) [500]	aAcc: 0.9307, mIoU: 0.5925, mAcc: 0.7029, IoU.road: 0.9680, IoU.sidewalk: 0.7557, IoU.building: 0.8749, IoU.wall: 0.4557, IoU.fence: 0.4506, IoU.pole: 0.3989, IoU.traffic light: 0.4369, IoU.traffic sign: 0.5746, IoU.vegetation: 0.8835, IoU.terrain: 0.5587, IoU.sky: 0.9085, IoU.person: 0.6531, IoU.rider: 0.4359, IoU.car: 0.8951, IoU.truck: 0.4927, IoU.bus: 0.6061, IoU.train: 0.3000, IoU.motorcycle: 0.0050, IoU.bicycle: 0.6037, Acc.road: 0.9826, Acc.sidewalk: 0.8766, Acc.building: 0.9289, Acc.wall: 0.6899, Acc.fence: 0.6232, Acc.pole: 0.5443, Acc.traffic light: 0.6491, Acc.traffic sign: 0.6398, Acc.vegetation: 0.9497, Acc.terrain: 0.6712, Acc.sky: 0.9689, Acc.person: 0.7802, Acc.rider: 0.5739, Acc.car: 0.9424, Acc.truck: 0.5587, Acc.bus: 0.8513, Acc.train: 0.3799, Acc.motorcycle: 0.0050, Acc.bicycle: 0.7403
2023-05-18 23:33:17,136 - mmseg - INFO - Iter [4550/60000]	lr: 9.315e-02, eta: 18:32:50, time: 1.964, data_time: 0.903, memory: 19944, decode.loss_ce: 0.1773, decode.acc_seg: 92.4751, aux_0.loss_ce: 0.1769, aux_0.acc_seg: 92.5362, aux_1.loss_ce: 0.1925, aux_1.acc_seg: 91.8241, aux_2.loss_ce: 0.0938, aux_2.loss_dice: 0.2467, aux_2.acc_seg: 97.3089, aux_3.loss_ce: 0.1981, aux_3.acc_seg: 91.5132, loss: 1.0854
2023-05-18 23:34:18,610 - mmseg - INFO - Iter [4600/60000]	lr: 9.307e-02, eta: 18:32:05, time: 1.229, data_time: 0.161, memory: 19944, decode.loss_ce: 0.1578, decode.acc_seg: 93.0504, aux_0.loss_ce: 0.1582, aux_0.acc_seg: 93.0697, aux_1.loss_ce: 0.1751, aux_1.acc_seg: 92.2691, aux_2.loss_ce: 0.0922, aux_2.loss_dice: 0.2423, aux_2.acc_seg: 97.3205, aux_3.loss_ce: 0.1824, aux_3.acc_seg: 91.8745, loss: 1.0080
2023-05-18 23:35:15,206 - mmseg - INFO - Iter [4650/60000]	lr: 9.300e-02, eta: 18:30:22, time: 1.132, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1739, decode.acc_seg: 92.5028, aux_0.loss_ce: 0.1730, aux_0.acc_seg: 92.5699, aux_1.loss_ce: 0.1895, aux_1.acc_seg: 91.8026, aux_2.loss_ce: 0.0930, aux_2.loss_dice: 0.2440, aux_2.acc_seg: 97.3065, aux_3.loss_ce: 0.1959, aux_3.acc_seg: 91.4420, loss: 1.0693
2023-05-18 23:36:17,492 - mmseg - INFO - Iter [4700/60000]	lr: 9.292e-02, eta: 18:29:46, time: 1.246, data_time: 0.173, memory: 19944, decode.loss_ce: 0.1675, decode.acc_seg: 92.7390, aux_0.loss_ce: 0.1671, aux_0.acc_seg: 92.8224, aux_1.loss_ce: 0.1835, aux_1.acc_seg: 92.0879, aux_2.loss_ce: 0.0930, aux_2.loss_dice: 0.2450, aux_2.acc_seg: 97.3298, aux_3.loss_ce: 0.1894, aux_3.acc_seg: 91.6814, loss: 1.0455
2023-05-18 23:37:14,174 - mmseg - INFO - Iter [4750/60000]	lr: 9.285e-02, eta: 18:28:05, time: 1.134, data_time: 0.066, memory: 19944, decode.loss_ce: 0.1572, decode.acc_seg: 93.0944, aux_0.loss_ce: 0.1574, aux_0.acc_seg: 93.1474, aux_1.loss_ce: 0.1723, aux_1.acc_seg: 92.4108, aux_2.loss_ce: 0.0926, aux_2.loss_dice: 0.2436, aux_2.acc_seg: 97.3336, aux_3.loss_ce: 0.1813, aux_3.acc_seg: 92.0109, loss: 1.0044
2023-05-18 23:38:15,435 - mmseg - INFO - Iter [4800/60000]	lr: 9.277e-02, eta: 18:27:18, time: 1.225, data_time: 0.160, memory: 19944, decode.loss_ce: 0.1724, decode.acc_seg: 92.5603, aux_0.loss_ce: 0.1729, aux_0.acc_seg: 92.6020, aux_1.loss_ce: 0.1873, aux_1.acc_seg: 91.8803, aux_2.loss_ce: 0.0946, aux_2.loss_dice: 0.2447, aux_2.acc_seg: 97.2548, aux_3.loss_ce: 0.1941, aux_3.acc_seg: 91.5154, loss: 1.0659
2023-05-18 23:39:11,816 - mmseg - INFO - Iter [4850/60000]	lr: 9.270e-02, eta: 18:25:34, time: 1.128, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1726, decode.acc_seg: 92.4591, aux_0.loss_ce: 0.1721, aux_0.acc_seg: 92.5261, aux_1.loss_ce: 0.1888, aux_1.acc_seg: 91.7507, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 97.2898, aux_3.loss_ce: 0.1941, aux_3.acc_seg: 91.4608, loss: 1.0704
2023-05-18 23:40:08,317 - mmseg - INFO - Iter [4900/60000]	lr: 9.262e-02, eta: 18:23:53, time: 1.130, data_time: 0.063, memory: 19944, decode.loss_ce: 0.1614, decode.acc_seg: 93.0429, aux_0.loss_ce: 0.1610, aux_0.acc_seg: 93.0922, aux_1.loss_ce: 0.1763, aux_1.acc_seg: 92.4107, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2460, aux_2.acc_seg: 97.3083, aux_3.loss_ce: 0.1879, aux_3.acc_seg: 91.8921, loss: 1.0264
2023-05-18 23:41:10,095 - mmseg - INFO - Iter [4950/60000]	lr: 9.254e-02, eta: 18:23:12, time: 1.236, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1777, decode.acc_seg: 92.4020, aux_0.loss_ce: 0.1773, aux_0.acc_seg: 92.4524, aux_1.loss_ce: 0.1924, aux_1.acc_seg: 91.7309, aux_2.loss_ce: 0.0912, aux_2.loss_dice: 0.2430, aux_2.acc_seg: 97.3611, aux_3.loss_ce: 0.1947, aux_3.acc_seg: 91.5081, loss: 1.0763
2023-05-18 23:42:06,742 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-18 23:42:06,742 - mmseg - INFO - Iter [5000/60000]	lr: 9.247e-02, eta: 18:21:33, time: 1.133, data_time: 0.064, memory: 19944, decode.loss_ce: 0.1787, decode.acc_seg: 92.3242, aux_0.loss_ce: 0.1789, aux_0.acc_seg: 92.3842, aux_1.loss_ce: 0.1934, aux_1.acc_seg: 91.6814, aux_2.loss_ce: 0.0931, aux_2.loss_dice: 0.2448, aux_2.acc_seg: 97.3148, aux_3.loss_ce: 0.1966, aux_3.acc_seg: 91.4186, loss: 1.0856
2023-05-18 23:43:08,329 - mmseg - INFO - Iter [5050/60000]	lr: 9.239e-02, eta: 18:20:50, time: 1.232, data_time: 0.165, memory: 19944, decode.loss_ce: 0.2059, decode.acc_seg: 91.4019, aux_0.loss_ce: 0.2061, aux_0.acc_seg: 91.4708, aux_1.loss_ce: 0.2196, aux_1.acc_seg: 90.7990, aux_2.loss_ce: 0.0966, aux_2.loss_dice: 0.2502, aux_2.acc_seg: 97.2735, aux_3.loss_ce: 0.2190, aux_3.acc_seg: 90.6820, loss: 1.1974
2023-05-18 23:44:05,209 - mmseg - INFO - Iter [5100/60000]	lr: 9.232e-02, eta: 18:19:15, time: 1.138, data_time: 0.064, memory: 19944, decode.loss_ce: 0.1941, decode.acc_seg: 91.7396, aux_0.loss_ce: 0.1932, aux_0.acc_seg: 91.8205, aux_1.loss_ce: 0.2093, aux_1.acc_seg: 91.0323, aux_2.loss_ce: 0.0960, aux_2.loss_dice: 0.2478, aux_2.acc_seg: 97.2590, aux_3.loss_ce: 0.2102, aux_3.acc_seg: 90.8903, loss: 1.1506
2023-05-18 23:45:01,564 - mmseg - INFO - Iter [5150/60000]	lr: 9.224e-02, eta: 18:17:35, time: 1.127, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1807, decode.acc_seg: 92.3212, aux_0.loss_ce: 0.1806, aux_0.acc_seg: 92.3716, aux_1.loss_ce: 0.1978, aux_1.acc_seg: 91.5680, aux_2.loss_ce: 0.0953, aux_2.loss_dice: 0.2467, aux_2.acc_seg: 97.2352, aux_3.loss_ce: 0.2024, aux_3.acc_seg: 91.2379, loss: 1.1035
2023-05-18 23:46:03,842 - mmseg - INFO - Iter [5200/60000]	lr: 9.217e-02, eta: 18:16:59, time: 1.246, data_time: 0.175, memory: 19944, decode.loss_ce: 0.1692, decode.acc_seg: 92.7697, aux_0.loss_ce: 0.1696, aux_0.acc_seg: 92.8002, aux_1.loss_ce: 0.1864, aux_1.acc_seg: 92.0197, aux_2.loss_ce: 0.0951, aux_2.loss_dice: 0.2489, aux_2.acc_seg: 97.2823, aux_3.loss_ce: 0.1926, aux_3.acc_seg: 91.7215, loss: 1.0618
2023-05-18 23:47:00,497 - mmseg - INFO - Iter [5250/60000]	lr: 9.209e-02, eta: 18:15:23, time: 1.133, data_time: 0.064, memory: 19944, decode.loss_ce: 0.1699, decode.acc_seg: 92.6981, aux_0.loss_ce: 0.1704, aux_0.acc_seg: 92.7477, aux_1.loss_ce: 0.1870, aux_1.acc_seg: 91.9959, aux_2.loss_ce: 0.0929, aux_2.loss_dice: 0.2454, aux_2.acc_seg: 97.3408, aux_3.loss_ce: 0.1871, aux_3.acc_seg: 91.8198, loss: 1.0526
2023-05-18 23:48:02,124 - mmseg - INFO - Iter [5300/60000]	lr: 9.202e-02, eta: 18:14:40, time: 1.233, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1861, decode.acc_seg: 92.0609, aux_0.loss_ce: 0.1868, aux_0.acc_seg: 92.1443, aux_1.loss_ce: 0.2010, aux_1.acc_seg: 91.4427, aux_2.loss_ce: 0.0947, aux_2.loss_dice: 0.2459, aux_2.acc_seg: 97.2553, aux_3.loss_ce: 0.2022, aux_3.acc_seg: 91.3435, loss: 1.1166
2023-05-18 23:48:58,395 - mmseg - INFO - Iter [5350/60000]	lr: 9.194e-02, eta: 18:13:01, time: 1.125, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1714, decode.acc_seg: 92.6654, aux_0.loss_ce: 0.1715, aux_0.acc_seg: 92.7358, aux_1.loss_ce: 0.1862, aux_1.acc_seg: 92.0578, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2466, aux_2.acc_seg: 97.2929, aux_3.loss_ce: 0.1908, aux_3.acc_seg: 91.8462, loss: 1.0601
2023-05-18 23:49:54,567 - mmseg - INFO - Iter [5400/60000]	lr: 9.186e-02, eta: 18:11:23, time: 1.123, data_time: 0.060, memory: 19944, decode.loss_ce: 0.1739, decode.acc_seg: 92.6122, aux_0.loss_ce: 0.1744, aux_0.acc_seg: 92.6608, aux_1.loss_ce: 0.1882, aux_1.acc_seg: 91.9833, aux_2.loss_ce: 0.0943, aux_2.loss_dice: 0.2469, aux_2.acc_seg: 97.2768, aux_3.loss_ce: 0.1922, aux_3.acc_seg: 91.7095, loss: 1.0700
2023-05-18 23:50:56,563 - mmseg - INFO - Iter [5450/60000]	lr: 9.179e-02, eta: 18:10:43, time: 1.240, data_time: 0.170, memory: 19944, decode.loss_ce: 0.1571, decode.acc_seg: 93.2083, aux_0.loss_ce: 0.1571, aux_0.acc_seg: 93.2559, aux_1.loss_ce: 0.1725, aux_1.acc_seg: 92.5220, aux_2.loss_ce: 0.0926, aux_2.loss_dice: 0.2440, aux_2.acc_seg: 97.3352, aux_3.loss_ce: 0.1827, aux_3.acc_seg: 91.9981, loss: 1.0059
2023-05-18 23:51:52,819 - mmseg - INFO - Iter [5500/60000]	lr: 9.171e-02, eta: 18:09:06, time: 1.125, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1634, decode.acc_seg: 92.9656, aux_0.loss_ce: 0.1636, aux_0.acc_seg: 93.0215, aux_1.loss_ce: 0.1801, aux_1.acc_seg: 92.2716, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2447, aux_2.acc_seg: 97.2696, aux_3.loss_ce: 0.1899, aux_3.acc_seg: 91.8130, loss: 1.0359
2023-05-18 23:52:54,381 - mmseg - INFO - Iter [5550/60000]	lr: 9.164e-02, eta: 18:08:22, time: 1.231, data_time: 0.166, memory: 19944, decode.loss_ce: 0.1656, decode.acc_seg: 92.8014, aux_0.loss_ce: 0.1650, aux_0.acc_seg: 92.8735, aux_1.loss_ce: 0.1787, aux_1.acc_seg: 92.1374, aux_2.loss_ce: 0.0934, aux_2.loss_dice: 0.2445, aux_2.acc_seg: 97.3134, aux_3.loss_ce: 0.1838, aux_3.acc_seg: 91.9064, loss: 1.0311
2023-05-18 23:53:50,757 - mmseg - INFO - Iter [5600/60000]	lr: 9.156e-02, eta: 18:06:47, time: 1.128, data_time: 0.062, memory: 19944, decode.loss_ce: 0.1670, decode.acc_seg: 92.7211, aux_0.loss_ce: 0.1678, aux_0.acc_seg: 92.7298, aux_1.loss_ce: 0.1812, aux_1.acc_seg: 92.0903, aux_2.loss_ce: 0.0926, aux_2.loss_dice: 0.2435, aux_2.acc_seg: 97.3109, aux_3.loss_ce: 0.1860, aux_3.acc_seg: 91.9032, loss: 1.0382
2023-05-18 23:54:47,326 - mmseg - INFO - Iter [5650/60000]	lr: 9.149e-02, eta: 18:05:15, time: 1.131, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1751, decode.acc_seg: 92.5199, aux_0.loss_ce: 0.1744, aux_0.acc_seg: 92.5666, aux_1.loss_ce: 0.1904, aux_1.acc_seg: 91.7604, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2436, aux_2.acc_seg: 97.2886, aux_3.loss_ce: 0.1916, aux_3.acc_seg: 91.5526, loss: 1.0688
2023-05-18 23:55:49,195 - mmseg - INFO - Iter [5700/60000]	lr: 9.141e-02, eta: 18:04:34, time: 1.237, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1646, decode.acc_seg: 92.8408, aux_0.loss_ce: 0.1641, aux_0.acc_seg: 92.9006, aux_1.loss_ce: 0.1793, aux_1.acc_seg: 92.1792, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2461, aux_2.acc_seg: 97.3125, aux_3.loss_ce: 0.1900, aux_3.acc_seg: 91.7295, loss: 1.0376
2023-05-18 23:56:45,990 - mmseg - INFO - Iter [5750/60000]	lr: 9.133e-02, eta: 18:03:04, time: 1.136, data_time: 0.066, memory: 19944, decode.loss_ce: 0.1713, decode.acc_seg: 92.6740, aux_0.loss_ce: 0.1695, aux_0.acc_seg: 92.8328, aux_1.loss_ce: 0.1861, aux_1.acc_seg: 92.0363, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2463, aux_2.acc_seg: 97.3279, aux_3.loss_ce: 0.1924, aux_3.acc_seg: 91.6657, loss: 1.0596
2023-05-18 23:57:47,937 - mmseg - INFO - Iter [5800/60000]	lr: 9.126e-02, eta: 18:02:23, time: 1.239, data_time: 0.171, memory: 19944, decode.loss_ce: 0.1598, decode.acc_seg: 93.0007, aux_0.loss_ce: 0.1604, aux_0.acc_seg: 93.0495, aux_1.loss_ce: 0.1769, aux_1.acc_seg: 92.2506, aux_2.loss_ce: 0.0921, aux_2.loss_dice: 0.2432, aux_2.acc_seg: 97.3616, aux_3.loss_ce: 0.1839, aux_3.acc_seg: 91.9016, loss: 1.0164
2023-05-18 23:58:44,592 - mmseg - INFO - Iter [5850/60000]	lr: 9.118e-02, eta: 18:00:53, time: 1.133, data_time: 0.064, memory: 19944, decode.loss_ce: 0.1714, decode.acc_seg: 92.5583, aux_0.loss_ce: 0.1712, aux_0.acc_seg: 92.6195, aux_1.loss_ce: 0.1864, aux_1.acc_seg: 91.8705, aux_2.loss_ce: 0.0929, aux_2.loss_dice: 0.2445, aux_2.acc_seg: 97.3236, aux_3.loss_ce: 0.1938, aux_3.acc_seg: 91.5755, loss: 1.0603
2023-05-18 23:59:41,224 - mmseg - INFO - Iter [5900/60000]	lr: 9.111e-02, eta: 17:59:24, time: 1.133, data_time: 0.063, memory: 19944, decode.loss_ce: 0.1662, decode.acc_seg: 92.6720, aux_0.loss_ce: 0.1671, aux_0.acc_seg: 92.7043, aux_1.loss_ce: 0.1840, aux_1.acc_seg: 91.8972, aux_2.loss_ce: 0.0912, aux_2.loss_dice: 0.2415, aux_2.acc_seg: 97.3743, aux_3.loss_ce: 0.1875, aux_3.acc_seg: 91.6508, loss: 1.0374
2023-05-19 00:00:42,946 - mmseg - INFO - Iter [5950/60000]	lr: 9.103e-02, eta: 17:58:41, time: 1.234, data_time: 0.165, memory: 19944, decode.loss_ce: 0.1565, decode.acc_seg: 93.2211, aux_0.loss_ce: 0.1566, aux_0.acc_seg: 93.2821, aux_1.loss_ce: 0.1734, aux_1.acc_seg: 92.4962, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2448, aux_2.acc_seg: 97.2978, aux_3.loss_ce: 0.1794, aux_3.acc_seg: 92.1639, loss: 1.0040
2023-05-19 00:01:39,541 - mmseg - INFO - Saving checkpoint at 6000 iterations
2023-05-19 00:01:42,885 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-19 00:01:42,885 - mmseg - INFO - Iter [6000/60000]	lr: 9.095e-02, eta: 17:57:42, time: 1.199, data_time: 0.063, memory: 19944, decode.loss_ce: 0.1479, decode.acc_seg: 93.3958, aux_0.loss_ce: 0.1489, aux_0.acc_seg: 93.3951, aux_1.loss_ce: 0.1653, aux_1.acc_seg: 92.6216, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2444, aux_2.acc_seg: 97.2832, aux_3.loss_ce: 0.1751, aux_3.acc_seg: 92.1577, loss: 0.9752
2023-05-19 00:02:18,169 - mmseg - INFO - per class results:
2023-05-19 00:02:18,170 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 95.99 | 98.09 |
|    sidewalk   | 73.67 | 85.38 |
|    building   | 88.56 | 95.04 |
|      wall     |  39.3 | 43.09 |
|     fence     | 46.58 | 73.56 |
|      pole     | 35.51 | 42.63 |
| traffic light | 47.57 |  58.5 |
|  traffic sign | 57.53 | 65.97 |
|   vegetation  | 88.44 | 95.21 |
|    terrain    | 57.62 | 67.79 |
|      sky      | 91.55 | 96.14 |
|     person    | 65.35 | 75.27 |
|     rider     | 43.29 | 72.44 |
|      car      | 90.05 | 93.49 |
|     truck     | 55.11 |  79.5 |
|      bus      | 64.89 | 77.13 |
|     train     | 33.08 | 40.08 |
|   motorcycle  | 42.11 | 48.07 |
|    bicycle    | 62.17 | 72.86 |
+---------------+-------+-------+
2023-05-19 00:02:18,170 - mmseg - INFO - Summary:
2023-05-19 00:02:18,170 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.13 | 62.02 | 72.64 |
+-------+-------+-------+
2023-05-19 00:02:18,228 - mmseg - INFO - The previous best checkpoint /tmp2/linchiayi/mmsegmentation/work_dirs/tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16/best_mIoU_iter_4500.pth was removed
2023-05-19 00:02:19,672 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_6000.pth.
2023-05-19 00:02:19,672 - mmseg - INFO - Best mIoU is 0.6202 at 6000 iter.
2023-05-19 00:02:19,672 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-19 00:02:19,672 - mmseg - INFO - Iter(val) [500]	aAcc: 0.9313, mIoU: 0.6202, mAcc: 0.7264, IoU.road: 0.9599, IoU.sidewalk: 0.7367, IoU.building: 0.8856, IoU.wall: 0.3930, IoU.fence: 0.4658, IoU.pole: 0.3551, IoU.traffic light: 0.4757, IoU.traffic sign: 0.5753, IoU.vegetation: 0.8844, IoU.terrain: 0.5762, IoU.sky: 0.9155, IoU.person: 0.6535, IoU.rider: 0.4329, IoU.car: 0.9005, IoU.truck: 0.5511, IoU.bus: 0.6489, IoU.train: 0.3308, IoU.motorcycle: 0.4211, IoU.bicycle: 0.6217, Acc.road: 0.9809, Acc.sidewalk: 0.8538, Acc.building: 0.9504, Acc.wall: 0.4309, Acc.fence: 0.7356, Acc.pole: 0.4263, Acc.traffic light: 0.5850, Acc.traffic sign: 0.6597, Acc.vegetation: 0.9521, Acc.terrain: 0.6779, Acc.sky: 0.9614, Acc.person: 0.7527, Acc.rider: 0.7244, Acc.car: 0.9349, Acc.truck: 0.7950, Acc.bus: 0.7713, Acc.train: 0.4008, Acc.motorcycle: 0.4807, Acc.bicycle: 0.7286
2023-05-19 00:03:21,958 - mmseg - INFO - Iter [6050/60000]	lr: 9.088e-02, eta: 18:02:31, time: 1.981, data_time: 0.909, memory: 19944, decode.loss_ce: 0.1638, decode.acc_seg: 92.8258, aux_0.loss_ce: 0.1648, aux_0.acc_seg: 92.8448, aux_1.loss_ce: 0.1808, aux_1.acc_seg: 92.1339, aux_2.loss_ce: 0.0934, aux_2.loss_dice: 0.2448, aux_2.acc_seg: 97.2890, aux_3.loss_ce: 0.1824, aux_3.acc_seg: 91.9910, loss: 1.0301
2023-05-19 00:04:18,321 - mmseg - INFO - Iter [6100/60000]	lr: 9.080e-02, eta: 18:00:57, time: 1.127, data_time: 0.061, memory: 19944, decode.loss_ce: 0.1719, decode.acc_seg: 92.7280, aux_0.loss_ce: 0.1699, aux_0.acc_seg: 92.8371, aux_1.loss_ce: 0.1876, aux_1.acc_seg: 92.1026, aux_2.loss_ce: 0.0930, aux_2.loss_dice: 0.2454, aux_2.acc_seg: 97.3384, aux_3.loss_ce: 0.1898, aux_3.acc_seg: 91.8664, loss: 1.0576
2023-05-19 00:05:14,565 - mmseg - INFO - Iter [6150/60000]	lr: 9.073e-02, eta: 17:59:23, time: 1.125, data_time: 0.060, memory: 19944, decode.loss_ce: 0.2742, decode.acc_seg: 88.9589, aux_0.loss_ce: 0.2775, aux_0.acc_seg: 88.8975, aux_1.loss_ce: 0.2881, aux_1.acc_seg: 88.3262, aux_2.loss_ce: 0.0998, aux_2.loss_dice: 0.2581, aux_2.acc_seg: 97.2291, aux_3.loss_ce: 0.2655, aux_3.acc_seg: 88.9790, loss: 1.4632
2023-05-19 00:06:16,026 - mmseg - INFO - Iter [6200/60000]	lr: 9.065e-02, eta: 17:58:34, time: 1.229, data_time: 0.164, memory: 19944, decode.loss_ce: 0.2191, decode.acc_seg: 90.9958, aux_0.loss_ce: 0.2198, aux_0.acc_seg: 90.9712, aux_1.loss_ce: 0.2361, aux_1.acc_seg: 90.1658, aux_2.loss_ce: 0.0966, aux_2.loss_dice: 0.2505, aux_2.acc_seg: 97.2780, aux_3.loss_ce: 0.2273, aux_3.acc_seg: 90.3372, loss: 1.2494
2023-05-19 00:07:12,396 - mmseg - INFO - Iter [6250/60000]	lr: 9.058e-02, eta: 17:57:01, time: 1.127, data_time: 0.062, memory: 19944, decode.loss_ce: 0.1788, decode.acc_seg: 92.3516, aux_0.loss_ce: 0.1782, aux_0.acc_seg: 92.4262, aux_1.loss_ce: 0.1957, aux_1.acc_seg: 91.6520, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 97.2959, aux_3.loss_ce: 0.2011, aux_3.acc_seg: 91.3309, loss: 1.0965
2023-05-19 00:08:14,390 - mmseg - INFO - Iter [6300/60000]	lr: 9.050e-02, eta: 17:56:17, time: 1.240, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1583, decode.acc_seg: 93.0834, aux_0.loss_ce: 0.1589, aux_0.acc_seg: 93.1151, aux_1.loss_ce: 0.1736, aux_1.acc_seg: 92.3973, aux_2.loss_ce: 0.0934, aux_2.loss_dice: 0.2453, aux_2.acc_seg: 97.3211, aux_3.loss_ce: 0.1857, aux_3.acc_seg: 91.8704, loss: 1.0152
2023-05-19 00:09:11,473 - mmseg - INFO - Iter [6350/60000]	lr: 9.042e-02, eta: 17:54:51, time: 1.142, data_time: 0.068, memory: 19944, decode.loss_ce: 0.1688, decode.acc_seg: 92.8254, aux_0.loss_ce: 0.1693, aux_0.acc_seg: 92.8539, aux_1.loss_ce: 0.1858, aux_1.acc_seg: 92.0921, aux_2.loss_ce: 0.0944, aux_2.loss_dice: 0.2486, aux_2.acc_seg: 97.3133, aux_3.loss_ce: 0.1948, aux_3.acc_seg: 91.6835, loss: 1.0616
2023-05-19 00:10:13,395 - mmseg - INFO - Iter [6400/60000]	lr: 9.035e-02, eta: 17:54:07, time: 1.238, data_time: 0.172, memory: 19944, decode.loss_ce: 0.1718, decode.acc_seg: 92.5422, aux_0.loss_ce: 0.1729, aux_0.acc_seg: 92.5636, aux_1.loss_ce: 0.1892, aux_1.acc_seg: 91.7784, aux_2.loss_ce: 0.0936, aux_2.loss_dice: 0.2452, aux_2.acc_seg: 97.3290, aux_3.loss_ce: 0.1942, aux_3.acc_seg: 91.5164, loss: 1.0669
2023-05-19 00:11:10,303 - mmseg - INFO - Iter [6450/60000]	lr: 9.027e-02, eta: 17:52:40, time: 1.138, data_time: 0.067, memory: 19944, decode.loss_ce: 0.1683, decode.acc_seg: 92.8045, aux_0.loss_ce: 0.1690, aux_0.acc_seg: 92.8127, aux_1.loss_ce: 0.1841, aux_1.acc_seg: 92.0998, aux_2.loss_ce: 0.0941, aux_2.loss_dice: 0.2463, aux_2.acc_seg: 97.3054, aux_3.loss_ce: 0.1897, aux_3.acc_seg: 91.7588, loss: 1.0515
2023-05-19 00:12:06,658 - mmseg - INFO - Iter [6500/60000]	lr: 9.020e-02, eta: 17:51:09, time: 1.127, data_time: 0.060, memory: 19944, decode.loss_ce: 0.1743, decode.acc_seg: 92.4779, aux_0.loss_ce: 0.1768, aux_0.acc_seg: 92.4647, aux_1.loss_ce: 0.1930, aux_1.acc_seg: 91.7168, aux_2.loss_ce: 0.0924, aux_2.loss_dice: 0.2445, aux_2.acc_seg: 97.3191, aux_3.loss_ce: 0.1948, aux_3.acc_seg: 91.4916, loss: 1.0758
2023-05-19 00:13:08,825 - mmseg - INFO - Iter [6550/60000]	lr: 9.012e-02, eta: 17:50:26, time: 1.243, data_time: 0.175, memory: 19944, decode.loss_ce: 0.1634, decode.acc_seg: 92.8379, aux_0.loss_ce: 0.1645, aux_0.acc_seg: 92.8579, aux_1.loss_ce: 0.1782, aux_1.acc_seg: 92.1741, aux_2.loss_ce: 0.0901, aux_2.loss_dice: 0.2425, aux_2.acc_seg: 97.4287, aux_3.loss_ce: 0.1825, aux_3.acc_seg: 91.9594, loss: 1.0211
2023-05-19 00:14:05,508 - mmseg - INFO - Iter [6600/60000]	lr: 9.004e-02, eta: 17:48:58, time: 1.134, data_time: 0.064, memory: 19944, decode.loss_ce: 0.1648, decode.acc_seg: 92.7714, aux_0.loss_ce: 0.1645, aux_0.acc_seg: 92.8324, aux_1.loss_ce: 0.1796, aux_1.acc_seg: 92.0859, aux_2.loss_ce: 0.0911, aux_2.loss_dice: 0.2415, aux_2.acc_seg: 97.3839, aux_3.loss_ce: 0.1865, aux_3.acc_seg: 91.7383, loss: 1.0280
2023-05-19 00:15:06,832 - mmseg - INFO - Iter [6650/60000]	lr: 8.997e-02, eta: 17:48:08, time: 1.226, data_time: 0.162, memory: 19944, decode.loss_ce: 0.1868, decode.acc_seg: 92.2466, aux_0.loss_ce: 0.1870, aux_0.acc_seg: 92.2816, aux_1.loss_ce: 0.2034, aux_1.acc_seg: 91.5365, aux_2.loss_ce: 0.0961, aux_2.loss_dice: 0.2480, aux_2.acc_seg: 97.2380, aux_3.loss_ce: 0.1998, aux_3.acc_seg: 91.4978, loss: 1.1211
2023-05-19 00:16:03,027 - mmseg - INFO - Iter [6700/60000]	lr: 8.989e-02, eta: 17:46:38, time: 1.124, data_time: 0.058, memory: 19944, decode.loss_ce: 0.1875, decode.acc_seg: 91.9828, aux_0.loss_ce: 0.1885, aux_0.acc_seg: 91.9785, aux_1.loss_ce: 0.2016, aux_1.acc_seg: 91.3368, aux_2.loss_ce: 0.0949, aux_2.loss_dice: 0.2482, aux_2.acc_seg: 97.2854, aux_3.loss_ce: 0.2069, aux_3.acc_seg: 91.1413, loss: 1.1275
2023-05-19 00:16:59,170 - mmseg - INFO - Iter [6750/60000]	lr: 8.982e-02, eta: 17:45:07, time: 1.123, data_time: 0.057, memory: 19944, decode.loss_ce: 0.2351, decode.acc_seg: 90.2944, aux_0.loss_ce: 0.2334, aux_0.acc_seg: 90.3611, aux_1.loss_ce: 0.2467, aux_1.acc_seg: 89.7738, aux_2.loss_ce: 0.0970, aux_2.loss_dice: 0.2529, aux_2.acc_seg: 97.3687, aux_3.loss_ce: 0.2476, aux_3.acc_seg: 89.5440, loss: 1.3126
2023-05-19 00:18:00,356 - mmseg - INFO - Iter [6800/60000]	lr: 8.974e-02, eta: 17:44:16, time: 1.224, data_time: 0.159, memory: 19944, decode.loss_ce: 0.2080, decode.acc_seg: 91.3204, aux_0.loss_ce: 0.2089, aux_0.acc_seg: 91.3048, aux_1.loss_ce: 0.2209, aux_1.acc_seg: 90.6555, aux_2.loss_ce: 0.0954, aux_2.loss_dice: 0.2498, aux_2.acc_seg: 97.3235, aux_3.loss_ce: 0.2202, aux_3.acc_seg: 90.6054, loss: 1.2030
2023-05-19 00:18:56,980 - mmseg - INFO - Iter [6850/60000]	lr: 8.967e-02, eta: 17:42:50, time: 1.132, data_time: 0.065, memory: 19944, decode.loss_ce: 0.1812, decode.acc_seg: 92.2187, aux_0.loss_ce: 0.1806, aux_0.acc_seg: 92.2668, aux_1.loss_ce: 0.1955, aux_1.acc_seg: 91.5500, aux_2.loss_ce: 0.0958, aux_2.loss_dice: 0.2483, aux_2.acc_seg: 97.2692, aux_3.loss_ce: 0.1985, aux_3.acc_seg: 91.3852, loss: 1.0998
2023-05-19 00:19:58,784 - mmseg - INFO - Iter [6900/60000]	lr: 8.959e-02, eta: 17:42:04, time: 1.236, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1815, decode.acc_seg: 92.0650, aux_0.loss_ce: 0.1820, aux_0.acc_seg: 92.0875, aux_1.loss_ce: 0.1968, aux_1.acc_seg: 91.3477, aux_2.loss_ce: 0.0937, aux_2.loss_dice: 0.2455, aux_2.acc_seg: 97.3245, aux_3.loss_ce: 0.2037, aux_3.acc_seg: 91.0167, loss: 1.1032
2023-05-19 00:20:55,450 - mmseg - INFO - Iter [6950/60000]	lr: 8.951e-02, eta: 17:40:38, time: 1.133, data_time: 0.064, memory: 19944, decode.loss_ce: 0.1661, decode.acc_seg: 92.7454, aux_0.loss_ce: 0.1667, aux_0.acc_seg: 92.7777, aux_1.loss_ce: 0.1819, aux_1.acc_seg: 92.0652, aux_2.loss_ce: 0.0921, aux_2.loss_dice: 0.2447, aux_2.acc_seg: 97.3824, aux_3.loss_ce: 0.1908, aux_3.acc_seg: 91.6727, loss: 1.0423
2023-05-19 00:21:51,844 - mmseg - INFO - Exp name: tuneprompt_stage3_EN_1x24_512x1024_scale0.5_60k_cityscapes_contextlength16.py
2023-05-19 00:21:51,845 - mmseg - INFO - Iter [7000/60000]	lr: 8.944e-02, eta: 17:39:11, time: 1.128, data_time: 0.062, memory: 19944, decode.loss_ce: 0.1763, decode.acc_seg: 92.6060, aux_0.loss_ce: 0.1765, aux_0.acc_seg: 92.6685, aux_1.loss_ce: 0.1919, aux_1.acc_seg: 91.9450, aux_2.loss_ce: 0.0959, aux_2.loss_dice: 0.2493, aux_2.acc_seg: 97.2868, aux_3.loss_ce: 0.1985, aux_3.acc_seg: 91.6459, loss: 1.0883
2023-05-19 00:22:53,798 - mmseg - INFO - Iter [7050/60000]	lr: 8.936e-02, eta: 17:38:26, time: 1.239, data_time: 0.168, memory: 19944, decode.loss_ce: 0.1726, decode.acc_seg: 92.5863, aux_0.loss_ce: 0.1730, aux_0.acc_seg: 92.6270, aux_1.loss_ce: 0.1871, aux_1.acc_seg: 91.9519, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2479, aux_2.acc_seg: 97.3435, aux_3.loss_ce: 0.1967, aux_3.acc_seg: 91.5155, loss: 1.0706
2023-05-19 00:23:50,138 - mmseg - INFO - Iter [7100/60000]	lr: 8.929e-02, eta: 17:36:59, time: 1.127, data_time: 0.059, memory: 19944, decode.loss_ce: 0.1721, decode.acc_seg: 92.5808, aux_0.loss_ce: 0.1723, aux_0.acc_seg: 92.6591, aux_1.loss_ce: 0.1874, aux_1.acc_seg: 91.9079, aux_2.loss_ce: 0.0939, aux_2.loss_dice: 0.2465, aux_2.acc_seg: 97.3080, aux_3.loss_ce: 0.1959, aux_3.acc_seg: 91.5269, loss: 1.0681
2023-05-19 00:24:51,739 - mmseg - INFO - Iter [7150/60000]	lr: 8.921e-02, eta: 17:36:11, time: 1.232, data_time: 0.164, memory: 19944, decode.loss_ce: 0.1615, decode.acc_seg: 92.9676, aux_0.loss_ce: 0.1623, aux_0.acc_seg: 92.9770, aux_1.loss_ce: 0.1790, aux_1.acc_seg: 92.1874, aux_2.loss_ce: 0.0942, aux_2.loss_dice: 0.2465, aux_2.acc_seg: 97.3187, aux_3.loss_ce: 0.1871, aux_3.acc_seg: 91.7877, loss: 1.0306
2023-05-19 00:25:48,009 - mmseg - INFO - Iter [7200/60000]	lr: 8.913e-02, eta: 17:34:44, time: 1.125, data_time: 0.060, memory: 19944, decode.loss_ce: 0.1554, decode.acc_seg: 93.2183, aux_0.loss_ce: 0.1557, aux_0.acc_seg: 93.2705, aux_1.loss_ce: 0.1719, aux_1.acc_seg: 92.5156, aux_2.loss_ce: 0.0933, aux_2.loss_dice: 0.2448, aux_2.acc_seg: 97.2939, aux_3.loss_ce: 0.1817, aux_3.acc_seg: 92.0596, loss: 1.0029
2023-05-19 00:26:44,848 - mmseg - INFO - Iter [7250/60000]	lr: 8.906e-02, eta: 17:33:22, time: 1.137, data_time: 0.067, memory: 19944, decode.loss_ce: 0.1580, decode.acc_seg: 93.2719, aux_0.loss_ce: 0.1574, aux_0.acc_seg: 93.3474, aux_1.loss_ce: 0.1725, aux_1.acc_seg: 92.6611, aux_2.loss_ce: 0.0940, aux_2.loss_dice: 0.2460, aux_2.acc_seg: 97.3029, aux_3.loss_ce: 0.1839, aux_3.acc_seg: 92.1373, loss: 1.0117
2023-05-19 00:27:46,348 - mmseg - INFO - Iter [7300/60000]	lr: 8.898e-02, eta: 17:32:34, time: 1.230, data_time: 0.163, memory: 19944, decode.loss_ce: 0.1656, decode.acc_seg: 92.6939, aux_0.loss_ce: 0.1651, aux_0.acc_seg: 92.7562, aux_1.loss_ce: 0.1807, aux_1.acc_seg: 91.9973, aux_2.loss_ce: 0.0923, aux_2.loss_dice: 0.2436, aux_2.acc_seg: 97.3424, aux_3.loss_ce: 0.1889, aux_3.acc_seg: 91.6270, loss: 1.0361
2023-05-19 00:28:42,765 - mmseg - INFO - Iter [7350/60000]	lr: 8.891e-02, eta: 17:31:09, time: 1.128, data_time: 0.062, memory: 19944, decode.loss_ce: 0.1531, decode.acc_seg: 93.2442, aux_0.loss_ce: 0.1540, aux_0.acc_seg: 93.2534, aux_1.loss_ce: 0.1681, aux_1.acc_seg: 92.5556, aux_2.loss_ce: 0.0932, aux_2.loss_dice: 0.2438, aux_2.acc_seg: 97.2952, aux_3.loss_ce: 0.1818, aux_3.acc_seg: 91.9873, loss: 0.9940
